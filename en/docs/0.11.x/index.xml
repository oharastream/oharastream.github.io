<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Overview | OharaStream</title>
    <link>https://oharastream.github.io/en/docs/0.11.x/</link>
      <atom:link href="https://oharastream.github.io/en/docs/0.11.x/index.xml" rel="self" type="application/rss+xml" />
    <description>Overview</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sun, 09 Sep 2018 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://oharastream.github.io/images/icon_huf5f81cd12511c4e8b7f06b033f435f0f_18329_512x512_fill_lanczos_center_2.png</url>
      <title>Overview</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/</link>
    </image>
    
    <item>
      <title>How to build Quickstart VM</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/build/build-quickstart-vm/</link>
      <pubDate>Mon, 15 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/build/build-quickstart-vm/</guid>
      <description>&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Operation system: Linux&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://en.wikipedia.org/wiki/Make_%28software%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Make&lt;/a&gt;: Make is a
build automation tool that automatically builds executable programs.
&lt;strong&gt;Make&lt;/strong&gt; is already built in Linux or macOS.&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://www.packer.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Packer&lt;/a&gt; 1.4+: Packer is an open source tool
for creating identical machine images for multiple platforms from a
single source configuration.&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://www.virtualbox.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VirtualBox&lt;/a&gt; 6.0+&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;build-ova-file&#34;&gt;Build OVA file&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;We use &lt;strong&gt;make&lt;/strong&gt; command to execute all our tasks. For building the
specific version of Ohara quickstart VM, you must provide the
argument &lt;strong&gt;OHARA_VER&lt;/strong&gt; when execute the &lt;strong&gt;make&lt;/strong&gt; command.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Build the OVA file, following is an example(OHARA_VER=0.7.1):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;[quickstart]$ cd vm
[vm]$ make OHARA_VER=0.7.1 ova
OHARA_VER=0.7.1
Build time: 2019/09/10 10:10
Start building quickstart VM ova file...
virtualbox-iso output will be in this color.

==&amp;gt; virtualbox-iso: Retrieving ISO
==&amp;gt; virtualbox-iso: Trying .cache/ubuntu-18.04.3-server-amd64.iso
==&amp;gt; virtualbox-iso: Trying .cache/ubuntu-18.04.3-server-amd64.iso?checksum=sha256%3A7d8e0055d663bffa27c1718685085626cb59346e7626ba3d3f476322271f573e
==&amp;gt; virtualbox-iso: .cache/ubuntu-18.04.3-server-amd64.iso?checksum=sha256%3A7d8e0055d663bffa27c1718685085626cb59346e7626ba3d3f476322271f573e =&amp;gt; /your/project/path/ohara/vms/quickstart/.cache/packer_cache/fdcf467e727a368c2aac26ac2284f0f517dc29fb.iso
==&amp;gt; virtualbox-iso: Starting HTTP server on port 8251
==&amp;gt; virtualbox-iso: Creating virtual machine...
==&amp;gt; virtualbox-iso: Creating hard drive...
==&amp;gt; virtualbox-iso: Creating forwarded port mapping for communicator (SSH, WinRM, etc) (host port 3248)
==&amp;gt; virtualbox-iso: Executing custom VBoxManage commands...
:   :   :   :
(SKIP)
:   :   :   :
==&amp;gt; virtualbox-iso: Gracefully halting virtual machine...
==&amp;gt; virtualbox-iso: Preparing to export machine...
    virtualbox-iso: Deleting forwarded port mapping for the communicator (SSH, WinRM, etc) (host port 3248)
==&amp;gt; virtualbox-iso: Exporting virtual machine...
    virtualbox-iso: Executing: export ohara-quickstart-0.7.1 --output build/ohara-quickstart-0.7.1.ova
==&amp;gt; virtualbox-iso: Deregistering and deleting VM...
Build &#39;virtualbox-iso&#39; finished.

==&amp;gt; Builds finished. The artifacts of successful builds are:
--&amp;gt; virtualbox-iso: VM files in directory: build
Done.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The OVA file will be output to: build/ohara-quickstart-{OHARA_VER}.ova&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;Currently, we use Ubuntu 18.04.03 LTS as Quickstart VM&amp;rsquo;s operation
system. Packer will try to find the ubuntu iso file in the
&lt;strong&gt;quickstart/.cache&lt;/strong&gt; folder first, and then download the &lt;a href=&#34;http://cdimage.ubuntu.com/ubuntu/releases/bionic/release/ubuntu-18.04.3-server-amd64.iso&#34;&gt;Ubuntu iso
file&lt;/a&gt;
from internet if the iso file not be found in the cache folder.&lt;/p&gt;
&lt;p&gt;To save your building time, you can download the &lt;a href=&#34;http://cdimage.ubuntu.com/ubuntu/releases/bionic/release/ubuntu-18.04.3-server-amd64.iso&#34;&gt;Ubuntu iso
file&lt;/a&gt;
manually and put into &lt;strong&gt;quickstart/.cache&lt;/strong&gt; folder.&lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;import-ova&#34;&gt;Import OVA&lt;/h2&gt;
&lt;p&gt;After generated the quickstart ova file, you can use VirtualBox user
interface to import the OVA file(&lt;strong&gt;File -&amp;gt; Import Appliance&lt;/strong&gt;) or use
following command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;[vm]$ make OHARA_VER=0.7.1 vm-import
vboxmanage import build/ohara-quickstart-0.7.1.ova --vsys 0 --vmname ohara-quickstart-0.7.1
0%...10%...20%...30%...40%...50%...60%...70%...80%...90%...100%
Interpreting /your/project/path/ohara/vms/quickstart/build/ohara-quickstart-0.7.1.ova...
OK.
Disks:
  vmdisk1       85899345920     -1      http://www.vmware.com/interfaces/specifications/vmdk.html#streamOptimized       ohara-quickstart-0.7.1-disk001.vmdk -1      -1

Virtual system 0:
 0: Suggested OS type: &amp;quot;Ubuntu_64&amp;quot;
    (change with &amp;quot;--vsys 0 --ostype &amp;lt;type&amp;gt;&amp;quot;; use &amp;quot;list ostypes&amp;quot; to list all possible values)
 1: VM name specified with --vmname: &amp;quot;ohara-quickstart-0.7.1&amp;quot;
 2: Description &amp;quot;Ohara Quickstart VM
Ohara version: 0.7.1
Build time: 2019/09/10 10:10&amp;quot;
    (change with &amp;quot;--vsys 0 --description &amp;lt;desc&amp;gt;&amp;quot;)
 3: Number of CPUs: 2
    (change with &amp;quot;--vsys 0 --cpus &amp;lt;n&amp;gt;&amp;quot;)
 4: Guest memory: 4096 MB
    (change with &amp;quot;--vsys 0 --memory &amp;lt;MB&amp;gt;&amp;quot;)
 5: Network adapter: orig NAT, config 3, extra slot=0;type=NAT
 6: Network adapter: orig HostOnly, config 3, extra slot=1;type=HostOnly
 7: IDE controller, type PIIX4
    (disable with &amp;quot;--vsys 0 --unit 7 --ignore&amp;quot;)
 8: IDE controller, type PIIX4
    (disable with &amp;quot;--vsys 0 --unit 8 --ignore&amp;quot;)
 9: Hard disk image: source image=ohara-quickstart-0.7.1-disk001.vmdk, target path=/home/xxxx/VirtualBox VMs/ohara-quickstart-0.7.1/ohara-quickstart-0.7.1-disk001.vmdk, controller=7;channel=0
    (change target path with &amp;quot;--vsys 0 --unit 9 --disk path&amp;quot;;
    disable with &amp;quot;--vsys 0 --unit 9 --ignore&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;use-quickstart-vm&#34;&gt;Use Quickstart VM&lt;/h2&gt;
&lt;p&gt;After import quickstart VM to VirtualBox, you can press &lt;strong&gt;Start&lt;/strong&gt; button
to start the VM. And then you can see following screen:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;Ubuntu 10.04.03 LTS ohara-vm tty1
ohara-vm login:
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Please use &lt;code&gt;ohara&lt;/code&gt; as login account and &lt;code&gt;oharastream&lt;/code&gt; as password to
login to VM. If this is your first time to login Quickstart VM, the
progress of pull Ohara docker images will be starting automatically. So
please make sure your machine can connect to Internet.&lt;/p&gt;
&lt;p&gt;After download the images, and then you can see the ip address info of
the VM, for example:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;IP address info:
lo              UNKNOWN         127.0.0.1/8 ::1/128
enp0s3          UP              10.0.2.15/24 fe80::a00:27ff:feac:ad8a/64
enp0s8          UP              192.168.56.114/24 fe80::a00:27ff:fe09:1a1e/64
docker0         DOWN            172.17.0.1/16
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can find the private IP address &lt;strong&gt;192.168.56.114&lt;/strong&gt; (enp0s8) in the
above list. So the configurator ip address is &lt;strong&gt;192.168.56.114&lt;/strong&gt; .&lt;/p&gt;
&lt;p&gt;Run Ohara configurator(port 12345):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ./ohara-configurator.sh
docker run --rm -p 12345:12345 -d oharastream/configurator:0.7.1 --port 12345
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Run Ohara manager(port 5050), provide the configurator ip address as parameter:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ./ohara-manager.sh 192.168.56.114
docker run --rm -p 5050:5050 -d oharastream/manager:0.7.1 --port 5050 --configurator http://192.168.56.114:12345/v0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now you can open your browser and input the link:
&lt;a href=&#34;http://192.168.56.114:5050&#34;&gt;http://192.168.56.114:5050&lt;/a&gt; to open the main page of Ohara Manager.&lt;/p&gt;
&lt;h2 id=&#34;commands&#34;&gt;commands&lt;/h2&gt;
&lt;p&gt;Following are other commands for development purpose:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;[vm]$ make OHARA_VER=0.7.1
Usage:
  $ make OHARA_VER={version} {command}
  Both {version} and {command} is required.
Command:
  clean: Remove following files:
         build/, .cache/packer_cache/, .cache/packer.log
  ova: Generate the OVA file.
       The output is build/ohara-quickstart-{OHARA_VER}.ova
  vm-import: Import the ova file into VirtualBox
  vm-start: Start quickstart VM
  vm-poweroff: Poweroff quickstart VM
  vm-reset: Reset quickstart VM
  vm-delete: Unregister &amp;amp; delete quickstart VM
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Using Quickstart VM</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/quickstart/quickstartvm/</link>
      <pubDate>Mon, 15 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/quickstart/quickstartvm/</guid>
      <description>&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;OS: Windows / Linux / MacOS&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.virtualbox.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VirtualBox 6.0+&lt;/a&gt;: Oracle VM VirtualBox, is a free and open-source virtual machine.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://github.com/oharastream/ohara-quickstart/releases&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ohara Quickstart VM image&lt;/a&gt;:
An OVA (Open Virtual Appliance) file, a pre-prepared virtual machine image for Ohara quickstart.
You can download the image file (.ova) from the 
&lt;a href=&#34;https://github.com/oharastream/ohara-quickstart/releases/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;release&lt;/a&gt; page.&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/download_assets.png&#34; &gt;


  &lt;img src=&#34;../img/download_assets.png&#34; alt=&#34;Release asserts&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Please download the VirtualBox from &lt;a href=&#34;https://www.virtualbox.org/wiki/Downloads&#34;&gt;here&lt;/a&gt;,
and reference &lt;a href=&#34;https://www.virtualbox.org/manual/ch02.html&#34;&gt;this article&lt;/a&gt; on how to install it on your machine.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    You might have noticed there&amp;rsquo;s another jar file listed in the screenshot: &amp;ldquo;ohara-it-stream.jar&amp;rdquo;.
It&amp;rsquo;s a stream jar that could be used later in our tutorial where we walks you through how to use our UI.
And download it if you would like to follow along with our tutorial later on.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;
&lt;h3 id=&#34;import-vm-and-setup-network-adapter&#34;&gt;Import VM and setup network adapter&lt;/h3&gt;
&lt;p&gt;You can use VirtualBox user interface to import the Ohara Quickstart VM (ova file):
&lt;span class=&#34;markup-quote&#34;&gt;&lt;strong&gt;&lt;em&gt;Main menu&lt;/em&gt;&lt;/strong&gt; -&amp;gt; &lt;strong&gt;&lt;em&gt;File&lt;/em&gt;&lt;/strong&gt; -&amp;gt; &lt;strong&gt;&lt;em&gt;Import Appliance&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Quickstart VM requires a &lt;strong&gt;Host-only network adapter&lt;/strong&gt; to be configured so that you can
connect from the host machine to guest machine (Quickstart VM).&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Quickstart VM uses network adapter &lt;code&gt;vboxnet0&lt;/code&gt; with DHCP Server enabled as &lt;strong&gt;default Host-only adapter&lt;/strong&gt;,
if there is already a &lt;code&gt;vboxnet0&lt;/code&gt; adapter in your VirtualBox, you can just skip this step.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;for-maclinux&#34;&gt;for Mac/Linux&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create new network adapter &amp;mdash; Click &lt;strong&gt;Tools&lt;/strong&gt; and then click &lt;strong&gt;Create&lt;/strong&gt;,
ensure that the DHCP Enable option is checked.















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/mac_add_network.jpg&#34; &gt;


  &lt;img data-src=&#34;../img/mac_add_network.jpg&#34; class=&#34;lazyload&#34; alt=&#34;macos/linux - Create network adapter&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Setting network adapter &amp;mdash; Select the imported &lt;strong&gt;ohara-quickstart-x.x.x&lt;/strong&gt; VM,
click &lt;strong&gt;Setting&lt;/strong&gt;, then click &lt;strong&gt;Network&lt;/strong&gt;, and click &lt;strong&gt;Adapter2&lt;/strong&gt;,
select &lt;strong&gt;Host-only Adapter&lt;/strong&gt;, and select the newly added network card.















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/mac_setting_network.png&#34; &gt;


  &lt;img data-src=&#34;../img/mac_setting_network.png&#34; class=&#34;lazyload&#34; alt=&#34;macos/linux - Setting VM&amp;#39;s network adapter&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;for-windows&#34;&gt;for Windows&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create new network adapter &amp;mdash; Click &lt;strong&gt;Global Tools&lt;/strong&gt; and then click &lt;strong&gt;Create&lt;/strong&gt;,
ensure that the DHCP Enable option is checked.















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/win_add_network.png&#34; &gt;


  &lt;img data-src=&#34;../img/win_add_network.png&#34; class=&#34;lazyload&#34; alt=&#34;Windows - Create network adapter&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Setting network adapter &amp;mdash; Select the imported &lt;strong&gt;ohara-quickstart-x.x.x&lt;/strong&gt; VM,
click &lt;strong&gt;Setting&lt;/strong&gt;, click &lt;strong&gt;Network&lt;/strong&gt;, click &lt;strong&gt;Adapter2&lt;/strong&gt;,
select &lt;strong&gt;Host-only Adapter&lt;/strong&gt;, and select the newly added network card.















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/win_setting_network.png&#34; &gt;


  &lt;img data-src=&#34;../img/win_setting_network.png&#34; class=&#34;lazyload&#34; alt=&#34;Windows - Setting VM&amp;#39;s network adapter&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;install-ohara&#34;&gt;Install Ohara&lt;/h3&gt;
&lt;p&gt;Once the Quickstart VM is imported and the network adapter is configured, you can press
the &lt;strong&gt;Start&lt;/strong&gt; button to start Quickstart VM and then use the following username and password to log into the system:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Username: &lt;em&gt;ohara&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Password: &lt;em&gt;oharastream&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The installation will be starting automatically if this is your first time log in to the system.
This step will take some time to complete as it needs to download all Ohara docker images.&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/vm_ohara_install_1.png&#34; &gt;


  &lt;img data-src=&#34;../img/vm_ohara_install_1.png&#34; class=&#34;lazyload&#34; alt=&#34;VM is pulling down images from Docker Hub&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/vm_ohara_install_2.png&#34; &gt;


  &lt;img data-src=&#34;../img/vm_ohara_install_2.png&#34; class=&#34;lazyload&#34; alt=&#34;Finishing the setup&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;After the installation is completed, you should see something like the following:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;&amp;gt; Start ohara-configurator...
74e0a19a063ce665a0bafba215827d6edd47b9433efdf26af9880d0b4f5e3737

&amp;gt; Start ohara-manager...

ecc6e2845f55b52c6a2ec4b2a203d249f117394cbc16c5387aa067ee5d02a096
&amp;gt; Ohara ready on http://192.168.56.102:5050

ohara@ohara-vm:~$
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we can see here, the VM&amp;rsquo;s IP address is &lt;code&gt;192.168.56.102&lt;/code&gt;
(this address will be varied depending on your VirtualBox network settings).
We can then open the browser and enter this URL in browser&amp;rsquo;s address bar
&lt;code&gt;http://192.168.56.102:5050&lt;/code&gt; to open Ohara Manager (Ohara&amp;rsquo;s UI, we will
introduce it in the following section).&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    After shutting down your VM, the docker containers will be deleted and restarted on your next login
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;terminology&#34;&gt;Terminology&lt;/h2&gt;
&lt;p&gt;Before jumping into the UI and create our very first workspace and pipeline.
Let&amp;rsquo;s get to know some of the terms that we will be using throughout this guide.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Manager&lt;/p&gt;
&lt;p&gt;Manager is the user interface of Ohara (UI). It provides a friendly user interface allowing user to design their data
pipeline without even touching a single line of code.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Node&lt;/p&gt;
&lt;p&gt;Node is the basic unit of running service. It can be either a physical server or virtual machine.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Workspace&lt;/p&gt;
&lt;p&gt;Workspace contains multiple OharaStream services including: Zookeepers, Brokers and Workers.
And pipelines are services that run in a workspace.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pipeline&lt;/p&gt;
&lt;p&gt;Pipeline allows you to define your data stream by utilizing &lt;strong&gt;Connector&lt;/strong&gt; to connect to
external storage systems, as well as a &lt;strong&gt;Stream&lt;/strong&gt; to customize data transformation and stream processing.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Connector&lt;/p&gt;
&lt;p&gt;Connector connects to external storage systems like Databases, HDFS or FTP.
It has two types &amp;mdash; source connector and sink connector.
Source connector is able to pull data from another system and then push the data to topic.
By contrast, Sink connector pulls data from topic and then push the data to another system.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Stream&lt;/p&gt;
&lt;p&gt;Stream is powered by 
&lt;a href=&#34;https://kafka.apache.org/documentation/streams/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kafka Streams&lt;/a&gt; which
provides users a simple way to write their own stream processing application.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Topic&lt;/p&gt;
&lt;p&gt;A topic is a place where all the data are written just like a database table where data is stored. It acts like a buffer, the data being pull in from the source connector is stored in the topic and so later can be pulled out again by another component (e.g., sink connectors)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ui-overview&#34;&gt;UI overview&lt;/h2&gt;
&lt;p&gt;Before we proceed, here is a screenshot of &lt;strong&gt;Ohara Manager&lt;/strong&gt; where we show you each component&amp;rsquo;s name, so you are better prepared for the upcoming tutorial. You can always come back to this overview if you are lost or not sure what we&amp;rsquo;re talking about in the tutorial.&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ui-overview.png&#34; &gt;


  &lt;img data-src=&#34;../img/ui-overview.png&#34; class=&#34;lazyload&#34; alt=&#34;UI overview&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    We do our best to make our docs as clear as we could, if you think there&amp;rsquo;s still room for improvement.
We would love to hear from you: &lt;a href=&#34;https://github.com/oharastream/ohara/issues&#34;&gt;https://github.com/oharastream/ohara/issues&lt;/a&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Now, Ohara Manager is up and running, we can use the UI to create our very first pipeline.
Here are the steps that we will be going through together:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Create a workspace&lt;/li&gt;
&lt;li&gt;Create a pipeline&lt;/li&gt;
&lt;li&gt;Add pipeline components, this includes:
&lt;ul&gt;
&lt;li&gt;A FTP source and a sink connector&lt;/li&gt;
&lt;li&gt;Two topics&lt;/li&gt;
&lt;li&gt;A stream&lt;/li&gt;
&lt;li&gt;Create connections between them&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Start the pipeline&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    During the tutorial, we will be using FTP source/sink connectors. And so you will need to prepare your own FTP in order to follow along.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;create-a-workspace&#34;&gt;Create a workspace&lt;/h2&gt;
&lt;p&gt;Open Ohara Manager with your browser (http://192.168.56.102:5050) and you should see a dialog
showing up right in the middle of your screen:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Click on the &lt;strong&gt;QUICK CREATE&lt;/strong&gt; button to open a new dialog















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/intro-dialog.png&#34; &gt;


  &lt;img data-src=&#34;../img/intro-dialog.png&#34; class=&#34;lazyload&#34; alt=&#34;Intro dialog&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Using the default name: &lt;em&gt;workspace1&lt;/em&gt; and hit the &lt;strong&gt;NEXT&lt;/strong&gt; button















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/quick-create-workspace-name.png&#34; &gt;


  &lt;img data-src=&#34;../img/quick-create-workspace-name.png&#34; class=&#34;lazyload&#34; alt=&#34;Quick create workspace new name&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Click on the Select nodes and click on the pencil icon to create a new node.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/quick-create-workspace-node.png&#34; &gt;


  &lt;img data-src=&#34;../img/quick-create-workspace-node.png&#34; class=&#34;lazyload&#34; alt=&#34;Quick create workspace new node&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/quick-create-workspace-add-node.png&#34; &gt;


  &lt;img data-src=&#34;../img/quick-create-workspace-add-node.png&#34; class=&#34;lazyload&#34; alt=&#34;Quick create workspace add node icon&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The node info that you need to enter are listed below:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hostname: &lt;em&gt;192.168.56.102&lt;/em&gt; (fill your own hostname here)&lt;/li&gt;
&lt;li&gt;Port: &lt;em&gt;22&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;User: &lt;em&gt;ohara&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Password: &lt;em&gt;oharastream&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/quick-create-workspace-add-node.png&#34; &gt;


  &lt;img data-src=&#34;../img/quick-create-workspace-add-node.png&#34; class=&#34;lazyload&#34; alt=&#34;Quick create workspace add a new node&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;The node should be added into the list. Select the node and click on the SAVE button to close the dialog&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/quick-create-workspace-select-node.png&#34; &gt;


  &lt;img data-src=&#34;../img/quick-create-workspace-select-node.png&#34; class=&#34;lazyload&#34; alt=&#34;Quick create workspace select node&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;Now, click the &lt;strong&gt;NEXT&lt;/strong&gt; button to finish selecting nodes&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/quick-create-workspace-node-summary.png&#34; &gt;


  &lt;img data-src=&#34;../img/quick-create-workspace-node-summary.png&#34; class=&#34;lazyload&#34; alt=&#34;Quick create workspace node summary&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;Click on the &lt;strong&gt;SUBMIT&lt;/strong&gt; button to create this workspace.&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/quick-create-workspace-summary.png&#34; &gt;


  &lt;img data-src=&#34;../img/quick-create-workspace-summary.png&#34; class=&#34;lazyload&#34; alt=&#34;Quick create workspace summary&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;A new dialog will open where it shows you the creating progress. This usually takes a while to finish. Once it&amp;rsquo;s done, You can close the dialog by clicking on the CLOSE button. And the UI will automatically redirect you to the newly created workspace: &lt;em&gt;Workspace1&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/quick-create-workspace-progress.png&#34; &gt;


  &lt;img data-src=&#34;../img/quick-create-workspace-progress.png&#34; class=&#34;lazyload&#34; alt=&#34;Quick create workspace creating progress&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/quick-create-workspace-done.png&#34; &gt;


  &lt;img data-src=&#34;../img/quick-create-workspace-done.png&#34; class=&#34;lazyload&#34; alt=&#34;Quick create workspace done&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    You can create more workspace with the plus icon(:heavy_plus_sign:) in the App bar.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;div&gt;
    Please keep in mind that this is a quick start VM where we run everything on a single node
with only 8GB of RAM and 2 CPU cores. We highly recommend you to add more RAM and CPU
core to your VM if you plan to create more than one workspace or lots of pipelines, connectors,
streams, etc. This is due to when Ohara is running without enough resources, it could be very
unstable and causing unexpected errors.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;create-a-pipeline&#34;&gt;Create a pipeline&lt;/h2&gt;
&lt;p&gt;Create a pipeline is fairly simple:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;On the Navigator, click on the plus icon.&lt;/li&gt;
&lt;li&gt;In the popup window, enter the name: pipeline1 and click the &lt;strong&gt;ADD&lt;/strong&gt; button















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-a-pipeline.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-a-pipeline.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a pipeline&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;The new pipeline will be added into the workspace and listed in the Navigator.
And just like creating workspace, you will be redirected to the pipeline you just created.















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-a-pipeline-done.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-a-pipeline-done.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a pipeline done&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;add-pipeline-components&#34;&gt;Add pipeline components&lt;/h3&gt;
&lt;p&gt;Since workspace and pipeline are both ready. We can now add new components into the pipeline.
The pipeline connection we&amp;rsquo;re about to create will look like:
&lt;code&gt;FTP source -&amp;gt; topic -&amp;gt; stream -&amp;gt; topic -&amp;gt; FTP sink&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Before we start, please make sure your FTP service is ready and let&amp;rsquo;s get started!&lt;/p&gt;
&lt;h4 id=&#34;drag-and-drop-new-pipeline-components&#34;&gt;Drag and drop new pipeline components&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;FTP source:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;From the Toolbox (Please refer to the overview image for what is Toolbox if needed)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Click on the title &amp;ldquo;Source&amp;rdquo;, the panel will be expanded and display all available source connectors















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ftpsource-add-toolbox.png&#34; &gt;


  &lt;img data-src=&#34;../img/ftpsource-add-toolbox.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a FTP source from Toolbox&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Drag the &amp;ldquo;FtpSource&amp;rdquo; from the list and drop into the Paper (Don&amp;rsquo;t worry about the position just yet. This can be changed later after it&amp;rsquo;s added into the Paper). A prompt will be asking you about the connector name, let&amp;rsquo;s name it &amp;ldquo;ftpsource&amp;rdquo; and click the ADD button.















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ftpsource-add-name.png&#34; &gt;


  &lt;img data-src=&#34;../img/ftpsource-add-name.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a FTP source name&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The FTP source connector should display in the Paper:















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ftpsource-add-done.png&#34; &gt;


  &lt;img data-src=&#34;../img/ftpsource-add-done.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a FTP source name done&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Now, hover over the Ftp source connector, a couple of buttons will show up. These are action buttons, let&amp;rsquo;s take a quick look and see what can we do with them (starting from left to right):















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ftpsource-add-action-buttons.png&#34; &gt;


  &lt;img data-src=&#34;../img/ftpsource-add-action-buttons.png&#34; class=&#34;lazyload&#34; alt=&#34;Action buttons&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Link&lt;/strong&gt;: create a new link, once a link is created you can move your mouse and the link will follow along your mouse position. To link to another component, you can hover over it and do a mouse left-click. To cancel the link creation, just click on the blank area within the Paper.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Start&lt;/strong&gt;: start a component. Once the component is properly configured, you can then use this button to start the component.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stop&lt;/strong&gt;: stop a running or failed component&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Configure&lt;/strong&gt;: open the Property dialog and fill out necessary configuration for the component.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Delete&lt;/strong&gt;: delete the selected component.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    A &lt;strong&gt;Link&lt;/strong&gt; can also be interacted with. You can remove it by clicking on the &amp;ldquo;x&amp;rdquo; button.
And click on any point of the link creates a vertex. The vertex can be moved and tweaked to change its position.
You can also delete a vertex by double clicking on it.
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Okay, that&amp;rsquo;s enough of these button things. Let&amp;rsquo;s click on the &amp;ldquo;configure&amp;rdquo; icon (a wrench) and fill in the following fields (Note that you need to use your own settings, and create completed, error, input and output directories on your own FTP service). For fields that we did not mention below, the default is used:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Completed Folder: &lt;em&gt;demo/completed&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Error Folder: &lt;em&gt;demo/error&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Hostname of FTP Server: &lt;em&gt;10.2.0.28&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Port of FTP Server: &lt;em&gt;21&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;User of FTP Server: &lt;em&gt;ohara&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Password of FTP Server: &lt;em&gt;oharastream&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Input Folder: &lt;em&gt;demo/input&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once these settings had been filled out, click on the &lt;strong&gt;SAVE CHANGES&lt;/strong&gt; button.















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ftpsource-add-config.png&#34; &gt;


  &lt;img data-src=&#34;../img/ftpsource-add-config.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a FTP source configuration&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    There are validation rules which will prevent you from submitting the form without filling require fields.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;FTP sink:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Just like FTP source connector, let&amp;rsquo;s drag and drop a FTP sink connector from the Toolbox and name it &amp;ldquo;ftpsink&amp;rdquo;.
After it&amp;rsquo;s added in the Paper, click on its &amp;ldquo;configure&amp;rdquo; button. The settings are mostly like FTP source with the only exception: &amp;ldquo;output&amp;rdquo;:&lt;/p&gt;
&lt;p&gt;














&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ftpsink-add-toolbox.png&#34; &gt;


  &lt;img data-src=&#34;../img/ftpsink-add-toolbox.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a FTP sink&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ftpsink-config.png&#34; &gt;


  &lt;img data-src=&#34;../img/ftpsink-config.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a FTP sink configuration&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hostname of FTP Server: &lt;em&gt;10.2.0.28&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Port of FTP Server: &lt;em&gt;21&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;User of FTP Server: &lt;em&gt;ohara&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Password of FTP Server: &lt;em&gt;oharastream&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Output Folder: &lt;em&gt;demo/output&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Great! Now we have both source and sink connectors ready. Let&amp;rsquo;s move on to create some topics.&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ftpsink-add-done.png&#34; &gt;


  &lt;img data-src=&#34;../img/ftpsink-add-done.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a FTP sink done&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;Topic:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In this tutorial, we need two topics for the pipeline, let&amp;rsquo;s add them from the Toolbox like what we did in the previous steps for FTP connectors:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;From the Toolbox, click on the title &amp;ldquo;Topic&amp;rdquo; to expand the topic panel.















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/topic-add-toolbox.png&#34; &gt;


  &lt;img data-src=&#34;../img/topic-add-toolbox.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a topic from Toolbox&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Click and drag &amp;ldquo;Pipeline Only&amp;rdquo; item from the list and drop it into the Paper to add a new Topic. Unlike source or sink connector, adding a topic doesn&amp;rsquo;t require entering a name, the name will be auto-generated like (T1, T2, T3, etc.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Repeat the above step to create another Topic. You should now have two topics (T1, T2) in your Paper in addition to those FTP connectors:&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/topic-add-done.png&#34; &gt;


  &lt;img data-src=&#34;../img/topic-add-done.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a topic done&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;And luckily, there&amp;rsquo;s no need to configure these topics as they&amp;rsquo;re preconfigured and already running after you added.&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    In Ohara, topics can either be a &amp;ldquo;Pipeline-only topic&amp;rdquo; or a &amp;ldquo;Shared topic&amp;rdquo;.
The pipeline-only topics are topics that only live within a pipeline.
And on the other hand, shared topics can be shared and used across different pipelines.
For simplicity sake, we only use pipeline-only topics throughout this tutorial.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    For quickly creating a new pipeline-only topic, you can also just add a source and a sink (or stream) connector and
then link them together with the &amp;ldquo;Link&amp;rdquo; button from the source connector component.
The pipeline-only topic will be created automatically.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Stream:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Stream is our last missing piece of the pipeline. Let&amp;rsquo;s add one very quick!&lt;/p&gt;
&lt;p&gt;Remember the 
&lt;a href=&#34;https://github.com/oharastream/ohara-quickstart/releases&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;stream jar&lt;/a&gt; you downloaded
along with the quickstart image? It&amp;rsquo;s time to use it:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Click on the &amp;ldquo;Stream&amp;rdquo; panel on the Toolbox and then click on the &amp;ldquo;Add streams&amp;rdquo; button&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-toolbox-upload.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-toolbox-upload.png&#34; class=&#34;lazyload&#34; alt=&#34;Upload a stream&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;It will open workspace settings and redirect you to the stream jars page:&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-page.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-page.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream settings page&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;Click on the plus icon to open select file dialog:&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-select-icon.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-select-icon.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream select file icon&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;The workspace file list are currently empty, let&amp;rsquo;s add a new file by clicking on the upload icon. This will open your OS file system, you can then select the stream jar file you downloaded. The stream class will be loaded and displayed in the list:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;














&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-upload-icon.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-upload-icon.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream upload icon&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-upload-done.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-upload-done.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream select file upload done&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Select the stream and click on the SAVE button to close select file dialog&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-list.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-list.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream list&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;The stream file should now listed in your Stream Jars page. Close this page by clicking on the close button on the upper-right corner&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-list-done.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-list-done.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream list done&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;Adding a stream is just like connector and topic, drag the &amp;ldquo;DumbStream&amp;rdquo; item from the Toolbox and drop it into the Paper and give a name &amp;ldquo;stream&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-name.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-name.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream name&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;Now let&amp;rsquo;s work through the configuration together. Hover over the stream component and click on the &amp;ldquo;Configure&amp;rdquo; button to open the configure dialog&lt;/li&gt;
&lt;li&gt;Fill out the form with the following settings and click the &amp;ldquo;&lt;strong&gt;SAVE CHANGES&lt;/strong&gt;&amp;rdquo; button:
&lt;ul&gt;
&lt;li&gt;header name to be filtered: &lt;em&gt;&amp;ldquo;Sex&amp;rdquo;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;column value to be filtered: &lt;em&gt;&amp;ldquo;M&amp;rdquo;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Node name list: &lt;em&gt;192.168.56.111&lt;/em&gt; (you should use you own IP)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-dialog.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-dialog.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream dialog&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    This stream is capable of filtering out columns and values that we specified and then push
the new result to a topic. Here we&amp;rsquo;re specifically setting the &amp;ldquo;Sex&amp;rdquo; as the filtered header
and &amp;ldquo;M&amp;rdquo; as the filtered value (stands for Man) and so our output data will only &amp;ldquo;include&amp;rdquo;
data that contains &amp;ldquo;M&amp;rdquo; value in the &amp;ldquo;Sex&amp;rdquo; column. We will verify the result later in the tutorial.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Everything is ready. We can now create the connection like we mentioned earlier:
&lt;code&gt;FTP source -&amp;gt; topic -&amp;gt; stream -&amp;gt; topic -&amp;gt; FTP sink&lt;/code&gt;.
But before doing so, let&amp;rsquo;s move these components a bit and so we can have more room
to work with (You can close the Toolbox by clicking on the close icon on the top right corner):&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-change-layout.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-change-layout.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream change layout&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;Okay, it&amp;rsquo;s time to create the connection:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hover over FTP source connector and click the &amp;ldquo;Link&amp;rdquo; button, and move your mouse to the first topic named &amp;ldquo;T1&amp;rdquo; and click on it. A connection should be created:&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-create-first-link.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-create-first-link.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream create first link&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;Repeat the same step but this time with &amp;ldquo;T1&amp;rdquo; to create a connection from T1 to stream&lt;/li&gt;
&lt;li&gt;And stream -&amp;gt; T2 then T2 -&amp;gt; FTP sink connector. After you are done, you should have a graph like this (Components position have been tweaked so it&amp;rsquo;s better to see the relation between these components):&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-done.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-done.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream done&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    You can also create the connection during configuring the connector or stream. For connector, just choose the topic from its topic list. For stream, you will need to choose both &lt;em&gt;&amp;ldquo;from&amp;rdquo;&lt;/em&gt; and &lt;em&gt;&amp;ldquo;to&amp;rdquo;&lt;/em&gt; topics from the topic list.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;start-pipeline-components&#34;&gt;Start pipeline components&lt;/h3&gt;
&lt;p&gt;So far so good, let&amp;rsquo;s start all the components simply by clicking on the &amp;ldquo;Start all components&amp;rdquo;
button located on the Toolbar menu. If everything goes well you should see that all components&amp;rsquo;
icons are now in green just like the following image:&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/start-components-done.png&#34; &gt;


  &lt;img data-src=&#34;../img/start-components-done.png&#34; class=&#34;lazyload&#34; alt=&#34;Start components done&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h3 id=&#34;test-our-new-pipeline&#34;&gt;Test our new pipeline&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s test this &amp;ldquo;pipeline&amp;rdquo; to see if it&amp;rsquo;s capable of transferring some data. We have
prepared a CSV file which looks like this (you can download this file from

&lt;a href=&#34;https://people.sc.fsu.edu/~jburkardt/data/csv/freshman_kgs.csv&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;):&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/csv.png&#34; &gt;


  &lt;img data-src=&#34;../img/csv.png&#34; class=&#34;lazyload&#34; alt=&#34;CSV file&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;Upload the file to the FTP service&amp;rsquo;s input folder. Wait for a while, the file should be
consumed and moved to the output folder. You can verify if the data is properly transferred
by using a FTP client to check the file (we&amp;rsquo;re using 
&lt;a href=&#34;https://filezilla-project.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;FileZilla&lt;/a&gt;).&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/csv-output.png&#34; &gt;


  &lt;img data-src=&#34;../img/csv-output.png&#34; class=&#34;lazyload&#34; alt=&#34;CSV output&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;The output data should be filtered with the result only &amp;ldquo;M&amp;rdquo; (man) data are listed as shown below:&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/csv-output-done.png&#34; &gt;


  &lt;img data-src=&#34;../img/csv-output-done.png&#34; class=&#34;lazyload&#34; alt=&#34;CSV output done&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h2 id=&#34;troubleshooting&#34;&gt;Troubleshooting&lt;/h2&gt;
&lt;p&gt;We now provide a few debugging tools that can help you pin down unexpected errors:&lt;/p&gt;
&lt;h3 id=&#34;event-log-panel&#34;&gt;Event log panel&lt;/h3&gt;
&lt;p&gt;All UI events are recorded, things like API request and response are also stored.
You can view all you event log by simply opening up the Event log panel. As you can
see in the screenshot, errors are highlighted and have more details that can be viewed
when click on each of them.&lt;/p&gt;
&lt;p&gt;














&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/event-log-icon.png&#34; &gt;


  &lt;img data-src=&#34;../img/event-log-icon.png&#34; class=&#34;lazyload&#34; alt=&#34;Event log icon&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/event-log-list.png&#34; &gt;


  &lt;img data-src=&#34;../img/event-log-list.png&#34; class=&#34;lazyload&#34; alt=&#34;Event log list&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/event-log-dialog.png&#34; &gt;


  &lt;img data-src=&#34;../img/event-log-dialog.png&#34; class=&#34;lazyload&#34; alt=&#34;Event log dialog&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Another thing that is worth mentioning here is the Event log icon will display the error log&amp;rsquo;s count on the icon&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/event-log-notification.png&#34; &gt;


  &lt;img data-src=&#34;../img/event-log-notification.png&#34; class=&#34;lazyload&#34; alt=&#34;Event log notification&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h3 id=&#34;developer-tools-panel&#34;&gt;Developer Tools panel&lt;/h3&gt;
&lt;p&gt;Open the dev tool from the App bar:&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/devtool-icon.png&#34; &gt;


  &lt;img data-src=&#34;../img/devtool-icon.png&#34; class=&#34;lazyload&#34; alt=&#34;DevTool icon&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;There are two main functionalities that could be utilized here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Topic panel: you can quickly preview the topic data here&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/devtool-topic-data.png&#34; &gt;


  &lt;img data-src=&#34;../img/devtool-topic-data.png&#34; class=&#34;lazyload&#34; alt=&#34;DevTool topic data&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;Log panel: view all running service&amp;rsquo;s full log&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/devtool-topic-log.png&#34; &gt;


  &lt;img data-src=&#34;../img/devtool-topic-log.png&#34; class=&#34;lazyload&#34; alt=&#34;DevTool topic log&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h3 id=&#34;delete-workspace&#34;&gt;Delete workspace&lt;/h3&gt;
&lt;p&gt;Deleting a workspace is a new feature implemented in 0.10.0, with this feature, you can now delete a workspace with our UI&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    All pipelines under the workspace that you&amp;rsquo;re about to delete should be stopped
(in other word, everything except topics in the pipeline should have the status &amp;ldquo;stopped&amp;rdquo;,
you can do so by going to each pipeline&amp;rsquo;s Toolbar and click on the &amp;ldquo;Stop all components&amp;rdquo;
item from the Pipeline actions
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;From Navigator, click on the workspace name, and click on the &amp;ldquo;Settings&amp;rdquo; item from that dropdown:&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/delete-workspace-menu.png&#34; &gt;


  &lt;img data-src=&#34;../img/delete-workspace-menu.png&#34; class=&#34;lazyload&#34; alt=&#34;Delete workspace menu&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;In the Settings dialog, scroll to the very bottom of the page, and click &amp;ldquo;Delete this workspace&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/delete-workspace-settings-button.png&#34; &gt;


  &lt;img data-src=&#34;../img/delete-workspace-settings-button.png&#34; class=&#34;lazyload&#34; alt=&#34;Delete workspace settings button&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;A confirm dialog will pop up. Enter the workspace name and click on the DELETE button to start deleting. (Note that if you still have some services running in the workspace, you won&amp;rsquo;t able to proceed. You should following the instruction mention in the above to stop all pipelines first)&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/delete-workspace-confirm.png&#34; &gt;


  &lt;img data-src=&#34;../img/delete-workspace-confirm.png&#34; class=&#34;lazyload&#34; alt=&#34;Delete workspace confirm dialog&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;The deletion is in progress, after the deletion is completed, you will be redirected to home or a default workspace if you have one.&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/delete-workspace-progress.png&#34; &gt;


  &lt;img data-src=&#34;../img/delete-workspace-progress.png&#34; class=&#34;lazyload&#34; alt=&#34;Delete workspace progress dialog&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h3 id=&#34;restart-workspace&#34;&gt;Restart workspace&lt;/h3&gt;
&lt;p&gt;When new changes were made in workspace, the restart is required. Also, if you ever run into issues that cannot be recovered from, you can try to restart the workspace to fix the issue.&lt;/p&gt;
&lt;p&gt;Since delete workspace and restart workspace are almost identical, the following instruction won&amp;rsquo;t include any screenshots as they are already included in the 
&lt;a href=&#34;#delete-workspace&#34;&gt;Delete workspace&lt;/a&gt; section&lt;/p&gt;
&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;div&gt;
    Same with delete a workspace, you will need to make sure all pipelines are stopped before starting:
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;From Navigator, click on the workspace name, and click on the &amp;ldquo;Settings&amp;rdquo; item from that dropdown.&lt;/li&gt;
&lt;li&gt;In the Settings dialog, scroll to the very bottom of the page, and click &amp;ldquo;Restart this workspace&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;A confirm dialog will pop up. Click on the RESTART button to start restarting this workspace.&lt;/li&gt;
&lt;li&gt;The restarting is in progress, after the restart is completed, you can close the progress
dialog and changes you made should applied to the workspace by now.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And if you think you ever encountered a bug, let us know: 
&lt;a href=&#34;https://github.com/oharastream/ohara/issues/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub Repo&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Custom Connector Guideline</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/custom_connector/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/custom_connector/</guid>
      <description>&lt;p&gt;Ohara custom connector is based on

&lt;a href=&#34;https://docs.confluent.io/current/connect/managing/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;kafka connector&lt;/a&gt;.
It offers a platform that enables you to define some simple actions to
connect topic to any other system. You don&amp;rsquo;t need to worry the
application availability, data durability, or distribution anymore. All
you have to do is to write your custom connector, which can have only
the pull()/push() method, and then compile your code to a jar file.
After uploading your jar to Ohara, you are able to &lt;strong&gt;deploy&lt;/strong&gt; your
connector on the
[worker cluster]/en/docs/0.11.x/rest-api/workers/#rest-workers-create. By
leveraging Ohara connector framework, apart from the availability,
scalability, and durability, you can also monitor your connector for

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/logs/&#34;&gt;logs&lt;/a&gt; and

&lt;a href=&#34;#metrics&#34;&gt;metrics&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The following sections start to explain how to write a good connector on
Ohara. You don&amp;rsquo;t need to read it through if you are familiar with

&lt;a href=&#34;https://docs.confluent.io/current/connect/managing/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;kafka connector&lt;/a&gt;.
However, Ohara connector has some improvements which are not in

&lt;a href=&#34;https://docs.confluent.io/current/connect/managing/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;kafka connector&lt;/a&gt;
so it has worth of taking a look at

&lt;a href=&#34;#metrics&#34;&gt;metrics&lt;/a&gt; and

&lt;a href=&#34;#setting_definition.md&#34;&gt;setting definitions&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;connector-overview&#34;&gt;Connector Overview&lt;/h2&gt;
&lt;p&gt;Ohara connector is composed of

&lt;a href=&#34;#source-connector&#34;&gt;source connector&lt;/a&gt; and

&lt;a href=&#34;#sink-connector&#34;&gt;sink connector&lt;/a&gt; .

&lt;a href=&#34;#source-connector&#34;&gt;source connector&lt;/a&gt;
is used to pull data &lt;strong&gt;from external system to topic&lt;/strong&gt;. By
contrast, 
&lt;a href=&#34;#sink-connector&#34;&gt;sink connector&lt;/a&gt; is
used to pull data from &lt;strong&gt;topic to external system&lt;/strong&gt;. A
complete connector consists of &lt;strong&gt;SourceConnector&lt;/strong&gt; / &lt;strong&gt;SinkConnector&lt;/strong&gt;
and &lt;strong&gt;SourceTask&lt;/strong&gt; / &lt;strong&gt;SinkTask&lt;/strong&gt;. Worker cluster picks up a node to
host your source/sink connector and then distributes the source/sink
tasks across cluster.&lt;/p&gt;
&lt;p&gt;You must include Ohara jars before starting to write your custom
connector. Please include both of ohara-common and ohara-kafka in your
dependencies. The ohara-common contains many helper methods and common
data used in whole Ohara. The ohara-kafka offers a lot of beautiful APIs
to help you to access kafka and design custom connector.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-groovy&#34;&gt;repositories {
     maven {
         url &amp;quot;https://dl.bintray.com/oharastream/ohara&amp;quot;
     }
 }
implementation &amp;quot;oharastream.ohara:ohara-common:0.11.0-SNAPSHOT&amp;quot;
implementation &amp;quot;oharastream.ohara:ohara-kafka:0.11.0-SNAPSHOT&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The &lt;a href=&#34;https://github.com/oharastream/ohara/releases&#34;&gt;releases&lt;/a&gt; page shows the available version of Ohara
  &lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 id=&#34;datamodel&#34;&gt;Data Model&lt;/h2&gt;
&lt;p&gt;Ohara has defined a table structure data in code base. We call it
&lt;strong&gt;row&lt;/strong&gt;. A row is comprised of multiple &lt;strong&gt;cells&lt;/strong&gt;. Each cell has its
&lt;strong&gt;name&lt;/strong&gt;, &lt;strong&gt;value&lt;/strong&gt; and &lt;strong&gt;tags&lt;/strong&gt;. The value in cell is a generic type
which accepts any serializable type of value. Following is an example
that shows you how to convert a csv data to Ohara row.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;c0,c1,c2
v0,v1,v2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above data can be converted to Ohara row by following code.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import oharastream.ohara.common.data.Row;
import oharastream.ohara.common.data.Cell;
class ExampleOfRow {
    public static void main(String[] args) {
        Row row = Row.of(
                Cell.of(&amp;quot;c0&amp;quot;, &amp;quot;v0&amp;quot;),
                Cell.of(&amp;quot;c1&amp;quot;, &amp;quot;v1&amp;quot;),
                Cell.of(&amp;quot;c2&amp;quot;, &amp;quot;v2&amp;quot;)
                );
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;c0,c1,c2
v0,,v2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above data can be converted to Ohara row by following code.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import oharastream.ohara.common.data.Row;
import oharastream.ohara.common.data.Cell;
class ExampleOfRow {
    public static void main(String[] args) {
        Row row = Row.of(
                Cell.of(&amp;quot;c0&amp;quot;, &amp;quot;v0&amp;quot;),
                Cell.of(&amp;quot;c2&amp;quot;, &amp;quot;v2&amp;quot;)
                );
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Don&amp;rsquo;t worry about the serialization. Ohara offers default serializations
for following data types:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;string&lt;/li&gt;
&lt;li&gt;boolean&lt;/li&gt;
&lt;li&gt;short&lt;/li&gt;
&lt;li&gt;int&lt;/li&gt;
&lt;li&gt;long&lt;/li&gt;
&lt;li&gt;float&lt;/li&gt;
&lt;li&gt;double&lt;/li&gt;
&lt;li&gt;bytes&lt;/li&gt;
&lt;li&gt;serializable object&lt;/li&gt;
&lt;li&gt;row (a nested row is acceptable!)&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The default serializer is located at
&lt;a href=&#34;https://github.com/oharastream/ohara/blob/0.11.x/ohara-common/src/main/java/oharastream/ohara/common/data/Serializer.java&#34;&gt;Here&lt;/a&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;When you get the rows in the connector, you should follow the &lt;strong&gt;cell
setting&lt;/strong&gt; to generate the output. The &lt;strong&gt;cell setting&lt;/strong&gt; in Ohara is
called &lt;strong&gt;column&lt;/strong&gt;. It shows the metadata of a &lt;strong&gt;cell&lt;/strong&gt;. The metadata
consists of:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;origin column name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; you can match the cell by this name&lt;/li&gt;
&lt;li&gt;new column name &amp;mdash; the new name of output.&lt;/li&gt;
&lt;li&gt;type (&lt;strong&gt;DataType&lt;/strong&gt;) &amp;mdash; the type of output value. Whatever the
origin type of value, you should convert the value according this
type. Don&amp;rsquo;t worry the casting error. It is up to the user who pass
the wrong configuration.
&lt;ul&gt;
&lt;li&gt;string&lt;/li&gt;
&lt;li&gt;boolean&lt;/li&gt;
&lt;li&gt;short&lt;/li&gt;
&lt;li&gt;int&lt;/li&gt;
&lt;li&gt;long&lt;/li&gt;
&lt;li&gt;float&lt;/li&gt;
&lt;li&gt;double&lt;/li&gt;
&lt;li&gt;bytes&lt;/li&gt;
&lt;li&gt;serializable object&lt;/li&gt;
&lt;li&gt;row&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;order (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; the order of cells in output.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;An example of converting data according to columns.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import oharastream.ohara.common.data.Cell;
import oharastream.ohara.common.data.Column;
class ExampleOfConverting {
    public static Object hello(Column column, String rawValue) {
        switch (column.dataType) {
            case DataType.BOOLEAN:
                return Boolean.valueOf(rawValue);
            case DataType.STRING:
                return rawValue;
            case DataType.SHORT:
                return Short.valueOf(rawValue);
            case DataType.INT:
                return Integer.valueOf(rawValue);
            case DataType.FLOAT:
                return Float.valueOf(rawValue);
            case DataType.DOUBLE:
                return Double.valueOf(rawValue);
            default:
                throw new IllegalArgumentException(&amp;quot;unsupported type:&amp;quot; + column.dataType);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The type is a complicated issue since there are countless types in this
world. It is impossible to define a general solution to handle all types
so the final types of value is &lt;strong&gt;byte array&lt;/strong&gt; or &lt;strong&gt;serializable
object&lt;/strong&gt;. If the type you want to pass is not in official support, you
should define it as &lt;strong&gt;byte array&lt;/strong&gt; or &lt;strong&gt;serializable object&lt;/strong&gt; and then
process it in your connectors.&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Feel free to throw an exception when your connector encounters an unknown
type. Don&amp;rsquo;t swallow it and convert to a weird value, such as null or
empty. Throwing exception is better than generating corrupt data!
  &lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 id=&#34;source-connector&#34;&gt;Source Connector&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;Source connector is used to pull data from outside system and then push
processed data to Ohara topics. A basic implementation for a source
connector only includes four methods &amp;mdash; &lt;strong&gt;run&lt;/strong&gt;, &lt;strong&gt;terminate&lt;/strong&gt;,
&lt;strong&gt;taskClass&lt;/strong&gt;, and &lt;strong&gt;taskSetting&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class RowSourceConnector extends SourceConnector {
  /**
   * Returns the RowSourceTask implementation for this Connector.
   *
   * @return a RowSourceTask class
   */
  protected abstract Class&amp;lt;? extends RowSourceTask&amp;gt; taskClass();

  /**
   * Return the settings for source task.
   *
   * @param maxTasks number of tasks for this connector
   * @return a seq from settings
   */
  protected abstract List&amp;lt;TaskSetting&amp;gt; taskSetting(int maxTasks);

  /**
   * Start this Connector. This method will only be called on a clean Connector, i.e. it has either
   * just been instantiated and initialized or terminate() has been invoked.
   *
   * @param taskSetting configuration settings
   */
  protected abstract void run(TaskSetting taskSetting);

  /** stop this connector */
  protected abstract void terminate();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;source-start&#34;&gt;run(TaskSetting)&lt;/h3&gt;
&lt;p&gt;After instantizing a connector, the first method called by worker is
&lt;strong&gt;start()&lt;/strong&gt;. You should initialize your connector in &lt;strong&gt;start&lt;/strong&gt; method,
since it has a input parameter &lt;strong&gt;TaskSetting&lt;/strong&gt; carrying all settings,
such as target topics, connector name and user-defined configs, from
user. If you (connector developer) are a good friend of your connector
user, you can get (and cast it to expected type) config, which is
passed by connector user, from &lt;strong&gt;TaskSetting&lt;/strong&gt;. For example, a
connector user calls

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/connectors/#create-settings&#34;&gt;Connector API&lt;/a&gt;
to store a config k0-v0 (both of them are string type) for
your connector, and then you can get v0 via
TaskSetting.stringValue(&amp;ldquo;k0&amp;rdquo;).&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Don&amp;rsquo;t be afraid of throwing exception when you notice that input
parameters are incorrect. Throwing an exception can fail a connector
quickly and stop worker to distribute connector task across cluster. It
saves the time and resources.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;We all hate wrong configs, right? When you design the connector, you can
&lt;strong&gt;define&lt;/strong&gt; the 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/setting_definition/&#34;&gt;setting&lt;/a&gt; on your own initiative.
The 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/setting_definition/&#34;&gt;setting&lt;/a&gt; enable
worker to check the input configs before starting connector. It can&amp;rsquo;t
eliminate incorrect configs completely, but it save your time of
fighting against wrong configs (have a great time with your family)&lt;/p&gt;
&lt;h3 id=&#34;source-terminate&#34;&gt;terminate()&lt;/h3&gt;
&lt;p&gt;This method is invoked by calling

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/connectors/#stop&#34;&gt;STOP API&lt;/a&gt;. You can
release the resources allocated by connector, or email to shout
at someone. It is ok to throw an exception when you fails to &lt;strong&gt;stop&lt;/strong&gt;
the connector. Worker cluster will mark &lt;strong&gt;failure&lt;/strong&gt; on the connector,
and the world keeps running.&lt;/p&gt;
&lt;h3 id=&#34;source-taskclass&#34;&gt;taskClass()&lt;/h3&gt;
&lt;p&gt;This method returns the java class of

&lt;a href=&#34;#sourcetask&#34;&gt;RowSourceTask&lt;/a&gt;
implementation. It tells worker cluster which class should be created
to pull data from external system. Noted that connector and task may
not be created on same node (jvm) so you should NOT share any objects
between them (for example, make them to access a global variable).&lt;/p&gt;
&lt;h3 id=&#34;source-tasksetting&#34;&gt;taskSetting(int maxTasks)&lt;/h3&gt;
&lt;p&gt;Connector has to generate configs for each task. The value of
&lt;strong&gt;maxTasks&lt;/strong&gt; is configured by

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/connectors/&#34;&gt;Connector API&lt;/a&gt;. If
you prefer to make all tasks do identical job, you can just clone the
task config passe by 
&lt;a href=&#34;#source-start&#34;&gt;start&lt;/a&gt;. Or you
can prepare different configs for each task. Noted that the number of
configuration you return MUST be equal with input value - maxTasks.
Otherwise, you will get an exception when running your connector.&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    It would be better to do the final check to input configs in Connector
rather than Task. Producing a failure quickly save your time and
resources.
  &lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 id=&#34;sourcetask&#34;&gt;Source Task&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class RowSourceTask extends SourceTask {

  /**
   * Start the Task. This should handle any configuration parsing and one-time setup from the task.
   *
   * @param config initial configuration
   */
  protected abstract void run(TaskSetting config);

  /**
   * Signal this SourceTask to stop. In SourceTasks, this method only needs to signal to the task
   * that it should stop trying to poll for new data and interrupt any outstanding poll() requests.
   * It is not required that the task has fully stopped. Note that this method necessarily may be
   * invoked from a different thread than pollRecords() and commitOffsets()
   */
  protected abstract void terminate();
  /**
   * Poll this SourceTask for new records. This method should block if no data is currently
   * available.
   *
   * @return a array from RowSourceRecord
   */
  protected abstract List&amp;lt;RowSourceRecord&amp;gt; pollRecords();
}  
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;RowSourceTask is the unit of executing &lt;strong&gt;poll&lt;/strong&gt;. A connector can invoke
multiple tasks if you set &lt;strong&gt;tasks.max&lt;/strong&gt; be bigger than 1 via

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/connectors/&#34;&gt;Connector API&lt;/a&gt;.
RowSourceTask has the similar lifecycle to Source connector. Worker cluster
call &lt;strong&gt;start&lt;/strong&gt; to initialize a task and call &lt;strong&gt;stop&lt;/strong&gt; to terminate a
task.&lt;/p&gt;
&lt;h3 id=&#34;sourcetask-pullrecords&#34;&gt;pullRecords()&lt;/h3&gt;
&lt;p&gt;You can ignore all methods except for &lt;strong&gt;pollRecords&lt;/strong&gt;. Worker cluster
call &lt;strong&gt;pollRecords&lt;/strong&gt; regularly to get &lt;strong&gt;RowSourceRecord&lt;/strong&gt; s and then
save them to topics. Worker cluster does not care for your
implementation. All you have to do is to put your data in
&lt;strong&gt;RowSourceRecord&lt;/strong&gt;. RowSourceRecord is a complicated object having
many elements. Some elements are significant. For example,
&lt;strong&gt;partition&lt;/strong&gt; can impact the distribution of records. In order to be
the best friend of programmer, Ohara follows the fluent pattern to allow
you to create record through builder, and you can only fill the
required elements.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class ExampleOfRowSourceRecord {
    public static RowSourceRecord create(Row row, String topicName) {
        return RowSourceRecord.builder()
        .row(row)
        .topicName(topicName)
        .build();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You can read the java docs of RowSourceRecord.Builder to see which
default values are set for other (optional) elements.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;sourcetask-partition-offsets&#34;&gt;Partition and Offsets in Source&lt;/h3&gt;
&lt;p&gt;De-duplicating data is not a easy job. When you keep pulling data from
external system to topics, you always need a place to record which
data have not processed. Connector offers two specific objects for you
to record the &lt;strong&gt;offset&lt;/strong&gt; and &lt;strong&gt;partition&lt;/strong&gt; of your data. You can
define a &lt;strong&gt;partition&lt;/strong&gt; and a &lt;strong&gt;offset&lt;/strong&gt; for RowSourceRecord. The
durability is on Worker&amp;rsquo;s shoulder, and you are always doable to get
&lt;strong&gt;partition&lt;/strong&gt; and &lt;strong&gt;offset&lt;/strong&gt; back even if the connector fail or
shutdown.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class ExampleOfRowSourceContext {
    public static Map&amp;lt;String, ?&amp;gt; getOffset(Map&amp;lt;String, ?&amp;gt; partition) {
        return RowSourceContext.offset(partition);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Both of them are Map type with string key and primitive type. Using Map
is a workaround to record the offsets for different connectors. You can
view them as a &lt;strong&gt;flatten&lt;/strong&gt; json representation. For example, one of task
is handling file_a, and it has processed first line of file_a. Then
the pair of &lt;strong&gt;partition&lt;/strong&gt; and &lt;strong&gt;offset&lt;/strong&gt; look like&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;fileName&amp;quot;: &amp;quot;file_a&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;offset&amp;quot;: 1
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can convert above json to &lt;strong&gt;partition&lt;/strong&gt; and &lt;strong&gt;offset&lt;/strong&gt; and then put
them in &lt;strong&gt;RowSourceRecord&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class ExampleOfPartitionAndOffset {
    public static RowSourceRecord addPartitionAndOffset(RowSourceRecord.Builder builder, String fileName, int offset) {
        Map&amp;lt;String, String&amp;gt; partition = Map.of(&amp;quot;fileName&amp;quot;, fileName);
        Map&amp;lt;String, Integer&amp;gt; offset = Map.of(&amp;quot;offset&amp;quot;, 1);
        return builder.sourcePartition(partition)
        .sourceOffset(offset)
        .build();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A news of &lt;strong&gt;partition&lt;/strong&gt; and &lt;strong&gt;offset&lt;/strong&gt; is that they are not stored with
data in RowSourceRecord. If you want to know the commit of &lt;strong&gt;partition&lt;/strong&gt;
and &lt;strong&gt;offset&lt;/strong&gt;, you can override the &lt;strong&gt;commitOffsets()&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class RowSourceTask extends SourceTask {
  /**
   * Commit the offsets, up to the offsets that have been returned by pollRecords(). This method should
   * block until the commit is complete.
   *
   * &amp;lt;p&amp;gt;SourceTasks are not required to implement this functionality; Kafka Connect will record
   * offsets automatically. This hook is provided for systems that also need to store offsets
   * internally in their own system.
   */
  protected void commitOffsets() {
    // do nothing
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;sourcetask-handle-exception&#34;&gt;Handle Exception in pollRecords()&lt;/h3&gt;
&lt;p&gt;Throwing exception make connector in &lt;strong&gt;failure&lt;/strong&gt; state, and inactivate
connector until you restart it. Hence, you SHOULD catch and handle the
exception as best you can. However, swallowing all exception is also a
weired behavior. You SHOULD fails the connector when encountering
unrecoverable exception.&lt;/p&gt;
&lt;h3 id=&#34;blocking-action-is-unwelcome-in-pollrecords&#34;&gt;Blocking Action Is Unwelcome In pollRecords()&lt;/h3&gt;
&lt;p&gt;Task is executed on a separate thread and there are many remaining
processing for data after pollRecords(). Hence, you should NOT block
pollRecords(). On the contrary, returning an empty list can yield the
resource to remaining processing.&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Returning null results in same result. However, we all should hate null
so please take away null from your code.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;data-from-pollrecords-are-committed-async&#34;&gt;Data From pollRecords() Are Committed Async&lt;/h3&gt;
&lt;p&gt;You don&amp;rsquo;t expect that the data you generated are commit at once,
right? Committing data invokes a large latency since we need to sync
data to multiple nodes and result in many disk I/O. Worker has another
thread sending your data in background. If your connector needs to
know the time of committing data, you can override the
&lt;strong&gt;commitOffsetsRecord(RowSourceRecord)&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class RowSourceTask extends SourceTask {
  /**
   * Commit an individual RowSourceRecord when the callback from the producer client is received, or
   * if a record is filtered by a transformation. SourceTasks are not required to implement this
   * functionality; Kafka Connect will record offsets automatically. This hook is provided for
   * systems that also need to store offsets internally in their own system.
   *
   * @param record RowSourceRecord that was successfully sent via the producer.
   */
  protected void commitOffsetsRecord(RowSourceRecord record) {
    // do nothing
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;sink-connector&#34;&gt;Sink Connector&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class RowSinkConnector extends SinkConnector {

  /**
   * Start this Connector. This method will only be called on a clean Connector, i.e. it has either
   * just been instantiated and initialized or terminate() has been invoked.
   *
   * @param config configuration settings
   */
  protected abstract void run(TaskSetting config);

  /** stop this connector */
  protected abstract void terminate();

  /**
   * Returns the RowSinkTask implementation for this Connector.
   *
   * @return a RowSinkTask class
   */
  protected abstract Class&amp;lt;? extends RowSinkTask&amp;gt; taskClass();

  /**
   * Return the settings for source task. NOTED: It is illegal to assign different topics to
   * RowSinkTask
   *
   * @param maxTasks number of tasks for this connector
   * @return the settings for each tasks
   */
  protected abstract List&amp;lt;TaskSetting&amp;gt; taskSetting(int maxTasks);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Sink connector is similar to

&lt;a href=&#34;#source-connector&#34;&gt;source connector&lt;/a&gt;. It also have

&lt;a href=&#34;#source-start&#34;&gt;run(TaskSetting)&lt;/a&gt;,

&lt;a href=&#34;#source-terminate&#34;&gt;terminate()&lt;/a&gt;,

&lt;a href=&#34;#source-taskclass&#34;&gt;taskClass()&lt;/a&gt;,

&lt;a href=&#34;#source-tasksetting&#34;&gt;taskSetting(int maxTasks)&lt;/a&gt;,

&lt;a href=&#34;#sourcetask-partition-offsets&#34;&gt;partition and offsets&lt;/a&gt;.
The main difference between sink connector and source
connector is that sink connector do pull data from topic and then push
processed data to outside system. Hence, it does have

&lt;a href=&#34;#sinktask-put-records&#34;&gt;pullRecords&lt;/a&gt; rather than

&lt;a href=&#34;#sourcetask-pullrecords&#34;&gt;pullRecords&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Though sink connector and source connector have many identical methods,
you should NOT make a connector mixed sink and source. Because Both
connector are &lt;strong&gt;abstract&lt;/strong&gt; class, you can&amp;rsquo;t have a class extending both
of them in java.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Sink connector also has to provide the task class to worker cluster. The
sink task in Ohara is called &lt;strong&gt;RowSinkTask&lt;/strong&gt;. It is also distributed
across whole worker cluster when you run a sink connector.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;sink-task&#34;&gt;Sink Task&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class RowSinkTask extends SinkTask {

  /**
   * Start the Task. This should handle any configuration parsing and one-time setup from the task.
   *
   * @param config initial configuration
   */
  protected abstract void run(TaskSetting config);

  /**
   * Perform any cleanup to stop this task. In SinkTasks, this method is invoked only once
   * outstanding calls to other methods have completed (e.g., pullRecords() has returned) and a final
   * flush() and offset commit has completed. Implementations from this method should only need to
   * perform final cleanup operations, such as closing network connections to the sink system.
   */
  protected abstract void terminate();

  /**
   * Put the table record in the sink. Usually this should send the records to the sink
   * asynchronously and immediately return.
   *
   * @param records table record
   */
  protected abstract void pullRecords(List&amp;lt;RowSinkRecord&amp;gt; records);
}  
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;RowSinkTask is similar to 
&lt;a href=&#34;#sourcetask&#34;&gt;RowSourceTask&lt;/a&gt;
that both of them have &lt;strong&gt;run&lt;/strong&gt; and &lt;strong&gt;stop&lt;/strong&gt; phase. RowSinkTask is
executed by a separate thread on worker also.&lt;/p&gt;
&lt;h3 id=&#34;sinktask-put-records&#34;&gt;pullRecords(List&lt;RowSinkRecord&gt; records)&lt;/h3&gt;
&lt;p&gt;Worker invokes a separate thread to fetch data from topic and put the
data to sink task. The input data is called &lt;strong&gt;RowSinkRecord&lt;/strong&gt; which
carries not only row but also metadata.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;topicName (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; where the data come from&lt;/li&gt;
&lt;li&gt;Row (&lt;strong&gt;row&lt;/strong&gt;) &amp;mdash; input data&lt;/li&gt;
&lt;li&gt;partition (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; index of partition&lt;/li&gt;
&lt;li&gt;offset (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; offset in topic-partition&lt;/li&gt;
&lt;li&gt;timestamp (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; data timestamp&lt;/li&gt;
&lt;li&gt;TimestampType (&lt;strong&gt;enum&lt;/strong&gt;) &amp;mdash; the way of generating timestamp
&lt;ul&gt;
&lt;li&gt;NO_TIMESTAMP_TYPE - means timestamp is nothing for this data&lt;/li&gt;
&lt;li&gt;CREATE_TIME - the timestamp is provided by user or the time of sending this data&lt;/li&gt;
&lt;li&gt;LOG_APPEND_TIME - the timestamp is broker&amp;rsquo;s local time when the data is append&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;partition-and-offsets-in-sink&#34;&gt;Partition and Offsets In Sink&lt;/h3&gt;
&lt;p&gt;Sink task has a component, which is called &lt;strong&gt;RowSinkContext&lt;/strong&gt;, saving
the offset and partitions for input data. Commonly, it is not big news
to you since kafka has responsibility to manage data offset in
topic-partition to avoid losing data. However, if you have something
more than data lost, such as exactly once, you can manage the data
offset manually and then use RowSinkContext to change the offset of
input data.&lt;/p&gt;
&lt;h3 id=&#34;handle-exception-in-pullrecordslistrowsinkrecord&#34;&gt;Handle Exception In pullRecords(List&lt;RowSinkRecord&gt;)&lt;/h3&gt;
&lt;p&gt;Any thrown exception will make this connector failed and stopped. You
should handle the recoverable error and throw the exception which
obstruct connector from running.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public interface RowSinkContext {
  /**
   * Reset the consumer offsets for the given topic partitions. SinkTasks should use this if they
   * manage offsets in the sink data store rather than using Kafka consumer offsets. For example, an
   * HDFS connector might record offsets in HDFS to provide exactly once delivery. When the SinkTask
   * is started or a rebalance occurs, the task would reload offsets from HDFS and use this method
   * to reset the consumer to those offsets.
   *
   * &amp;lt;p&amp;gt;SinkTasks that do not manage their own offsets do not need to use this method.
   *
   * @param offsets map from offsets for topic partitions
   */
  void offset(Map&amp;lt;TopicPartition, Long&amp;gt; offsets);

  /**
   * Reset the consumer offsets for the given topic partition. SinkTasks should use if they manage
   * offsets in the sink data store rather than using Kafka consumer offsets. For example, an HDFS
   * connector might record offsets in HDFS to provide exactly once delivery. When the topic
   * partition is recovered the task would reload offsets from HDFS and use this method to reset the
   * consumer to the offset.
   *
   * &amp;lt;p&amp;gt;SinkTasks that do not manage their own offsets do not need to use this method.
   *
   * @param partition the topic partition to reset offset.
   * @param offset the offset to reset to.
   */
  default void offset(TopicPartition partition, Long offset) {
    this.offset(Map.of(partition, offset));
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Noted that data offset is a order in topic-partition so the input of
RowSinkContext.offset consists of topic name and partition.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;handle-exception-in-pullrecordslistrowsinkrecord-1&#34;&gt;Handle Exception In pullRecords(List&lt;RowSinkRecord&gt;)&lt;/h3&gt;
&lt;p&gt;see 
&lt;a href=&#34;#sourcetask-handle-exception&#34;&gt;handle exception in pollRecords()&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;commit-your-output-data-when-kafka-commit-input-data&#34;&gt;Commit Your Output Data When Kafka Commit Input Data&lt;/h3&gt;
&lt;p&gt;While feeding data into your sink task, Kafka also tries to commit
previous data that make the data disappear from you. The method
&lt;strong&gt;preCommitOffsets&lt;/strong&gt; is a callback of committing data offset. If you
want to manage the offsets, you can change what to commit by kafka.
Another use case is that you have some stuff which needs to be committed
also, and you can trigger the commit in this callback.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class RowSinkTask extends SinkTask {
  /**
   * Pre-commit hook invoked prior to an offset commit.
   *
   * &amp;lt;p&amp;gt;The default implementation simply return the offsets and is thus able to assume all offsets
   * are safe to commit.
   *
   * @param offsets the current offset state as from the last call to pullRecords, provided for convenience
   *     but could also be determined by tracking all offsets included in the RowSourceRecord&#39;s
   *     passed to pullRecords.
   * @return an empty map if Connect-managed offset commit is not desired, otherwise a map from
   *     offsets by topic-partition that are safe to commit.
   */
  protected Map&amp;lt;TopicPartition, TopicOffset&amp;gt; preCommitOffsets(Map&amp;lt;TopicPartition, TopicOffset&amp;gt; offsets) {
    return offsets;
  }
}  
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The offsets exceeding the latest consumed offset are discarded
  &lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 id=&#34;version&#34;&gt;Version&lt;/h2&gt;
&lt;p&gt;We all love to show how good we are. If you are a connector designer,
Ohara connector offers a way to show the version, revision and author
for a connector.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class RowSourceConnector extends SourceConnector {
  public String version() {
    return VersionUtils.VERSION;
  }
  public String author() {
    return VersionUtils.USER;
  }
  public String revision() {
     return VersionUtils.REVISION;
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The default value is version of build. You can override one of them or
all of them when writing connector. The version information of a
connector is showed by 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/workers/&#34;&gt;Worker APIs&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;div&gt;
    Don&amp;rsquo;t return &lt;strong&gt;null&lt;/strong&gt;, please!!!
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Version in Ohara connector is different to kafka connector. The later
only supports &lt;strong&gt;version&lt;/strong&gt; and it&amp;rsquo;s APIs show only &lt;strong&gt;version&lt;/strong&gt;. Hence,
you can&amp;rsquo;t get revision, author or other

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/setting_definition/&#34;&gt;settings&lt;/a&gt; through kafka APIs&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;metrics&#34;&gt;Metrics&lt;/h2&gt;
&lt;p&gt;We are live in a world filled with number, and so do connectors. While a
connector is running, Ohara collects many counts from the data flow for
the connector in background. All of counters (and other records which
will be introduced in the future) are called &lt;strong&gt;metrics&lt;/strong&gt;, and it can be
fetched by 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/connectors/&#34;&gt;Connector API&lt;/a&gt;.
Apart from official metrics, connector developers are also
able to build custom metrics for custom connectors, and all custom
metrics are also showed by 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/connectors/&#34;&gt;Connector API&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Ohara leverage JMX to offer the metrics APIs to connector. It means all
metrics you created are stored as Java beans and is accessible through
JMX service. That is why you have to define a port via

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/workers/&#34;&gt;Worker APIs&lt;/a&gt; for creating
a worker cluster. Although you can see all java mbeans via the JMX
client (such as JMC), Ohara still encourage you to apply

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/connectors/&#34;&gt;Connector API&lt;/a&gt; as it
offers a more readable format of metrics.&lt;/p&gt;
&lt;h3 id=&#34;counter&#34;&gt;Counter&lt;/h3&gt;
&lt;p&gt;Counter is a common use case for metrics that you can
increment/decrement/add/ a number atomically. A counter consists of
following members.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the group of this counter&lt;/li&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the name of this counter&lt;/li&gt;
&lt;li&gt;unit (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the unit of value&lt;/li&gt;
&lt;li&gt;document (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the document for this metrics&lt;/li&gt;
&lt;li&gt;startTime (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; the time to start this counter&lt;/li&gt;
&lt;li&gt;value (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; current value of count&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A example of creating a counter is shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class ExampleOfCreatingCounter {
  public static Counter sizeCounter(String group) {
    return Counter.builder()
        .group(group)
        .name(&amp;quot;row.size&amp;quot;)
        .unit(&amp;quot;bytes&amp;quot;)
        .document(&amp;quot;size (in bytes) of rows&amp;quot;)
        .startTime(CommonUtils.current())
        .value(0)
        .register();
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Though &lt;strong&gt;unit&lt;/strong&gt; and &lt;strong&gt;document&lt;/strong&gt; are declared optional, making them have
meaning description can help reader to understand the magic number from
your counter.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The counter created by connector always has the group same to id of
connector, since Ohara needs to find the counters for specific connector
in &lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/connectors/&#34;&gt;Connector API&lt;/a&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;official-metrics&#34;&gt;Official Metrics&lt;/h3&gt;
&lt;p&gt;There are two official metrics for connector - row counter and bytes
counter. The former is the number of processed rows, and the later is
the number of processed data. Both of them are updated when data are
pull/push from/to your connector. Normally, you don&amp;rsquo;t need to care for
them when designing connectors. However, you can read the source code in
ConnectorUtils.java to see how Ohara create official counters.&lt;/p&gt;
&lt;h3 id=&#34;create-your-own-counters&#34;&gt;Create Your Own Counters&lt;/h3&gt;
&lt;p&gt;In order to reduce your duplicate code, Ohara offers the
&lt;strong&gt;CounterBuilder&lt;/strong&gt; to all connectors. CounterBuilder is a wrap of
Counter.Builder with some pre-defined variables, and hence the creation
of CounterBuilder must be after initializing the connector/task.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class ExampleOfCreatingCustomBuilder {
  public static Counter custom(RowSinkTask task) {
    return task.counterBuilder()
      .unit(&amp;quot;bytes&amp;quot;)
      .document(&amp;quot;size (in bytes) of rows&amp;quot;)
      .startTime(CommonUtils.current())
      .value(0)
      .register();
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Ohara doesn&amp;rsquo;t obstruct you from using Counter directly. However, using
CounterBuilder make sure that your custom metrics are available in
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/connectors/&#34;&gt;Connector API&lt;/a&gt;.
  &lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 id=&#34;csv-sink&#34;&gt;Csv Sink Connector&lt;/h2&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/csv_sink_connector_arch.png&#34; &gt;


  &lt;img src=&#34;../img/csv_sink_connector_arch.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;Csv Sink connector inherits from 
&lt;a href=&#34;#sink-connector&#34;&gt;Row Sink Connector&lt;/a&gt;.
It also have 
&lt;a href=&#34;#source-start&#34;&gt;run(TaskSetting)&lt;/a&gt;,

&lt;a href=&#34;#source-terminate&#34;&gt;terminate()&lt;/a&gt;,

&lt;a href=&#34;#source-taskclass&#34;&gt;taskClass()&lt;/a&gt;,

&lt;a href=&#34;#source-tasksetting&#34;&gt;taskSetting(int maxTasks)&lt;/a&gt;,

&lt;a href=&#34;#sourcetask-partition-offsets&#34;&gt;partition and offsets&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The main difference between csv sink connector and row sink
connector is that csv sink connector already has some default
definitions.&lt;/p&gt;
&lt;p&gt;Below is a list of default definitions for CsvSinkConnector:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;TOPICS_DIR_DEFINITION: Read csv data from topic and then write to
this folder&lt;/li&gt;
&lt;li&gt;FLUSH_SIZE_DEFINITION: Number of records write to store before
invoking file commits&lt;/li&gt;
&lt;li&gt;ROTATE_INTERVAL_MS_DEFINITION: Commit file time&lt;/li&gt;
&lt;li&gt;FILE_NEED_HEADER_DEFINITION: File need header for flush data&lt;/li&gt;
&lt;li&gt;FILE_ENCODE_DEFINITION: File encode for write to file&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Connector developers can override &lt;strong&gt;customSettingDefinitions&lt;/strong&gt; to add
other additional definitions:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class CsvSinkConnector extends RowSinkConnector {
  /**
   * Define the configuration for the connector.
   *
   * @return The SettingDef for this connector.
   */
  protected List&amp;lt;SettingDef&amp;gt; customSettingDefinitions() {
    return List.of();
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;csv-sink-task&#34;&gt;Csv Sink Task&lt;/h2&gt;
&lt;p&gt;Ohara has a well-incubated task class. We call it &lt;strong&gt;CsvSinkTask&lt;/strong&gt;. As
long as your data format is CSV type, you can use id to develop a sink
connector to connect various file systems.&lt;/p&gt;
&lt;p&gt;We all know that to make a strong and robust connector, you have to take
care of a lot of details. In order to ensure that the connector works,
we must also prepare a lot of tests. Connector developers will spend a
lot of time on this.&lt;/p&gt;
&lt;p&gt;Therefore, we have encapsulated most of the logic in CsvSinkTask, which
hides a lot of complex behaviors. Just provide a 
&lt;a href=&#34;#storage&#34;&gt;Storage&lt;/a&gt;
implementation to complete a sink connector. You can save time to enjoy
other happy things.&lt;/p&gt;
&lt;p&gt;The following are the two methods you need to care about inherited
CsvSinkTask:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class CsvSinkTask extends RowSinkTask {
  /**
   * Returns the Storage implementation for this Task.
   *
   * @param setting initial settings
   * @return a Storage instance
   */
  public abstract Storage _storage(TaskSetting setting);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;_storagetasksetting-setting&#34;&gt;_storage(TaskSetting setting)&lt;/h3&gt;
&lt;p&gt;The goal of Task is to write the data to an external file system. For
example, if we want to store the output files on FTP server, connector
developers must provide an implementation of

&lt;a href=&#34;#storage&#34;&gt;Storage&lt;/a&gt; that can access FTP.&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The input parameter &lt;em&gt;TaskSetting&lt;/em&gt; carrying all settings.
see &lt;a href=&#34;#source-tasksetting&#34;&gt;TaskSetting&lt;/a&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;storage&#34;&gt;Storage&lt;/h2&gt;
&lt;p&gt;This interface defines some common methods for accessing the file
system, such as checking for the existence of a file, creating a new
file, or reading an exiting file, etc. Connector developers can follow
this interface to implement different file systems, such as FTP, HDFS,
SMB, Amazon S3, etc. So, just provide the implementation of Storage to
CsvSinkTask and you can implement a

&lt;a href=&#34;#sink-connector&#34;&gt;Sink Connector&lt;/a&gt; very quickly.&lt;/p&gt;
&lt;p&gt;Below we list the important methods in the Storage interface:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public interface Storage extends Releasable {
  /**
   * Returns whether an object exists.
   *
   * @param path the path to the object.
   * @return true if object exists, false otherwise.
   */
  boolean exists(String path);

  /**
   * Creates a new object in the given path.
   *
   * @param path the path of the object to be created.
   * @throws OharaFileAlreadyExistsException if a object of that path already exists.
   * @throws OharaException if the parent container does not exist.
   * @return an output stream associated with the new object.
   */
  OutputStream create(String path);

  /**
   * Open for reading an object at the given path.
   *
   * @param path the path of the object to be read.
   * @return an input stream with the requested object.
   */
  InputStream open(String path);

  /**
   * Move or rename a object from source path to target path.
   *
   * @param sourcePath the path to the object to move
   * @param targetPath the path to the target object
   * @return true if object have moved to target path , false otherwise.
   */
  boolean move(String sourcePath, String targetPath);

  /** Stop using this storage. */
  void close();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You can read the
&lt;a href=&#34;https://github.com/oharastream/ohara/blob/0.11.x/ohara-connector/src/main/scala/oharastream/ohara/connector/ftp/FtpStorage.scala&#34;&gt;FtpStorage&lt;/a&gt;
as an example to see how to implement your own Storage.
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Custom Stream Guideline</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/custom_stream/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/custom_stream/</guid>
      <description>&lt;p&gt;Ohara stream is an unparalleled wrap of 
&lt;a href=&#34;https://kafka.apache.org/documentation/streams&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;kafka streams&lt;/a&gt; which gives you
a straightforward thought to design your streaming flow. It offers a
simple way to implement and define actions to process data between
topics. You only have to write your logic in

&lt;a href=&#34;#start-method&#34;&gt;start()&lt;/a&gt; method and
compile your code to a jar file. After jar file is compiled
successfully, you can &lt;strong&gt;deploy&lt;/strong&gt; your jar file to Ohara, run it, and
monitor your stream by 
&lt;a href=&#34;#logs&#34;&gt;logs&lt;/a&gt; and 
&lt;a href=&#34;#metrics&#34;&gt;metrics&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The following sections will describe how to write a stream application
in Ohara.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;ohara-stream-overview&#34;&gt;Ohara Stream Overview&lt;/h2&gt;
&lt;p&gt;Ohara stream is a wrap of 
&lt;a href=&#34;https://kafka.apache.org/documentation/streams&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;kafka
streams&lt;/a&gt; and provided an
entry of interface class 
&lt;a href=&#34;#stream-entry&#34;&gt;Stream&lt;/a&gt; to define user custom streaming code.
A normal stream application will use 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/custom_connector/#datamodel&#34;&gt;Row&lt;/a&gt;
as data type to interactive topics in Ohara.&lt;/p&gt;
&lt;p&gt;Before writing your stream, you should download the ohara dependencies
first. Ohara includes many powerful tools for developer but not all
tools are requisite in designing stream. The required dependencies are
shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-groovy&#34;&gt;repositories {
     maven {
         url &amp;quot;https://dl.bintray.com/oharastream/ohara&amp;quot;
     }
 }
implementation &amp;quot;oharastream.ohara:ohara-stream:0.11.0-SNAPSHOT&amp;quot;
implementation &amp;quot;oharastream.ohara:ohara-common:0.11.0-SNAPSHOT&amp;quot;
implementation &amp;quot;oharastream.ohara:ohara-kafka:0.11.0-SNAPSHOT&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The &lt;a href=&#34;https://github.com/oharastream/ohara/releases&#34;&gt;releases&lt;/a&gt; page shows the available version of ohara
  &lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 id=&#34;stream-entry&#34;&gt;Stream Entry &lt;/h2&gt;
&lt;p&gt;We will automatically find your custom class which should be extended by
&lt;strong&gt;oharastream.ohara.stream.Stream&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In Ohara environment, the required parameters are defined in Ohara UI.
You only need to initial the &lt;code&gt;OStream&lt;/code&gt; as following:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;OStream&amp;lt;Row&amp;gt; ostream = OStream.builder().toOharaEnvStream();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A base implementation for a custom stream only need to include

&lt;a href=&#34;#start-method&#34;&gt;start()&lt;/a&gt; method,
but you could include other methods which are described below for your
convenience.&lt;/p&gt;
&lt;p&gt;The following example is a simple stream application which can run in
Ohara. Note that this example simply starts the stream application
without doing any transformation but writing data, i.e., the target
topic will have same data as the source topic.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class SimpleApplicationForOharaEnv extends Stream {

  @Override
  public void start(OStream&amp;lt;Row&amp;gt; ostream, StreamDefinitions streamSetting) {
    ostream.start();
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The following methods we provided belongs to Ohara Stream, which has
many powerful and friendly features. Native Kafka Streams API does not
have these methods.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;init-method&#34;&gt;init() method&lt;/h3&gt;
&lt;p&gt;After we find the user custom class, the first method will be called by
Stream is &lt;strong&gt;init()&lt;/strong&gt;. This is an optional method that can be used for
user to initialize some external data source connections or input
parameters.&lt;/p&gt;
&lt;h3 id=&#34;config-method&#34;&gt;config() method&lt;/h3&gt;
&lt;p&gt;In a stream application, you may want to configure your own parameters.
We support a method here to help you define a custom streamSetting list
in stream. The details of streamSetting are list

&lt;a href=&#34;#setting-definitions&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In the following example, we want to add a custom definition which is
used to define &amp;ldquo;join topic&amp;rdquo;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Override
public StreamDefinitions config() {
 return StreamDefinitions
   // add a definition of &amp;quot;filter name&amp;quot; in &amp;quot;default&amp;quot; group
   .with(SettingDef.builder().key(&amp;quot;filterName&amp;quot;).group(&amp;quot;default&amp;quot;).build());
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After define the definition, you can use it in 
&lt;a href=&#34;#start-method&#34;&gt;start()&lt;/a&gt; method&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    This method is optional. We will append all the definitions you provide
in this method to the stream default definitions. That is, the absent
config() method means you only need the default definitions.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;start-method&#34;&gt;start(OStream&lt;Row&gt;, StreamDefinitions) method&lt;/h3&gt;
&lt;p&gt;This method will be called after 
&lt;a href=&#34;#init-method&#34;&gt;init()&lt;/a&gt;.
Normally, you could only define start() method for most cases in Ohara. We
encourage user to use &lt;strong&gt;source connector&lt;/strong&gt;
(see 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/custom_connector/#source-connector&#34;&gt;Source Connector&lt;/a&gt; section)
for importing external data source to Ohara and use topic data as custom
stream data source in start() method.&lt;/p&gt;
&lt;p&gt;We provide two arguments in this method:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;OStream &amp;mdash; the entry class of ohara stream&lt;br&gt;
OStream (a.k.a. ohara stream) helps you to construct your
application and use all the powerful APIs in Stream.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;StreamDefinitions &amp;mdash; the definitions of ohara stream&lt;br&gt;
from the definition you can use &lt;em&gt;StreamDefinitions.string()&lt;/em&gt; to get the value from the

&lt;a href=&#34;#config-method&#34;&gt;config method&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The return value is wrap in a Java object &lt;strong&gt;Optional&lt;/strong&gt;, you need to
decide whether the value is present or not.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;For example:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Override
public void start(OStream&amp;lt;Row&amp;gt; ostream, StreamDefinitions streamSetting) {
 ostream
   .map(row -&amp;gt; Row.of(row.cell(&amp;quot;name&amp;quot;), row.cell(&amp;quot;age&amp;quot;)))
   // use the previous defined definition in config()
   .filter(row -&amp;gt; row.cell(streamSetting.string(&amp;quot;filterName&amp;quot;).get()).value() != null)
   .map(row -&amp;gt; Row.of(Cell.of(&amp;quot;name&amp;quot;, row.cell(&amp;quot;name&amp;quot;).value().toString().toUpperCase())))
   .start();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above code does the following transformations:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;pick cell of the header: &lt;code&gt;name&lt;/code&gt;, &lt;code&gt;age&lt;/code&gt; from each row&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;filter out that if &lt;code&gt;filterName&lt;/code&gt; is null &amp;mdash;
here we get the value from &lt;strong&gt;filterName&lt;/strong&gt; of definitions. the value you should update by

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/streams/#update&#34;&gt;Stream update api&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;PUT /v0/streams/XXX&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
 &amp;quot;filterName&amp;quot;: &amp;quot;name&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;convert the cell of &lt;code&gt;name&lt;/code&gt; to upperCase&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;From now on, you can use the 
&lt;a href=&#34;#java-api&#34;&gt;Stream Java API&lt;/a&gt; to
design your own application, happy coding!&lt;/p&gt;
&lt;h2 id=&#34;java-api&#34;&gt;Stream Java API &lt;/h2&gt;
&lt;p&gt;In Stream, we provide three different classes for developers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OStream: define the functions for operating streaming data (each row record one-by-one)&lt;/li&gt;
&lt;li&gt;OGroupedStream: define the functions for operating grouped streaming data&lt;/li&gt;
&lt;li&gt;OTable: define the functions for operating table data (changelog for same key of row record)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The above classes will be auto converted when you use the correspond
functions; You should not worry about the usage of which class is
right to use. All the starting point of development is just &lt;strong&gt;OStream&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Below we list the available functions in each class (See more information in javadoc):&lt;/p&gt;
&lt;h3 id=&#34;ostream&#34;&gt;OStream&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;constructTable(String topicName)&lt;/p&gt;
&lt;p&gt;Create a OTable with specified topicName from current OStream.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;filter(Predicate predicate)&lt;/p&gt;
&lt;p&gt;Create a new OStream that filter by the given predicate.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;through(String topicName, int partitions)&lt;/p&gt;
&lt;p&gt;Transfer this OStream to specify topic and use the required
partition number.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;leftJoin(String joinTopicName, Conditions conditions, ValueJoiner joiner)&lt;/p&gt;
&lt;p&gt;Join this OStream with required joinTopicName and conditions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;map(ValueMapper mapper)&lt;/p&gt;
&lt;p&gt;Transform the value of each record to a new value of the output record.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;groupByKey(List keys)&lt;/p&gt;
&lt;p&gt;Group the records by key to a OGroupedStream.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;foreach(ForeachAction action)&lt;/p&gt;
&lt;p&gt;Perform an action on each record of OStream.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;start()&lt;/p&gt;
&lt;p&gt;Run this stream application.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;stop()&lt;/p&gt;
&lt;p&gt;Stop this stream application.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;describe()&lt;/p&gt;
&lt;p&gt;Describe the topology of this stream.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;getPoneglyph()&lt;/p&gt;
&lt;p&gt;Get the Ohara format Poneglyph from topology.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ogroupedstream&#34;&gt;OGroupedStream&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;count()&lt;/p&gt;
&lt;p&gt;Count the number of records in this OGroupedStream and return the
count value.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;reduce(final Reducer reducer)&lt;/p&gt;
&lt;p&gt;Combine the values of each record in this OGroupedStream by the
grouped key.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;otable&#34;&gt;OTable&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;toOStream()&lt;/p&gt;
&lt;p&gt;Convert this OTable to OStream&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;stream-examples&#34;&gt;Stream Examples&lt;/h2&gt;
&lt;p&gt;Below we provide some examples that demonstrate how to develop your own
stream applications. More description of each example could be found in
javadoc.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/oharastream/ohara/blob/0.11.x/ohara-stream/src/test/java/oharastream/ohara/stream/examples/WordCountExample.java&#34;&gt;WordCount&lt;/a&gt;:
count the words in &amp;ldquo;word&amp;rdquo; column&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/oharastream/ohara/blob/0.11.x/ohara-stream/src/test/java/oharastream/ohara/stream/examples/PageViewRegionExample.java&#34;&gt;PageViewRegion&lt;/a&gt;:
count the views by each region&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/oharastream/ohara/blob/0.11.x/ohara-stream/src/test/java/oharastream/ohara/stream/examples/SumExample.java&#34;&gt;Sum&lt;/a&gt;:
sum odd numbers in &amp;ldquo;number&amp;rdquo; column&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;setting-definitions&#34;&gt;Stream Definitions&lt;/h2&gt;
&lt;p&gt;Stream stores a list of

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/setting_definition/&#34;&gt;SettingDef&lt;/a&gt;, which
is StreamDefinitions, in the data store. By default, we will keep the
following definitions in the &amp;ldquo;core&amp;rdquo; group and generate the definition
in stream API :&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;DefaultConfigs.BROKER_DEFINITION : The broker list&lt;/li&gt;
&lt;li&gt;DefaultConfigs.IMAGE_NAME_DEFINITION : The image name&lt;/li&gt;
&lt;li&gt;DefaultConfigs.NAME_DEFINITION : The stream application name&lt;/li&gt;
&lt;li&gt;DefaultConfigs.GROUP_DEFINITION : The stream group name&lt;/li&gt;
&lt;li&gt;DefaultConfigs.FROM_TOPICS_DEFINITION : The from topic&lt;/li&gt;
&lt;li&gt;DefaultConfigs.TO_TOPICS_DEFINITION : The to topic&lt;/li&gt;
&lt;li&gt;DefaultConfigs.JMX_PORT_DEFINITION : The exposed jmx port&lt;/li&gt;
&lt;li&gt;DefaultConfigs.NODE_NAMES_DEFINITION : The node name list&lt;/li&gt;
&lt;li&gt;DefaultConfigs.VERSION_DEFINITION : The version of stream&lt;/li&gt;
&lt;li&gt;DefaultConfigs.REVISION_DEFINITION : The revision of stream&lt;/li&gt;
&lt;li&gt;DefaultConfigs.AUTHOR_DEFINITION : The author of stream&lt;/li&gt;
&lt;li&gt;DefaultConfigs.TAGS_DEFINITION : The tags of stream&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Any other definition except above list will be treated as a custom
definition. You can define:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder().key(joinTopic).group(&amp;quot;default&amp;quot;).build()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;as a definition that is listed in &amp;ldquo;default&amp;rdquo; group, or&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder().key(otherKey).group(&amp;quot;common&amp;quot;).build()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;as a definition that is listed in the &amp;ldquo;common&amp;rdquo; group.&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Any group category will generate a new &amp;ldquo;tab&amp;rdquo; in Ohara-Manager.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The value of each definition will be kept in environment of stream
running container, and you should set the value by

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/streams/#update&#34;&gt;stream api&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;metrics&#34;&gt;Metrics&lt;/h2&gt;
&lt;p&gt;When a stream application is running, Ohara automatically collects some
metrics data from the stream in the background. The metrics data here
means 
&lt;a href=&#34;#official-metrics&#34;&gt;official metrics&lt;/a&gt; which contains

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/custom_connector/#counter&#34;&gt;Counters&lt;/a&gt; for now
(other type of metrics will be introduced in the future). The metrics
data could be fetched by 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/streams/&#34;&gt;Stream APIs&lt;/a&gt;.
Developers will be able to implement their own custom
metrics in the foreseeable future.&lt;/p&gt;
&lt;p&gt;Ohara leverages JMX to offer the metrics data to stream. It means that
all metrics you have created are stored as Java beans and accessible
through JMX service. The stream will expose a port via

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/streams/&#34;&gt;Stream APIs&lt;/a&gt; for other JMX
client tool used, such as JMC, but we still encourage you to use

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/streams/&#34;&gt;Stream APIs&lt;/a&gt; as it offers a
more readable format of metrics.&lt;/p&gt;
&lt;h3 id=&#34;official-metrics&#34;&gt;Official Metrics&lt;/h3&gt;
&lt;p&gt;There are two type of official metrics for stream:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;consumed topic records (counter)&lt;/li&gt;
&lt;li&gt;produced topic records (counter)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A normal stream will connect to two topics, one is the source topic that
stream will consume from, and the other is the target topic that stream
will produce to. We use prefix words (&lt;strong&gt;TOPIC_IN&lt;/strong&gt;, &lt;strong&gt;TOPIC_OUT&lt;/strong&gt;) in
the response data (
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/streams/&#34;&gt;Stream APIs&lt;/a&gt;)
in order to improve readabilities of those types. You don&amp;rsquo;t
need to worry about the implementation of these official metrics, but
you can still read the

&lt;a href=&#34;https://github.com/oharastream/ohara/blob/0.11.x/ohara-stream/src/main/java/oharastream/ohara/stream/metric/MetricFactory.java&#34;&gt;source code&lt;/a&gt;
to see how Ohara creates official metrics.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;logs&#34;&gt;Logs&lt;/h2&gt;
&lt;p&gt;Will be implemented in the near future. Also see issue: 
&lt;a href=&#34;https://github.com/oharastream/ohara/issues/962

&#34;&gt;#962&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Setting Definition Guide</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/setting_definition/</link>
      <pubDate>Wed, 17 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/setting_definition/</guid>
      <description>&lt;p&gt;A powerful application always has a complicated configuration. In order
to be a best friend of Ohara users, Ohara provides a method which can
return the details of setting definitions, and ohara suggests that all
developers ought to implement the method so as to guide users through
the complicated settings of your applications.&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    If you have no interest in settings or your application is too simple to
have any settings, you can just skip this section.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;SettingDef is a class used to describe the details of &lt;strong&gt;a&lt;/strong&gt; setting. It
consists of following arguments.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;a href=&#34;#setting-reference&#34;&gt;reference&lt;/a&gt;(&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; works for ohara manager.
It represents the reference of value.&lt;/li&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the group of this setting (all core setting are in core group)&lt;/li&gt;
&lt;li&gt;orderInGroup (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; the order in group&lt;/li&gt;
&lt;li&gt;displayName (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the readable name of this setting&lt;/li&gt;
&lt;li&gt;permission (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the way to &amp;ldquo;touch&amp;rdquo; value. It consists of
&lt;ul&gt;
&lt;li&gt;READ_ONLY &amp;mdash; you can&amp;rsquo;t define an new value for it&lt;/li&gt;
&lt;li&gt;CREATE_ONLY &amp;mdash; you can&amp;rsquo;t update the value to an new one&lt;/li&gt;
&lt;li&gt;EDITABLE &amp;mdash; feel free to modify the value as you wish :)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;key (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the key of configuration&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#value-type&#34;&gt;valueType&lt;/a&gt;(&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the type of value&lt;/li&gt;
&lt;li&gt;necessary (&lt;strong&gt;string&lt;/strong&gt;)
&lt;ul&gt;
&lt;li&gt;REQUIRED &amp;mdash; this field has no default and user MUST define something for it.&lt;/li&gt;
&lt;li&gt;OPTIONAL &amp;mdash; this field has no default and user does NOT need to define something for it.&lt;/li&gt;
&lt;li&gt;RANDOM_DEFAULT &amp;mdash; this field has a &amp;ldquo;random&amp;rdquo; default value&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;defaultValue (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the default value. the type is equal to what valueType
defines but we only allow string, number and boolean type to have default value currently.&lt;/li&gt;
&lt;li&gt;documentation (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the explanation of this definition&lt;/li&gt;
&lt;li&gt;internal (&lt;strong&gt;boolean&lt;/strong&gt;) &amp;mdash; true if this setting is assigned by system automatically.&lt;/li&gt;
&lt;li&gt;tableKeys (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the description to Type.TABLE
&lt;ul&gt;
&lt;li&gt;tableKeys[i].name &amp;mdash; the column name&lt;/li&gt;
&lt;li&gt;tableKeys[i].type &amp;mdash; acceptable type (string, number and boolean)&lt;/li&gt;
&lt;li&gt;tableKeys[i].recommendedValues &amp;mdash; recommended values
(it is legal to enter other values you prefer)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You can call &lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/workers/&#34;&gt;Worker APIs&lt;/a&gt;
to get all connectors&amp;rsquo; setting definitions, and use &lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/streams/&#34;&gt;Stream APIs&lt;/a&gt;
to get all stream setting definitions.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Although a SettingDef can include many elements, you can simply build a
SettingDef with only what you need. An extreme example is that you can
create a SettingDef with only key.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notwithstanding it is flexible to build a SettingDef, we encourage
developers to create a description-rich SettingDef. More description to
your setting produces more &lt;strong&gt;document&lt;/strong&gt; in calling ohara rest APIs. We
all hate write documentation, so it would be better to make your code
readable.&lt;/p&gt;
&lt;h2 id=&#34;reference-internal-and-tablekeys-are-not-public&#34;&gt;Reference, Internal and TableKeys Are NOT Public&lt;/h2&gt;
&lt;p&gt;Ohara offers a great UI, which is located at ohara-manager. The UI
requires some &lt;strong&gt;private&lt;/strong&gt; information to generate forms for custom
applications. The such private information is specific-purpose and is
meaningless to non-ohara developers. Hence, all of them are declared as
package-private and ohara does not encourage developers to stop at
nothing to use them.&lt;/p&gt;
&lt;h2 id=&#34;optional-required-and-default-value&#34;&gt;Optional, Required And Default Value&lt;/h2&gt;
&lt;p&gt;We know a great application must have countless settings and only The
Chosen One can control it. In order to shorten the gap between your
application and human begin, ohara encourage developers to offer the
default values to most of settings as much as possible. Assigning a
default value to a SettingDef is a piece of cake.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .optional(defaultValue)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    the default value is declared as &lt;strong&gt;string&lt;/strong&gt; type as it must be &lt;strong&gt;readable&lt;/strong&gt; in Restful APIs.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;After calling the &lt;strong&gt;optional(String)&lt;/strong&gt; method, the response, created by

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/workers/&#34;&gt;Worker APIs&lt;/a&gt; for example,
will display the following information.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;necessary&amp;quot;: &amp;quot;OPTIONAL_WITH_DEFAULT&amp;quot;,
  &amp;quot;defaultValue&amp;quot;: &amp;quot;ur_default_value&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The default value will be added to
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/custom_connector/#source-start&#34;&gt;TaskSetting&lt;/a&gt;
automatically if the specified key is not already associated with a value.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;a-readonly-setting-definition&#34;&gt;A Readonly Setting Definition&lt;/h2&gt;
&lt;p&gt;You can declare a &lt;strong&gt;readonly&lt;/strong&gt; setting that not only exposes something
of your application to user but also remind user the setting can&amp;rsquo;t be
changed at runtime. For instance, the information of

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/custom_connector/#version&#34;&gt;version&lt;/a&gt; is fixed
after you have completed your connector so it is not an &lt;strong&gt;editable&lt;/strong&gt;
setting. Hence, ohara define a setting for &lt;strong&gt;version&lt;/strong&gt; with a readonly
label. By the way, you should assign a default value to a readonly
setting since a readonly setting without default value is really weird.
There is an example of creating a readonly setting.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .optional(defaultValue)
    .permission(SettingDef.Permission.READ_ONLY)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The input value will be removed automatically if the associated setting
is declared readonly.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;setting-reference&#34;&gt;Setting Reference&lt;/h2&gt;
&lt;p&gt;This element is a specific purpose. It is used by Ohara manager (UI) only.
If you don&amp;rsquo;t have interest in UI, you can just ignore this element.
However, we still list the available values here.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NODE&lt;/li&gt;
&lt;li&gt;TOPIC&lt;/li&gt;
&lt;li&gt;ZOOKEEPER&lt;/li&gt;
&lt;li&gt;BROKER&lt;/li&gt;
&lt;li&gt;WORKER&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    For each reference value, it may have different type and will produce
different behavior.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Topic String&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder().key(&amp;quot;topic&amp;quot;).reference(Reference.TOPIC).required(Type.STRING).build();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which means the request should &amp;ldquo;accept one topic of string type&amp;rdquo;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;topic&amp;quot;: &amp;quot;t1&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;TopicKey List&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(&amp;quot;topicKeys&amp;quot;)
    .reference(Reference.TOPIC)
    .required(Type.OBJECT_KEYS)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which means the request should &amp;ldquo;accept topic list of &lt;strong&gt;TopicKey&lt;/strong&gt; type&amp;rdquo;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;topicKeys&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;t1&amp;quot;
    },
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;t2&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;Topic String List&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(&amp;quot;topics&amp;quot;)
    .reference(Reference.TOPIC)
    .required(Type.ARRAY)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which means the request should &amp;ldquo;accept topic list of string type&amp;rdquo;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;topics&amp;quot;: [&amp;quot;t1&amp;quot;, &amp;quot;t2&amp;quot;, &amp;quot;t3&amp;quot;]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;value-type&#34;&gt;Value Type&lt;/h2&gt;
&lt;p&gt;In a custom application, the settings could have various data type. In
order to display correct data type in ohara manager and leverage the
benefit of 
&lt;a href=&#34;#checker&#34;&gt;type checker&lt;/a&gt;, we
strongly suggest you to define the correct data type for each setting.&lt;/p&gt;
&lt;p&gt;The following data types are supported currently.&lt;/p&gt;
&lt;h4 id=&#34;typeboolean&#34;&gt;Type.BOOLEAN&lt;/h4&gt;
&lt;p&gt;Boolean type represents that the data should have only two possible
value: &lt;strong&gt;true&lt;/strong&gt; or &lt;strong&gt;false&lt;/strong&gt;. The value must be able cast to
&lt;strong&gt;java.lang.Boolean&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;typestring&#34;&gt;Type.STRING&lt;/h4&gt;
&lt;p&gt;String type represents that the data should be a string. The value must
be able cast to &lt;strong&gt;java.lang.String&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.STRING)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typepositive_short&#34;&gt;Type.POSITIVE_SHORT&lt;/h4&gt;
&lt;p&gt;Short type represents that the data should be a 2-bytes integer. The
value must be able cast to &lt;strong&gt;java.lang.Short&lt;/strong&gt;. Noted: only positive
number is acceptable&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.POSITIVE_SHORT)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typeshort&#34;&gt;Type.SHORT&lt;/h4&gt;
&lt;p&gt;Short type represents that the data should be a 2-bytes integer. The
value must be able cast to &lt;strong&gt;java.lang.Short&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.SHORT)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typepositive_int&#34;&gt;Type.POSITIVE_INT&lt;/h4&gt;
&lt;p&gt;Int type represents that the data should be a 4-bytes integer. The value
must be able cast to &lt;strong&gt;java.lang.Integer&lt;/strong&gt;. Noted: only positive number
is acceptable&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.POSITIVE_INT)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typeint&#34;&gt;Type.INT&lt;/h4&gt;
&lt;p&gt;Int type represents that the data should be a 4-bytes integer. The value
must be able cast to &lt;strong&gt;java.lang.Integer&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.INT)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typepositive_long&#34;&gt;Type.POSITIVE_LONG&lt;/h4&gt;
&lt;p&gt;Long type represents that the data should be a 8-bytes integer. The
value must be able cast to &lt;strong&gt;java.lang.Long&lt;/strong&gt;. Noted: only positive
number is acceptable&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.POSITIVE_LONG)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typelong&#34;&gt;Type.LONG&lt;/h4&gt;
&lt;p&gt;Long type represents that the data should be a 8-bytes integer. The
value must be able cast to &lt;strong&gt;java.lang.Long&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.LONG)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typepositive_double&#34;&gt;Type.POSITIVE_DOUBLE&lt;/h4&gt;
&lt;p&gt;Double type represents that the data should be a 8-bytes floating-point.
The value must be able cast to &lt;strong&gt;java.lang.Double&lt;/strong&gt;. Noted: only
positive number is acceptable&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.POSITIVE_DOUBLE)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typedouble&#34;&gt;Type.DOUBLE&lt;/h4&gt;
&lt;p&gt;Double type represents that the data should be a 8-bytes floating point.
The value must be able cast to &lt;strong&gt;java.lang.Double&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.DOUBLE)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typearray&#34;&gt;Type.ARRAY&lt;/h4&gt;
&lt;p&gt;Array type represents that the data should be a collection of data. We
don&amp;rsquo;t check the element data type in the collection, that is, the
following request is legal in SettingDef but will produce a weird
behavior in ohara manager. We suggest you use the same data type of
element in an array.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;key&amp;quot;: [&amp;quot;abc&amp;quot;, 123, 2.0]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.ARRAY)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;An empty array is ok and will pass the checker:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;key&amp;quot;: []
}
&lt;/code&gt;&lt;/pre&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    the default value to array value is empty
  &lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;typeclass&#34;&gt;Type.CLASS&lt;/h4&gt;
&lt;p&gt;Class type represents that the data is a class. This data type is used
to display a value that is a class. The value must be able cast to
&lt;strong&gt;java.lang.String&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.CLASS)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typepassword&#34;&gt;Type.PASSWORD&lt;/h4&gt;
&lt;p&gt;Password type represents that the data is a password. We will replace
the value by &lt;strong&gt;hidden&lt;/strong&gt; symbol in APIs. if the data type is used as
password. The value must be able cast to &lt;strong&gt;java.lang.String&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.PASSWORD)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typejdbc_table&#34;&gt;Type.JDBC_TABLE&lt;/h4&gt;
&lt;p&gt;JDBC_TABLE is a specific string type used to reminder Ohara Manager
that this field requires a &lt;strong&gt;magic&lt;/strong&gt; button to show available tables of
remote database via Query APIs. Except for the &lt;strong&gt;magic&lt;/strong&gt; in UI, there is
no other stuff for this JDBC_TYPE since kafka can&amp;rsquo;t verify the input
arguments according to other arguments. It means we can&amp;rsquo;t connect to
remote database to check the existence of input table.&lt;/p&gt;
&lt;p&gt;It is ok to replace this field by Type.STRING if you don&amp;rsquo;t use Ohara
Manager. Nevertheless, we still encourage the developer to choose the
&lt;strong&gt;fitting&lt;/strong&gt; type for your setting if you demand your user to input a
database table.&lt;/p&gt;
&lt;h4 id=&#34;typetable&#34;&gt;Type.TABLE&lt;/h4&gt;
&lt;p&gt;Table type enable you to define a setting having table structure value.
Apart from assigning Type.Table to your setting definition, you also
have to define which keys are in your table. The following example show
a case that declares a table having two columns called &lt;strong&gt;c0&lt;/strong&gt; and
&lt;strong&gt;c1&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .tableKeys(Arrays.asList(&amp;quot;c0&amp;quot;, &amp;quot;c1&amp;quot;))
    .required(Type.TABLE)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The legal value for above setting definition is shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;key&amp;quot;: [
    {
      &amp;quot;c0&amp;quot;: &amp;quot;v0&amp;quot;,
      &amp;quot;c1&amp;quot;: &amp;quot;v1&amp;quot;
    },
    {
      &amp;quot;c0&amp;quot;: &amp;quot;v2&amp;quot;,
      &amp;quot;c1&amp;quot;: &amp;quot;v3&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above example implies there is a table having two columns called
&lt;strong&gt;c0&lt;/strong&gt; and &lt;strong&gt;c1&lt;/strong&gt;. Also, you assign two values to &lt;strong&gt;c0&lt;/strong&gt; that first is
&lt;strong&gt;v0&lt;/strong&gt; and another is &lt;strong&gt;v2&lt;/strong&gt;. Ohara offers a check for Type.Table that
the input value &lt;strong&gt;must&lt;/strong&gt; match all keys in.&lt;/p&gt;
&lt;p&gt;How to get the description of above &lt;strong&gt;keys&lt;/strong&gt; ? If the setting type is
&lt;strong&gt;table&lt;/strong&gt;, the setting must have &lt;strong&gt;tableKeys&lt;/strong&gt;. It is an array of string
which shows the keys used in the table type. For instance, a setting
having table type is shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;reference&amp;quot;: &amp;quot;NONE&amp;quot;,
  &amp;quot;displayName&amp;quot;: &amp;quot;columns&amp;quot;,
  &amp;quot;internal&amp;quot;: false,
  &amp;quot;documentation&amp;quot;: &amp;quot;output schema&amp;quot;,
  &amp;quot;valueType&amp;quot;: &amp;quot;TABLE&amp;quot;,
  &amp;quot;tableKeys&amp;quot;: [
    &amp;quot;order&amp;quot;,
    &amp;quot;dataType&amp;quot;,
    &amp;quot;name&amp;quot;,
    &amp;quot;newName&amp;quot;
  ],
  &amp;quot;orderInGroup&amp;quot;: 6,
  &amp;quot;key&amp;quot;: &amp;quot;columns&amp;quot;,
  &amp;quot;necessary&amp;quot;: &amp;quot;REQUIRED&amp;quot;,
  &amp;quot;defaultValue&amp;quot;: null,
  &amp;quot;group&amp;quot;: &amp;quot;core&amp;quot;,
  &amp;quot;permission&amp;quot;: &amp;quot;EDITABLE&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    If you ignore the table keys for Type.Table, the check to your input
value is also ignored. By contrast, the table keys are useless for other
types.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    the default value to table value is empty
  &lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;typeduration&#34;&gt;Type.DURATION&lt;/h4&gt;
&lt;p&gt;The time-based amount of time is a common setting in our world. However,
it is also hard to reach the consensus about the &lt;strong&gt;string representation&lt;/strong&gt;
for a duration. For instance, the &lt;code&gt;java.time.Duration&lt;/code&gt;
prefers ISO-8601, such as PT10S. The scala.concurrent.duration.Duration
prefers simple format, such as 10 seconds. Ohara offers a official
support to Duration type so as to ease the pain of using string in
connector. When you declare a setting with duration type, ohara provides
the default check which casts input value to java Duration and scala
Duration. Also, your connector can get the &lt;strong&gt;Duration&lt;/strong&gt; from

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/custom_connector/#source-start&#34;&gt;TaskSetting&lt;/a&gt;
easily without worrying about the conversion between java and scala.
Furthermore, connector users can input both java.Duration and
scala.Duration when starting connector.&lt;/p&gt;
&lt;p&gt;The value must be castable to &lt;strong&gt;java.time.Duration&lt;/strong&gt; and it is based on
the ISO-860 duration format PnDTnHnMn.nS&lt;/p&gt;
&lt;h4 id=&#34;typeremote_port&#34;&gt;Type.REMOTE_PORT&lt;/h4&gt;
&lt;p&gt;Remote port is a common property to connector. For example, the ftp
connector needs port used to connect to source/target ftp server in
remote . Inputting an illegal port can destroy connector easily.
Declaring your type of value to Port involve a check that only the port
which is smaller than 65536 and bigger than zero can be accepted. Other
port value will be rejected in starting connector.&lt;/p&gt;
&lt;h4 id=&#34;typebinding_port&#34;&gt;Type.BINDING_PORT&lt;/h4&gt;
&lt;p&gt;This type is similar to Type.PORT except that the value mapped to
BINDING_PORT has an extra check to the availability on the target nodes.
For example, you define value 5555 as a BINDING_PORT, and you will get
a exception when you try to deploy your code on the node which is using
port 5555 as well. The legal value of binding port is between [0, 65535].&lt;/p&gt;
&lt;h4 id=&#34;typeobject_key&#34;&gt;Type.OBJECT_KEY&lt;/h4&gt;
&lt;p&gt;object key represents a format of
&lt;strong&gt;oharastream.ohara.common.setting.ObjectKey&lt;/strong&gt; for a specific object. It
consists &amp;ldquo;group&amp;rdquo; and &amp;ldquo;name&amp;rdquo; fields. In a custom application, you
should check the request contains both fields.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;key&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;abc&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typeobject_keys&#34;&gt;Type.OBJECT_KEYS&lt;/h4&gt;
&lt;p&gt;OBJECT_KEYS represents a list of
&lt;strong&gt;oharastream.ohara.common.setting.Obj&lt;/strong&gt;. Note the type of the plural
char &amp;ldquo;s&amp;rdquo;. It means the request value should pass an array.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;objectKeys&amp;quot;: [{
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;t1&amp;quot;
  }]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    the default value to table value is empty
  &lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;typetags&#34;&gt;Type.TAGS&lt;/h4&gt;
&lt;p&gt;Tags is a flexible type that accept a json object. It could use in some
circumstances that user needs to define additional values which type is
not list above.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;tags&amp;quot;: {
    &amp;quot;name&amp;quot;: &amp;quot;hello&amp;quot;,
    &amp;quot;anArray&amp;quot;: [&amp;quot;bar&amp;quot;, &amp;quot;foo&amp;quot;],
    &amp;quot;count&amp;quot;: 10,
    &amp;quot;params&amp;quot;: {
      &amp;quot;k&amp;quot;: &amp;quot;v&amp;quot;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    the default value to table value is empty
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;necessary&#34;&gt;Necessary&lt;/h2&gt;
&lt;p&gt;In Ohara world, most components have a lot of configs to offers various
usage in production. In order to simplify the settings, most configs
have default value and you can trace Necessary field to know that.&lt;/p&gt;
&lt;p&gt;Necessary field has three values.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;REQUIRED&lt;/strong&gt; &amp;mdash; this value has no default value, and it must be defined.
You may get error if you don&amp;rsquo;t give any value to it.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OPTIONAL&lt;/strong&gt; &amp;mdash; this value has no default value, but it is ok to leave nothing.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RANDOM_DEFAULT&lt;/strong&gt; &amp;mdash; the default value assigned to this value is random.
For example, all objects&amp;rsquo; name has a random string by default; The binding
port field has a random free port by default.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;checker&#34;&gt;Checker&lt;/h2&gt;
&lt;p&gt;We all love quick failure, right? A quick failure can save our resource
and time. Ohara offers many checks for your setting according to the
&lt;strong&gt;expected&lt;/strong&gt; type. For example, a setting declared &lt;strong&gt;Duration&lt;/strong&gt; type has
a checker which validate whether the input value is able to be cast to
either java.time.Duration or scala.duration.Duration. However, you are
going to design a complicated connector which has specific limit for
input value.&lt;/p&gt;
&lt;h2 id=&#34;denylist&#34;&gt;DenyList&lt;/h2&gt;
&lt;p&gt;The denyList is useful information that it offers following checks.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The restful APIs will reject the values in the denyList&lt;/li&gt;
&lt;li&gt;Ohara UI disable user to input the illegal words&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Currently, denyList is used by Array type only.&lt;/p&gt;
&lt;h2 id=&#34;recommended-values&#34;&gt;Recommended values&lt;/h2&gt;
&lt;p&gt;Recommended values is used by Ohara UI that it able to pop a list to
users when they are using UI.&lt;/p&gt;
&lt;p&gt;Currently, recommended values is used by String type only.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>User Guide</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/user_guide/</link>
      <pubDate>Wed, 17 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/user_guide/</guid>
      <description>&lt;p&gt;This documentation is for Ohara users who try to exercise or test Ohara
without writing any code. Ohara team design and implement Ohara to
provide a unparalleled platform which enable everyone to build streaming
easily and quickly. For normal users, you can manipulate Ohara through
UI interface even if you have no idea about the magic infra of Ohara.
For advanced users trying to build custom streaming, they are encouraged
to design and write application based on Ohara&amp;rsquo;s various and powerful
APIs (see 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/custom_connector/&#34;&gt;Custom Connector&lt;/a&gt;
and 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/custom_stream/&#34;&gt;Custom Stream&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Ohara consists of many services, such as&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;a href=&#34;#configurator&#34;&gt;Ohara Configurator&lt;/a&gt; &amp;mdash; the controller of Ohara.
It cooperates other services and provides the 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/&#34;&gt;Restful APIs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#manager&#34;&gt;Ohara Manager&lt;/a&gt; &amp;mdash; the UI service of Ohara. It offers a
streaming flow called &lt;strong&gt;pipeline&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#zookeeper&#34;&gt;Zookeeper&lt;/a&gt; &amp;mdash; works for Broker. It has charge of managing
the configuration of topics and health of node&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#broker&#34;&gt;Broker&lt;/a&gt; &amp;mdash; It provides the access of topics, topics&amp;rsquo; data
durability and balance.&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#worker&#34;&gt;Worker&lt;/a&gt; &amp;mdash;
It hosts and execute 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/custom_connector/&#34;&gt;Custom Connector&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#docker&#34;&gt;Docker&lt;/a&gt; &amp;mdash; It packages the configs, dependencies and binary
required by services and execute them in a isolated environments&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#k8s&#34;&gt;Kubernetes&lt;/a&gt; &amp;mdash; a management tool of docker instances&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Ohara has a complicated software stack, but most services are almost
transparent to you. For example, before creating a topic on Ohara, you
ought to set up a zookeeper cluster and a broker cluster. There are ,
unfortunately, a bunch of configs which you have to design and write for
both cluster. Ohara auto-generates most configs for you as best as it
can, and Ohara offers the the readable

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/&#34;&gt;Restful APIs&lt;/a&gt; and friendly UI to
you. All complicated configs are replaced by some simple steps showed on
UI. The 
&lt;a href=&#34;#quickstart&#34;&gt;Quick Start&lt;/a&gt; section teach you to exercise Ohara easily and quickly.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;quickstart&#34;&gt;Quick Start&lt;/h2&gt;
&lt;p&gt;The core component of Ohara is 
&lt;a href=&#34;#configurator&#34;&gt;Configurator&lt;/a&gt;. After installing

&lt;a href=&#34;#installation&#34;&gt;related tools&lt;/a&gt;, you can set up a Configurator via following docker command.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ docker run --rm -p 12345:12345 oharastream/configurator:0.11.0-SNAPSHOT --port 12345 --hostname ${host}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    click &lt;a href=&#34;#execute-configurator&#34;&gt;here&lt;/a&gt; to see more options for configurator
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;And then you can also create a manager to provide a beautiful UI based on above Ohara Configurator.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ docker run --rm -p 5050:5050 oharastream/manager:0.11.0-SNAPSHOT --port 5050 --configurator http://$ip:12345/v0
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Please replace the &lt;strong&gt;ip&lt;/strong&gt; by your host&amp;rsquo;s address
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Open your browser (we recommend 
&lt;a href=&#34;https://www.google.com/intl/zh-TW/chrome/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google Chrome&lt;/a&gt;)
and link to 
&lt;a href=&#34;http://localhost:5050/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://localhost:5050/&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;
&lt;p&gt;We all love docker, right? All Ohara services are executed by docker
container. However, it is ok to run Ohara services through

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/build/build-ohara/#build-binary&#34;&gt;assembly file&lt;/a&gt; if you
really really really hate docker.&lt;/p&gt;
&lt;h3 id=&#34;network-configurations&#34;&gt;Network Configurations&lt;/h3&gt;
&lt;p&gt;We are trying to do everything for you. However, your network your
problem (reference to Hadoop&amp;rsquo;s

&lt;a href=&#34;https://cwiki.apache.org/confluence/display/HADOOP2/YourNetworkYourProblem&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;motto&lt;/a&gt;.
A bad network configurations can bring any kind of exception in any
time, and it is hard to diagnose your network problems. In order to make
each container be able to find each other, please ensure following
common problems (reference to

&lt;a href=&#34;https://cwiki.apache.org/confluence/display/HADOOP2/YourNetworkYourProblem&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hadoop&lt;/a&gt;
again) don&amp;rsquo;t happen on your nodes.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;DNS and reverse DNS broken/non-existent.&lt;/li&gt;
&lt;li&gt;Host tables in the machines invalid.&lt;/li&gt;
&lt;li&gt;Firewalls in the hosts blocking connections.&lt;/li&gt;
&lt;li&gt;Routers blocking traffic.&lt;/li&gt;
&lt;li&gt;Hosts with multiple network cards listening/talking on the wrong NIC.&lt;/li&gt;
&lt;li&gt;Difference between the hadoop configuration files&amp;rsquo; definition of the
cluster (especially hostnames and ports) from that of the actual
cluster setup.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;After validating your network configurations layer by layer, you could
try filing issue on github if you still can&amp;rsquo;t get Ohara to work.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;We often encounter problems with network problems&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;After install Docker-ce package in CentOS,the network default policy is
block docker&amp;rsquo;s bridge to host network, You &lt;strong&gt;must&lt;/strong&gt; add a rule on the
firewall:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ sudo firewall-cmd --zone=trusted --permanent --add-interface=docker0
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;install-docker-ce-on-centos&#34;&gt;Install Docker-ce on CentOS&lt;/h3&gt;
&lt;p&gt;Docker has provided a great docs about installing docker-ce. Please
click this 
&lt;a href=&#34;https://docs.docker.com/install/linux/docker-ce/centos/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;download-images&#34;&gt;Download Ohara Images&lt;/h3&gt;
&lt;p&gt;Ohara deploys docker images on 
&lt;a href=&#34;https://hub.docker.com/u/oharastream&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;docker hub&lt;/a&gt;.
You can download images via &lt;code&gt;docker pull&lt;/code&gt; command. All images are list below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;oharastream/broker:0.11.0-SNAPSHOT&lt;/li&gt;
&lt;li&gt;oharastream/zookeeper:0.11.0-SNAPSHOT&lt;/li&gt;
&lt;li&gt;oharastream/connect-worker:0.11.0-SNAPSHOT&lt;/li&gt;
&lt;li&gt;oharastream/configurator:0.11.0-SNAPSHOT&lt;/li&gt;
&lt;li&gt;oharastream/manager:0.11.0-SNAPSHOT&lt;/li&gt;
&lt;li&gt;oharastream/stream:0.11.0-SNAPSHOT&lt;/li&gt;
&lt;li&gt;oharastream/shabondi:0.11.0-SNAPSHOT&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;execute-configurator&#34;&gt;Execute Configurator&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ docker run --rm -p ${port}:${port} --add-host ${nodeHostName}:${nodeHostIP} oharastream/configurator:0.11.0-SNAPSHOT --port ${port} --hostname ${host}
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--folder&lt;/code&gt;: the folder used to store data (default is random). Mount
the volume if you want to keep your data after restarting Configurator&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--port&lt;/code&gt;: bound by Configurator (default is random)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--add-host&lt;/code&gt;: add a host mapping to /etc/hosts in Ohara Configurator
(nodeHostName:nodeHostIP). If you have DNS server, you can just
ignore parameter of add-host.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--hostname&lt;/code&gt;: hostname to run Ohara Configurator (defaults to 0.0.0.0)&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;You can enable the jmx reporter via inputting two env variables -
&amp;ldquo;JMX_HOSTNAME&amp;rdquo; and &amp;ldquo;JMX_PORT&amp;rdquo;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;JMX_HOSTNAME&amp;rdquo; should be same as the host running Ohara
Configurator container so as to access the jmx service in docker
from outside.&lt;/li&gt;
&lt;li&gt;&amp;ldquo;JMX_PORT&amp;rdquo; should be opened by docker (for example, add &amp;ldquo;-p $JMX_PORT:$JMX_PORT&amp;rdquo;)&lt;/li&gt;
&lt;/ul&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;All services host by Ohara Configurator are based on docker technique.
By default Ohara Configurator use ssh to control the docker containers
from remote nodes (see 
&lt;a href=&#34;#docker&#34;&gt;Docker&lt;/a&gt; section).
In this mode, please make sure the ssh account
added by 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/nodes/&#34;&gt;Node APIs&lt;/a&gt; should
have sudo permission to run docker command (see

&lt;a href=&#34;https://docs.docker.com/install/linux/linux-postinstall/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt; for
related steps).&lt;/p&gt;
&lt;h3 id=&#34;configurator-data&#34;&gt;Keep the data of Configurator&lt;/h3&gt;
&lt;p&gt;Ohara Configurator demand a folder to store &lt;code&gt;data&lt;/code&gt; and

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/files/&#34;&gt;jars&lt;/a&gt;. As Ohara Configurator
is running in docker container, you have to mount the volume, which is
located on container host, on the home folder of Ohara Configurator if
you want to keep all data of Ohara Configurator. The following example
is to mount a local folder (/tmp/configurator) on
&lt;strong&gt;/home/ohara/configurator&lt;/strong&gt; of Ohara Configurator&amp;rsquo;s container.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ mkdir /tmp/configurator
$ docker run -v /tmp/configurator:/home/ohara/configurator \
         -p 12345:12345 \
         oharastream/configurator:0.11.0-SNAPSHOT \
         --port 12345 \
         --hostname ${host} \
         --folder /home/ohara/configurator
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The user account in docker container is &lt;strong&gt;ohara&lt;/strong&gt;, and hence it would be
better to set the folder under the &lt;strong&gt;/home/ohara&lt;/strong&gt;. Otherwise, you will
encounter the permission error. Noted that you have tell Ohara
Configurator to save data in the folder referencing to the outside
folder. Otherwise, Ohara Configurator flush all data to a random folder.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How to solve the start configurator container permission denied issue?&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;You must confirm your host username is the ohara and UID is 1000.
Please refer to issue 
&lt;a href=&#34;https://github.com/oharastream/ohara/issues/2573

&#34;&gt;#2573&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Please confirm the &lt;strong&gt;/tmp/configurator&lt;/strong&gt; host path owner is ohara user
and have to write permission.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;execute-manager&#34;&gt;Execute Manager&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ docker run --rm -p 5050:5050 oharastream/manager:0.11.0-SNAPSHOT --port 5050 --configurator http://localhost:12345/v0
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--port&lt;/code&gt;: bound by manager (default is 5050)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--configurator&lt;/code&gt;: basic form of restful API of Ohara Configurator&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;execute-postgresql-instance&#34;&gt;Execute PostgreSQL Instance&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ docker run -d --rm --name postgresql -p 5432:5432 --env POSTGRES_DB=${DB_NAME} --env POSTGRES_USER=${USER_NAME} --env POSTGRES_PASSWORD=${PASSWORD} -it islandsystems/postgresql:9.2.24
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;POSTGRES_DB: PostgreSQL DataBase name&lt;/li&gt;
&lt;li&gt;POSTGRES_USER: PostgreSQL login user name.&lt;/li&gt;
&lt;li&gt;POSTGRES_PASSWORD: PostgreSQL login password.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    POSTGRES_USER=&amp;quot;user&amp;rdquo; is illegal to postgresql
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;execute-ftp-instance&#34;&gt;Execute FTP Instance&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ docker run --rm -p 10000-10011:10000-10011 oharastream/backend:0.11.0-SNAPSHOT oharastream.ohara.testing.service.FtpServer --controlPort 10000 --dataPorts 10001-10011 --user ${UserName} --password ${Password} --hostname ${hostIP or hostName}
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;controlPort: bound by FTP Server&lt;/li&gt;
&lt;li&gt;dataPorts: bound by data transportation in FTP Server&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;configurator&#34;&gt;Ohara Configurator&lt;/h2&gt;
&lt;p&gt;Ohara consists of many services, and Ohara Configurator plays the most
important rule which coordinates all services and offers a bunch of
restful APIs to user to get all under control. The brief architecture of
Ohara Configurator is shown below.&lt;/p&gt;















&lt;figure id=&#34;figure-configurator-architecture&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/configurator_arch.jpg&#34; data-caption=&#34;Configurator architecture&#34;&gt;


  &lt;img src=&#34;../img/configurator_arch.jpg&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Configurator architecture
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;The introduction of each components are shown below. Feel free to trace
the component in which you have interest.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#configurator-route&#34;&gt;Route of Ohara Configurator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#configurator-store&#34;&gt;Store of Ohara Configurator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#configurator-cache&#34;&gt;Cache of Ohara Configurator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#configurator-collie&#34;&gt;Collie of Ohara Configurator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#configurator-client&#34;&gt;Client of Ohara Configurator&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;configurator-route&#34;&gt;Route of Configurator&lt;/h3&gt;
&lt;p&gt;Ohara Configurator leverages the akka-http to implements the rest server
and handle the conversion of json objects. You can click our

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/&#34;&gt;RESTful API docs&lt;/a&gt; to see all
public APIs and introduction.&lt;/p&gt;
&lt;p&gt;The APIs supported by Ohara Configurator is only the Restful APIs. Of
course, you can raise a question to us - why we choose the Restful APIs
rather than pure Java APIs? The answer is - We all hate the other
programming language except for the one we are using. However, we always
need to work with other people who are typing terrible and weird code,
and all they want to do is to call your APIs. In order to save our time
from co-working with them, providing the Restful APIs is always to be
our solution. For another reason, Ohara Configurator is not in charge of
I/O flow. Coordinating all services requires small bandwidth only. We
don&amp;rsquo;t need to care for the performance issue about Restful APIs.&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You can use our internal scala APIs to control Configurator. The
library is called ohara-client and it covers all Restful APIs of
Configurator. However, we don&amp;rsquo;t guarantee any compatibility for
ohara-client.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;configurator-store&#34;&gt;Store of Configurator&lt;/h3&gt;
&lt;p&gt;All settings you request to Ohara Configurator are saved in Store, such
as connector settings, cluster information and pipeline description. The
default implementation of Store is 
&lt;a href=&#34;https://rocksdb.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RocksDB&lt;/a&gt; which
offers fast in-memory access and persists all data on disk. Please read
this 
&lt;a href=&#34;#configurator-data&#34;&gt;section&lt;/a&gt; about mounting host&amp;rsquo;s
folder on docker container.&lt;/p&gt;
&lt;h3 id=&#34;configurator-cache&#34;&gt;Cache of Configurator&lt;/h3&gt;
&lt;p&gt;The cost of coordinating countless services is the big &lt;strong&gt;latency&lt;/strong&gt;. For
example, 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/topics/&#34;&gt;Topic APIs&lt;/a&gt; allows
you to fetch metrics from different

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/brokers/&#34;&gt;broker clusters&lt;/a&gt;. Ohara
Configurator has to file a bunch of connections to different clusters to
retrieve all requisite information, and, of course, the &lt;strong&gt;connections&lt;/strong&gt;
bring the large latency to the GET request. Hence, Ohara Configurator
sets up a inner cache which stores the data from remote clusters. It
reduces the latency from seconds to milliseconds and allay your anger.
In order to make all data up-to-date as much as possible, the cache
auto-refreshes timeout data in the background. It brings some extra cost
of building connections to remote clusters.&lt;/p&gt;
&lt;h3 id=&#34;configurator-collie&#34;&gt;Collie of Configurator&lt;/h3&gt;
&lt;p&gt;Apart from the data flow, Ohara Configurator is also doable to manage
clusters for you. For instance, you can&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;add 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/nodes/&#34;&gt;node&lt;/a&gt; to Ohara Configurator&lt;/li&gt;
&lt;li&gt;deploy a 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/zookeepers/&#34;&gt;zookeeper cluster&lt;/a&gt; on the node&lt;/li&gt;
&lt;li&gt;deploy a 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/brokers/&#34;&gt;broker cluster&lt;/a&gt; on the node as well&lt;/li&gt;
&lt;li&gt;deploy a 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/workers/&#34;&gt;worker cluster&lt;/a&gt; on the node&lt;/li&gt;
&lt;li&gt;finally, you can run a connector to stream your data and all
services you have created are hosted by Ohara Configurator&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In order to host your services safely and quickly, Ohara Configurator
leverages the Docker technique that all services are packaged to a
container and executed on the node(s) specified by you. As a good
software stack, Ohara Configurator creates a container manager, which is
called &lt;strong&gt;collie&lt;/strong&gt;, to wrap Restful APIs of 
&lt;a href=&#34;#k8s&#34;&gt;k8s&lt;/a&gt;
and ssh command to Scala APIs.&lt;/p&gt;
&lt;h3 id=&#34;configurator-client&#34;&gt;Client of Configurator&lt;/h3&gt;
&lt;p&gt;As a good programmer, we all love to reuse the code. However, it is hard
to trust all third-party libraries guarantee the suitable compatibility
policy. The Client code in Ohara is a collection of wrap for all client
codes to services, such as broker and worker, so as not to be badly hurt
by the update of services.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;manager&#34;&gt;Ohara Manager&lt;/h2&gt;
&lt;p&gt;Ohara Manager is the user interface (UI) of Ohara. It&amp;rsquo;s built with the
standard web technologies and so can be run in almost all the modern
browsers (We recommend you to use Google chrome though). Ohara Manager
talks to Ohara Configurator via its RESTful APIs under the hook which
then connects with the rest of Ohara services.&lt;/p&gt;
&lt;p&gt;Ohara Manager was built and designed with the user&amp;rsquo;s needs in mind. We
aimed to reduce the pain of complex operations that often required in a
big data system. With Ohara Manager, you can create your own services,
pipelines and working with data streaming without touching a single line
of code.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Following is a quick walk through of Ohara Manager&amp;rsquo;s user interface:&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;pipelines&#34;&gt;Pipelines&lt;/h3&gt;
&lt;p&gt;Pipeline list page is where you can view, create, edit and delete
pipelines.&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/pipelines.png&#34; &gt;


  &lt;img src=&#34;../img/pipelines.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;Inside the new/edit pipeline page, you can create and play around with
your pipelines here. This is also where you can run and stop your
pipelines. The pipeline graph helps you to easily visualize the pipeline
that you&amp;rsquo;re working on. Also, you can edit and tweak a connector&amp;rsquo;s
configuration by clicking on the graph and edit the configuration form
which will be displayed in the sidebar. We know it&amp;rsquo;s sometimes tedious
and time consuming to edit the configuration and it&amp;rsquo;s also frustrating
when you lose all of your configuration without saving them! That&amp;rsquo;s why
we made these configuration forms automatically save changes for you.
Whenever you type in a text field, choose a new topic form a dropdown,
the changes will be saved immediately.&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/pipelines_new.png&#34; &gt;


  &lt;img src=&#34;../img/pipelines_new.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;Please note that a pipeline can only be added to a workspace, so
before creating pipelines, you will need to 
&lt;a href=&#34;#workspaces&#34;&gt;create a workspace first&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;nodes&#34;&gt;Nodes&lt;/h3&gt;
&lt;p&gt;This is where you create and edit Ohara Nodes. These nodes are usually
your VMs. When you&amp;rsquo;re starting a new Ohara Configurator. You can
optionally supply some node information with the CLI command. The node
you supplied to the CLI will then be listed in this page.&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/nodes.png&#34; &gt;


  &lt;img src=&#34;../img/nodes.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h3 id=&#34;workspaces&#34;&gt;Workspaces&lt;/h3&gt;
&lt;p&gt;A workspace contains multiple Ohara services including: Zookeepers,
Brokers and Workers. You can create a workspace and add new node, topic
and stream application in these pages.&lt;/p&gt;















&lt;figure id=&#34;figure-ohara-manager-workspaces-page&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/workspaces.png&#34; data-caption=&#34;Ohara Manager Workspaces page&#34;&gt;


  &lt;img src=&#34;../img/workspaces.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Ohara Manager Workspaces page
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Overview&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;Overview page is like a dashboard of the workspace. You can view the
services, connectors, topics and stream jars that are using in this
workspace&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/workspaces_overview.png&#34; &gt;


  &lt;img src=&#34;../img/workspaces_overview.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Nodes&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;When creating a workspace, you can choose which node to deploy your
services. But you tweak the node settings here.&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/workspaces_nodes.png&#34; &gt;


  &lt;img src=&#34;../img/workspaces_nodes.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Topics&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;You can add new topics to your workspace as well as deleting them
here.&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/workspaces_topics.png&#34; &gt;


  &lt;img src=&#34;../img/workspaces_topics.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Stream jars&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;Same like the topics page, you can add and delete stream jars in
this page&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/workspaces_stream_jars.png&#34; &gt;


  &lt;img src=&#34;../img/workspaces_stream_jars.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you&amp;rsquo;d like to learn more about the development setup or have issue
starting/working with it. Please see

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/manager_dev_guide/&#34;&gt;Ohara Manager Development Guideline&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;zookeeper&#34;&gt;Zookeeper&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://zookeeper.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Zookeeper&lt;/a&gt; plays an important role in
Ohara that it persists metadata for kafka and monitors the running nodes
of kafka. Setting up a zookeeper cluster is always the first phase
before you start to use Ohara to host your clusters. It may be weird,
however, to you since this cryptic service is almost transparent to you.
Currently, zookeeper cluster exists only for kafka. At any rate, you are
still doable to access zookeeper via any zk client if you have to.&lt;/p&gt;
&lt;p&gt;As a result of algorithm used by zookeeper, we recommend your zookeeper
cluster should have 2n + 1 nodes which can address the best reliability
and availability
(
&lt;a href=&#34;https://stackoverflow.com/questions/4228227/what-does-2n-1-quorum-mean&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;related discussion&lt;/a&gt;).
In most cases, running a zookeeper cluster with 3 servers is enough to
your production because we don&amp;rsquo;t put our data flow on zookeeper cluster.
However, you should consider higher number of nodes if your production
does care for the recovery time of node crash. More nodes in zookeeper
cluster brings more time to you for fixing your broken zookeeper
cluster.&lt;/p&gt;
&lt;p&gt;Ohara is responsible for creating your zookeeper cluster, and hence
Ohara also auto-generate most configs used by a zookeeper cluster. A
basic auto-generated configs file to zookeeper cluster is shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tickTime=2000
initLimit=10
syncLimit=5
maxClientCnxns=60
clientPort=2181
dataDir=/tmp/zookeeper/data
server.0=node00:2888:3888
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Most options are auto-generated by Ohara Configurator, and

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/zookeepers/#create-properties&#34;&gt;Zookeeper APIs&lt;/a&gt;
displays the configurable settings to user.
Feel free to file an issue to Ohara community if you have better configs for zookeeper.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;broker&#34;&gt;Broker&lt;/h2&gt;
&lt;p&gt;After setting up a 
&lt;a href=&#34;#zookeeepr&#34;&gt;Zookeeper cluster&lt;/a&gt;,
you have to build a broker cluster before going on your streaming trip.

&lt;a href=&#34;https://kafka.apache.org/intro&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Broker&lt;/a&gt; is the streaming center of
Ohara that all applications on Ohara goes through brokers to switch
data. There are many stories about Ohara leverages the broker to
complete countless significant works. But the most important usage of
Brokers for Ohara is the 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/topics/&#34;&gt;Topic&lt;/a&gt;.
Each endpoint in

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/pipelines/&#34;&gt;Pipeline&lt;/a&gt; must connect
to/from a topic, and each topic in Ohara is mapped to a topic in broker.
It means all data sent/received to/from topic is implemented by a true
connection to a broker.&lt;/p&gt;
&lt;p&gt;As a result of addressing scalability, a topic is split to many
&lt;strong&gt;partitions&lt;/strong&gt; distributed on different brokers. It implies the number
of brokers directly impact the performance of Ohara

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/pipelines/&#34;&gt;Pipeline&lt;/a&gt;. If you are
streaming a bunch of data and there is only a broker in your broker
cluster, you will get a slow streaming since all data in the streaming
are processed by the single broker. Hence, please be careful on
deploying your broker cluster. But you don&amp;rsquo;t worry about the incorrect
settings to cluster. Ohara provides many flexible

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/brokers/&#34;&gt;Broker APIs&lt;/a&gt; to
increase/decrease nodes of a running broker cluster. You are able to
scale your cluster up/down arbitrarily via Ohara APIs.&lt;/p&gt;
&lt;p&gt;In order to simplify your life, Ohara auto-generate most configs for
your broker cluster.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
num.partitions=1
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
log.retention.hours=168
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000
zookeeper.connection.timeout.ms=6000
group.initial.rebalance.delay.ms=0
broker.id=0
listeners=PLAINTEXT://:9092
log.dirs=/tmp/broker/data
zookeeper.connect=node00:2181
advertised.listeners=PLAINTEXT://node00:9092
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Most options are auto-generated by Ohara Configurator, and

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/brokers/&#34;&gt;Broker APIs&lt;/a&gt;
displays the configurable settings to user. Ohara community always
welcomes user to raise issue about &lt;strong&gt;we should give a better default
configs&lt;/strong&gt; or &lt;strong&gt;we should enable user to change xxx config&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;worker&#34;&gt;Worker&lt;/h2&gt;
&lt;p&gt;In contrast with 
&lt;a href=&#34;#broker&#34;&gt;Broker&lt;/a&gt;,
Worker takes charge of hosting and distributing your
applications. Via Ohara Configurator you can deploy applications on a
worker cluster. Worker executes your application on a single thread and
handle following issues for you.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;tolerance - worker cluster auto-migrate your application from a dead
node to another live one.&lt;/li&gt;
&lt;li&gt;distribution - you can decide the number of threads invoked by
worker cluster to run your applications. Of course, the threads are
distributed across whole cluster.&lt;/li&gt;
&lt;li&gt;Data - Worker is in charge of fetching/pushing data from/to topics
specified by your application. All you have to do is to process the
data.&lt;/li&gt;
&lt;li&gt;consistency - The offset of data in/from topics are auto-record by
worker. Also, for advanced user, there are a lot of offset-related
APIs, which is exposed to your application, that you can control the
offsets of data. 1.balance - worker cluster keeps tracing the
loading for each worker node and auto-balance the loading for heavy
one. Via 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/workers/&#34;&gt;Ohara APIs&lt;/a&gt;,
you can increase the node of a running worker cluster easily if you
do want to scala the throughput up.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Setting up a worker cluster also requires many configurations. Ohara
Configurator auto-fill the following settings for you when you request
to create a worker cluster.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;key.converter=org.apache.kafka.connect.json.JsonConverter
value.converter=org.apache.kafka.connect.json.JsonConverter
key.converter.schemas.enable=true
value.converter.schemas.enable=true
offset.flush.interval.ms=10000
internal.key.converter=org.apache.kafka.connect.json.JsonConverter
internal.value.converter=org.apache.kafka.connect.json.JsonConverter
internal.key.converter.schemas.enable=false
internal.value.converter.schemas.enable=false
group.id=339f4352b3
offset.storage.topic=offset-8e5c68825d
offset.storage.replication.factor=1
offset.storage.partitions=1
config.storage.topic=setting-2b86167398
config.storage.replication.factor=1
status.storage.topic=status-4841be564b
status.storage.replication.factor=1
status.storage.partitions=1
plugin.path=/tmp/plugins
bootstrap.servers=node00:9092
rest.port=8083
rest.advertised.host.name=node00
rest.advertised.port=8083
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Most options are auto-generated by Ohara Configurator, and

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/workers/#rest-workers-create&#34;&gt;Worker APIs&lt;/a&gt;
displays the configurable settings to user. Welcome you to file an issue
to request more control right of worker cluster.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;docker&#34;&gt;Docker&lt;/h2&gt;
&lt;p&gt;All services host by Ohara are based on docker containers, such as

&lt;a href=&#34;#configurator&#34;&gt;Configurator&lt;/a&gt;, 
&lt;a href=&#34;#manager&#34;&gt;Manager&lt;/a&gt;,

&lt;a href=&#34;#zookeeper&#34;&gt;Zookeeper&lt;/a&gt;,

&lt;a href=&#34;#broker&#34;&gt;Broker&lt;/a&gt; and 
&lt;a href=&#34;#worker&#34;&gt;Worker&lt;/a&gt;.
You should install suggested version of Docker before enjoying Ohara service
(see 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/build/build-ohara/&#34;&gt;how to build&lt;/a&gt; for prerequisite).&lt;/p&gt;
&lt;p&gt;The post-installation for all docker nodes are listed below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/build/build-ohara/#prerequisites&#34;&gt;Install the supported version of docker&lt;/a&gt; -
Ohara community does not support the legacy docker.&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#download-images&#34;&gt;download all ohara images&lt;/a&gt; -
Ohara Configurator expect all images are available from local disk rather than network.&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://docs.docker.com/install/linux/linux-postinstall/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;create a user account which can access docker without sudo&lt;/a&gt; -
Ohara Configurator may use ssh to control docker of remote node.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    all containers created by Ohara, which is on docker mode, have a
specific label - createdByOhara - this label enables Ohara to ignore the
unrelated containers. For examples, You request Ohara Configurator (of
course, it is on docker mode) to create a zookeeper service. The
container of zookeeper service will have label - createdByOhara=docker.
  &lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 id=&#34;k8s&#34;&gt;Kubernetes&lt;/h2&gt;
&lt;p&gt;Kubernetes is a managed container platform. It can across different
container communication of a node. solve more deploy multiple a node
container problems, below is Kubernetes advantage:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Automatically deploy Docker container&lt;/li&gt;
&lt;li&gt;Docker container resource manage and scaling&lt;/li&gt;
&lt;li&gt;Orcherstrate docker container on multiple hosts&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;About details please refer:
&lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/&#34;&gt;https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ohara builds multiple docker images. This includes zookeeper, broker,
and connect-worker. These services can be run and controlled through
Kubernetes and making container management a lot easier. Before running
any Ohara containers, you need to install Kubernetes first. We&amp;rsquo;ll walk
you through this process with a few k8s commands:&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    all containers created by Ohara, which is on k8s mode, have a specific
label - createdByOhara - this label enables Ohara to ignore the
unrelated containers. For examples, You request Ohara Configurator (of
course, it is on k8s mode) to create a zookeeper service. The container
of zookeeper service will have label - createdByOhara=k8s.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;install-distribution-mode-for-kubernetes&#34;&gt;Install distribution mode for Kubernetes&lt;/h3&gt;
&lt;h4 id=&#34;hardware-requirement&#34;&gt;Hardware requirement&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;2 CPUs or more&lt;/li&gt;
&lt;li&gt;2 GB or more of RAM per machine&lt;/li&gt;
&lt;li&gt;Full network connectivity between all machines in the cluster&lt;/li&gt;
&lt;li&gt;Swap disabled&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    &lt;ul&gt;
&lt;li&gt;Ohara support install Kubernetes shell script OS only CentOS7&lt;/li&gt;
&lt;li&gt;More details is
&lt;a href=&#34;https://kubernetes.io/docs/setup/independent/install-kubeadm/#before-you-begin&#34;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;step-1-install-kubernetes-master-node&#34;&gt;Step 1. Install Kubernetes master node&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Switch to root user
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ su root
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    &lt;strong&gt;Why change to root user?&lt;/strong&gt;
Use the root user to install Kubernetes is simple and convenient. Avoid
changing not an admin user. Of course, you can use the admin user and
add the &amp;ldquo;sudo&amp;rdquo; keyword to execute install the Kubernetes shell script.
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Change directory to &lt;code&gt;kubernetes/distribute&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# cd $OHARA_HOME/kubernetes/distribute
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run &lt;code&gt;bash k8s-master-install.sh ${Your_K8S_Master_Host_IP}&lt;/code&gt; to
install Kubernetes master&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# bash k8s-master-install.sh ${Your_K8S_Master_Host_IP}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Token and hash will be used in worker installation later on&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# cat /tmp/k8s-install-info.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The token and hash should look like the following:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# kubeadm join 10.100.0.178:6443 --token 14aoza.xpgpa26br32sxwl8 --discovery-token-ca-cert-hash sha256:f5614e6b6376f7559910e66bc014df63398feb7411fe6d0e7057531d7143d47b
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;step-2-install-kubernetes-worker-node&#34;&gt;Step 2. Install Kubernetes worker node&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Switch to root&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ su root
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Goto &lt;code&gt;kubernetes/distribute&lt;/code&gt; directory&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# cd $OHARA_HOME/kubernetes/distribute 
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run following command in your terminal:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# bash k8s-worker-install.sh ${Your_K8S_Master_Host_IP} ${TOKEN} ${HASH_CODE}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;&lt;strong&gt;TOKEN&lt;/strong&gt; and &lt;strong&gt;HASH_CODE&lt;/strong&gt; can be found in the
/tmp/k8s-install-info.txt file of Kubernetes master, the one we
mention in the previous steps&lt;/p&gt;
&lt;p&gt;For example:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# bash k8s-worker-install.sh 10.100.0.178 14aoza.xpgpa26br32sxwl8 sha256:f5614e6b6376f7559910e66bc014df63398feb7411fe6d0e7057531d7143d47b
&lt;/code&gt;&lt;/pre&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;step-3-ensure-the-k8s-api-server-is-running-properly&#34;&gt;Step 3. Ensure the K8S API server is running properly&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Log into Kubernetes master and use the following command to see if these
Kubernetes nodes are running properly:
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# kubectl get nodes
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;You can check Kubernetes node status like the following:
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# curl -X GET http://${Your_K8S_Master_Host_IP}:8080/api/v1/nodes
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;troubleshooting&#34;&gt;Troubleshooting&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;How to autostart the Kubernetes API proxy server after reboot server?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Copy &amp;ldquo;ohara/kubernetes/k8sproxyserver.service&amp;rdquo; file to your
Kubernetes master server &amp;ldquo;/etc/systemd/system&amp;rdquo; path&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Below is setting autostart the command to run the Kubernetes API
proxy server &lt;code&gt;(default port is 8080)&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# systemctl enable k8sproxyserver.service
# systemctl start k8sproxyserver.service
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;how-to-use-kubernetes-in-ohara&#34;&gt;How to use Kubernetes in Ohara?&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;You must create the service to Kubernetes for DNS use in kubernetes
master host, Below is the command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# cd $OHARA_HOME/kubernetes
# kubectl create -f dns-service.yaml
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Below is an example command to run Ohara configurator service for K8S mode:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# docker run --rm \
             -p 5000:5000 \
             --add-host ${K8S_WORKER01_HOSTNAME}:${K8S_WORKER01_IP} \
             --add-host ${K8S_WORKER02_HOSTNAME}:${K8S_WORKER02_IP} \
             oharastream/configurator:$|version| \
             --port 5000 \
             --hostname ${Start Configurator Host Name} \
             --k8s http://${Your_K8S_Master_Host_IP}:8080/api/v1
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--add-host&lt;/code&gt;: Add all k8s worker hostname and ip information to
configurator container /etc/hosts file. If you have DNS server, you
can just ignore parameter of &lt;code&gt;--add-host&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--k8s-namespace&lt;/code&gt;: If you don&amp;rsquo;t use the Kubernetes default namespace,
you can assign the &amp;ndash;k8s-namespace argument to set other the Kubernetes namespace.
Kubernetes namespace default value is &amp;ldquo;default&amp;rdquo; string&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--k8s-metrics-server&lt;/code&gt;: If you have installed the Kubernetes metrics
server, you can set metrics server URL to monitor your Kubernetes node
resource. Example: &lt;code&gt;--k8s-metrics-server http://ohara-kubernetes:8080/apis&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--k8s&lt;/code&gt;: Assignment your K8S API server HTTP URL&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use Ohara configurator to create a zookeeper and broker in
Kubernetes pod for the test:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# Add Ohara Node example
$ curl -H &amp;quot;Content-Type: application/json&amp;quot; \
       -X POST \
       -d &#39;{&amp;quot;hostname&amp;quot;: &amp;quot;${K8S_WORKER01_HOSTNAME}&amp;quot;, \
            &amp;quot;port&amp;quot;: 22, \
            &amp;quot;user&amp;quot;: &amp;quot;${USERNAME}&amp;quot;, \
            &amp;quot;password&amp;quot;: &amp;quot;${PASSWORD}&amp;quot;}&#39; \
       http://${CONFIGURATOR_HOSTNAME_OR_IP}:5000/v0/nodes
  
$ curl -H &amp;quot;Content-Type: application/json&amp;quot; \
       -X POST \
       -d &#39;{&amp;quot;hostname&amp;quot;: &amp;quot;${K8S_WORKER02_HOSTNAME}&amp;quot;, \
            &amp;quot;port&amp;quot;: 22, \
            &amp;quot;user&amp;quot;: &amp;quot;${USERNAME}&amp;quot;, \
            &amp;quot;password&amp;quot;: &amp;quot;${PASSWORD}&amp;quot;}&#39; \
       http://${CONFIGURATOR_HOSTNAME_OR_IP}:5000/v0/nodes
  
# You must pre pull docker image in the ${K8S_WORKER01_HOSTNAME} and ${K8S_WORKER02_HOSTNAME} host, Below is command:
docker pull oharastream/zookeeper:0.11.0-SNAPSHOT
docker pull oharastream/broker:0.11.0-SNAPSHOT
  
# Create Zookeeper cluster service
$ curl -H &amp;quot;Content-Type: application/json&amp;quot; \
       -X POST \
       -d &#39;{&amp;quot;name&amp;quot;: &amp;quot;zk&amp;quot;, \
            &amp;quot;clientPort&amp;quot;: 2181, \
            &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/zookeeper:$|version|&amp;quot;, \
            &amp;quot;peerPort&amp;quot;: 2000, \
            &amp;quot;electionPort&amp;quot;: 2001, \
            &amp;quot;nodeNames&amp;quot;: [&amp;quot;${K8S_WORKER01_HOSTNAME}&amp;quot;]}&#39; \
       http://${CONFIGURATOR_HOSTNAME_OR_IP}:5000/v0/zookeepers
  
# Start Zookeeper cluster service
$ curl -H &amp;quot;Content-Type: application/json&amp;quot; -X PUT http://${CONFIGURATOR_HOSTNAME_OR_IP}:5000/v0/zookeepers/zk/start
  
# Create Broker service example
$ curl -H &amp;quot;Content-Type: application/json&amp;quot; \
       -X POST \
       -d &#39;{&amp;quot;name&amp;quot;: &amp;quot;bk&amp;quot;, \
            &amp;quot;clientPort&amp;quot;: 9092, \
            &amp;quot;zookeeperClusterName&amp;quot;: &amp;quot;zk&amp;quot;, \
            &amp;quot;nodeNames&amp;quot;: [&amp;quot;${K8S_WORKER02_HOSTNAME}&amp;quot;]}&#39; \
       http://${CONFIGURATOR_HOSTNAME_OR_IP}:5000/v0/brokers
  
# Start Broker cluster service
$ curl -H &amp;quot;Content-Type: application/json&amp;quot; -X PUT http://${CONFIGURATOR_HOSTNAME_OR_IP}:5000/v0/brokers/bk/start
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You can use the &lt;strong&gt;kubectl&lt;/strong&gt; command to get zookeeper and broker pod
status with the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# kubectl get pods
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;how-to-install-k8s-metrics-server&#34;&gt;How to install K8S metrics server?&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;You must install the git command to pull the Kubernetes metrics
server source code from the repository to deploy metrics server,
below is sample command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# yum install -y git
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;After complete install git, you can pull the K8S metrics server
source code, below is sample command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# git clone https://github.com/kubernetes-sigs/metrics-server.git
# git checkout tags/v0.3.7 -b v0.3.7
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There should encounter an issue that kubelet and apiserver unable to
communicate with metric-server with default setting. Please use
following YAML setting to override the content of
&lt;strong&gt;deploy/1.8+/metrics-server-deployment.yaml&lt;/strong&gt; file.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: metrics-server
  namespace: kube-system
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: metrics-server
  namespace: kube-system
  labels:
    k8s-app: metrics-server
spec:
  selector:
    matchLabels:
      k8s-app: metrics-server
  template:
    metadata:
      name: metrics-server
      labels:
        k8s-app: metrics-server
    spec:
      serviceAccountName: metrics-server
      volumes:
      # mount in tmp so we can safely use from-scratch images and/or read-only containers
      - name: tmp-dir
        emptyDir: {}
      containers:
      - name: metrics-server
        command:
        - /metrics-server
        - --kubelet-preferred-address-types=InternalIP
        - --kubelet-insecure-tls
        image: k8s.gcr.io/metrics-server-amd64:v0.3.6
        args:
          - --cert-dir=/tmp
          - --secure-port=4443
        ports:
        - name: main-port
          containerPort: 4443
          protocol: TCP
        imagePullPolicy: Always
        volumeMounts:
        - name: tmp-dir
          mountPath: /tmp
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    For more details please refer to &lt;a href=&#34;https://github.com/kubernetes-sigs/metrics-server/issues/131&#34;&gt;here&lt;/a&gt;.
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Deploy the Kubernetes metrics server, below is the command:
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# kubectl apply -f deploy/1.8+
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;Confirm the Kubernetes metrics service is installed complete, you
can input the URL to the browser, below is the example:
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;http://${Your_Kubernetes_Master_HostName_OR_IP}:8080/apis/metrics.k8s.io/v1beta1/nodes
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You maybe wait seconds time to receive the Kubernetes node metrics data.&lt;/p&gt;
&lt;h4 id=&#34;how-to-revert-k8s-environment-setting&#34;&gt;How to revert K8S environment setting?&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;You must stop the K8S API server with this command: &lt;code&gt;kubeadm reset&lt;/code&gt; command.&lt;/li&gt;
&lt;li&gt;More details is 
&lt;a href=&#34;https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-reset&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;how-to-get-the-log-info-in-container-for-debug&#34;&gt;How to get the log info in container for debug?&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;First, log into Kubernetes&amp;rsquo; master server&lt;/li&gt;
&lt;li&gt;List all Kubernetes pod name to query
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# kubectl get pods
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;Get log info in container
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# kubectl logs ${Your_K8S_Pod_Name}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;other&#34;&gt;Other&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Ohara K8SClient ImagePullPolicy default is IfNotPresent.&lt;/li&gt;
&lt;li&gt;Please remember to start K8S API server after you reboot the K8S master server:
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# nohup kubectl proxy --accept-hosts=^*$ --address=$Your_master_host_IP --port=8080 &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Docker and Docker-compose</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/docker/</link>
      <pubDate>Tue, 16 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/docker/</guid>
      <description>&lt;h2 id=&#34;why-we-need-docker-compose&#34;&gt;Why we need docker-compose&lt;/h2&gt;
&lt;p&gt;Ohara is good at connecting to various systems to collect, transform, aggregate
(and other operations you can imagine) data. In order to test Ohara, we need a
way to run a bunch of systems simultaneously. We can build a heavy infra to iron
out this problem. Or we can leverage docker-compose to host various systems &amp;ldquo;locally&amp;rdquo;
(yes, you need a powerful machine to use Ohara&amp;rsquo;s docker-compose file).&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Centos 7.6+ (supported by official community. However, other
GNU/Linux should work well also)&lt;/li&gt;
&lt;li&gt;Docker 18.09+&lt;/li&gt;
&lt;li&gt;Docker-compose 1.23.2+&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;how-to-install&#34;&gt;How to install&lt;/h2&gt;
&lt;h3 id=&#34;install-docker&#34;&gt;Install docker&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;This section is a clone of &lt;a href=&#34;https://docs.docker.com/install/linux/docker-ce/centos/&#34;&gt;https://docs.docker.com/install/linux/docker-ce/centos/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Uninstall old versions&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ sudo yum remove docker \
                  docker-client \
                  docker-client-latest \
                  docker-common \
                  docker-latest \
                  docker-latest-logrotate \
                  docker-logrotate \
                  docker-engine
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Install required packages&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ sudo yum install -y yum-utils \
    device-mapper-persistent-data \
    lvm2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Install using the repository&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ sudo yum-config-manager \
    --add-repo \
    https://download.docker.com/linux/centos/docker-ce.repo
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Install docker-ce&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ sudo yum install docker-ce
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;install-docker-compose&#34;&gt;Install Docker-compose&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ wget https://github.com/docker/compose/releases/download/1.23.2/docker-compose-Linux-x86_64 -O docker-compose
$ sudo chmod +x ./docker-compose
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    see &lt;a href=&#34;https://github.com/docker/compose/releases&#34;&gt;https://github.com/docker/compose/releases&lt;/a&gt; for more details
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;how-to-&#34;&gt;How to &amp;hellip;&lt;/h2&gt;
&lt;h3 id=&#34;start-services-by-docker-compose-file&#34;&gt;Start services by docker-compose file&lt;/h3&gt;
&lt;p&gt;Before start services, you must set postgresql connection info for
environment variable, example:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export POSTGRES_DB=postgres
export POSTGRES_USER=username
export POSTGRES_PASSWORD=password
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start services command&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ./docker-compose -f {docker-compose file} up
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;stop-services&#34;&gt;Stop services&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ctrl+c
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We are talking about tests, right? We don&amp;rsquo;t care about how to shut down services gracefully&lt;/p&gt;
&lt;h3 id=&#34;clean-up-all-containers&#34;&gt;Clean up all containers&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ docker rm -f $(docker ps -q -a)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We are talking about tests, right? You should have a machine for testing
only so it is ok to remove all containers quickly. That does simplify
your work and life.&lt;/p&gt;
&lt;h3 id=&#34;enable-ipv4-ip-forwarding&#34;&gt;Enable IPv4 IP Forwarding&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ sudo vi /usr/lib/sysctl.d/00-system.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Add the following line:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;net.ipv4.ip_forward=1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Save and exit the file. Restart network:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ sudo systemctl restart network
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Integration Test</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/integration_test/</link>
      <pubDate>Tue, 16 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/integration_test/</guid>
      <description>&lt;p&gt;&lt;strong&gt;How to deploy ohara integration test to QA environment?&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;node-裡需要安裝的工具&#34;&gt;Node 裡需要安裝的工具&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;安裝 JDK 11, 需要設定以下的 link&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ sudo yum install -y java-11-openjdk-devel
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在 CentOS 的 Node 需要安裝 jq&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ sudo yum install -y epel-release
$ sudo yum install -y jq
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ssh server&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ sudo yum install -y openssh-server
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Docker: Please follow 
&lt;a href=&#34;https://docs.docker.com/install/linux/docker-ce/centos/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;docker official tutorial&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;防火牆設定允許 docker container 的 port, 並且重新 reload 防火牆的服務&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# sudo firewall-cmd --permanent --zone=trusted --add-interface={docker network}
# sudo firewall-cmd --reload
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;jenkins-需要做的設定&#34;&gt;Jenkins 需要做的設定&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;確認 jenkins 是否加入了登入的帳號密碼設定&lt;/p&gt;
&lt;p&gt;Credentials -&amp;gt; global -&amp;gt; Add Credentials -&amp;gt; 輸入 Username, Password, Description. ID 不用輸入 -&amp;gt; OK&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;把 Node 加入到 Jenkins 裡&lt;/p&gt;
&lt;p&gt;管理 Jenkins -&amp;gt; 管理節點 -&amp;gt; 新增節點 -&amp;gt; 輸入節點名稱的 hostname -&amp;gt; 選複製既有節點 -&amp;gt; 複製來源選一台現有的 slave 來輸入, 例如：ohara-it01 -&amp;gt; OK&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;把 Node 加入到 ssh remote hosts&lt;/p&gt;
&lt;p&gt;管理 Jenkins -&amp;gt; 設定系統 -&amp;gt; SSH remote hosts -&amp;gt; 往下拉會看到新增按鈕 -&amp;gt; 之後輸入 Hostname, port, 選 Credentials -&amp;gt; 新增&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;設定 PreTest 和 PreCommit Job&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;修改標籤表示式, 避免 IT 的 node 跑到 UT 上面&lt;/li&gt;
&lt;li&gt;增加 node 在 shell script 裡
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;NODE01_HOSTNAME=&amp;quot;ohara-it02&amp;quot;
NODE01_IP=$(getent hosts $NODE01_HOSTNAME | cut -d&amp;quot; &amp;quot; -f 1)
NODE01_INFO=&amp;quot;$NODE_USER_NAME:$NODE_PASSWORD@$NODE01_HOSTNAME:22&amp;quot;
EXTRA_PROPERTIES=&amp;quot;-Pohara.it.docker=$NODE00_INFO,$NODE01_INFO&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;建立 Execute shell script on remote host using ssh, 用來在 IT 的 Node 拉 docker image
新增建置步驟 -&amp;gt; Execute shell script on remote host using ssh -&amp;gt; 輸入拉 docker image 的 command&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Ohara Manager Development Guideline</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/manager_dev_guide/</link>
      <pubDate>Tue, 16 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/manager_dev_guide/</guid>
      <description>&lt;p&gt;This module contains Ohara manager (an HTTP server powered by

&lt;a href=&#34;https://nodejs.org/en/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Node.js&lt;/a&gt;) and Ohara manager client (A web-based
user interface built with 
&lt;a href=&#34;https://reactjs.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;React.js&lt;/a&gt; ). In the
following docs, we will refer &lt;strong&gt;Server&lt;/strong&gt; as Ohara manager and &lt;strong&gt;Client&lt;/strong&gt;
as Ohara manager client.&lt;/p&gt;
&lt;h2 id=&#34;initial-machine-setup&#34;&gt;Initial machine setup&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Install 
&lt;a href=&#34;https://nodejs.org/en/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Node.js&lt;/a&gt; 10.16.3 or
node.js &amp;gt;=10.16.3 and &amp;lt; 13.0.0&lt;/li&gt;
&lt;li&gt;Install 
&lt;a href=&#34;https://yarnpkg.com/en/docs/install#mac-stable&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yarn&lt;/a&gt;
1.13.0 or greater&lt;/li&gt;
&lt;li&gt;Make sure you&amp;rsquo;re in the ohara-manager root and use this command to
setup the app: &lt;code&gt;yarn setup&lt;/code&gt;. This will install all the dependencies
for both the &lt;strong&gt;Server&lt;/strong&gt; and &lt;strong&gt;Client&lt;/strong&gt; as well as creating a
production build for the client.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Optional&lt;/strong&gt;: If you&amp;rsquo;re using Visual Studio Code as your editor,
have a look at our 
&lt;a href=&#34;#editors&#34;&gt;Editors&lt;/a&gt; section.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;mac&#34;&gt;Mac&lt;/h3&gt;
&lt;p&gt;Make sure you have &lt;code&gt;watchman&lt;/code&gt; installed on your machine. You can do this
with homebrew:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ brew install watchman
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;linux&#34;&gt;Linux&lt;/h3&gt;
&lt;p&gt;Install these dependencies for cypress:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yum install -y xorg-x11-server-Xvfb gtk2-2.24* libXtst* libXScrnSaver* GConf2* alsa-lib*
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;development&#34;&gt;Development&lt;/h2&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    If this is your first time running this project, you need to complete
the &lt;a href=&#34;#initial-machine-setup&#34;&gt;Initial machine setup&lt;/a&gt; section above 👆
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;quick-start-guide&#34;&gt;Quick start guide&lt;/h3&gt;
&lt;p&gt;Make sure you&amp;rsquo;re at the Ohara manager root, then start it with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn start --configurator ${http://host:port/v0}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that the configurator option is &lt;strong&gt;required&lt;/strong&gt;, and you should have
configurator running before starting Ohara manager. You can see the

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/user_guide/&#34;&gt;user guide&lt;/a&gt; on how to spin
up a Configurator&lt;/p&gt;
&lt;p&gt;Open another terminal tab, and start the &lt;strong&gt;Client&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn start:client
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, go to http://localhost:3000 and start your development, happy
hacking 😎&lt;/p&gt;
&lt;h3 id=&#34;full-development-guide&#34;&gt;Full development guide&lt;/h3&gt;
&lt;p&gt;In development, you need to start both the &lt;strong&gt;Ohara manager&lt;/strong&gt; and &lt;strong&gt;Ohara
manager client&lt;/strong&gt; servers before you can start your development. Follow
the instructions below:&lt;/p&gt;
&lt;h4 id=&#34;server&#34;&gt;Server&lt;/h4&gt;
&lt;p&gt;Make sure you&amp;rsquo;re at the ohara-manager root:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn start --configurator ${http://host:port/v0}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Note that the &lt;code&gt;--configurator&lt;/code&gt; argument is required, you should pass
in Ohara configurator API URL.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;You can also override the default port &lt;code&gt;5050&lt;/code&gt; by passing in &lt;code&gt;--port&lt;/code&gt;
like the following:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn start --configurator ${http://host:port/v0} --port ${1234}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After starting the server, visit &lt;code&gt;http://localhost:${PORT}&lt;/code&gt; in your browser.&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Passing the CLI option &lt;code&gt;-c&lt;/code&gt; has the same effect as &lt;code&gt;--configurator&lt;/code&gt;
and &lt;code&gt;-p&lt;/code&gt; for &lt;code&gt;--port&lt;/code&gt; as well
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Double check the &lt;code&gt;--configurator&lt;/code&gt; spelling and API URL, the URL should
contain the API version number: &lt;code&gt;/v0&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&#34;client&#34;&gt;Client&lt;/h4&gt;
&lt;p&gt;Start the &lt;strong&gt;Client&lt;/strong&gt; development server with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn start:client
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After starting the dev server, visit &lt;code&gt;http://localhost:3000&lt;/code&gt; in your
browser and start you development.&lt;/p&gt;
&lt;p&gt;You can override the default port &lt;code&gt;3000&lt;/code&gt; by passing in an environment
variable:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ PORT=7777 yarn start:client
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The dev server will then start at &lt;code&gt;http://localhost:7777&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&#34;testing&#34;&gt;Testing&lt;/h3&gt;
&lt;h4 id=&#34;unit-test&#34;&gt;Unit test&lt;/h4&gt;
&lt;p&gt;You can run &lt;strong&gt;Client&lt;/strong&gt; unit test with a single npm script:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn test:unit:ci
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Please note that this is a one-off run command, often when you&amp;rsquo;re in
the development, you would run test and stay in Jest&amp;rsquo;s watch mode
which reloads the test once you save your changes:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn test:unit:watch
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn test:unit:ci
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This command will generate test coverage reports, which can be found in
&lt;code&gt;ohara-manager/client/coverage/ut/&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    We will automate check the threshold of code coverage by
&lt;strong&gt;Statements &amp;gt; 40%&lt;/strong&gt; if you issued the &lt;code&gt;test:unit:ci&lt;/code&gt; command.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;api-test&#34;&gt;API test&lt;/h4&gt;
&lt;p&gt;We&amp;rsquo;re using Cypress to test our RESTful API, this ensures our backend
API is always compatible with Ohara manager and won&amp;rsquo;t break our UI
(ideally). You can run the test in different modes:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;GUI mode&lt;/strong&gt;: this will open Cypress test runner, you can then run
your test manually through the UI.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn test:api:open
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Electron mode(headless)&lt;/strong&gt;: since we&amp;rsquo;re running our API test on CI
under this mode. You might often want to run your tests in this mode
locally as well.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn test:api:ci --configurator ${http://host:port/v0 --port 0}
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;Generated test coverage reports could be found in &lt;code&gt;ohara-manager/client/coverage/api&lt;/code&gt;
if you executed test with &lt;strong&gt;Electron mode&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;--port 0&lt;/code&gt; means randomly choose a port for this test run.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    We will automate check the threshold of code coverage by
&lt;strong&gt;Statements &amp;gt; 80%&lt;/strong&gt; if you issued the &lt;code&gt;test:api:ci&lt;/code&gt; command.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;it-test&#34;&gt;IT test&lt;/h4&gt;
&lt;p&gt;To test our UI flows, we use Cypress to test our UI flow with &lt;strong&gt;fake&lt;/strong&gt; configurator. These
tests focus on the behaviors of UI flow (by different operations from UI), so they should
cover most of our UI logic.  You can run the test in different modes:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;GUI mode&lt;/strong&gt;: this will open Cypress test runner, you can then run
your test manually through the UI.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn test:it:open
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Electron mode(headless)&lt;/strong&gt;: since we&amp;rsquo;re running our API test on CI
under this mode. You might often want to run your tests in this mode
locally as well.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn test:it:ci --configurator ${http://host:port/v0 --port 0}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This command will generate test coverage reports, which can be found in
&lt;code&gt;ohara-manager/client/coverage/it/&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    We will automate check the threshold of code coverage by
&lt;strong&gt;Statements &amp;gt; 75%&lt;/strong&gt; if you issued the &lt;code&gt;test:it:ci&lt;/code&gt; command.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;end-to-end-test&#34;&gt;End-to-End test&lt;/h4&gt;
&lt;p&gt;Just like API test, our End-to-End test also runs in two different
modes:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;GUI mode&lt;/strong&gt;: this will open Cypress test runner, you can then run
your test manually through the UI.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn test:e2e:open
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Electron mode(headless)&lt;/strong&gt;: since we&amp;rsquo;re running our E2E test on CI
under this mode. You might often want to run your tests in this mode
locally as well.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn test:e2e:ci --configurator ${http://host:port/v0}
&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Before running in this mode we advise that you run &lt;code&gt;yarn setup&lt;/code&gt; prior
to the tests as the dev server is not running, so you might have stale
build asserts in your build directory&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You also need to create a &lt;strong&gt;cypress.env.json&lt;/strong&gt; under the
&lt;code&gt;/ohara-manager/client/&lt;/code&gt;, these are the config that Cypress will
be using when running tests:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;nodeHost&amp;quot;: &amp;quot;ohara-dev-01&amp;quot;,
  &amp;quot;nodePort&amp;quot;: 22,
  &amp;quot;nodeUser&amp;quot;: &amp;quot;nodeUserName&amp;quot;,
  &amp;quot;nodePass&amp;quot;: &amp;quot;nodePassword&amp;quot;,
  &amp;quot;servicePrefix&amp;quot;: &amp;quot;prPrefix&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Unlike API test, the test should run in production environment&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;code-coverage&#34;&gt;Code Coverage&lt;/h3&gt;
&lt;p&gt;As the above test phases are tend to cover different range of our source code, after you executed
the following commands:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;yarn test:unit:ci&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;yarn test:api:ci&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;yarn test:it:ci&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;we will generate the corresponded coverage reports in relative path as each test section described, and
you could combine them to see the overall picture:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn report:combined
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The combined coverage report could be found at &lt;code&gt;/ohara-manager/client/coverage/index.html&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-info&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;You could also check the combined report by yourself:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn test:coverage:check
&lt;/code&gt;&lt;/pre&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;linting&#34;&gt;Linting&lt;/h3&gt;
&lt;p&gt;We use 
&lt;a href=&#34;https://github.com/eslint/eslint&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ESLint&lt;/a&gt; to lint all the
JavaScript:&lt;/p&gt;
&lt;p&gt;Server:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn lint:server
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It&amp;rsquo;s usually helpful to run linting while developing and that&amp;rsquo;s
included in &lt;code&gt;yarn start&lt;/code&gt; command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn start --configurator ${http://host:port/v0}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will start the server with &lt;code&gt;nodemon&lt;/code&gt; and run the linting script
whenever nodemon reloads.&lt;/p&gt;
&lt;p&gt;Client:&lt;/p&gt;
&lt;p&gt;Since our client is bootstrapped with create-react-app, so the
linting part is already taken care. When starting the &lt;strong&gt;Client&lt;/strong&gt; dev
server with &lt;code&gt;yarn start:client&lt;/code&gt;, the linting will be starting
automatically.&lt;/p&gt;
&lt;p&gt;Note that due to create-react-app doesn&amp;rsquo;t support custom eslint
rules. You need to use your text editor plugin to display the custom
linting rule warnings or errors. For more info about this, please
take a look at the create-react-app

&lt;a href=&#34;https://facebook.github.io/create-react-app/docs/setting-up-your-editor#displaying-lint-output-in-the-editor&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;docs&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;format&#34;&gt;Format&lt;/h3&gt;
&lt;p&gt;We use 
&lt;a href=&#34;https://github.com/prettier/prettier&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Prettier&lt;/a&gt; to format our
code. You can format all &lt;code&gt;.js&lt;/code&gt; files with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn format
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;You can ignore files or folders when running &lt;code&gt;yarn format&lt;/code&gt; by
editing the &lt;code&gt;.prettierignore&lt;/code&gt; in the Ohara-manager root.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;build&#34;&gt;Build&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Note that this step is only required for the Client NOT THE SERVER&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You can get production-ready static files by using the following
command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn build
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    These static files will be built and put into the
&lt;strong&gt;/ohara-manager/client/build&lt;/strong&gt; directory.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;ohara-manager-image&#34;&gt;Ohara manager image&lt;/h3&gt;
&lt;p&gt;Run the following command to get the production ready build of both
the &lt;strong&gt;Server&lt;/strong&gt; and &lt;strong&gt;Client&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn setup
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After the build, copy/use these files and directories to the
destination directory (Note this step is automatically done by
Ohara-${module} module):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;start.js&lt;/li&gt;
&lt;li&gt;config.js&lt;/li&gt;
&lt;li&gt;client &amp;ndash; only build directory is needed
&lt;ul&gt;
&lt;li&gt;build&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;constants&lt;/li&gt;
&lt;li&gt;node_modules&lt;/li&gt;
&lt;li&gt;routes&lt;/li&gt;
&lt;li&gt;utils&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Note that if you add new files or dirs to the &lt;strong&gt;Server&lt;/strong&gt; or &lt;strong&gt;Client&lt;/strong&gt;
and these files and dirs are required for production build, please
list that file in the above list as well as editing the gradle file
under &lt;code&gt;ohara/ohara-manager/build.gradle&lt;/code&gt;. &lt;strong&gt;Skipping this step will
cause production build failed!&lt;/strong&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;From the Ohara manager project root&lt;/strong&gt;, use the following command to
start the manager:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn start:prod --configurator ${http://host:port/v0}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;ci-server-integration&#34;&gt;CI server integration&lt;/h3&gt;
&lt;p&gt;In order to run tests on Jenkins, Ohara manager provides a few npm scripts that are used in Gradle, these scripts generate test reports in &lt;em&gt;/ohara-manager/test-reports&lt;/em&gt; which can be consumed by Jenkins to determine if a test passes or not, you will sometimes need to run these commands locally if you edit related npm scripts in Ohara manager or want to reproduce fail build on CI:&lt;/p&gt;
&lt;p&gt;Unit test:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ ./gradlew test
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Run &lt;strong&gt;Client&lt;/strong&gt;&amp;rsquo;s unit tests. The test reports can be found in &lt;code&gt;ohara-manager/test-reports/&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;API test:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ ./gradlew api -Pohara.manager.api.configurator=${http://host:port/v0}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;End-to-End test:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ ./gradlew e2e -Pohara.manager.e2e.port=5050 -Pohara.manager.e2e.configurator=${http://host:port/v0}-Pohara.manager.e2e.nodeHost=${slaveNodeName} -Pohara.manager.e2e.nodePort=${slaveNodePort} -Pohara.manager.e2e.nodeUser=${slaveNodeUsername} -Pohara.manager.e2e.nodePass=${slaveNodePassword} -Pohara.it.container.prefix=${pullRequestNumber}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&amp;rsquo;s take a close look at these options:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-Pohara.manager.e2e.port=5050&lt;/code&gt;: start Ohara manager at this port in the test run&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-Pohara.manager.e2e.configurator=${http://host:port/v0}&lt;/code&gt;: Configurator URL, Ohara manager will hit this API endpoint when running test&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-Pohara.manager.e2e.nodeHost=${slaveNodeName}&lt;/code&gt;: K8s&amp;rsquo; slave node, the services started in the test will be deploy on this node&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-Pohara.manager.e2e.nodePort=${slaveNodePort}&lt;/code&gt;: port of the given node&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-Pohara.manager.e2e.nodeUser=${slaveNodeUsername}&lt;/code&gt;: username of the given node&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-Pohara.manager.e2e.nodePass=${slaveNodePassword}&lt;/code&gt;: password of the given node&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-Pohara.it.container.prefix=${pullRequestNumber}&lt;/code&gt;: pull request number of this test run, this prefix is used by Jenkins to do the cleanup after the test is done&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are more gradle tasks that are not listed in the above, you can
view them in &lt;code&gt;/ohara-manager/build.gradle&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&#34;clean&#34;&gt;Clean&lt;/h3&gt;
&lt;p&gt;Clean up all running processes, removing &lt;code&gt;test-reports/&lt;/code&gt; in the
&lt;strong&gt;Server&lt;/strong&gt; and &lt;code&gt;/build&lt;/code&gt; directory in the &lt;strong&gt;Client&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn clean
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Clean all running processes started with node.js&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn clean:process
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is useful when you want to kill all node.js processes locally&lt;/p&gt;
&lt;h3 id=&#34;prepush&#34;&gt;Prepush&lt;/h3&gt;
&lt;p&gt;We also provide a npm script to run Client&amp;rsquo;s unit test, linting, and
format all the JavaScript files with. &lt;strong&gt;Ideally, you&amp;rsquo;d run this
before pushing your code to the remote repo:&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn prepush
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;editors&#34;&gt;Editors&lt;/h2&gt;
&lt;p&gt;We highly recommended that you use 
&lt;a href=&#34;https://code.visualstudio.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Visual Studio
Code&lt;/a&gt; (vscode for short) to edit and
author Ohara manager code.&lt;/p&gt;
&lt;p&gt;Recommended vscode settings&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;editor.tabSize&amp;quot;: 2,
  &amp;quot;editor.formatOnSave&amp;quot;: true,
  &amp;quot;editor.formatOnSaveTimeout&amp;quot;: 2000,
  &amp;quot;editor.tabCompletion&amp;quot;: true,
  &amp;quot;emmet.triggerExpansionOnTab&amp;quot;: true,
  &amp;quot;emmet.includeLanguages&amp;quot;: {
    &amp;quot;javascript&amp;quot;: &amp;quot;javascriptreact&amp;quot;,
    &amp;quot;markdown&amp;quot;: &amp;quot;html&amp;quot;
  },
  &amp;quot;search.exclude&amp;quot;: {
    &amp;quot;**/node_modules&amp;quot;: true,
    &amp;quot;**/bower_components&amp;quot;: true,
    &amp;quot;**/coverage&amp;quot;: true
  },
  &amp;quot;javascript.updateImportsOnFileMove.enabled&amp;quot;: &amp;quot;always&amp;quot;,
  &amp;quot;eslint.workingDirectories&amp;quot;: [
     &amp;quot;./client&amp;quot;
   ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Recommend extensions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=dbaeumer.vscode-eslint&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ESLint&lt;/a&gt; &amp;mdash;
install this so vscode can display linting errors right in the editor&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=jpoissonnier.vscode-styled-components&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;vscode-styled-components&lt;/a&gt; &amp;mdash;
syntax highlighting support for 
&lt;a href=&#34;https://github.com/styled-components/styled-components&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;styled component&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=esbenp.prettier-vscode&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Prettier - Code formatter&lt;/a&gt; &amp;mdash;
code formatter, it consumes the config in &lt;code&gt;.prettierrc&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=mikestead.dotenv&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DotENV&lt;/a&gt; &amp;mdash;
&lt;code&gt;.env&lt;/code&gt; file syntax highlighting support&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=naumovs.color-highlight&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Color Highlight&lt;/a&gt; &amp;mdash;
Highlight web colors in VSCode&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;switch-different-version-of-nodejs&#34;&gt;Switch different version of Node.js&lt;/h2&gt;
&lt;p&gt;Oftentimes you would need to switch between different Node.js versions
for debugging. There&amp;rsquo;s a handy npm package that can reduce the pain of
managing different version of Node.js on your machine:&lt;/p&gt;
&lt;p&gt;First, let&amp;rsquo;s install this package &lt;code&gt;n&lt;/code&gt;, note that we&amp;rsquo;re installing it globally so it&amp;rsquo;s can be used throughout your projects:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ npm install -g n # or yarn global add n
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Second, let&amp;rsquo;s use &lt;code&gt;n&lt;/code&gt; to install a specific version of Node.js:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ n 8.16.0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Switch between installed NodeJS versions:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ n # Yep, just type n in your terminal...,
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more info, you can read the 
&lt;a href=&#34;https://github.com/tj/n&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;docs&lt;/a&gt; here.&lt;/p&gt;
&lt;h2 id=&#34;having-issues&#34;&gt;Having issues?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Got an error while starting up the server: Error: Cannot find
module ${module-name}&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If you&amp;rsquo;re running into this, it&amp;rsquo;s probably that this module is not
correctly installed on your machine. You can fix this by simply
run:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn # If this doesn&#39;t work, try `yarn add ${module-name}`
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After the installation is completed, start the server again.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Got an error while starting up the server or client on a Linux
machine: ENOSPC&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You can run this command to increase the limit on the number of
files Linux will watch. Read more

&lt;a href=&#34;https://github.com/guard/listen/wiki/Increasing-the-amount-of-inotify-watchers#the-technical-details&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ echo fs.inotify.max_user_watches=524288 | sudo tee -a /etc/sysctl.conf &amp;amp;&amp;amp; sudo sysctl -p.
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Node.js processes cannot be stopped even after using kill -9&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;re using &lt;code&gt;forever&lt;/code&gt; to start our node.js servers on CI, and
&lt;code&gt;nodemon&lt;/code&gt; while in development, so you need to use the following
commands to kill them. &lt;code&gt;kill -9&lt;/code&gt; or &lt;code&gt;fuser&lt;/code&gt; might not work as you
expected.&lt;/p&gt;
&lt;p&gt;use &lt;code&gt;yarn clean:processes&lt;/code&gt; command or &lt;code&gt;pkill node&lt;/code&gt; to kill all the
node.js processes&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;While running test in jest&amp;rsquo;s watch modal, an error is thrown&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Error watching file for changes: EMFILE
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Try installing &lt;code&gt;watchman&lt;/code&gt; for your mac with the 
&lt;a href=&#34;#mac&#34;&gt;instruction&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For more info: &lt;a href=&#34;https://github.com/facebook/jest/issues/1767&#34;&gt;https://github.com/facebook/jest/issues/1767&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ohara manager is not able to connect to Configurator&lt;/strong&gt; And I&amp;rsquo;m seeing something like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--configurator: we&#39;re not able to connect to `{http://host:port/v0}`
Please make sure your Configurator is running at `${http://host:port/v0}`
[nodemon] app crashed - waiting for file changes before starting...
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This could happen due to several reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Configurator hasn&amp;rsquo;t fully started yet&lt;/strong&gt;: after you start the
configurator container. The container needs some time to fully
initialize the service. This usually takes about a minute or
so. And as we&amp;rsquo;re doing the API check by hitting the real API
in Ohara manager. This results to the error in the above.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;You&amp;rsquo;re not using the correct IP in Manager container&lt;/strong&gt;: if
you start a configurator container in your local as well as a
manager. You should specify an IP instead of something like
localhost in: &lt;code&gt;--configurator http://localhost:12345/v0&lt;/code&gt; This
won&amp;rsquo;t work as the manager is started in the container so it
won&amp;rsquo;t be able to connect to the configurator without a real IP&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;As we mentioned in the previous sections. Please double
check your configurator URL spelling. This is usually the
cause of the above-mentioned error.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Shabondi</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/shabondi/</link>
      <pubDate>Tue, 16 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/shabondi/</guid>
      <description>&lt;p&gt;Shabondi service play the role of a &lt;em&gt;http proxy service&lt;/em&gt; in the Pipeline
of Ohara. If you want to integrate Ohara pipeline with your application,
Shabondi is a good choice. Just send the simple http request to
&lt;strong&gt;Shabondi source&lt;/strong&gt; service, you can hand over your data to Pipeline for
processing. On the other hand, you can send the http request to
&lt;strong&gt;Shabondi sink&lt;/strong&gt; service to fetch the output data of the Pipeline.&lt;/p&gt;
&lt;p&gt;Following is a simple diagram of Pipeline to demonstrate about both the source and sink of Shabondi:&lt;/p&gt;















&lt;figure id=&#34;figure-shabondi-pipeline&#34;&gt;



  &lt;img src=&#34;../img/shabondi-pipeline.png&#34; alt=&#34;&#34;  &gt;



  
  
  &lt;figcaption&gt;
    Shabondi Pipeline
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;data-format&#34;&gt;Data format&lt;/h2&gt;
&lt;p&gt;Both Shabondi source and sink use 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/custom_connector/#datamodel&#34;&gt;Row&lt;/a&gt; in JSON format
for data input and output. Row is a table structure data defined in Ohara code base.
A row is comprised of multiple cells. Each cell has its &lt;strong&gt;name&lt;/strong&gt; and &lt;strong&gt;value&lt;/strong&gt;.
Every row of your input data will be stored in the &lt;strong&gt;Topic&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;A table:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;row #&lt;/th&gt;
&lt;th&gt;name&lt;/th&gt;
&lt;th&gt;age&lt;/th&gt;
&lt;th&gt;email&lt;/th&gt;
&lt;th&gt;career&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;(row 1)&lt;/td&gt;
&lt;td&gt;jason&lt;/td&gt;
&lt;td&gt;42&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;mailto:jason@example.com&#34;&gt;jason@example.com&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Surgeon&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;(row n)&lt;/td&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Example of row using Java:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import oharastream.ohara.common.data.Row;
import oharastream.ohara.common.data.Cell;
class ExampleOfRow {
    public static void main(String[] args) {
        Row row = Row.of(
                Cell.of(&amp;quot;name&amp;quot;, &amp;quot;jason&amp;quot;),
                Cell.of(&amp;quot;age&amp;quot;, &amp;quot;42&amp;quot;),
                Cell.of(&amp;quot;email&amp;quot;, &amp;quot;jason@example.com&amp;quot;),
                Cell.of(&amp;quot;career&amp;quot;, &amp;quot;Surgeon&amp;quot;)
                );
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Example of row in JSON format&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;jason&amp;quot;,
  &amp;quot;age&amp;quot;: 42,
  &amp;quot;email&amp;quot;: &amp;quot;jason@example.com&amp;quot;,
  &amp;quot;career&amp;quot;: &amp;quot;Surgeon&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;deployment&#34;&gt;Deployment&lt;/h2&gt;
&lt;p&gt;There are two ways to deploy Shabondi service&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ohara Manager: (TBD)&lt;/li&gt;
&lt;li&gt;Use Configurator 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/shabondis/&#34;&gt;REST API&lt;/a&gt; to create
and start Shabondi service.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After a Shabondi service is properly configured, deploy and successfully started.
It&amp;rsquo;s ready to receive or send requests via HTTP.&lt;/p&gt;
&lt;h2 id=&#34;service-rest-api&#34;&gt;Service REST API&lt;/h2&gt;
&lt;p&gt;Shabondi source service receives single row message through HTTP
requests and then writes to the connected &lt;strong&gt;Topic&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;source-api&#34;&gt;Source API&lt;/h3&gt;
&lt;h4 id=&#34;send-row&#34;&gt;Send Row&lt;/h4&gt;
&lt;p&gt;Send a JSON data of 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/custom_connector/#datamodel&#34;&gt;Row&lt;/a&gt; to Shabondi source service.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Request&lt;br&gt;
POST /&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Request body&lt;br&gt;
The row data in JSON format&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example 1 (Succeed)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;POST http://node00:58456 HTTP/1.1
Content-Type: application/json

{
  &amp;quot;name&amp;quot;: &amp;quot;jason&amp;quot;,
  &amp;quot;age&amp;quot;: 42,
  &amp;quot;email&amp;quot;: &amp;quot;jason@example.com&amp;quot;,
  &amp;quot;career&amp;quot;: &amp;quot;Surgeon&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;HTTP/1.1 200 OK
Server: akka-http/10.1.11
Date: Tue, 19 May 2020 02:41:20 GMT
Content-Type: text/plain; charset=UTF-8
Content-Length: 2

OK
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example 2 (Failure)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{.http}&#34;&gt;GET http://node00:58456 HTTP/1.1
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;HTTP/1.1 405 Method Not Allowed
Server: akka-http/10.1.11
Date: Tue, 19 May 2020 02:45:56 GMT
Content-Type: text/plain; charset=UTF-8
Content-Length: 90
    
Unsupported method, please reference: https://oharastream.github.io/docs/master/shabondi/
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;sink-api&#34;&gt;Sink API&lt;/h3&gt;
&lt;p&gt;The Shabondi Sink service accepts the http request, and then reads the
rows from the connected &lt;strong&gt;Topic&lt;/strong&gt; and response it in JSON format.&lt;/p&gt;
&lt;h4 id=&#34;fetch-rows&#34;&gt;Fetch Rows&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Request&lt;br&gt;
GET /groups/$groupName&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Response&lt;br&gt;
The array of row in JSON format&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example 1 (Succeed)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;GET http://node00:58458/groups/g1 HTTP/1.1
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;HTTP/1.1 200 OK
Server: akka-http/10.1.11
Date: Wed, 20 May 2020 06:18:44 GMT
Content-Type: application/json
Content-Length: 115
    
[
  {
    &amp;quot;name&amp;quot;: &amp;quot;jason&amp;quot;,
    &amp;quot;age&amp;quot;: 42,
    &amp;quot;email&amp;quot;: &amp;quot;jason@example.com&amp;quot;,
    &amp;quot;career&amp;quot;: &amp;quot;Surgeon&amp;quot;
  },
  {
    &amp;quot;name&amp;quot;: &amp;quot;robert&amp;quot;,
    &amp;quot;age&amp;quot;: 36,
    &amp;quot;email&amp;quot;: &amp;quot;robert99@gmail.com&amp;quot;,
    &amp;quot;career&amp;quot;: &amp;quot;Teacher&amp;quot;
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example 2 - Failure response(Illegal group name)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;GET http://node00:58458/groups/g1-h HTTP/1.1
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;HTTP/1.1 406 Not Acceptable
Server: akka-http/10.1.11
Date: Wed, 20 May 2020 07:34:10 GMT
Content-Type: text/plain; charset=UTF-8
Content-Length: 50
    
Illegal group name, only accept alpha and numeric.
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Contributing</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/contributing/</link>
      <pubDate>Mon, 15 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/contributing/</guid>
      <description>&lt;p&gt;All we love is only pull request so we have some rules used to make your
PR looks good for reviewers.&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Note that you should file a new issue to discuss the PR detail with us
before submitting a PR.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;quick-start&#34;&gt;Quick start&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Fork and clone the 
&lt;a href=&#34;https://github.com/oharastream/ohara&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;oharastream/ohara&lt;/a&gt; repo&lt;/li&gt;
&lt;li&gt;Install dependencies. See our 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/build/build-ohara/&#34;&gt;how_to_build_Ohara&lt;/a&gt; for
development machine setup&lt;/li&gt;
&lt;li&gt;Create a branch with your PR with:&lt;br&gt;
&lt;code&gt;git checkout -b ${your-branch-name}&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Push your PR to remote:&lt;br&gt;
&lt;code&gt;git push origin ${your-branch-name}&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Create the PR with GitHub web UI and wait for reviews from our committers&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;testing-commands-in-the-pull-request&#34;&gt;Testing commands in the pull request&lt;/h2&gt;
&lt;p&gt;These commands will come in handy when you want to test your PR on our QA(CI server). To start a QA run,
you can simply leave a comment with one of the following commands in the PR:&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Note that the comment should contain the exact command as listed below,
comments like &lt;strong&gt;Please retry my PR&lt;/strong&gt; or &lt;strong&gt;Bot, retry -fae&lt;/strong&gt; won&amp;rsquo;t work:
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;retry&lt;/code&gt;&lt;br&gt;
trigger a full QA run&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;retry -fae&lt;/code&gt;&lt;br&gt;
trigger a full QA run even if there&amp;rsquo;s fail test during the run&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;retry ${moduleName}&lt;/code&gt;&lt;br&gt;
trigger a QA run for a specific module. If a module is named &lt;strong&gt;ohara-awesome&lt;/strong&gt;, you can enter
&lt;code&gt;retry awesome&lt;/code&gt; to run the QA against this specific module. Note that the module prefix
&lt;strong&gt;ohara-&lt;/strong&gt; is not needed. Following are some examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;retry manager&lt;/code&gt;: run &lt;strong&gt;ohara-manager&lt;/strong&gt;&amp;rsquo;s unit test.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;retry configurator&lt;/code&gt;: run &lt;strong&gt;ohara-configurator&lt;/strong&gt;&amp;rsquo;s unit test.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ohara manager has a couple of different tests and can be run separately by using the
above-mentioned &lt;code&gt;retry&lt;/code&gt; command.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;retry manager-api&lt;/code&gt;: run manager&amp;rsquo;s API tests&lt;/li&gt;
&lt;li&gt;&lt;code&gt;retry manager-ut&lt;/code&gt;: run manager&amp;rsquo;s unit tests&lt;/li&gt;
&lt;li&gt;&lt;code&gt;retry manager-e2e&lt;/code&gt;: run manager&amp;rsquo;s end-to-end tests&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;run&lt;/code&gt;: start both Configurator and Manager on jenkins server. If the specified PR makes
some changes to UI, you can run this command to see the changes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The QA build status can be seen at the bottom of your PR.&lt;/p&gt;
&lt;h2 id=&#34;important-things-about-pull-request&#34;&gt;Important things about pull request&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;A pull request must&amp;hellip;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Pass all tests&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Your PR should not make ohara unstable, if it does. It should be reverted ASAP.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You can either run these tests on your local
(see our 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/build/build-ohara/&#34;&gt;how_to_build_Ohara&lt;/a&gt; for more
info on how to run tests) or by opening the PR on our repo. These tests will be running
on your CI server.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pass code style check. You can automatically fix these issues with a
single command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ./gradlew spotlessApply
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Address all reviewers&amp;rsquo; comments&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;A pull request should&amp;hellip;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Be as small in scope as possible. Large PR is often hard to review.&lt;/li&gt;
&lt;li&gt;Add new tests&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;A pull request should not&amp;hellip;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bring in new libraries (or updating libraries to new version) without prior discussion.
Do not update the dependencies unless you have a good reason.&lt;/li&gt;
&lt;li&gt;Bring in the new module without prior discussion&lt;/li&gt;
&lt;li&gt;Bring in new APIs for Configurator without prior discussion&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>How to build Ohara</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/build/build-ohara/</link>
      <pubDate>Mon, 15 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/build/build-ohara/</guid>
      <description>&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;OpenJDK 11&lt;/li&gt;
&lt;li&gt;Scala 2.13.2&lt;/li&gt;
&lt;li&gt;Gradle 6.5&lt;/li&gt;
&lt;li&gt;Node.js 8.12.0&lt;/li&gt;
&lt;li&gt;Yarn 1.13.0 or greater&lt;/li&gt;
&lt;li&gt;Docker 19.03.8 (Docker multi-stage, which is supported by Docker 17.05 or higher, is required in building ohara images. see 
&lt;a href=&#34;https://docs.docker.com/develop/develop-images/multistage-build/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Use multi-stage builds&lt;/a&gt; for more details)&lt;/li&gt;
&lt;li&gt;Kubernetes 1.18.1 (Official QA uses the Kubernetes version is 1.18.1)&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;gradle-commands&#34;&gt;Gradle Commands&lt;/h2&gt;
&lt;p&gt;Ohara build is based on 
&lt;a href=&#34;https://gradle.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;gradle&lt;/a&gt;. Ohara has defined many gradle tasks to simplify the development of Ohara.&lt;/p&gt;
&lt;h3 id=&#34;build-binary&#34;&gt;Build Binary&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ./gradlew clean build -x test
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    the tar file is located at ohara-${module}/build/distributions
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;run-all-uts&#34;&gt;Run All UTs&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ./gradlew clean test
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Ohara IT tests requires specific envs, and all IT tests will be skipped if you don&amp;rsquo;t pass the related setting to IT. Ohara recommends you testing your code on &lt;a href=&#34;https://builds.is-land.com.tw/job/PreCommit-OHARA/&#34;&gt;official QA&lt;/a&gt; which offers the powerful machine and IT envs.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    add flag &amp;ldquo;-PskipManager&amp;rdquo; to skip the tests of Ohara Manager. Ohara Manager is a module in charge of Ohara UI. Feel free to skip it if you are totally a backend developer. By the way, the prerequisites of testing Ohara Manager is shown in &lt;code&gt;here &amp;lt;managerdev&amp;gt;&lt;/code&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    add flag &amp;ldquo;-PmaxParallelForks=6&amp;rdquo; to increase the number of test process to start in parallel. The default value is number of cores / 2, and noted that too many tests running in parallel may easily
produce tests timeout.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;code-style-auto-apply&#34;&gt;Code Style Auto-Apply&lt;/h3&gt;
&lt;p&gt;Use this task to make sure your added code will have the same format and conventions with the rest of codebase.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{.console}&#34;&gt;$ ./gradlew spotlessApply
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    we have this style check in early QA build.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;license-auto-apply&#34;&gt;License Auto-Apply&lt;/h3&gt;
&lt;p&gt;If you have added any new files in a PR. This task will automatically insert an Apache 2.0 license header in each one of these newly created files&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ./gradlew licenseApply
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Note that a file without the license header will fail at early QA build
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;publish-artifacts&#34;&gt;Publish Artifacts&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ./gradlew clean bintrayUpload -PskipManager -PbintrayUser=$user -PbintrayKey=$key
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;ul&gt;
&lt;li&gt;bintrayUser: the account that has write permission to the
repository&lt;/li&gt;
&lt;li&gt;bintrayKey: the account API Key&lt;/li&gt;
&lt;li&gt;public: whether to auto published after uploading. default is
false&lt;/li&gt;
&lt;li&gt;override: whether to override version artifacts already
published. default is false&lt;/li&gt;
&lt;/ul&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: Only release manager has permission to upload artifacts&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;publish-artifacts-1&#34;&gt;Publish Artifacts&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ./gradlew clean build publishToMavenLocal -PskipManager -x test
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;
&lt;p&gt;see 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/user_guide/&#34;&gt;User Guide&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
