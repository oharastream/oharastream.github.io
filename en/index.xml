<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>OharaStream</title>
    <link>https://oharastream.github.io/en/</link>
      <atom:link href="https://oharastream.github.io/en/index.xml" rel="self" type="application/rss+xml" />
    <description>OharaStream</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Thu, 18 Jun 2020 00:00:00 +0100</lastBuildDate>
    <image>
      <url>https://oharastream.github.io/images/icon_huf5f81cd12511c4e8b7f06b033f435f0f_18329_512x512_fill_lanczos_center_2.png</url>
      <title>OharaStream</title>
      <link>https://oharastream.github.io/en/</link>
    </image>
    
    <item>
      <title>How to build Quickstart VM</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/build/build-quickstart-vm/</link>
      <pubDate>Mon, 15 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/build/build-quickstart-vm/</guid>
      <description>&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Operation system: Linux&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://en.wikipedia.org/wiki/Make_%28software%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Make&lt;/a&gt;: Make is a
build automation tool that automatically builds executable programs.
&lt;strong&gt;Make&lt;/strong&gt; is already built in Linux or macOS.&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://www.packer.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Packer&lt;/a&gt; 1.4+: Packer is an open source tool
for creating identical machine images for multiple platforms from a
single source configuration.&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://www.virtualbox.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VirtualBox&lt;/a&gt; 6.0+&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;build-ova-file&#34;&gt;Build OVA file&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;We use &lt;strong&gt;make&lt;/strong&gt; command to execute all our tasks. For building the
specific version of Ohara quickstart VM, you must provide the
argument &lt;strong&gt;OHARA_VER&lt;/strong&gt; when execute the &lt;strong&gt;make&lt;/strong&gt; command.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Build the OVA file, following is an example(OHARA_VER=0.7.1):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;[quickstart]$ cd vm
[vm]$ make OHARA_VER=0.7.1 ova
OHARA_VER=0.7.1
Build time: 2019/09/10 10:10
Start building quickstart VM ova file...
virtualbox-iso output will be in this color.

==&amp;gt; virtualbox-iso: Retrieving ISO
==&amp;gt; virtualbox-iso: Trying .cache/ubuntu-18.04.3-server-amd64.iso
==&amp;gt; virtualbox-iso: Trying .cache/ubuntu-18.04.3-server-amd64.iso?checksum=sha256%3A7d8e0055d663bffa27c1718685085626cb59346e7626ba3d3f476322271f573e
==&amp;gt; virtualbox-iso: .cache/ubuntu-18.04.3-server-amd64.iso?checksum=sha256%3A7d8e0055d663bffa27c1718685085626cb59346e7626ba3d3f476322271f573e =&amp;gt; /your/project/path/ohara/vms/quickstart/.cache/packer_cache/fdcf467e727a368c2aac26ac2284f0f517dc29fb.iso
==&amp;gt; virtualbox-iso: Starting HTTP server on port 8251
==&amp;gt; virtualbox-iso: Creating virtual machine...
==&amp;gt; virtualbox-iso: Creating hard drive...
==&amp;gt; virtualbox-iso: Creating forwarded port mapping for communicator (SSH, WinRM, etc) (host port 3248)
==&amp;gt; virtualbox-iso: Executing custom VBoxManage commands...
:   :   :   :
(SKIP)
:   :   :   :
==&amp;gt; virtualbox-iso: Gracefully halting virtual machine...
==&amp;gt; virtualbox-iso: Preparing to export machine...
    virtualbox-iso: Deleting forwarded port mapping for the communicator (SSH, WinRM, etc) (host port 3248)
==&amp;gt; virtualbox-iso: Exporting virtual machine...
    virtualbox-iso: Executing: export ohara-quickstart-0.7.1 --output build/ohara-quickstart-0.7.1.ova
==&amp;gt; virtualbox-iso: Deregistering and deleting VM...
Build &#39;virtualbox-iso&#39; finished.

==&amp;gt; Builds finished. The artifacts of successful builds are:
--&amp;gt; virtualbox-iso: VM files in directory: build
Done.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The OVA file will be output to: build/ohara-quickstart-{OHARA_VER}.ova&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;Currently, we use Ubuntu 18.04.03 LTS as Quickstart VM&amp;rsquo;s operation
system. Packer will try to find the ubuntu iso file in the
&lt;strong&gt;quickstart/.cache&lt;/strong&gt; folder first, and then download the &lt;a href=&#34;http://cdimage.ubuntu.com/ubuntu/releases/bionic/release/ubuntu-18.04.3-server-amd64.iso&#34;&gt;Ubuntu iso
file&lt;/a&gt;
from internet if the iso file not be found in the cache folder.&lt;/p&gt;
&lt;p&gt;To save your building time, you can download the &lt;a href=&#34;http://cdimage.ubuntu.com/ubuntu/releases/bionic/release/ubuntu-18.04.3-server-amd64.iso&#34;&gt;Ubuntu iso
file&lt;/a&gt;
manually and put into &lt;strong&gt;quickstart/.cache&lt;/strong&gt; folder.&lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;import-ova&#34;&gt;Import OVA&lt;/h2&gt;
&lt;p&gt;After generated the quickstart ova file, you can use VirtualBox user
interface to import the OVA file(&lt;strong&gt;File -&amp;gt; Import Appliance&lt;/strong&gt;) or use
following command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;[vm]$ make OHARA_VER=0.7.1 vm-import
vboxmanage import build/ohara-quickstart-0.7.1.ova --vsys 0 --vmname ohara-quickstart-0.7.1
0%...10%...20%...30%...40%...50%...60%...70%...80%...90%...100%
Interpreting /your/project/path/ohara/vms/quickstart/build/ohara-quickstart-0.7.1.ova...
OK.
Disks:
  vmdisk1       85899345920     -1      http://www.vmware.com/interfaces/specifications/vmdk.html#streamOptimized       ohara-quickstart-0.7.1-disk001.vmdk -1      -1

Virtual system 0:
 0: Suggested OS type: &amp;quot;Ubuntu_64&amp;quot;
    (change with &amp;quot;--vsys 0 --ostype &amp;lt;type&amp;gt;&amp;quot;; use &amp;quot;list ostypes&amp;quot; to list all possible values)
 1: VM name specified with --vmname: &amp;quot;ohara-quickstart-0.7.1&amp;quot;
 2: Description &amp;quot;Ohara Quickstart VM
Ohara version: 0.7.1
Build time: 2019/09/10 10:10&amp;quot;
    (change with &amp;quot;--vsys 0 --description &amp;lt;desc&amp;gt;&amp;quot;)
 3: Number of CPUs: 2
    (change with &amp;quot;--vsys 0 --cpus &amp;lt;n&amp;gt;&amp;quot;)
 4: Guest memory: 4096 MB
    (change with &amp;quot;--vsys 0 --memory &amp;lt;MB&amp;gt;&amp;quot;)
 5: Network adapter: orig NAT, config 3, extra slot=0;type=NAT
 6: Network adapter: orig HostOnly, config 3, extra slot=1;type=HostOnly
 7: IDE controller, type PIIX4
    (disable with &amp;quot;--vsys 0 --unit 7 --ignore&amp;quot;)
 8: IDE controller, type PIIX4
    (disable with &amp;quot;--vsys 0 --unit 8 --ignore&amp;quot;)
 9: Hard disk image: source image=ohara-quickstart-0.7.1-disk001.vmdk, target path=/home/xxxx/VirtualBox VMs/ohara-quickstart-0.7.1/ohara-quickstart-0.7.1-disk001.vmdk, controller=7;channel=0
    (change target path with &amp;quot;--vsys 0 --unit 9 --disk path&amp;quot;;
    disable with &amp;quot;--vsys 0 --unit 9 --ignore&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;use-quickstart-vm&#34;&gt;Use Quickstart VM&lt;/h2&gt;
&lt;p&gt;After import quickstart VM to VirtualBox, you can press &lt;strong&gt;Start&lt;/strong&gt; button
to start the VM. And then you can see following screen:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;Ubuntu 10.04.03 LTS ohara-vm tty1
ohara-vm login:
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Please use &lt;code&gt;ohara&lt;/code&gt; as login account and &lt;code&gt;oharastream&lt;/code&gt; as password to
login to VM. If this is your first time to login Quickstart VM, the
progress of pull Ohara docker images will be starting automatically. So
please make sure your machine can connect to Internet.&lt;/p&gt;
&lt;p&gt;After download the images, and then you can see the ip address info of
the VM, for example:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;IP address info:
lo              UNKNOWN         127.0.0.1/8 ::1/128
enp0s3          UP              10.0.2.15/24 fe80::a00:27ff:feac:ad8a/64
enp0s8          UP              192.168.56.114/24 fe80::a00:27ff:fe09:1a1e/64
docker0         DOWN            172.17.0.1/16
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can find the private IP address &lt;strong&gt;192.168.56.114&lt;/strong&gt; (enp0s8) in the
above list. So the configurator ip address is &lt;strong&gt;192.168.56.114&lt;/strong&gt; .&lt;/p&gt;
&lt;p&gt;Run Ohara configurator(port 12345):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ./ohara-configurator.sh
docker run --rm -p 12345:12345 -d oharastream/configurator:0.7.1 --port 12345
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Run Ohara manager(port 5050), provide the configurator ip address as parameter:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ./ohara-manager.sh 192.168.56.114
docker run --rm -p 5050:5050 -d oharastream/manager:0.7.1 --port 5050 --configurator http://192.168.56.114:12345/v0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now you can open your browser and input the link:
&lt;a href=&#34;http://192.168.56.114:5050&#34;&gt;http://192.168.56.114:5050&lt;/a&gt; to open the main page of Ohara Manager.&lt;/p&gt;
&lt;h2 id=&#34;commands&#34;&gt;commands&lt;/h2&gt;
&lt;p&gt;Following are other commands for development purpose:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;[vm]$ make OHARA_VER=0.7.1
Usage:
  $ make OHARA_VER={version} {command}
  Both {version} and {command} is required.
Command:
  clean: Remove following files:
         build/, .cache/packer_cache/, .cache/packer.log
  ova: Generate the OVA file.
       The output is build/ohara-quickstart-{OHARA_VER}.ova
  vm-import: Import the ova file into VirtualBox
  vm-start: Start quickstart VM
  vm-poweroff: Poweroff quickstart VM
  vm-reset: Reset quickstart VM
  vm-delete: Unregister &amp;amp; delete quickstart VM
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>How to build Quickstart VM</title>
      <link>https://oharastream.github.io/en/docs/master/build/build-quickstart-vm/</link>
      <pubDate>Mon, 15 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/master/build/build-quickstart-vm/</guid>
      <description>&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Operation system: Linux&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://en.wikipedia.org/wiki/Make_%28software%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Make&lt;/a&gt;: Make is a
build automation tool that automatically builds executable programs.
&lt;strong&gt;Make&lt;/strong&gt; is already built in Linux or macOS.&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://www.packer.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Packer&lt;/a&gt; 1.4+: Packer is an open source tool
for creating identical machine images for multiple platforms from a
single source configuration.&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://www.virtualbox.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VirtualBox&lt;/a&gt; 6.0+&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;build-ova-file&#34;&gt;Build OVA file&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;We use &lt;strong&gt;make&lt;/strong&gt; command to execute all our tasks. For building the
specific version of Ohara quickstart VM, you must provide the
argument &lt;strong&gt;OHARA_VER&lt;/strong&gt; when execute the &lt;strong&gt;make&lt;/strong&gt; command.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Build the OVA file, following is an example(OHARA_VER=0.7.1):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;[quickstart]$ cd vm
[vm]$ make OHARA_VER=0.7.1 ova
OHARA_VER=0.7.1
Build time: 2019/09/10 10:10
Start building quickstart VM ova file...
virtualbox-iso output will be in this color.

==&amp;gt; virtualbox-iso: Retrieving ISO
==&amp;gt; virtualbox-iso: Trying .cache/ubuntu-18.04.3-server-amd64.iso
==&amp;gt; virtualbox-iso: Trying .cache/ubuntu-18.04.3-server-amd64.iso?checksum=sha256%3A7d8e0055d663bffa27c1718685085626cb59346e7626ba3d3f476322271f573e
==&amp;gt; virtualbox-iso: .cache/ubuntu-18.04.3-server-amd64.iso?checksum=sha256%3A7d8e0055d663bffa27c1718685085626cb59346e7626ba3d3f476322271f573e =&amp;gt; /your/project/path/ohara/vms/quickstart/.cache/packer_cache/fdcf467e727a368c2aac26ac2284f0f517dc29fb.iso
==&amp;gt; virtualbox-iso: Starting HTTP server on port 8251
==&amp;gt; virtualbox-iso: Creating virtual machine...
==&amp;gt; virtualbox-iso: Creating hard drive...
==&amp;gt; virtualbox-iso: Creating forwarded port mapping for communicator (SSH, WinRM, etc) (host port 3248)
==&amp;gt; virtualbox-iso: Executing custom VBoxManage commands...
:   :   :   :
(SKIP)
:   :   :   :
==&amp;gt; virtualbox-iso: Gracefully halting virtual machine...
==&amp;gt; virtualbox-iso: Preparing to export machine...
    virtualbox-iso: Deleting forwarded port mapping for the communicator (SSH, WinRM, etc) (host port 3248)
==&amp;gt; virtualbox-iso: Exporting virtual machine...
    virtualbox-iso: Executing: export ohara-quickstart-0.7.1 --output build/ohara-quickstart-0.7.1.ova
==&amp;gt; virtualbox-iso: Deregistering and deleting VM...
Build &#39;virtualbox-iso&#39; finished.

==&amp;gt; Builds finished. The artifacts of successful builds are:
--&amp;gt; virtualbox-iso: VM files in directory: build
Done.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The OVA file will be output to: build/ohara-quickstart-{OHARA_VER}.ova&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;Currently, we use Ubuntu 18.04.03 LTS as Quickstart VM&amp;rsquo;s operation
system. Packer will try to find the ubuntu iso file in the
&lt;strong&gt;quickstart/.cache&lt;/strong&gt; folder first, and then download the &lt;a href=&#34;http://cdimage.ubuntu.com/ubuntu/releases/bionic/release/ubuntu-18.04.3-server-amd64.iso&#34;&gt;Ubuntu iso
file&lt;/a&gt;
from internet if the iso file not be found in the cache folder.&lt;/p&gt;
&lt;p&gt;To save your building time, you can download the &lt;a href=&#34;http://cdimage.ubuntu.com/ubuntu/releases/bionic/release/ubuntu-18.04.3-server-amd64.iso&#34;&gt;Ubuntu iso
file&lt;/a&gt;
manually and put into &lt;strong&gt;quickstart/.cache&lt;/strong&gt; folder.&lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;import-ova&#34;&gt;Import OVA&lt;/h2&gt;
&lt;p&gt;After generated the quickstart ova file, you can use VirtualBox user
interface to import the OVA file(&lt;strong&gt;File -&amp;gt; Import Appliance&lt;/strong&gt;) or use
following command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;[vm]$ make OHARA_VER=0.7.1 vm-import
vboxmanage import build/ohara-quickstart-0.7.1.ova --vsys 0 --vmname ohara-quickstart-0.7.1
0%...10%...20%...30%...40%...50%...60%...70%...80%...90%...100%
Interpreting /your/project/path/ohara/vms/quickstart/build/ohara-quickstart-0.7.1.ova...
OK.
Disks:
  vmdisk1       85899345920     -1      http://www.vmware.com/interfaces/specifications/vmdk.html#streamOptimized       ohara-quickstart-0.7.1-disk001.vmdk -1      -1

Virtual system 0:
 0: Suggested OS type: &amp;quot;Ubuntu_64&amp;quot;
    (change with &amp;quot;--vsys 0 --ostype &amp;lt;type&amp;gt;&amp;quot;; use &amp;quot;list ostypes&amp;quot; to list all possible values)
 1: VM name specified with --vmname: &amp;quot;ohara-quickstart-0.7.1&amp;quot;
 2: Description &amp;quot;Ohara Quickstart VM
Ohara version: 0.7.1
Build time: 2019/09/10 10:10&amp;quot;
    (change with &amp;quot;--vsys 0 --description &amp;lt;desc&amp;gt;&amp;quot;)
 3: Number of CPUs: 2
    (change with &amp;quot;--vsys 0 --cpus &amp;lt;n&amp;gt;&amp;quot;)
 4: Guest memory: 4096 MB
    (change with &amp;quot;--vsys 0 --memory &amp;lt;MB&amp;gt;&amp;quot;)
 5: Network adapter: orig NAT, config 3, extra slot=0;type=NAT
 6: Network adapter: orig HostOnly, config 3, extra slot=1;type=HostOnly
 7: IDE controller, type PIIX4
    (disable with &amp;quot;--vsys 0 --unit 7 --ignore&amp;quot;)
 8: IDE controller, type PIIX4
    (disable with &amp;quot;--vsys 0 --unit 8 --ignore&amp;quot;)
 9: Hard disk image: source image=ohara-quickstart-0.7.1-disk001.vmdk, target path=/home/xxxx/VirtualBox VMs/ohara-quickstart-0.7.1/ohara-quickstart-0.7.1-disk001.vmdk, controller=7;channel=0
    (change target path with &amp;quot;--vsys 0 --unit 9 --disk path&amp;quot;;
    disable with &amp;quot;--vsys 0 --unit 9 --ignore&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;use-quickstart-vm&#34;&gt;Use Quickstart VM&lt;/h2&gt;
&lt;p&gt;After import quickstart VM to VirtualBox, you can press &lt;strong&gt;Start&lt;/strong&gt; button
to start the VM. And then you can see following screen:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;Ubuntu 10.04.03 LTS ohara-vm tty1
ohara-vm login:
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Please use &lt;code&gt;ohara&lt;/code&gt; as login account and &lt;code&gt;oharastream&lt;/code&gt; as password to
login to VM. If this is your first time to login Quickstart VM, the
progress of pull Ohara docker images will be starting automatically. So
please make sure your machine can connect to Internet.&lt;/p&gt;
&lt;p&gt;After download the images, and then you can see the ip address info of
the VM, for example:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;IP address info:
lo              UNKNOWN         127.0.0.1/8 ::1/128
enp0s3          UP              10.0.2.15/24 fe80::a00:27ff:feac:ad8a/64
enp0s8          UP              192.168.56.114/24 fe80::a00:27ff:fe09:1a1e/64
docker0         DOWN            172.17.0.1/16
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can find the private IP address &lt;strong&gt;192.168.56.114&lt;/strong&gt; (enp0s8) in the
above list. So the configurator ip address is &lt;strong&gt;192.168.56.114&lt;/strong&gt; .&lt;/p&gt;
&lt;p&gt;Run Ohara configurator(port 12345):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ./ohara-configurator.sh
docker run --rm -p 12345:12345 -d oharastream/configurator:0.7.1 --port 12345
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Run Ohara manager(port 5050), provide the configurator ip address as parameter:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ./ohara-manager.sh 192.168.56.114
docker run --rm -p 5050:5050 -d oharastream/manager:0.7.1 --port 5050 --configurator http://192.168.56.114:12345/v0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now you can open your browser and input the link:
&lt;a href=&#34;http://192.168.56.114:5050&#34;&gt;http://192.168.56.114:5050&lt;/a&gt; to open the main page of Ohara Manager.&lt;/p&gt;
&lt;h2 id=&#34;commands&#34;&gt;commands&lt;/h2&gt;
&lt;p&gt;Following are other commands for development purpose:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;[vm]$ make OHARA_VER=0.7.1
Usage:
  $ make OHARA_VER={version} {command}
  Both {version} and {command} is required.
Command:
  clean: Remove following files:
         build/, .cache/packer_cache/, .cache/packer.log
  ova: Generate the OVA file.
       The output is build/ohara-quickstart-{OHARA_VER}.ova
  vm-import: Import the ova file into VirtualBox
  vm-start: Start quickstart VM
  vm-poweroff: Poweroff quickstart VM
  vm-reset: Reset quickstart VM
  vm-delete: Unregister &amp;amp; delete quickstart VM
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Using Quickstart VM</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/quickstart/quickstartvm/</link>
      <pubDate>Mon, 15 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/quickstart/quickstartvm/</guid>
      <description>&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;OS: Windows / Linux / MacOS&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.virtualbox.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VirtualBox 6.0+&lt;/a&gt;: Oracle VM VirtualBox, is a free and open-source virtual machine.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://github.com/oharastream/ohara-quickstart/releases&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ohara Quickstart VM image&lt;/a&gt;:
An OVA (Open Virtual Appliance) file, a pre-prepared virtual machine image for Ohara quickstart.
You can download the image file (.ova) from the 
&lt;a href=&#34;https://github.com/oharastream/ohara-quickstart/releases/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;release&lt;/a&gt; page.&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/download_assets.png&#34; &gt;


  &lt;img src=&#34;../img/download_assets.png&#34; alt=&#34;Release asserts&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Please download the VirtualBox from &lt;a href=&#34;https://www.virtualbox.org/wiki/Downloads&#34;&gt;here&lt;/a&gt;,
and reference &lt;a href=&#34;https://www.virtualbox.org/manual/ch02.html&#34;&gt;this article&lt;/a&gt; on how to install it on your machine.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    You might have noticed there&amp;rsquo;s another jar file listed in the screenshot: &amp;ldquo;ohara-it-stream.jar&amp;rdquo;.
It&amp;rsquo;s a stream jar that could be used later in our tutorial where we walks you through how to use our UI.
And download it if you would like to follow along with our tutorial later on.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;
&lt;h3 id=&#34;import-vm-and-setup-network-adapter&#34;&gt;Import VM and setup network adapter&lt;/h3&gt;
&lt;p&gt;You can use VirtualBox user interface to import the Ohara Quickstart VM (ova file):
&lt;span class=&#34;markup-quote&#34;&gt;&lt;strong&gt;&lt;em&gt;Main menu&lt;/em&gt;&lt;/strong&gt; -&amp;gt; &lt;strong&gt;&lt;em&gt;File&lt;/em&gt;&lt;/strong&gt; -&amp;gt; &lt;strong&gt;&lt;em&gt;Import Appliance&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Quickstart VM requires a &lt;strong&gt;Host-only network adapter&lt;/strong&gt; to be configured so that you can
connect from the host machine to guest machine (Quickstart VM).&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Quickstart VM uses network adapter &lt;code&gt;vboxnet0&lt;/code&gt; with DHCP Server enabled as &lt;strong&gt;default Host-only adapter&lt;/strong&gt;,
if there is already a &lt;code&gt;vboxnet0&lt;/code&gt; adapter in your VirtualBox, you can just skip this step.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;for-maclinux&#34;&gt;for Mac/Linux&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create new network adapter &amp;mdash; Click &lt;strong&gt;Tools&lt;/strong&gt; and then click &lt;strong&gt;Create&lt;/strong&gt;,
ensure that the DHCP Enable option is checked.















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/mac_add_network.jpg&#34; &gt;


  &lt;img data-src=&#34;../img/mac_add_network.jpg&#34; class=&#34;lazyload&#34; alt=&#34;macos/linux - Create network adapter&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Setting network adapter &amp;mdash; Select the imported &lt;strong&gt;ohara-quickstart-x.x.x&lt;/strong&gt; VM,
click &lt;strong&gt;Setting&lt;/strong&gt;, then click &lt;strong&gt;Network&lt;/strong&gt;, and click &lt;strong&gt;Adapter2&lt;/strong&gt;,
select &lt;strong&gt;Host-only Adapter&lt;/strong&gt;, and select the newly added network card.















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/mac_setting_network.png&#34; &gt;


  &lt;img data-src=&#34;../img/mac_setting_network.png&#34; class=&#34;lazyload&#34; alt=&#34;macos/linux - Setting VM&amp;#39;s network adapter&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;for-windows&#34;&gt;for Windows&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create new network adapter &amp;mdash; Click &lt;strong&gt;Global Tools&lt;/strong&gt; and then click &lt;strong&gt;Create&lt;/strong&gt;,
ensure that the DHCP Enable option is checked.















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/win_add_network.png&#34; &gt;


  &lt;img data-src=&#34;../img/win_add_network.png&#34; class=&#34;lazyload&#34; alt=&#34;Windows - Create network adapter&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Setting network adapter &amp;mdash; Select the imported &lt;strong&gt;ohara-quickstart-x.x.x&lt;/strong&gt; VM,
click &lt;strong&gt;Setting&lt;/strong&gt;, click &lt;strong&gt;Network&lt;/strong&gt;, click &lt;strong&gt;Adapter2&lt;/strong&gt;,
select &lt;strong&gt;Host-only Adapter&lt;/strong&gt;, and select the newly added network card.















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/win_setting_network.png&#34; &gt;


  &lt;img data-src=&#34;../img/win_setting_network.png&#34; class=&#34;lazyload&#34; alt=&#34;Windows - Setting VM&amp;#39;s network adapter&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;install-ohara&#34;&gt;Install Ohara&lt;/h3&gt;
&lt;p&gt;Once the Quickstart VM is imported and the network adapter is configured, you can press
the &lt;strong&gt;Start&lt;/strong&gt; button to start Quickstart VM and then use the following username and password to log into the system:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Username: &lt;em&gt;ohara&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Password: &lt;em&gt;oharastream&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The installation will be starting automatically if this is your first time log in to the system.
This step will take some time to complete as it needs to download all Ohara docker images.&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/vm_ohara_install_1.png&#34; &gt;


  &lt;img data-src=&#34;../img/vm_ohara_install_1.png&#34; class=&#34;lazyload&#34; alt=&#34;VM is pulling down images from Docker Hub&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/vm_ohara_install_2.png&#34; &gt;


  &lt;img data-src=&#34;../img/vm_ohara_install_2.png&#34; class=&#34;lazyload&#34; alt=&#34;Finishing the setup&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;After the installation is completed, you should see something like the following:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;&amp;gt; Start ohara-configurator...
74e0a19a063ce665a0bafba215827d6edd47b9433efdf26af9880d0b4f5e3737

&amp;gt; Start ohara-manager...

ecc6e2845f55b52c6a2ec4b2a203d249f117394cbc16c5387aa067ee5d02a096
&amp;gt; Ohara ready on http://192.168.56.102:5050

ohara@ohara-vm:~$
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we can see here, the VM&amp;rsquo;s IP address is &lt;code&gt;192.168.56.102&lt;/code&gt;
(this address will be varied depending on your VirtualBox network settings).
We can then open the browser and enter this URL in browser&amp;rsquo;s address bar
&lt;code&gt;http://192.168.56.102:5050&lt;/code&gt; to open Ohara Manager (Ohara&amp;rsquo;s UI, we will
introduce it in the following section).&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    After shutting down your VM, the docker containers will be deleted and restarted on your next login
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;terminology&#34;&gt;Terminology&lt;/h2&gt;
&lt;p&gt;Before jumping into the UI and create our very first workspace and pipeline.
Let&amp;rsquo;s get to know some of the terms that we will be using throughout this guide.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Manager&lt;/p&gt;
&lt;p&gt;Manager is the user interface of Ohara (UI). It provides a friendly user interface allowing user to design their data
pipeline without even touching a single line of code.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Node&lt;/p&gt;
&lt;p&gt;Node is the basic unit of running service. It can be either a physical server or virtual machine.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Workspace&lt;/p&gt;
&lt;p&gt;Workspace contains multiple OharaStream services including: Zookeepers, Brokers and Workers.
And pipelines are services that run in a workspace.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pipeline&lt;/p&gt;
&lt;p&gt;Pipeline allows you to define your data stream by utilizing &lt;strong&gt;Connector&lt;/strong&gt; to connect to
external storage systems, as well as a &lt;strong&gt;Stream&lt;/strong&gt; to customize data transformation and stream processing.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Connector&lt;/p&gt;
&lt;p&gt;Connector connects to external storage systems like Databases, HDFS or FTP.
It has two types &amp;mdash; source connector and sink connector.
Source connector is able to pull data from another system and then push the data to topic.
By contrast, Sink connector pulls data from topic and then push the data to another system.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Stream&lt;/p&gt;
&lt;p&gt;Stream is powered by 
&lt;a href=&#34;https://kafka.apache.org/documentation/streams/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kafka Streams&lt;/a&gt; which
provides users a simple way to write their own stream processing application.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Topic&lt;/p&gt;
&lt;p&gt;A topic is a place where all the data are written just like a database table where data is stored. It acts like a buffer, the data being pull in from the source connector is stored in the topic and so later can be pulled out again by another component (e.g., sink connectors)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ui-overview&#34;&gt;UI overview&lt;/h2&gt;
&lt;p&gt;Before we proceed, here is a screenshot of &lt;strong&gt;Ohara Manager&lt;/strong&gt; where we show you each component&amp;rsquo;s name, so you are better prepared for the upcoming tutorial. You can always come back to this overview if you are lost or not sure what we&amp;rsquo;re talking about in the tutorial.&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ui-overview.png&#34; &gt;


  &lt;img data-src=&#34;../img/ui-overview.png&#34; class=&#34;lazyload&#34; alt=&#34;UI overview&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    We do our best to make our docs as clear as we could, if you think there&amp;rsquo;s still room for improvement.
We would love to hear from you: &lt;a href=&#34;https://github.com/oharastream/ohara/issues&#34;&gt;https://github.com/oharastream/ohara/issues&lt;/a&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Now, Ohara Manager is up and running, we can use the UI to create our very first pipeline.
Here are the steps that we will be going through together:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Create a workspace&lt;/li&gt;
&lt;li&gt;Create a pipeline&lt;/li&gt;
&lt;li&gt;Add pipeline components, this includes:
&lt;ul&gt;
&lt;li&gt;A FTP source and a sink connector&lt;/li&gt;
&lt;li&gt;Two topics&lt;/li&gt;
&lt;li&gt;A stream&lt;/li&gt;
&lt;li&gt;Create connections between them&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Start the pipeline&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    During the tutorial, we will be using FTP source/sink connectors. And so you will need to prepare your own FTP in order to follow along.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;create-a-workspace&#34;&gt;Create a workspace&lt;/h2&gt;
&lt;p&gt;Open Ohara Manager with your browser (http://192.168.56.102:5050) and you should see a dialog
showing up right in the middle of your screen:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Click on the &lt;strong&gt;QUICK CREATE&lt;/strong&gt; button to open a new dialog















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/intro-dialog.png&#34; &gt;


  &lt;img data-src=&#34;../img/intro-dialog.png&#34; class=&#34;lazyload&#34; alt=&#34;Intro dialog&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Using the default name: &lt;em&gt;workspace1&lt;/em&gt; and hit the &lt;strong&gt;NEXT&lt;/strong&gt; button















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/quick-create-workspace-name.png&#34; &gt;


  &lt;img data-src=&#34;../img/quick-create-workspace-name.png&#34; class=&#34;lazyload&#34; alt=&#34;Quick create workspace new name&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Click on the Select nodes and click on the pencil icon to create a new node.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/quick-create-workspace-node.png&#34; &gt;


  &lt;img data-src=&#34;../img/quick-create-workspace-node.png&#34; class=&#34;lazyload&#34; alt=&#34;Quick create workspace new node&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/quick-create-workspace-add-node.png&#34; &gt;


  &lt;img data-src=&#34;../img/quick-create-workspace-add-node.png&#34; class=&#34;lazyload&#34; alt=&#34;Quick create workspace add node icon&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The node info that you need to enter are listed below:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hostname: &lt;em&gt;192.168.56.102&lt;/em&gt; (fill your own hostname here)&lt;/li&gt;
&lt;li&gt;Port: &lt;em&gt;22&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;User: &lt;em&gt;ohara&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Password: &lt;em&gt;oharastream&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/quick-create-workspace-add-node.png&#34; &gt;


  &lt;img data-src=&#34;../img/quick-create-workspace-add-node.png&#34; class=&#34;lazyload&#34; alt=&#34;Quick create workspace add a new node&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;The node should be added into the list. Select the node and click on the SAVE button to close the dialog&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/quick-create-workspace-select-node.png&#34; &gt;


  &lt;img data-src=&#34;../img/quick-create-workspace-select-node.png&#34; class=&#34;lazyload&#34; alt=&#34;Quick create workspace select node&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;Now, click the &lt;strong&gt;NEXT&lt;/strong&gt; button to finish selecting nodes&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/quick-create-workspace-node-summary.png&#34; &gt;


  &lt;img data-src=&#34;../img/quick-create-workspace-node-summary.png&#34; class=&#34;lazyload&#34; alt=&#34;Quick create workspace node summary&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;Click on the &lt;strong&gt;SUBMIT&lt;/strong&gt; button to create this workspace.&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/quick-create-workspace-summary.png&#34; &gt;


  &lt;img data-src=&#34;../img/quick-create-workspace-summary.png&#34; class=&#34;lazyload&#34; alt=&#34;Quick create workspace summary&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;A new dialog will open where it shows you the creating progress. This usually takes a while to finish. Once it&amp;rsquo;s done, You can close the dialog by clicking on the CLOSE button. And the UI will automatically redirect you to the newly created workspace: &lt;em&gt;Workspace1&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/quick-create-workspace-progress.png&#34; &gt;


  &lt;img data-src=&#34;../img/quick-create-workspace-progress.png&#34; class=&#34;lazyload&#34; alt=&#34;Quick create workspace creating progress&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/quick-create-workspace-done.png&#34; &gt;


  &lt;img data-src=&#34;../img/quick-create-workspace-done.png&#34; class=&#34;lazyload&#34; alt=&#34;Quick create workspace done&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    You can create more workspace with the plus icon(:heavy_plus_sign:) in the App bar.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;div&gt;
    Please keep in mind that this is a quick start VM where we run everything on a single node
with only 8GB of RAM and 2 CPU cores. We highly recommend you to add more RAM and CPU
core to your VM if you plan to create more than one workspace or lots of pipelines, connectors,
streams, etc. This is due to when Ohara is running without enough resources, it could be very
unstable and causing unexpected errors.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;create-a-pipeline&#34;&gt;Create a pipeline&lt;/h2&gt;
&lt;p&gt;Create a pipeline is fairly simple:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;On the Navigator, click on the plus icon.&lt;/li&gt;
&lt;li&gt;In the popup window, enter the name: pipeline1 and click the &lt;strong&gt;ADD&lt;/strong&gt; button















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-a-pipeline.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-a-pipeline.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a pipeline&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;The new pipeline will be added into the workspace and listed in the Navigator.
And just like creating workspace, you will be redirected to the pipeline you just created.















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-a-pipeline-done.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-a-pipeline-done.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a pipeline done&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;add-pipeline-components&#34;&gt;Add pipeline components&lt;/h3&gt;
&lt;p&gt;Since workspace and pipeline are both ready. We can now add new components into the pipeline.
The pipeline connection we&amp;rsquo;re about to create will look like:
&lt;code&gt;FTP source -&amp;gt; topic -&amp;gt; stream -&amp;gt; topic -&amp;gt; FTP sink&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Before we start, please make sure your FTP service is ready and let&amp;rsquo;s get started!&lt;/p&gt;
&lt;h4 id=&#34;drag-and-drop-new-pipeline-components&#34;&gt;Drag and drop new pipeline components&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;FTP source:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;From the Toolbox (Please refer to the overview image for what is Toolbox if needed)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Click on the title &amp;ldquo;Source&amp;rdquo;, the panel will be expanded and display all available source connectors















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ftpsource-add-toolbox.png&#34; &gt;


  &lt;img data-src=&#34;../img/ftpsource-add-toolbox.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a FTP source from Toolbox&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Drag the &amp;ldquo;FtpSource&amp;rdquo; from the list and drop into the Paper (Don&amp;rsquo;t worry about the position just yet. This can be changed later after it&amp;rsquo;s added into the Paper). A prompt will be asking you about the connector name, let&amp;rsquo;s name it &amp;ldquo;ftpsource&amp;rdquo; and click the ADD button.















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ftpsource-add-name.png&#34; &gt;


  &lt;img data-src=&#34;../img/ftpsource-add-name.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a FTP source name&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The FTP source connector should display in the Paper:















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ftpsource-add-done.png&#34; &gt;


  &lt;img data-src=&#34;../img/ftpsource-add-done.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a FTP source name done&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Now, hover over the Ftp source connector, a couple of buttons will show up. These are action buttons, let&amp;rsquo;s take a quick look and see what can we do with them (starting from left to right):















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ftpsource-add-action-buttons.png&#34; &gt;


  &lt;img data-src=&#34;../img/ftpsource-add-action-buttons.png&#34; class=&#34;lazyload&#34; alt=&#34;Action buttons&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Link&lt;/strong&gt;: create a new link, once a link is created you can move your mouse and the link will follow along your mouse position. To link to another component, you can hover over it and do a mouse left-click. To cancel the link creation, just click on the blank area within the Paper.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Start&lt;/strong&gt;: start a component. Once the component is properly configured, you can then use this button to start the component.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stop&lt;/strong&gt;: stop a running or failed component&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Configure&lt;/strong&gt;: open the Property dialog and fill out necessary configuration for the component.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Delete&lt;/strong&gt;: delete the selected component.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    A &lt;strong&gt;Link&lt;/strong&gt; can also be interacted with. You can remove it by clicking on the &amp;ldquo;x&amp;rdquo; button.
And click on any point of the link creates a vertex. The vertex can be moved and tweaked to change its position.
You can also delete a vertex by double clicking on it.
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Okay, that&amp;rsquo;s enough of these button things. Let&amp;rsquo;s click on the &amp;ldquo;configure&amp;rdquo; icon (a wrench) and fill in the following fields (Note that you need to use your own settings, and create completed, error, input and output directories on your own FTP service). For fields that we did not mention below, the default is used:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Completed Folder: &lt;em&gt;demo/completed&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Error Folder: &lt;em&gt;demo/error&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Hostname of FTP Server: &lt;em&gt;10.2.0.28&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Port of FTP Server: &lt;em&gt;21&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;User of FTP Server: &lt;em&gt;ohara&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Password of FTP Server: &lt;em&gt;oharastream&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Input Folder: &lt;em&gt;demo/input&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once these settings had been filled out, click on the &lt;strong&gt;SAVE CHANGES&lt;/strong&gt; button.















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ftpsource-add-config.png&#34; &gt;


  &lt;img data-src=&#34;../img/ftpsource-add-config.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a FTP source configuration&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    There are validation rules which will prevent you from submitting the form without filling require fields.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;FTP sink:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Just like FTP source connector, let&amp;rsquo;s drag and drop a FTP sink connector from the Toolbox and name it &amp;ldquo;ftpsink&amp;rdquo;.
After it&amp;rsquo;s added in the Paper, click on its &amp;ldquo;configure&amp;rdquo; button. The settings are mostly like FTP source with the only exception: &amp;ldquo;output&amp;rdquo;:&lt;/p&gt;
&lt;p&gt;














&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ftpsink-add-toolbox.png&#34; &gt;


  &lt;img data-src=&#34;../img/ftpsink-add-toolbox.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a FTP sink&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ftpsink-config.png&#34; &gt;


  &lt;img data-src=&#34;../img/ftpsink-config.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a FTP sink configuration&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hostname of FTP Server: &lt;em&gt;10.2.0.28&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Port of FTP Server: &lt;em&gt;21&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;User of FTP Server: &lt;em&gt;ohara&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Password of FTP Server: &lt;em&gt;oharastream&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Output Folder: &lt;em&gt;demo/output&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Great! Now we have both source and sink connectors ready. Let&amp;rsquo;s move on to create some topics.&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ftpsink-add-done.png&#34; &gt;


  &lt;img data-src=&#34;../img/ftpsink-add-done.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a FTP sink done&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;Topic:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In this tutorial, we need two topics for the pipeline, let&amp;rsquo;s add them from the Toolbox like what we did in the previous steps for FTP connectors:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;From the Toolbox, click on the title &amp;ldquo;Topic&amp;rdquo; to expand the topic panel.















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/topic-add-toolbox.png&#34; &gt;


  &lt;img data-src=&#34;../img/topic-add-toolbox.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a topic from Toolbox&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Click and drag &amp;ldquo;Pipeline Only&amp;rdquo; item from the list and drop it into the Paper to add a new Topic. Unlike source or sink connector, adding a topic doesn&amp;rsquo;t require entering a name, the name will be auto-generated like (T1, T2, T3, etc.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Repeat the above step to create another Topic. You should now have two topics (T1, T2) in your Paper in addition to those FTP connectors:&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/topic-add-done.png&#34; &gt;


  &lt;img data-src=&#34;../img/topic-add-done.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a topic done&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;And luckily, there&amp;rsquo;s no need to configure these topics as they&amp;rsquo;re preconfigured and already running after you added.&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    In Ohara, topics can either be a &amp;ldquo;Pipeline-only topic&amp;rdquo; or a &amp;ldquo;Shared topic&amp;rdquo;.
The pipeline-only topics are topics that only live within a pipeline.
And on the other hand, shared topics can be shared and used across different pipelines.
For simplicity sake, we only use pipeline-only topics throughout this tutorial.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    For quickly creating a new pipeline-only topic, you can also just add a source and a sink (or stream) connector and
then link them together with the &amp;ldquo;Link&amp;rdquo; button from the source connector component.
The pipeline-only topic will be created automatically.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Stream:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Stream is our last missing piece of the pipeline. Let&amp;rsquo;s add one very quick!&lt;/p&gt;
&lt;p&gt;Remember the 
&lt;a href=&#34;https://github.com/oharastream/ohara-quickstart/releases&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;stream jar&lt;/a&gt; you downloaded
along with the quickstart image? It&amp;rsquo;s time to use it:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Click on the &amp;ldquo;Stream&amp;rdquo; panel on the Toolbox and then click on the &amp;ldquo;Add streams&amp;rdquo; button&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-toolbox-upload.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-toolbox-upload.png&#34; class=&#34;lazyload&#34; alt=&#34;Upload a stream&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;It will open workspace settings and redirect you to the stream jars page:&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-page.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-page.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream settings page&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;Click on the plus icon to open select file dialog:&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-select-icon.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-select-icon.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream select file icon&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;The workspace file list are currently empty, let&amp;rsquo;s add a new file by clicking on the upload icon. This will open your OS file system, you can then select the stream jar file you downloaded. The stream class will be loaded and displayed in the list:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;














&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-upload-icon.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-upload-icon.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream upload icon&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-upload-done.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-upload-done.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream select file upload done&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Select the stream and click on the SAVE button to close select file dialog&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-list.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-list.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream list&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;The stream file should now listed in your Stream Jars page. Close this page by clicking on the close button on the upper-right corner&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-list-done.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-list-done.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream list done&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;Adding a stream is just like connector and topic, drag the &amp;ldquo;DumbStream&amp;rdquo; item from the Toolbox and drop it into the Paper and give a name &amp;ldquo;stream&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-name.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-name.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream name&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;Now let&amp;rsquo;s work through the configuration together. Hover over the stream component and click on the &amp;ldquo;Configure&amp;rdquo; button to open the configure dialog&lt;/li&gt;
&lt;li&gt;Fill out the form with the following settings and click the &amp;ldquo;&lt;strong&gt;SAVE CHANGES&lt;/strong&gt;&amp;rdquo; button:
&lt;ul&gt;
&lt;li&gt;header name to be filtered: &lt;em&gt;&amp;ldquo;Sex&amp;rdquo;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;column value to be filtered: &lt;em&gt;&amp;ldquo;M&amp;rdquo;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Node name list: &lt;em&gt;192.168.56.111&lt;/em&gt; (you should use you own IP)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-dialog.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-dialog.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream dialog&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    This stream is capable of filtering out columns and values that we specified and then push
the new result to a topic. Here we&amp;rsquo;re specifically setting the &amp;ldquo;Sex&amp;rdquo; as the filtered header
and &amp;ldquo;M&amp;rdquo; as the filtered value (stands for Man) and so our output data will only &amp;ldquo;include&amp;rdquo;
data that contains &amp;ldquo;M&amp;rdquo; value in the &amp;ldquo;Sex&amp;rdquo; column. We will verify the result later in the tutorial.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Everything is ready. We can now create the connection like we mentioned earlier:
&lt;code&gt;FTP source -&amp;gt; topic -&amp;gt; stream -&amp;gt; topic -&amp;gt; FTP sink&lt;/code&gt;.
But before doing so, let&amp;rsquo;s move these components a bit and so we can have more room
to work with (You can close the Toolbox by clicking on the close icon on the top right corner):&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-change-layout.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-change-layout.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream change layout&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;Okay, it&amp;rsquo;s time to create the connection:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hover over FTP source connector and click the &amp;ldquo;Link&amp;rdquo; button, and move your mouse to the first topic named &amp;ldquo;T1&amp;rdquo; and click on it. A connection should be created:&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-create-first-link.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-create-first-link.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream create first link&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;Repeat the same step but this time with &amp;ldquo;T1&amp;rdquo; to create a connection from T1 to stream&lt;/li&gt;
&lt;li&gt;And stream -&amp;gt; T2 then T2 -&amp;gt; FTP sink connector. After you are done, you should have a graph like this (Components position have been tweaked so it&amp;rsquo;s better to see the relation between these components):&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-done.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-done.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream done&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    You can also create the connection during configuring the connector or stream. For connector, just choose the topic from its topic list. For stream, you will need to choose both &lt;em&gt;&amp;ldquo;from&amp;rdquo;&lt;/em&gt; and &lt;em&gt;&amp;ldquo;to&amp;rdquo;&lt;/em&gt; topics from the topic list.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;start-pipeline-components&#34;&gt;Start pipeline components&lt;/h3&gt;
&lt;p&gt;So far so good, let&amp;rsquo;s start all the components simply by clicking on the &amp;ldquo;Start all components&amp;rdquo;
button located on the Toolbar menu. If everything goes well you should see that all components&amp;rsquo;
icons are now in green just like the following image:&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/start-components-done.png&#34; &gt;


  &lt;img data-src=&#34;../img/start-components-done.png&#34; class=&#34;lazyload&#34; alt=&#34;Start components done&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h3 id=&#34;test-our-new-pipeline&#34;&gt;Test our new pipeline&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s test this &amp;ldquo;pipeline&amp;rdquo; to see if it&amp;rsquo;s capable of transferring some data. We have
prepared a CSV file which looks like this (you can download this file from

&lt;a href=&#34;https://people.sc.fsu.edu/~jburkardt/data/csv/freshman_kgs.csv&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;):&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/csv.png&#34; &gt;


  &lt;img data-src=&#34;../img/csv.png&#34; class=&#34;lazyload&#34; alt=&#34;CSV file&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;Upload the file to the FTP service&amp;rsquo;s input folder. Wait for a while, the file should be
consumed and moved to the output folder. You can verify if the data is properly transferred
by using a FTP client to check the file (we&amp;rsquo;re using 
&lt;a href=&#34;https://filezilla-project.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;FileZilla&lt;/a&gt;).&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/csv-output.png&#34; &gt;


  &lt;img data-src=&#34;../img/csv-output.png&#34; class=&#34;lazyload&#34; alt=&#34;CSV output&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;The output data should be filtered with the result only &amp;ldquo;M&amp;rdquo; (man) data are listed as shown below:&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/csv-output-done.png&#34; &gt;


  &lt;img data-src=&#34;../img/csv-output-done.png&#34; class=&#34;lazyload&#34; alt=&#34;CSV output done&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h2 id=&#34;troubleshooting&#34;&gt;Troubleshooting&lt;/h2&gt;
&lt;p&gt;We now provide a few debugging tools that can help you pin down unexpected errors:&lt;/p&gt;
&lt;h3 id=&#34;event-log-panel&#34;&gt;Event log panel&lt;/h3&gt;
&lt;p&gt;All UI events are recorded, things like API request and response are also stored.
You can view all you event log by simply opening up the Event log panel. As you can
see in the screenshot, errors are highlighted and have more details that can be viewed
when click on each of them.&lt;/p&gt;
&lt;p&gt;














&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/event-log-icon.png&#34; &gt;


  &lt;img data-src=&#34;../img/event-log-icon.png&#34; class=&#34;lazyload&#34; alt=&#34;Event log icon&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/event-log-list.png&#34; &gt;


  &lt;img data-src=&#34;../img/event-log-list.png&#34; class=&#34;lazyload&#34; alt=&#34;Event log list&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/event-log-dialog.png&#34; &gt;


  &lt;img data-src=&#34;../img/event-log-dialog.png&#34; class=&#34;lazyload&#34; alt=&#34;Event log dialog&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Another thing that is worth mentioning here is the Event log icon will display the error log&amp;rsquo;s count on the icon&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/event-log-notification.png&#34; &gt;


  &lt;img data-src=&#34;../img/event-log-notification.png&#34; class=&#34;lazyload&#34; alt=&#34;Event log notification&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h3 id=&#34;developer-tools-panel&#34;&gt;Developer Tools panel&lt;/h3&gt;
&lt;p&gt;Open the dev tool from the App bar:&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/devtool-icon.png&#34; &gt;


  &lt;img data-src=&#34;../img/devtool-icon.png&#34; class=&#34;lazyload&#34; alt=&#34;DevTool icon&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;There are two main functionalities that could be utilized here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Topic panel: you can quickly preview the topic data here&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/devtool-topic-data.png&#34; &gt;


  &lt;img data-src=&#34;../img/devtool-topic-data.png&#34; class=&#34;lazyload&#34; alt=&#34;DevTool topic data&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;Log panel: view all running service&amp;rsquo;s full log&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/devtool-topic-log.png&#34; &gt;


  &lt;img data-src=&#34;../img/devtool-topic-log.png&#34; class=&#34;lazyload&#34; alt=&#34;DevTool topic log&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h3 id=&#34;delete-workspace&#34;&gt;Delete workspace&lt;/h3&gt;
&lt;p&gt;Deleting a workspace is a new feature implemented in 0.10.0, with this feature, you can now delete a workspace with our UI&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    All pipelines under the workspace that you&amp;rsquo;re about to delete should be stopped
(in other word, everything except topics in the pipeline should have the status &amp;ldquo;stopped&amp;rdquo;,
you can do so by going to each pipeline&amp;rsquo;s Toolbar and click on the &amp;ldquo;Stop all components&amp;rdquo;
item from the Pipeline actions
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;From Navigator, click on the workspace name, and click on the &amp;ldquo;Settings&amp;rdquo; item from that dropdown:&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/delete-workspace-menu.png&#34; &gt;


  &lt;img data-src=&#34;../img/delete-workspace-menu.png&#34; class=&#34;lazyload&#34; alt=&#34;Delete workspace menu&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;In the Settings dialog, scroll to the very bottom of the page, and click &amp;ldquo;Delete this workspace&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/delete-workspace-settings-button.png&#34; &gt;


  &lt;img data-src=&#34;../img/delete-workspace-settings-button.png&#34; class=&#34;lazyload&#34; alt=&#34;Delete workspace settings button&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;A confirm dialog will pop up. Enter the workspace name and click on the DELETE button to start deleting. (Note that if you still have some services running in the workspace, you won&amp;rsquo;t able to proceed. You should following the instruction mention in the above to stop all pipelines first)&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/delete-workspace-confirm.png&#34; &gt;


  &lt;img data-src=&#34;../img/delete-workspace-confirm.png&#34; class=&#34;lazyload&#34; alt=&#34;Delete workspace confirm dialog&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;The deletion is in progress, after the deletion is completed, you will be redirected to home or a default workspace if you have one.&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/delete-workspace-progress.png&#34; &gt;


  &lt;img data-src=&#34;../img/delete-workspace-progress.png&#34; class=&#34;lazyload&#34; alt=&#34;Delete workspace progress dialog&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h3 id=&#34;restart-workspace&#34;&gt;Restart workspace&lt;/h3&gt;
&lt;p&gt;When new changes were made in workspace, the restart is required. Also, if you ever run into issues that cannot be recovered from, you can try to restart the workspace to fix the issue.&lt;/p&gt;
&lt;p&gt;Since delete workspace and restart workspace are almost identical, the following instruction won&amp;rsquo;t include any screenshots as they are already included in the 
&lt;a href=&#34;#delete-workspace&#34;&gt;Delete workspace&lt;/a&gt; section&lt;/p&gt;
&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;div&gt;
    Same with delete a workspace, you will need to make sure all pipelines are stopped before starting:
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;From Navigator, click on the workspace name, and click on the &amp;ldquo;Settings&amp;rdquo; item from that dropdown.&lt;/li&gt;
&lt;li&gt;In the Settings dialog, scroll to the very bottom of the page, and click &amp;ldquo;Restart this workspace&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;A confirm dialog will pop up. Click on the RESTART button to start restarting this workspace.&lt;/li&gt;
&lt;li&gt;The restarting is in progress, after the restart is completed, you can close the progress
dialog and changes you made should applied to the workspace by now.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And if you think you ever encountered a bug, let us know: 
&lt;a href=&#34;https://github.com/oharastream/ohara/issues/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub Repo&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Using Quickstart VM</title>
      <link>https://oharastream.github.io/en/docs/master/quickstart/quickstartvm/</link>
      <pubDate>Mon, 15 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/master/quickstart/quickstartvm/</guid>
      <description>&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;OS: Windows / Linux / MacOS&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.virtualbox.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VirtualBox 6.0+&lt;/a&gt;: Oracle VM VirtualBox, is a free and open-source virtual machine.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://github.com/oharastream/ohara-quickstart/releases&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ohara Quickstart VM image&lt;/a&gt;:
An OVA (Open Virtual Appliance) file, a pre-prepared virtual machine image for Ohara quickstart.
You can download the image file (.ova) from the 
&lt;a href=&#34;https://github.com/oharastream/ohara-quickstart/releases/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;release&lt;/a&gt; page.&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/download_assets.png&#34; &gt;


  &lt;img src=&#34;../img/download_assets.png&#34; alt=&#34;Release asserts&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Please download the VirtualBox from &lt;a href=&#34;https://www.virtualbox.org/wiki/Downloads&#34;&gt;here&lt;/a&gt;,
and reference &lt;a href=&#34;https://www.virtualbox.org/manual/ch02.html&#34;&gt;this article&lt;/a&gt; on how to install it on your machine.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    You might have noticed there&amp;rsquo;s another jar file listed in the screenshot: &amp;ldquo;ohara-it-stream.jar&amp;rdquo;.
It&amp;rsquo;s a stream jar that could be used later in our tutorial where we walks you through how to use our UI.
And download it if you would like to follow along with our tutorial later on.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;
&lt;h3 id=&#34;import-vm-and-setup-network-adapter&#34;&gt;Import VM and setup network adapter&lt;/h3&gt;
&lt;p&gt;You can use VirtualBox user interface to import the Ohara Quickstart VM (ova file):
&lt;span class=&#34;markup-quote&#34;&gt;&lt;strong&gt;&lt;em&gt;Main menu&lt;/em&gt;&lt;/strong&gt; -&amp;gt; &lt;strong&gt;&lt;em&gt;File&lt;/em&gt;&lt;/strong&gt; -&amp;gt; &lt;strong&gt;&lt;em&gt;Import Appliance&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Quickstart VM requires a &lt;strong&gt;Host-only network adapter&lt;/strong&gt; to be configured so that you can
connect from the host machine to guest machine (Quickstart VM).&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Quickstart VM uses network adapter &lt;code&gt;vboxnet0&lt;/code&gt; with DHCP Server enabled as &lt;strong&gt;default Host-only adapter&lt;/strong&gt;,
if there is already a &lt;code&gt;vboxnet0&lt;/code&gt; adapter in your VirtualBox, you can just skip this step.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;for-maclinux&#34;&gt;for Mac/Linux&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create new network adapter &amp;mdash; Click &amp;ldquo;Tools&amp;rdquo; and then click &amp;ldquo;Create&amp;rdquo;,
ensure that the DHCP Enable option is checked.















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/mac_add_network.jpg&#34; &gt;


  &lt;img data-src=&#34;../img/mac_add_network.jpg&#34; class=&#34;lazyload&#34; alt=&#34;macos/linux - Create network adapter&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Setting network adapter &amp;mdash; Select the imported &lt;strong&gt;ohara-quickstart-x.x.x&lt;/strong&gt; VM,
click &amp;ldquo;Setting&amp;rdquo;, then click &amp;ldquo;Network&amp;rdquo;, and click &amp;ldquo;Adapter2&amp;rdquo;,
select &amp;ldquo;Host-only Adapter&amp;rdquo;, and select the newly added network card.















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/mac_setting_network.png&#34; &gt;


  &lt;img data-src=&#34;../img/mac_setting_network.png&#34; class=&#34;lazyload&#34; alt=&#34;macos/linux - Setting VM&amp;#39;s network adapter&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;for-windows&#34;&gt;for Windows&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create new network adapter &amp;mdash; Click &amp;ldquo;Global Tools&amp;rdquo; and then click &amp;ldquo;Create&amp;rdquo;,
ensure that the DHCP Enable option is checked.















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/win_add_network.png&#34; &gt;


  &lt;img data-src=&#34;../img/win_add_network.png&#34; class=&#34;lazyload&#34; alt=&#34;Windows - Create network adapter&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Setting network adapter &amp;mdash; Select the imported &lt;strong&gt;ohara-quickstart-x.x.x&lt;/strong&gt; VM,
click &amp;ldquo;Setting&amp;rdquo;, click &amp;ldquo;Network&amp;rdquo;, click &amp;ldquo;Adapter2&amp;rdquo;,
select &amp;ldquo;Host-only Adapter&amp;rdquo;, and select the newly added network card.















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/win_setting_network.png&#34; &gt;


  &lt;img data-src=&#34;../img/win_setting_network.png&#34; class=&#34;lazyload&#34; alt=&#34;Windows - Setting VM&amp;#39;s network adapter&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;install-ohara&#34;&gt;Install Ohara&lt;/h3&gt;
&lt;p&gt;Once the Quickstart VM is imported and the network adapter is configured, you can press
the &lt;strong&gt;Start&lt;/strong&gt; button to start Quickstart VM and then use the following username and password to log into the system:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Username: &lt;em&gt;ohara&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Password: &lt;em&gt;oharastream&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The installation will be starting automatically if this is your first time log in to the system.
This step will take some time to complete as it needs to download all Ohara docker images.&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/vm_ohara_install_1.png&#34; &gt;


  &lt;img data-src=&#34;../img/vm_ohara_install_1.png&#34; class=&#34;lazyload&#34; alt=&#34;VM is pulling down images from Docker Hub&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/vm_ohara_install_2.png&#34; &gt;


  &lt;img data-src=&#34;../img/vm_ohara_install_2.png&#34; class=&#34;lazyload&#34; alt=&#34;Finishing the setup&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;After the installation is completed, you should see something like the following:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;&amp;gt; Start ohara-configurator...
74e0a19a063ce665a0bafba215827d6edd47b9433efdf26af9880d0b4f5e3737

&amp;gt; Start ohara-manager...

ecc6e2845f55b52c6a2ec4b2a203d249f117394cbc16c5387aa067ee5d02a096
&amp;gt; Ohara ready on http://192.168.56.102:5050

ohara@ohara-vm:~$
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we can see here, the VM&amp;rsquo;s IP address is &lt;code&gt;192.168.56.102&lt;/code&gt;
(this address will be varied depending on your VirtualBox network settings).
We can then open the browser and enter this URL in browser&amp;rsquo;s address bar
&lt;code&gt;http://192.168.56.102:5050&lt;/code&gt; to open Ohara Manager (Ohara&amp;rsquo;s UI, we will
introduce it in the following section).&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    After shutting down your VM, the docker containers will be deleted and restarted on your next login
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;terminology&#34;&gt;Terminology&lt;/h2&gt;
&lt;p&gt;Before jumping into the UI and create our very first workspace and pipeline.
Let&amp;rsquo;s get to know some of the terms that we will be using throughout this guide.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Manager&lt;/p&gt;
&lt;p&gt;Manager is the user interface of Ohara (UI). It provides a friendly user interface allowing user to design their data
pipeline without even touching a single line of code.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Node&lt;/p&gt;
&lt;p&gt;Node is the basic unit of running service. It can be either a physical server or virtual machine.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Workspace&lt;/p&gt;
&lt;p&gt;Workspace contains multiple OharaStream services including: Zookeepers, Brokers and Workers.
And pipelines are services that run in a workspace.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pipeline&lt;/p&gt;
&lt;p&gt;Pipeline allows you to define your data stream by utilizing &amp;ldquo;Connector&amp;rdquo; to connect to
external storage systems, as well as a &amp;ldquo;Stream&amp;rdquo; to customize data transformation and stream processing.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Connector&lt;/p&gt;
&lt;p&gt;Connector connects to external storage systems like Databases, HDFS or FTP.
It has two types &amp;mdash; source connector and sink connector.
Source connector is able to pull data from another system and then push the data to topic.
By contrast, Sink connector pulls data from topic and then push the data to another system.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Stream&lt;/p&gt;
&lt;p&gt;Stream is powered by 
&lt;a href=&#34;https://kafka.apache.org/documentation/streams/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kafka Streams&lt;/a&gt; which
provides users a simple way to write their own stream processing application.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Topic&lt;/p&gt;
&lt;p&gt;A topic is a place where all the data are written just like a database table where data is stored. It acts like a buffer, the data being pull in from the source connector is stored in the topic and so later can be pulled out again by another component (e.g., sink connectors)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ui-overview&#34;&gt;UI overview&lt;/h2&gt;
&lt;p&gt;Before we proceed, here is a screenshot of &amp;ldquo;Ohara Manager&amp;rdquo; where we show you each component&amp;rsquo;s name, so you are better prepared for the upcoming tutorial. You can always come back to this overview if you are lost or not sure what we&amp;rsquo;re talking about in the tutorial.&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ui-overview.png&#34; &gt;


  &lt;img data-src=&#34;../img/ui-overview.png&#34; class=&#34;lazyload&#34; alt=&#34;UI overview&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    We do our best to make our docs as clear as we could, if you think there&amp;rsquo;s still room for improvement.
We would love to hear from you: &lt;a href=&#34;https://github.com/oharastream/ohara/issues&#34;&gt;https://github.com/oharastream/ohara/issues&lt;/a&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Now, Ohara Manager is up and running, we can use the UI to create our very first pipeline.
Here are the steps that we will be going through together:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Create a workspace&lt;/li&gt;
&lt;li&gt;Create a pipeline&lt;/li&gt;
&lt;li&gt;Add pipeline components, this includes:
&lt;ul&gt;
&lt;li&gt;A FTP source and a sink connector&lt;/li&gt;
&lt;li&gt;Two topics&lt;/li&gt;
&lt;li&gt;A stream&lt;/li&gt;
&lt;li&gt;Create connections between them&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Start the pipeline&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    During the tutorial, we will be using FTP source/sink connectors. And so you will need to prepare your own FTP in order to follow along.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;create-a-workspace&#34;&gt;Create a workspace&lt;/h2&gt;
&lt;p&gt;Open Ohara Manager with your browser of choice (http://192.168.56.102:5050) and you should see a dialog
showing up right in the middle of your screen:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Click on the &amp;ldquo;QUICK CREATE&amp;rdquo; button to open quick create workspace dialog















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/intro-dialog.png&#34; &gt;


  &lt;img data-src=&#34;../img/intro-dialog.png&#34; class=&#34;lazyload&#34; alt=&#34;Intro dialog&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Using the default name: &lt;em&gt;workspace1&lt;/em&gt; and hit the &amp;ldquo;NEXT&amp;rdquo; button















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/quick-create-workspace-name.png&#34; &gt;


  &lt;img data-src=&#34;../img/quick-create-workspace-name.png&#34; class=&#34;lazyload&#34; alt=&#34;Quick create workspace new name&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Click on the &amp;ldquo;Select nodes&amp;rdquo; and click on the &amp;ldquo;plus&amp;rdquo; icon to create a new node.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/quick-create-workspace-node-icon.png&#34; &gt;


  &lt;img data-src=&#34;../img/quick-create-workspace-node-icon.png&#34; class=&#34;lazyload&#34; alt=&#34;Quick create workspace new node icon&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/quick-create-workspace-node.png&#34; &gt;


  &lt;img data-src=&#34;../img/quick-create-workspace-node.png&#34; class=&#34;lazyload&#34; alt=&#34;Quick create workspace new node&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/quick-create-workspace-add-node.png&#34; &gt;


  &lt;img data-src=&#34;../img/quick-create-workspace-add-node.png&#34; class=&#34;lazyload&#34; alt=&#34;Quick create workspace add node icon&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The node info that you need to enter are listed below:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hostname: &lt;em&gt;192.168.56.102&lt;/em&gt; (replace with your own hostname here)&lt;/li&gt;
&lt;li&gt;Port: &lt;em&gt;22&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;User: &lt;em&gt;ohara&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Password: &lt;em&gt;oharastream&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/quick-create-workspace-add-node.png&#34; &gt;


  &lt;img data-src=&#34;../img/quick-create-workspace-add-node.png&#34; class=&#34;lazyload&#34; alt=&#34;Quick create workspace add a new node&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;The node should be added into the list. Select the node and click on the &amp;ldquo;SAVE&amp;rdquo; button to close the dialog&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/quick-create-workspace-select-node.png&#34; &gt;


  &lt;img data-src=&#34;../img/quick-create-workspace-select-node.png&#34; class=&#34;lazyload&#34; alt=&#34;Quick create workspace select node&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;Now, click the &amp;ldquo;NEXT&amp;rdquo; button to finish this step&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/quick-create-workspace-node-summary.png&#34; &gt;


  &lt;img data-src=&#34;../img/quick-create-workspace-node-summary.png&#34; class=&#34;lazyload&#34; alt=&#34;Quick create workspace node summary&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;We won&amp;rsquo;t be using the volumes in this tutorial, so click on the &amp;ldquo;NEXT&amp;rdquo; button to skip this step.&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/quick-create-workspace-volumes.png&#34; &gt;


  &lt;img data-src=&#34;../img/quick-create-workspace-volumes.png&#34; class=&#34;lazyload&#34; alt=&#34;Quick create workspace node summary&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;Here you can see a summary of your workspace settings. If everything looks good to you, let&amp;rsquo;s click on the &amp;ldquo;SUBMIT&amp;rdquo; button to create this workspace!&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/quick-create-workspace-summary.png&#34; &gt;


  &lt;img data-src=&#34;../img/quick-create-workspace-summary.png&#34; class=&#34;lazyload&#34; alt=&#34;Quick create workspace summary&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;A new dialog with the title &amp;ldquo;Create Workspace&amp;rdquo; will be opened where it shows you the creating progress. This usually takes a while to finish. Once it&amp;rsquo;s done, You can close the dialog by clicking on the &amp;ldquo;CLOSE&amp;rdquo; button. And the UI will redirect you to the newly created workspace: &lt;em&gt;Workspace1&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/quick-create-workspace-progress.png&#34; &gt;


  &lt;img data-src=&#34;../img/quick-create-workspace-progress.png&#34; class=&#34;lazyload&#34; alt=&#34;Quick create workspace creating progress&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/quick-create-workspace-done.png&#34; &gt;


  &lt;img data-src=&#34;../img/quick-create-workspace-done.png&#34; class=&#34;lazyload&#34; alt=&#34;Quick create workspace done&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    You can create more workspace with the plus icon(:heavy_plus_sign:) in the App bar.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;div&gt;
    Please keep in mind that since this is a just a quick start VM where we run everything on a single node
with only 8GB of RAM and 2 CPU cores. If you plan to create more workspace in this VM or services like pipelines, connectors or stream, etc. We highly recommend you to add more RAM and CPU
core to your VM. And when Ohara is running without enough resources, it could be very
unstable and causing unexpected errors.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;create-a-pipeline&#34;&gt;Create a pipeline&lt;/h2&gt;
&lt;p&gt;Create a pipeline is fairly simple:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;On the Navigator, click on the &amp;ldquo;plus&amp;rdquo; icon.&lt;/li&gt;
&lt;li&gt;In the dialog, enter the name: &amp;ldquo;pipeline1&amp;rdquo; and click the &amp;ldquo;ADD&amp;rdquo; button















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-a-pipeline.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-a-pipeline.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a pipeline&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;The new pipeline will be added right into the workspace and listed in the Navigator.
And just like creating workspace, you will be redirected to the pipeline you just created.















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-a-pipeline-done.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-a-pipeline-done.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a pipeline done&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;add-pipeline-components&#34;&gt;Add pipeline components&lt;/h3&gt;
&lt;p&gt;Since workspace and pipeline are both ready. We can now add new components into the pipeline.
The pipeline connection we&amp;rsquo;re about to create will look like:
&lt;code&gt;FTP source -&amp;gt; topic -&amp;gt; stream -&amp;gt; topic -&amp;gt; FTP sink&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Before we start, please make sure your FTP service is ready and let&amp;rsquo;s get started!&lt;/p&gt;
&lt;h4 id=&#34;drag-and-drop-new-pipeline-components&#34;&gt;Drag and drop new pipeline components&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;FTP source:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;From the Toolbox (Please refer to the overview image for what Toolbox is if necessary)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Click on the title &amp;ldquo;Source&amp;rdquo;, the panel will be expanded and display all available source connectors















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ftpsource-add-toolbox.png&#34; &gt;


  &lt;img data-src=&#34;../img/ftpsource-add-toolbox.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a FTP source from Toolbox&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Click and drag the &amp;ldquo;FtpSource&amp;rdquo; from the list and drop it into the Paper (Don&amp;rsquo;t worry about the position just yet. This can be changed after it&amp;rsquo;s added). A prompt will be asking you about the connector name, let&amp;rsquo;s name it &amp;ldquo;ftpsource&amp;rdquo; and click the &amp;ldquo;ADD&amp;rdquo; button.















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ftpsource-add-name.png&#34; &gt;


  &lt;img data-src=&#34;../img/ftpsource-add-name.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a FTP source name&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The FTP source connector should display in the Paper:















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ftpsource-add-done.png&#34; &gt;


  &lt;img data-src=&#34;../img/ftpsource-add-done.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a FTP source name done&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Now, hover over the Ftp source connector, a couple of buttons will show up. These are action buttons, let&amp;rsquo;s take a quick look to see what we can do with them (starting from left to right):















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ftpsource-add-action-buttons.png&#34; &gt;


  &lt;img data-src=&#34;../img/ftpsource-add-action-buttons.png&#34; class=&#34;lazyload&#34; alt=&#34;Action buttons&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Link&lt;/strong&gt;: create a new link, once a link is created you can move your mouse and the link will follow along your mouse position. To link to another component, you can hover over it and do a mouse left-click. To cancel the link creation, just click on the blank area within the Paper.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Start&lt;/strong&gt;: start a component. Once the component is properly configured, you can then use this button to start the component.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stop&lt;/strong&gt;: stop a running or failed component&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Configure&lt;/strong&gt;: open the Property dialog and fill out necessary configuration for the component.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Delete&lt;/strong&gt;: delete the selected component.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    A &amp;ldquo;Link&amp;rdquo; can also be interacted with. You can remove it by clicking on the &amp;ldquo;x&amp;rdquo; button.
And click on any point of the link creates a vertex. The vertex can be moved and tweaked to change its position.
You can also delete a vertex by double clicking on it.
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Okay, that&amp;rsquo;s enough of these button things. Let&amp;rsquo;s click on the &amp;ldquo;configure&amp;rdquo; icon (a wrench) and fill in the following fields (Again, you need to use your own settings, and create &lt;em&gt;completed&lt;/em&gt;, &lt;em&gt;error&lt;/em&gt;, &lt;em&gt;input&lt;/em&gt; and &lt;em&gt;output&lt;/em&gt; directories on your own FTP service). For fields that we did not mention below, the default is used:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Completed Folder: &lt;em&gt;demo/completed&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Error Folder: &lt;em&gt;demo/error&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Hostname of FTP Server: &lt;em&gt;10.2.0.28&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Port of FTP Server: &lt;em&gt;21&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;User of FTP Server: &lt;em&gt;ohara&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Password of FTP Server: &lt;em&gt;oharastream&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Input Folder: &lt;em&gt;demo/input&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once these settings had been filled out, click on the &amp;ldquo;SAVE CHANGES&amp;rdquo; button.















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ftpsource-add-config.png&#34; &gt;


  &lt;img data-src=&#34;../img/ftpsource-add-config.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a FTP source configuration&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    There are validation rules which will prevent you from submitting the form without filling required fields.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;FTP sink:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Just like FTP source connector, let&amp;rsquo;s drag and drop a FTP sink connector from the Toolbox and name it &amp;ldquo;ftpsink&amp;rdquo;.
After it&amp;rsquo;s added into the Paper, click on its &amp;ldquo;configure&amp;rdquo; button. The settings are mostly like FTP source with the only exception: &amp;ldquo;output&amp;rdquo;:&lt;/p&gt;
&lt;p&gt;














&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ftpsink-add-toolbox.png&#34; &gt;


  &lt;img data-src=&#34;../img/ftpsink-add-toolbox.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a FTP sink&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ftpsink-add-config.png&#34; &gt;


  &lt;img data-src=&#34;../img/ftpsink-add-config.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a FTP sink configuration&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hostname of FTP Server: &lt;em&gt;10.2.0.28&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Port of FTP Server: &lt;em&gt;21&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;User of FTP Server: &lt;em&gt;ohara&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Password of FTP Server: &lt;em&gt;oharastream&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Output Folder: &lt;em&gt;demo/output&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Great! Now we have both source and sink connectors ready. Let&amp;rsquo;s move on to create some topics.&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ftpsink-add-done.png&#34; &gt;


  &lt;img data-src=&#34;../img/ftpsink-add-done.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a FTP sink done&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;Topic:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In this tutorial, we need two topics for the pipeline, let&amp;rsquo;s add them from the Toolbox like what we did in the previous steps for FTP connectors:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;From the Toolbox, click on the title &amp;ldquo;Topic&amp;rdquo; to expand the topic panel.















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/topic-add-toolbox.png&#34; &gt;


  &lt;img data-src=&#34;../img/topic-add-toolbox.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a topic from Toolbox&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Click and drag &amp;ldquo;Pipeline Only&amp;rdquo; item from the list and drop it into the Paper to add a new Topic. Unlike source or sink connector, adding a topic doesn&amp;rsquo;t require entering a name, the name will be auto-generated like (T1, T2, T3, etc.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Repeat the above step to create another Topic. You should now have two topics (T1, T2) in your Paper in addition to those FTP connectors:&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/topic-add-done.png&#34; &gt;


  &lt;img data-src=&#34;../img/topic-add-done.png&#34; class=&#34;lazyload&#34; alt=&#34;Add a topic done&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;And luckily, there&amp;rsquo;s no need to configure these topics as they&amp;rsquo;re preconfigured and already running after you added.&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    In Ohara, topics can either be a &amp;ldquo;Pipeline-only topic&amp;rdquo; or a &amp;ldquo;Shared topic&amp;rdquo;.
The pipeline-only topics are topics that only live within a pipeline.
And on the other hand, shared topics can be shared and used across different pipelines.
For simplicity sake, we only use pipeline-only topics throughout this tutorial.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    For quickly creating a new pipeline-only topic, you can also just add a source and a sink (or stream) connector and
then link them together with the &amp;ldquo;Link&amp;rdquo; button from the source connector component.
The pipeline-only topic will be created automatically.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Stream:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Stream is our last missing piece of the pipeline. Let&amp;rsquo;s add one very quick!&lt;/p&gt;
&lt;p&gt;Remember the 
&lt;a href=&#34;https://github.com/oharastream/ohara-quickstart/releases&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;stream jar&lt;/a&gt; you downloaded
along with the quickstart image? It&amp;rsquo;s time to use it:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Click on the &amp;ldquo;Stream&amp;rdquo; panel on the Toolbox and then click on the &amp;ldquo;Add streams&amp;rdquo; button&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-toolbox-upload.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-toolbox-upload.png&#34; class=&#34;lazyload&#34; alt=&#34;Upload a stream&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;It will open workspace settings and redirect you to the stream jars page:&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-page.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-page.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream settings page&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;Click on the &amp;ldquo;plus&amp;rdquo; icon to open Select file dialog:&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-select-icon.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-select-icon.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream select file icon&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;The workspace file list are empty right now, let&amp;rsquo;s add a new file by clicking on the upload icon. This will open your OS file system, you can then select the stream jar file you downloaded. The stream class will be loaded and displayed in the list:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;














&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-upload-icon.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-upload-icon.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream upload icon&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-upload-done.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-upload-done.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream select file upload done&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Select the stream and click on the &amp;ldquo;SAVE&amp;rdquo; button to close select file dialog&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-list.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-list.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream list&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;The stream file should now listed in your Stream Jars page. Close this page by clicking on the close button on the upper-right corner&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    The stream file listed in the list should have a green check icon in the valid column (see below screenshot), if it somehow doesn&amp;rsquo;t have that, double check your stream file is the one downloaded from our release page. Or file an issue to our GitHub repository if the issue persists.
  &lt;/div&gt;
&lt;/div&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-list-done.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-list-done.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream list done&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;Adding a stream is just like connector and topic, drag the &amp;ldquo;DumbStream&amp;rdquo; item from the Toolbox and drop it into the Paper and give a name &amp;ldquo;stream&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-name.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-name.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream name&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;Now let&amp;rsquo;s work through the configuration together. Hover over the stream component and click on the &amp;ldquo;Configure&amp;rdquo; button to open the configure dialog&lt;/li&gt;
&lt;li&gt;Fill out the form with the following settings and click the &amp;ldquo;SAVE CHANGES&amp;rdquo; button:
&lt;ul&gt;
&lt;li&gt;header name to be filtered: &lt;code&gt;&amp;quot;Sex&amp;quot;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;column value to be filtered: &lt;code&gt;&amp;quot;M&amp;quot;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Node name list: &lt;em&gt;192.168.56.111&lt;/em&gt; (replace with your own)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-dialog.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-dialog.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream dialog&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    This stream is capable of filtering out columns and values that we specified and then push
the new result to a topic. Here we&amp;rsquo;re specifically setting the &amp;ldquo;Sex&amp;rdquo; as the filtered header
and &amp;ldquo;M&amp;rdquo; as the filtered value (M stands for Man) and so our output data will only &amp;ldquo;includes&amp;rdquo;
data that contains &amp;ldquo;M&amp;rdquo; value in the &amp;ldquo;Sex&amp;rdquo; column. We will verify the result later.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Everything is ready. We can now create the connection like we mentioned earlier:
&lt;code&gt;FTP source -&amp;gt; topic -&amp;gt; stream -&amp;gt; topic -&amp;gt; FTP sink&lt;/code&gt;.
But before doing so, let&amp;rsquo;s move these components a bit and so we can have more room
to work with (You can close the Toolbox by clicking on the close icon on the top right corner):&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-change-layout.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-change-layout.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream change layout&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;Okay, it&amp;rsquo;s time to create the connection:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hover over FTP source connector and click the &amp;ldquo;Link&amp;rdquo; button, and move your mouse to the first topic named &amp;ldquo;T1&amp;rdquo; and click on it. A connection should be created:&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-create-first-link.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-create-first-link.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream create first link&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;Repeat the same step but this time with &amp;ldquo;T1&amp;rdquo; to create a connection from T1 to stream&lt;/li&gt;
&lt;li&gt;And stream -&amp;gt; T2 then T2 -&amp;gt; FTP sink connector.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After you complete the whole connection, you should have a graph like this (Components position have been tweaked as well so it&amp;rsquo;s easier to see the relation between them):&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/add-stream-done.png&#34; &gt;


  &lt;img data-src=&#34;../img/add-stream-done.png&#34; class=&#34;lazyload&#34; alt=&#34;Add stream done&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    There is another way to create a connection. When configuring a connector, just choose the topic from its topic list. When configuring stream, you will need to choose both &lt;em&gt;&amp;ldquo;from&amp;rdquo;&lt;/em&gt; and &lt;em&gt;&amp;ldquo;to&amp;rdquo;&lt;/em&gt; topics from the topic list.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;start-pipeline-components&#34;&gt;Start pipeline components&lt;/h3&gt;
&lt;p&gt;So far so good, let&amp;rsquo;s start all the components simply by clicking on the &amp;ldquo;Start all components&amp;rdquo;
button located on the Toolbar menu. If everything goes well you should see that all components&amp;rsquo;
icons are now in green just like the following image:&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/start-components-done.png&#34; &gt;


  &lt;img data-src=&#34;../img/start-components-done.png&#34; class=&#34;lazyload&#34; alt=&#34;Start components done&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h3 id=&#34;test-our-new-pipeline&#34;&gt;Test our new pipeline&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s test this &amp;ldquo;pipeline&amp;rdquo; to see if it&amp;rsquo;s capable of transferring some data. We have
prepared a CSV file which looks like this (you can download this file from

&lt;a href=&#34;https://people.sc.fsu.edu/~jburkardt/data/csv/freshman_kgs.csv&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;):&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/csv.png&#34; &gt;


  &lt;img data-src=&#34;../img/csv.png&#34; class=&#34;lazyload&#34; alt=&#34;CSV file&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;Upload the file to the FTP service&amp;rsquo;s input folder. Wait for a while, the file should be
consumed and moved to the output folder. You can verify if the data is properly transferred
by using a FTP client to check the file (we&amp;rsquo;re using 
&lt;a href=&#34;https://filezilla-project.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;FileZilla&lt;/a&gt;).&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/csv-output.png&#34; &gt;


  &lt;img data-src=&#34;../img/csv-output.png&#34; class=&#34;lazyload&#34; alt=&#34;CSV output&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;The output data should be filtered with the result only &amp;ldquo;M&amp;rdquo; (man) data are listed as shown below:&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/csv-output-done.png&#34; &gt;


  &lt;img data-src=&#34;../img/csv-output-done.png&#34; class=&#34;lazyload&#34; alt=&#34;CSV output done&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h2 id=&#34;troubleshooting&#34;&gt;Troubleshooting&lt;/h2&gt;
&lt;p&gt;We now provide a few debugging tools that can help you pin down unexpected errors:&lt;/p&gt;
&lt;h3 id=&#34;event-log-panel&#34;&gt;Event log panel&lt;/h3&gt;
&lt;p&gt;All UI events are recorded, things like API request and response are also stored.
You can view all you event log by simply opening up the Event log panel. As you can
see in the screenshot, errors are highlighted and have more details that can be viewed
when click on each of them.&lt;/p&gt;
&lt;p&gt;














&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/event-log-icon.png&#34; &gt;


  &lt;img data-src=&#34;../img/event-log-icon.png&#34; class=&#34;lazyload&#34; alt=&#34;Event log icon&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/event-log-list.png&#34; &gt;


  &lt;img data-src=&#34;../img/event-log-list.png&#34; class=&#34;lazyload&#34; alt=&#34;Event log list&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/event-log-dialog.png&#34; &gt;


  &lt;img data-src=&#34;../img/event-log-dialog.png&#34; class=&#34;lazyload&#34; alt=&#34;Event log dialog&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Another thing that is worth mentioning here is the Event log icon will display the error log&amp;rsquo;s count on the icon&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/event-log-notification.png&#34; &gt;


  &lt;img data-src=&#34;../img/event-log-notification.png&#34; class=&#34;lazyload&#34; alt=&#34;Event log notification&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h3 id=&#34;developer-tools-panel&#34;&gt;Developer Tools panel&lt;/h3&gt;
&lt;p&gt;Open the dev tool from the App bar:&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/devtool-icon.png&#34; &gt;


  &lt;img data-src=&#34;../img/devtool-icon.png&#34; class=&#34;lazyload&#34; alt=&#34;DevTool icon&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;There are two main functionalities that could be utilized here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Topic panel: you can quickly preview the topic data here&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/devtool-topic-data.png&#34; &gt;


  &lt;img data-src=&#34;../img/devtool-topic-data.png&#34; class=&#34;lazyload&#34; alt=&#34;DevTool topic data&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;Log panel: view all running service&amp;rsquo;s full log&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/devtool-topic-log.png&#34; &gt;


  &lt;img data-src=&#34;../img/devtool-topic-log.png&#34; class=&#34;lazyload&#34; alt=&#34;DevTool topic log&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h3 id=&#34;delete-workspace&#34;&gt;Delete workspace&lt;/h3&gt;
&lt;p&gt;Deleting a workspace is a new feature implemented in 0.10.0, with this feature, you can now delete a workspace with our UI&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    All pipelines under the workspace that you&amp;rsquo;re about to delete should be stopped
(in other word, everything except topics in the pipeline should have the status &amp;ldquo;stopped&amp;rdquo;,
you can do so by going to each pipeline&amp;rsquo;s Toolbar and click on the &amp;ldquo;Stop all components&amp;rdquo;
item from the Pipeline actions
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;From Navigator, click on the workspace name, and click on the &amp;ldquo;Settings&amp;rdquo; item from that dropdown:&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/delete-workspace-menu.png&#34; &gt;


  &lt;img data-src=&#34;../img/delete-workspace-menu.png&#34; class=&#34;lazyload&#34; alt=&#34;Delete workspace menu&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;In the Settings dialog, scroll to the very bottom of the page, and click &amp;ldquo;Delete this workspace&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/delete-workspace-settings-button.png&#34; &gt;


  &lt;img data-src=&#34;../img/delete-workspace-settings-button.png&#34; class=&#34;lazyload&#34; alt=&#34;Delete workspace settings button&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;A confirm dialog will pop up. Enter the workspace name and click on the &amp;ldquo;DELETE&amp;rdquo; button to start deleting. (Note that if you still have some services running in the workspace, you won&amp;rsquo;t able to proceed. You should following the instruction mention in the above to stop all pipelines first)&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/delete-workspace-confirm.png&#34; &gt;


  &lt;img data-src=&#34;../img/delete-workspace-confirm.png&#34; class=&#34;lazyload&#34; alt=&#34;Delete workspace confirm dialog&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;The deletion is in progress, after the deletion is completed, you will be redirected to home or a default workspace if you have one.&lt;/li&gt;
&lt;/ul&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/delete-workspace-progress.png&#34; &gt;


  &lt;img data-src=&#34;../img/delete-workspace-progress.png&#34; class=&#34;lazyload&#34; alt=&#34;Delete workspace progress dialog&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h3 id=&#34;restart-workspace&#34;&gt;Restart workspace&lt;/h3&gt;
&lt;p&gt;When new changes were made in workspace, the restart is required. Also, if you ever run into issues that cannot be recovered from, you can try to restart the workspace to fix the issue.&lt;/p&gt;
&lt;p&gt;Since delete workspace and restart workspace are almost identical, the following instruction won&amp;rsquo;t include any screenshots as they are already included in the 
&lt;a href=&#34;#delete-workspace&#34;&gt;Delete workspace&lt;/a&gt; section&lt;/p&gt;
&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;div&gt;
    Same with delete a workspace, you will need to make sure all pipelines are stopped before starting:
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;From Navigator, click on the workspace name, and click on the &amp;ldquo;Settings&amp;rdquo; item from that dropdown.&lt;/li&gt;
&lt;li&gt;In the Settings dialog, scroll to the very bottom of the page, and click &amp;ldquo;Restart this workspace&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;A confirm dialog will pop up. Click on the RESTART button to start restarting this workspace.&lt;/li&gt;
&lt;li&gt;The restarting is in progress, after the restart is completed, you can close the progress
dialog and changes you made should applied to the workspace by now.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And if you think you ever encountered a bug, let us know: 
&lt;a href=&#34;https://github.com/oharastream/ohara/issues/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub Repo&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Example Page 1</title>
      <link>https://oharastream.github.io/en/docs/0.10.x/example1/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.10.x/example1/</guid>
      <description>&lt;p&gt;In this tutorial, I&amp;rsquo;ll share my top 10 tips for getting started with Academic:&lt;/p&gt;
&lt;h2 id=&#34;tip-1&#34;&gt;Tip 1&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
&lt;h2 id=&#34;tip-2&#34;&gt;Tip 2&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Example Page 2</title>
      <link>https://oharastream.github.io/en/docs/0.10.x/example2/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.10.x/example2/</guid>
      <description>&lt;p&gt;Here are some more tips for getting started with Academic:&lt;/p&gt;
&lt;h2 id=&#34;tip-3&#34;&gt;Tip 3&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
&lt;h2 id=&#34;tip-4&#34;&gt;Tip 4&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Broker</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/rest-api/brokers/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/rest-api/brokers/</guid>
      <description>&lt;p&gt;
&lt;a href=&#34;https://kafka.apache.org/intro&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Broker&lt;/a&gt; is core of data transmission in
ohara. The topic, which is a part our data lake, is hosted by broker
cluster. The number of brokers impacts the performance of transferring
data and data durability. But it is ok to setup broker cluster in single
node when testing. As with 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/zookeepers/&#34;&gt;zookeeper&lt;/a&gt;, broker has
many configs also. Ohara still provide default to most configs and then
enable user to overwrite them.&lt;/p&gt;
&lt;p&gt;Broker is based on 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/zookeepers/&#34;&gt;zookeeper&lt;/a&gt;,
hence you have to create zookeeper cluster first. Noted
that a zookeeper cluster can be used by only a broker cluster. It will
fail if you try to multi broker cluster on same zookeeper cluster.&lt;/p&gt;
&lt;p&gt;The properties which can be set by user are shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; cluster name&lt;/li&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; cluster group&lt;/li&gt;
&lt;li&gt;imageName (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; docker image&lt;/li&gt;
&lt;li&gt;clientPort (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; broker client port.&lt;/li&gt;
&lt;li&gt;jmxPort (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; port used by jmx service&lt;/li&gt;
&lt;li&gt;zookeeperClusterKey (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; key of zookeeper cluster used
to store metadata of broker cluster
&lt;ul&gt;
&lt;li&gt;zookeeperClusterKey.group(&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the group of
zookeeper cluster&lt;/li&gt;
&lt;li&gt;zookeeperClusterKey.name(&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the name of zookeeper
cluster&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    the following forms are legal as well: (1) &lt;code&gt;{&amp;quot;name&amp;quot;: &amp;quot;n&amp;quot;}&lt;/code&gt;, (2) &lt;code&gt;&amp;quot;n&amp;quot;&lt;/code&gt;.
Both forms are converted to &lt;code&gt;{&amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;n&amp;quot;}&lt;/code&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ol start=&#34;7&#34;&gt;
&lt;li&gt;nodeNames (&lt;strong&gt;array(string)&lt;/strong&gt;) &amp;mdash; the nodes running the zookeeper
process&lt;/li&gt;
&lt;li&gt;tags (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the user defined parameters&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The following information are updated by Ohara.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;aliveNodes (&lt;strong&gt;array(string)&lt;/strong&gt;) &amp;mdash; the nodes that host the running
containers of broker cluster&lt;/li&gt;
&lt;li&gt;state (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; only started/failed broker has state
(RUNNING or DEAD)&lt;/li&gt;
&lt;li&gt;error (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the error message from a failed
broker. If broker is fine or un-started, you won&amp;rsquo;t get this field.&lt;/li&gt;
&lt;li&gt;lastModified (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; last modified this jar time&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;create&#34;&gt;create a broker cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;POST /v0/brokers&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;bk&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [&amp;quot;node00&amp;quot;],
  &amp;quot;zookeeperClusterKey&amp;quot;: &amp;quot;zk&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;bk00&amp;quot;,
  &amp;quot;offsets.topic.replication.factor&amp;quot;: 1,
  &amp;quot;xms&amp;quot;: 1024,
  &amp;quot;routes&amp;quot;: {},
  &amp;quot;num.partitions&amp;quot;: 1,
  &amp;quot;lastModified&amp;quot;: 1578903360246,
  &amp;quot;num.network.threads&amp;quot;: 1,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;xmx&amp;quot;: 1024,
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/broker:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;log.dirs&amp;quot;: &amp;quot;/home/ohara/default/data&amp;quot;,
  &amp;quot;aliveNodes&amp;quot;: [],
  &amp;quot;jmxPort&amp;quot;: 42020,
  &amp;quot;num.io.threads&amp;quot;: 1,
  &amp;quot;clientPort&amp;quot;: 39614,
  &amp;quot;zookeeperClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;zk00&amp;quot;
  },
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;list-all-broker-clusters&#34;&gt;list all broker clusters&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/brokers&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
  {
    &amp;quot;name&amp;quot;: &amp;quot;bk00&amp;quot;,
    &amp;quot;offsets.topic.replication.factor&amp;quot;: 1,
    &amp;quot;xms&amp;quot;: 1024,
    &amp;quot;routes&amp;quot;: {},
    &amp;quot;num.partitions&amp;quot;: 1,
    &amp;quot;lastModified&amp;quot;: 1578903360246,
    &amp;quot;num.network.threads&amp;quot;: 1,
    &amp;quot;tags&amp;quot;: {},
    &amp;quot;xmx&amp;quot;: 1024,
    &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/broker:0.11.0-SNAPSHOT&amp;quot;,
    &amp;quot;log.dirs&amp;quot;: &amp;quot;/home/ohara/default/data&amp;quot;,
    &amp;quot;aliveNodes&amp;quot;: [],
    &amp;quot;jmxPort&amp;quot;: 42020,
    &amp;quot;num.io.threads&amp;quot;: 1,
    &amp;quot;clientPort&amp;quot;: 39614,
    &amp;quot;zookeeperClusterKey&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;zk00&amp;quot;
    },
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;nodeNames&amp;quot;: [
      &amp;quot;node00&amp;quot;
    ]
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;update-broker-cluster-properties&#34;&gt;update broker cluster properties&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/brokers/$name?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;If the required broker (group, name) was not exists, we will try to use
this request as POST&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;xmx&amp;quot;: 2048
}
&lt;/code&gt;&lt;/pre&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;bk00&amp;quot;,
  &amp;quot;offsets.topic.replication.factor&amp;quot;: 1,
  &amp;quot;xms&amp;quot;: 1024,
  &amp;quot;routes&amp;quot;: {},
  &amp;quot;num.partitions&amp;quot;: 1,
  &amp;quot;lastModified&amp;quot;: 1578903494681,
  &amp;quot;num.network.threads&amp;quot;: 1,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;xmx&amp;quot;: 2048,
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/broker:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;log.dirs&amp;quot;: &amp;quot;/home/ohara/default/data&amp;quot;,
  &amp;quot;aliveNodes&amp;quot;: [],
  &amp;quot;jmxPort&amp;quot;: 42020,
  &amp;quot;num.io.threads&amp;quot;: 1,
  &amp;quot;clientPort&amp;quot;: 39614,
  &amp;quot;zookeeperClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;zk00&amp;quot;
  },
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;delete-a-broker-properties&#34;&gt;delete a broker properties&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;DELETE /v0/brokers/$name?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;You cannot delete properties of an non-stopped broker cluster. We will
use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you don&amp;rsquo;t
specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;204 NoContent
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    It is ok to delete an nonexistent broker cluster, and the response
is 204 NoContent.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;get&#34;&gt;get a broker cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/brokers/$name?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;bk00&amp;quot;,
  &amp;quot;offsets.topic.replication.factor&amp;quot;: 1,
  &amp;quot;xms&amp;quot;: 1024,
  &amp;quot;routes&amp;quot;: {},
  &amp;quot;num.partitions&amp;quot;: 1,
  &amp;quot;lastModified&amp;quot;: 1578903494681,
  &amp;quot;num.network.threads&amp;quot;: 1,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;xmx&amp;quot;: 2048,
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/broker:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;log.dirs&amp;quot;: &amp;quot;/home/ohara/default/data&amp;quot;,
  &amp;quot;aliveNodes&amp;quot;: [],
  &amp;quot;jmxPort&amp;quot;: 42020,
  &amp;quot;num.io.threads&amp;quot;: 1,
  &amp;quot;clientPort&amp;quot;: 39614,
  &amp;quot;zookeeperClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;zk00&amp;quot;
  },
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;start-a-broker-cluster&#34;&gt;start a broker cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/brokers/$name/start?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#get&#34;&gt;Get broker cluster&lt;/a&gt; to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;stop-a-broker-cluster&#34;&gt;stop a broker cluster&lt;/h2&gt;
&lt;p&gt;Gracefully stopping a running broker cluster. It is disallowed to stop a
broker cluster used by a running

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/workers/&#34;&gt;worker cluster&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/brokers/$name/stop?group=$group[&amp;amp;force=true]&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Query Parameters&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;force (&lt;strong&gt;boolean&lt;/strong&gt;) &amp;mdash; true if you don&amp;rsquo;t want to wait the
graceful shutdown (it can save your time but may damage your
data).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#get&#34;&gt;Get broker cluster&lt;/a&gt; to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;add-a-new-node-to-a-running-broker-cluster&#34;&gt;add a new node to a running broker cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/brokers/$name/$nodeName?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;If you want to extend a running broker cluster, you can add a node to
share the heavy loading of a running broker cluster. However, the
balance is not triggered at once.&lt;/p&gt;
&lt;p&gt;We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;Although it&amp;rsquo;s a rare case, you should not use the &amp;ldquo;API keyword&amp;rdquo;
as the nodeName. For example, the following APIs are invalid and
will trigger different behavior!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;/v0/brokers/$name/start&lt;/li&gt;
&lt;li&gt;/v0/brokers/$name/stop&lt;/li&gt;
&lt;/ul&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;remove-a-node-from-a-running-broker-cluster&#34;&gt;remove a node from a running broker cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;DELETE /v0/brokers/$name/$nodeName?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;If your budget is limited, you can decrease the number of nodes running
broker cluster. BUT, removing a node from a running broker cluster
invoke a lot of data move. The loading may burn out the remaining nodes.&lt;/p&gt;
&lt;p&gt;We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;204 NoContent
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    It is ok to delete an nonexistent broker node, and the response is 204 NoContent.
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Broker</title>
      <link>https://oharastream.github.io/en/docs/master/rest-api/brokers/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/master/rest-api/brokers/</guid>
      <description>&lt;p&gt;
&lt;a href=&#34;https://kafka.apache.org/intro&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Broker&lt;/a&gt; is core of data transmission in
ohara. The topic, which is a part our data lake, is hosted by broker
cluster. The number of brokers impacts the performance of transferring
data and data durability. But it is ok to setup broker cluster in single
node when testing. As with 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/zookeepers/&#34;&gt;zookeeper&lt;/a&gt;, broker has
many configs also. Ohara still provide default to most configs and then
enable user to overwrite them.&lt;/p&gt;
&lt;p&gt;Broker is based on 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/zookeepers/&#34;&gt;zookeeper&lt;/a&gt;,
hence you have to create zookeeper cluster first. Noted
that a zookeeper cluster can be used by only a broker cluster. It will
fail if you try to multi broker cluster on same zookeeper cluster.&lt;/p&gt;
&lt;p&gt;The properties which can be set by user are shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; cluster name&lt;/li&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; cluster group&lt;/li&gt;
&lt;li&gt;imageName (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; docker image&lt;/li&gt;
&lt;li&gt;clientPort (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; broker client port.&lt;/li&gt;
&lt;li&gt;jmxPort (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; port used by jmx service&lt;/li&gt;
&lt;li&gt;zookeeperClusterKey (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; key of zookeeper cluster used
to store metadata of broker cluster
&lt;ul&gt;
&lt;li&gt;zookeeperClusterKey.group(&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the group of
zookeeper cluster&lt;/li&gt;
&lt;li&gt;zookeeperClusterKey.name(&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the name of zookeeper
cluster&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    the following forms are legal as well: (1) &lt;code&gt;{&amp;quot;name&amp;quot;: &amp;quot;n&amp;quot;}&lt;/code&gt;, (2) &lt;code&gt;&amp;quot;n&amp;quot;&lt;/code&gt;.
Both forms are converted to &lt;code&gt;{&amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;n&amp;quot;}&lt;/code&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ol start=&#34;7&#34;&gt;
&lt;li&gt;nodeNames (&lt;strong&gt;array(string)&lt;/strong&gt;) &amp;mdash; the nodes running the zookeeper
process&lt;/li&gt;
&lt;li&gt;tags (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the user defined parameters&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The following information are updated by Ohara.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;aliveNodes (&lt;strong&gt;array(string)&lt;/strong&gt;) &amp;mdash; the nodes that host the running
containers of broker cluster&lt;/li&gt;
&lt;li&gt;state (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; only started/failed broker has state
(RUNNING or DEAD)&lt;/li&gt;
&lt;li&gt;error (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the error message from a failed
broker. If broker is fine or un-started, you won&amp;rsquo;t get this field.&lt;/li&gt;
&lt;li&gt;lastModified (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; last modified this jar time&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;create&#34;&gt;create a broker cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;POST /v0/brokers&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;bk&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [&amp;quot;node00&amp;quot;],
  &amp;quot;zookeeperClusterKey&amp;quot;: &amp;quot;zk&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;bk00&amp;quot;,
  &amp;quot;offsets.topic.replication.factor&amp;quot;: 1,
  &amp;quot;xms&amp;quot;: 1024,
  &amp;quot;routes&amp;quot;: {},
  &amp;quot;num.partitions&amp;quot;: 1,
  &amp;quot;lastModified&amp;quot;: 1578903360246,
  &amp;quot;num.network.threads&amp;quot;: 1,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;xmx&amp;quot;: 1024,
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/broker:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;log.dirs&amp;quot;: &amp;quot;/home/ohara/default/data&amp;quot;,
  &amp;quot;aliveNodes&amp;quot;: [],
  &amp;quot;jmxPort&amp;quot;: 42020,
  &amp;quot;num.io.threads&amp;quot;: 1,
  &amp;quot;clientPort&amp;quot;: 39614,
  &amp;quot;zookeeperClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;zk00&amp;quot;
  },
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;list-all-broker-clusters&#34;&gt;list all broker clusters&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/brokers&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
  {
    &amp;quot;name&amp;quot;: &amp;quot;bk00&amp;quot;,
    &amp;quot;offsets.topic.replication.factor&amp;quot;: 1,
    &amp;quot;xms&amp;quot;: 1024,
    &amp;quot;routes&amp;quot;: {},
    &amp;quot;num.partitions&amp;quot;: 1,
    &amp;quot;lastModified&amp;quot;: 1578903360246,
    &amp;quot;num.network.threads&amp;quot;: 1,
    &amp;quot;tags&amp;quot;: {},
    &amp;quot;xmx&amp;quot;: 1024,
    &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/broker:0.11.0-SNAPSHOT&amp;quot;,
    &amp;quot;log.dirs&amp;quot;: &amp;quot;/home/ohara/default/data&amp;quot;,
    &amp;quot;aliveNodes&amp;quot;: [],
    &amp;quot;jmxPort&amp;quot;: 42020,
    &amp;quot;num.io.threads&amp;quot;: 1,
    &amp;quot;clientPort&amp;quot;: 39614,
    &amp;quot;zookeeperClusterKey&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;zk00&amp;quot;
    },
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;nodeNames&amp;quot;: [
      &amp;quot;node00&amp;quot;
    ]
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;update-broker-cluster-properties&#34;&gt;update broker cluster properties&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/brokers/$name?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;If the required broker (group, name) was not exists, we will try to use
this request as POST&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;xmx&amp;quot;: 2048
}
&lt;/code&gt;&lt;/pre&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;bk00&amp;quot;,
  &amp;quot;offsets.topic.replication.factor&amp;quot;: 1,
  &amp;quot;xms&amp;quot;: 1024,
  &amp;quot;routes&amp;quot;: {},
  &amp;quot;num.partitions&amp;quot;: 1,
  &amp;quot;lastModified&amp;quot;: 1578903494681,
  &amp;quot;num.network.threads&amp;quot;: 1,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;xmx&amp;quot;: 2048,
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/broker:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;log.dirs&amp;quot;: &amp;quot;/home/ohara/default/data&amp;quot;,
  &amp;quot;aliveNodes&amp;quot;: [],
  &amp;quot;jmxPort&amp;quot;: 42020,
  &amp;quot;num.io.threads&amp;quot;: 1,
  &amp;quot;clientPort&amp;quot;: 39614,
  &amp;quot;zookeeperClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;zk00&amp;quot;
  },
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;delete-a-broker-properties&#34;&gt;delete a broker properties&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;DELETE /v0/brokers/$name?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;You cannot delete properties of an non-stopped broker cluster. We will
use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you don&amp;rsquo;t
specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;204 NoContent
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    It is ok to delete an nonexistent broker cluster, and the response
is 204 NoContent.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;get&#34;&gt;get a broker cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/brokers/$name?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;bk00&amp;quot;,
  &amp;quot;offsets.topic.replication.factor&amp;quot;: 1,
  &amp;quot;xms&amp;quot;: 1024,
  &amp;quot;routes&amp;quot;: {},
  &amp;quot;num.partitions&amp;quot;: 1,
  &amp;quot;lastModified&amp;quot;: 1578903494681,
  &amp;quot;num.network.threads&amp;quot;: 1,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;xmx&amp;quot;: 2048,
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/broker:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;log.dirs&amp;quot;: &amp;quot;/home/ohara/default/data&amp;quot;,
  &amp;quot;aliveNodes&amp;quot;: [],
  &amp;quot;jmxPort&amp;quot;: 42020,
  &amp;quot;num.io.threads&amp;quot;: 1,
  &amp;quot;clientPort&amp;quot;: 39614,
  &amp;quot;zookeeperClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;zk00&amp;quot;
  },
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;start-a-broker-cluster&#34;&gt;start a broker cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/brokers/$name/start?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#get&#34;&gt;Get broker cluster&lt;/a&gt; to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;stop-a-broker-cluster&#34;&gt;stop a broker cluster&lt;/h2&gt;
&lt;p&gt;Gracefully stopping a running broker cluster. It is disallowed to stop a
broker cluster used by a running

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/workers/&#34;&gt;worker cluster&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/brokers/$name/stop?group=$group[&amp;amp;force=true]&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Query Parameters&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;force (&lt;strong&gt;boolean&lt;/strong&gt;) &amp;mdash; true if you don&amp;rsquo;t want to wait the
graceful shutdown (it can save your time but may damage your
data).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#get&#34;&gt;Get broker cluster&lt;/a&gt; to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;add-a-new-node-to-a-running-broker-cluster&#34;&gt;add a new node to a running broker cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/brokers/$name/$nodeName?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;If you want to extend a running broker cluster, you can add a node to
share the heavy loading of a running broker cluster. However, the
balance is not triggered at once.&lt;/p&gt;
&lt;p&gt;We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;Although it&amp;rsquo;s a rare case, you should not use the &amp;ldquo;API keyword&amp;rdquo;
as the nodeName. For example, the following APIs are invalid and
will trigger different behavior!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;/v0/brokers/$name/start&lt;/li&gt;
&lt;li&gt;/v0/brokers/$name/stop&lt;/li&gt;
&lt;/ul&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;remove-a-node-from-a-running-broker-cluster&#34;&gt;remove a node from a running broker cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;DELETE /v0/brokers/$name/$nodeName?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;If your budget is limited, you can decrease the number of nodes running
broker cluster. BUT, removing a node from a running broker cluster
invoke a lot of data move. The loading may burn out the remaining nodes.&lt;/p&gt;
&lt;p&gt;We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;204 NoContent
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    It is ok to delete an nonexistent broker node, and the response is 204 NoContent.
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Connector</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/rest-api/connectors/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/rest-api/connectors/</guid>
      <description>&lt;p&gt;Connector is core of application in Ohara

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/pipelines/&#34;&gt;pipeline&lt;/a&gt;. Connector has
two type - source and sink. Source connector pulls data from another
system and then push to topic. By contrast, Sink connector pulls data
from topic and then push to another system. In order to use connector in

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/pipelines/&#34;&gt;pipeline&lt;/a&gt;, you have to
set up a connector settings in Ohara and then add it to

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/pipelines/&#34;&gt;pipeline&lt;/a&gt;. Of course,
the connector settings must belong to a existent connector in target
worker cluster. By default, worker cluster hosts only the official
connectors. If you have more custom requirement for connector, please
follow 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/custom_connector/&#34;&gt;custom connector guideline&lt;/a&gt;
to write your connector.&lt;/p&gt;
&lt;p&gt;Apart from custom settings, common settings are required by all
connectors. The common settings are shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the value of group is always &amp;ldquo;default&amp;rdquo;. The
legal character is number, lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the name of this connector. The legal
character is number, lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;connector.class (&lt;strong&gt;class&lt;/strong&gt;) &amp;mdash; class name of connector
implementation&lt;/li&gt;
&lt;li&gt;topicKeys(&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the source topics or target topics
for this connector&lt;/li&gt;
&lt;li&gt;columns (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the schema of data for this
connector
&lt;ul&gt;
&lt;li&gt;columns[i].name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; origin name of column&lt;/li&gt;
&lt;li&gt;columns[i].newName (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; new name of column&lt;/li&gt;
&lt;li&gt;columns[i].dataType (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the type used to convert
data&lt;/li&gt;
&lt;li&gt;columns[i].order (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; the order of this column&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;numberOfTasks (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; the number of tasks&lt;/li&gt;
&lt;li&gt;workerClusterKey (&lt;strong&gt;Object&lt;/strong&gt;) &amp;mdash; target worker cluster.
&lt;ul&gt;
&lt;li&gt;workerClusterKey.group (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the group of
cluster&lt;/li&gt;
&lt;li&gt;workerClusterKey.name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the name of cluster&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    the following forms are legal as well: (1) &lt;code&gt;{&amp;quot;name&amp;quot;: &amp;quot;n&amp;quot;}&lt;/code&gt;, (2) &lt;code&gt;&amp;quot;n&amp;quot;&lt;/code&gt;.
Both forms are converted to &lt;code&gt;{&amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;n&amp;quot;}&lt;/code&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ol start=&#34;8&#34;&gt;
&lt;li&gt;tags (&lt;strong&gt;object&lt;/strong&gt;) - the extra description to this object&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The following information are updated by Ohara:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; connector&amp;rsquo;s group&lt;/li&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; connector&amp;rsquo;s name&lt;/li&gt;
&lt;li&gt;lastModified (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; the last time to update this connector&lt;/li&gt;
&lt;li&gt;state (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the state of a started connector&lt;/li&gt;
&lt;li&gt;aliveNodes (&lt;strong&gt;Set(string)&lt;/strong&gt;) &amp;mdash; the nodes hosting this connector&lt;/li&gt;
&lt;li&gt;error (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the error message from a failed
connector. If the connector is fine or un-started, you won&amp;rsquo;t get
this field.&lt;/li&gt;
&lt;li&gt;tasksStatus (&lt;strong&gt;Array(object)&lt;/strong&gt;) &amp;mdash; the tasks status of this connector
&lt;ul&gt;
&lt;li&gt;tasksStatus[i].state (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the state of a started task.&lt;/li&gt;
&lt;li&gt;tasksStatus[i].nodeName (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the node hosting this task&lt;/li&gt;
&lt;li&gt;tasksStatus[i].error (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the error
message from a failed task. If the task is fine or un-started,
you won&amp;rsquo;t get this field.&lt;/li&gt;
&lt;li&gt;tasksStatus[i].coordinator (&lt;strong&gt;boolean&lt;/strong&gt;) &amp;mdash; true if this status
is coordinator. otherwise, false&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/custom_connector/#metrics&#34;&gt;nodeMetrics&lt;/a&gt; (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash;
the metrics from a running connector
&lt;ul&gt;
&lt;li&gt;meters (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the metrics in meter type
&lt;ul&gt;
&lt;li&gt;meters[i].name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the number of this meter
(normally, it is unique)&lt;/li&gt;
&lt;li&gt;meters[i].value (&lt;strong&gt;double&lt;/strong&gt;) &amp;mdash; the value in double&lt;/li&gt;
&lt;li&gt;meters[i].valueInPerSec (&lt;strong&gt;double&lt;/strong&gt;) &amp;mdash; the average value
in per second&lt;/li&gt;
&lt;li&gt;meters[i].unit (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the unit of value&lt;/li&gt;
&lt;li&gt;meters[i].document (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; human-readable
description to this meter&lt;/li&gt;
&lt;li&gt;meters[i].queryTime (&lt;strong&gt;Long&lt;/strong&gt;) &amp;mdash; the time we query this
meter from remote nodes&lt;/li&gt;
&lt;li&gt;meters[i].startTime (&lt;strong&gt;Long&lt;/strong&gt;) &amp;mdash; the time to start this
meter (not all services offer this record)&lt;/li&gt;
&lt;li&gt;meters[i].lastModified (&lt;strong&gt;Long&lt;/strong&gt;) &amp;mdash; the time of modifying
metrics&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The following keys are internal and protected so you can&amp;rsquo;t define them
in creating/updating connector.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;connectorKey &amp;mdash; It points to the really (group, name) for the
connector running in kafka.&lt;/li&gt;
&lt;li&gt;topics &amp;mdash; It points to the really topic names in kafka for the
connector running in kafka.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;create-settings&#34;&gt;create the settings of connector&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;POST /v0/connectors&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;It is ok to lack some common settings when creating settings for a
connector. However, it is illegal to start a connector with incomplete
settings. For example, storing the settings consisting of only
&lt;strong&gt;connector.name&lt;/strong&gt; is ok. But stating a connector with above incomplete
settings will introduce a error.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;:&amp;quot;perf&amp;quot;,
  &amp;quot;topicKeys&amp;quot;: [&amp;quot;t0&amp;quot;],
  &amp;quot;workerClusterKey&amp;quot;: &amp;quot;wk&amp;quot;,
  &amp;quot;connector.class&amp;quot;:&amp;quot;oharastream.ohara.connector.perf.PerfSource&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;header.converter&amp;quot;: &amp;quot;org.apache.kafka.connect.converters.ByteArrayConverter&amp;quot;,
  &amp;quot;author&amp;quot;: &amp;quot;root&amp;quot;,
  &amp;quot;topicKeys&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;t0&amp;quot;
    }
  ],
  &amp;quot;name&amp;quot;: &amp;quot;perf&amp;quot;,
  &amp;quot;check.rule&amp;quot;: &amp;quot;NONE&amp;quot;,
  &amp;quot;key.converter&amp;quot;: &amp;quot;org.apache.kafka.connect.converters.ByteArrayConverter&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1577282907085,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;value.converter&amp;quot;: &amp;quot;org.apache.kafka.connect.converters.ByteArrayConverter&amp;quot;,
  &amp;quot;perf.cell.length&amp;quot;: 10,
  &amp;quot;tasks.max&amp;quot;: 1,
  &amp;quot;perf.batch&amp;quot;: 10,
  &amp;quot;perf.frequency&amp;quot;: &amp;quot;1000 milliseconds&amp;quot;,
  &amp;quot;connector.class&amp;quot;: &amp;quot;oharastream.ohara.connector.perf.PerfSource&amp;quot;,
  &amp;quot;revision&amp;quot;: &amp;quot;baafe4a3d875e5e5028b686c4f74f26cfd8b1b66&amp;quot;,
  &amp;quot;version&amp;quot;: &amp;quot;0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;columns&amp;quot;: [],
  &amp;quot;nodeMetrics&amp;quot;: {
    &amp;quot;node00&amp;quot;: {
      &amp;quot;meters&amp;quot;: [
        {
          &amp;quot;document&amp;quot;: &amp;quot;number of ignored messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068827510,
          &amp;quot;name&amp;quot;: &amp;quot;ignored.message.number&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827510,
          &amp;quot;unit&amp;quot;: &amp;quot;messages&amp;quot;,
          &amp;quot;value&amp;quot;: 0.0,
          &amp;quot;valueInPerSec&amp;quot;: 0.0
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;size (in bytes) of messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068870445,
          &amp;quot;name&amp;quot;: &amp;quot;message.size&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827510,
          &amp;quot;unit&amp;quot;: &amp;quot;bytes&amp;quot;,
          &amp;quot;value&amp;quot;: 8.19825E+8,
          &amp;quot;valueInPerSec&amp;quot;: 19094561.546523817
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;size of ignored messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068827510,
          &amp;quot;name&amp;quot;: &amp;quot;ignored.message.size&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827510,
          &amp;quot;unit&amp;quot;: &amp;quot;bytes&amp;quot;,
          &amp;quot;value&amp;quot;: 0.0,
          &amp;quot;valueInPerSec&amp;quot;: 0.0
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;number of messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068870445,
          &amp;quot;name&amp;quot;: &amp;quot;message.number&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827508,
          &amp;quot;unit&amp;quot;: &amp;quot;messages&amp;quot;,
          &amp;quot;value&amp;quot;: 1275000.0,
          &amp;quot;valueInPerSec&amp;quot;: 29694.66893355381
        }
      ]
    }
  },
  &amp;quot;workerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;wk&amp;quot;
  },
  &amp;quot;tasksStatus&amp;quot;: [],
  &amp;quot;kind&amp;quot;: &amp;quot;source&amp;quot;,
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;update-the-settings-of-connector&#34;&gt;update the settings of connector&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/connectors/${name}?group=${group}&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    you cannot update a non-stopped connector.
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;topicKeys&amp;quot;: [
    &amp;quot;t1&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;header.converter&amp;quot;: &amp;quot;org.apache.kafka.connect.converters.ByteArrayConverter&amp;quot;,
  &amp;quot;author&amp;quot;: &amp;quot;root&amp;quot;,
  &amp;quot;topicKeys&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;t1&amp;quot;
    }
  ],
  &amp;quot;name&amp;quot;: &amp;quot;perf&amp;quot;,
  &amp;quot;check.rule&amp;quot;: &amp;quot;NONE&amp;quot;,
  &amp;quot;key.converter&amp;quot;: &amp;quot;org.apache.kafka.connect.converters.ByteArrayConverter&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1577283010533,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;value.converter&amp;quot;: &amp;quot;org.apache.kafka.connect.converters.ByteArrayConverter&amp;quot;,
  &amp;quot;perf.cell.length&amp;quot;: 10,
  &amp;quot;tasks.max&amp;quot;: 1,
  &amp;quot;perf.batch&amp;quot;: 10,
  &amp;quot;perf.frequency&amp;quot;: &amp;quot;1000 milliseconds&amp;quot;,
  &amp;quot;connector.class&amp;quot;: &amp;quot;oharastream.ohara.connector.perf.PerfSource&amp;quot;,
  &amp;quot;revision&amp;quot;: &amp;quot;baafe4a3d875e5e5028b686c4f74f26cfd8b1b66&amp;quot;,
  &amp;quot;version&amp;quot;: &amp;quot;0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;columns&amp;quot;: [],
  &amp;quot;nodeMetrics&amp;quot;: {
    &amp;quot;node00&amp;quot;: {
      &amp;quot;meters&amp;quot;: [
        {
          &amp;quot;document&amp;quot;: &amp;quot;number of ignored messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068827510,
          &amp;quot;name&amp;quot;: &amp;quot;ignored.message.number&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827510,
          &amp;quot;unit&amp;quot;: &amp;quot;messages&amp;quot;,
          &amp;quot;value&amp;quot;: 0.0,
          &amp;quot;valueInPerSec&amp;quot;: 0.0
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;size (in bytes) of messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068870445,
          &amp;quot;name&amp;quot;: &amp;quot;message.size&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827510,
          &amp;quot;unit&amp;quot;: &amp;quot;bytes&amp;quot;,
          &amp;quot;value&amp;quot;: 8.19825E+8,
          &amp;quot;valueInPerSec&amp;quot;: 19094561.546523817
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;size of ignored messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068827510,
          &amp;quot;name&amp;quot;: &amp;quot;ignored.message.size&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827510,
          &amp;quot;unit&amp;quot;: &amp;quot;bytes&amp;quot;,
          &amp;quot;value&amp;quot;: 0.0,
          &amp;quot;valueInPerSec&amp;quot;: 0.0
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;number of messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068870445,
          &amp;quot;name&amp;quot;: &amp;quot;message.number&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827508,
          &amp;quot;unit&amp;quot;: &amp;quot;messages&amp;quot;,
          &amp;quot;value&amp;quot;: 1275000.0,
          &amp;quot;valueInPerSec&amp;quot;: 29694.66893355381
        }
      ]
    }
  },
  &amp;quot;workerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;wk&amp;quot;
  },
  &amp;quot;tasksStatus&amp;quot;: [],
  &amp;quot;kind&amp;quot;: &amp;quot;source&amp;quot;,
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;list-information-of-all-connectors&#34;&gt;list information of all connectors&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/connectors&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;the accepted query keys are listed below.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;group&lt;/li&gt;
&lt;li&gt;name&lt;/li&gt;
&lt;li&gt;lastModified&lt;/li&gt;
&lt;li&gt;tags&lt;/li&gt;
&lt;li&gt;tag - this field is similar to tags but it addresses the &amp;ldquo;contain&amp;rdquo; behavior.&lt;/li&gt;
&lt;li&gt;key&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
  {
    &amp;quot;header.converter&amp;quot;: &amp;quot;org.apache.kafka.connect.converters.ByteArrayConverter&amp;quot;,
    &amp;quot;author&amp;quot;: &amp;quot;root&amp;quot;,
    &amp;quot;topicKeys&amp;quot;: [
      {
        &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
        &amp;quot;name&amp;quot;: &amp;quot;t1&amp;quot;
      }
    ],
    &amp;quot;name&amp;quot;: &amp;quot;perf&amp;quot;,
    &amp;quot;check.rule&amp;quot;: &amp;quot;NONE&amp;quot;,
    &amp;quot;key.converter&amp;quot;: &amp;quot;org.apache.kafka.connect.converters.ByteArrayConverter&amp;quot;,
    &amp;quot;lastModified&amp;quot;: 1577283010533,
    &amp;quot;tags&amp;quot;: {},
    &amp;quot;value.converter&amp;quot;: &amp;quot;org.apache.kafka.connect.converters.ByteArrayConverter&amp;quot;,
    &amp;quot;perf.cell.length&amp;quot;: 10,
    &amp;quot;tasks.max&amp;quot;: 1,
    &amp;quot;perf.batch&amp;quot;: 10,
    &amp;quot;perf.frequency&amp;quot;: &amp;quot;1000 milliseconds&amp;quot;,
    &amp;quot;connector.class&amp;quot;: &amp;quot;oharastream.ohara.connector.perf.PerfSource&amp;quot;,
    &amp;quot;revision&amp;quot;: &amp;quot;baafe4a3d875e5e5028b686c4f74f26cfd8b1b66&amp;quot;,
    &amp;quot;version&amp;quot;: &amp;quot;0.11.0-SNAPSHOT&amp;quot;,
    &amp;quot;columns&amp;quot;: [],
  &amp;quot;nodeMetrics&amp;quot;: {
    &amp;quot;node00&amp;quot;: {
      &amp;quot;meters&amp;quot;: [
        {
          &amp;quot;document&amp;quot;: &amp;quot;number of ignored messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068827510,
          &amp;quot;name&amp;quot;: &amp;quot;ignored.message.number&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827510,
          &amp;quot;unit&amp;quot;: &amp;quot;messages&amp;quot;,
          &amp;quot;value&amp;quot;: 0.0,
          &amp;quot;valueInPerSec&amp;quot;: 0.0
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;size (in bytes) of messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068870445,
          &amp;quot;name&amp;quot;: &amp;quot;message.size&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827510,
          &amp;quot;unit&amp;quot;: &amp;quot;bytes&amp;quot;,
          &amp;quot;value&amp;quot;: 8.19825E+8,
          &amp;quot;valueInPerSec&amp;quot;: 19094561.546523817
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;size of ignored messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068827510,
          &amp;quot;name&amp;quot;: &amp;quot;ignored.message.size&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827510,
          &amp;quot;unit&amp;quot;: &amp;quot;bytes&amp;quot;,
          &amp;quot;value&amp;quot;: 0.0,
          &amp;quot;valueInPerSec&amp;quot;: 0.0
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;number of messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068870445,
          &amp;quot;name&amp;quot;: &amp;quot;message.number&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827508,
          &amp;quot;unit&amp;quot;: &amp;quot;messages&amp;quot;,
          &amp;quot;value&amp;quot;: 1275000.0,
          &amp;quot;valueInPerSec&amp;quot;: 29694.66893355381
        }
      ]
    }
  },
    &amp;quot;workerClusterKey&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;wk&amp;quot;
    },
    &amp;quot;tasksStatus&amp;quot;: [],
    &amp;quot;kind&amp;quot;: &amp;quot;source&amp;quot;,
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;delete&#34;&gt;delete a connector&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;DELETE /v0/connectors/${name}?group=${group}&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Deleting the settings used by a running connector is not allowed. You
should 
&lt;a href=&#34;#stop&#34;&gt;stop&lt;/a&gt; connector before deleting it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;204 NoContent
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    It is ok to delete an jar from an nonexistent connector or a running
connector, and the response is 204 NoContent.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;get-info&#34;&gt;get information of connector&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/connectors/${name}?group=${group}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;header.converter&amp;quot;: &amp;quot;org.apache.kafka.connect.converters.ByteArrayConverter&amp;quot;,
  &amp;quot;author&amp;quot;: &amp;quot;root&amp;quot;,
  &amp;quot;topicKeys&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;t1&amp;quot;
    }
  ],
  &amp;quot;name&amp;quot;: &amp;quot;perf&amp;quot;,
  &amp;quot;check.rule&amp;quot;: &amp;quot;NONE&amp;quot;,
  &amp;quot;key.converter&amp;quot;: &amp;quot;org.apache.kafka.connect.converters.ByteArrayConverter&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1577283010533,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;value.converter&amp;quot;: &amp;quot;org.apache.kafka.connect.converters.ByteArrayConverter&amp;quot;,
  &amp;quot;perf.cell.length&amp;quot;: 10,
  &amp;quot;tasks.max&amp;quot;: 1,
  &amp;quot;perf.batch&amp;quot;: 10,
  &amp;quot;perf.frequency&amp;quot;: &amp;quot;1000 milliseconds&amp;quot;,
  &amp;quot;connector.class&amp;quot;: &amp;quot;oharastream.ohara.connector.perf.PerfSource&amp;quot;,
  &amp;quot;revision&amp;quot;: &amp;quot;baafe4a3d875e5e5028b686c4f74f26cfd8b1b66&amp;quot;,
  &amp;quot;version&amp;quot;: &amp;quot;0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;columns&amp;quot;: [],
  &amp;quot;nodeMetrics&amp;quot;: {
    &amp;quot;node00&amp;quot;: {
      &amp;quot;meters&amp;quot;: [
        {
          &amp;quot;document&amp;quot;: &amp;quot;number of ignored messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068827510,
          &amp;quot;name&amp;quot;: &amp;quot;ignored.message.number&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827510,
          &amp;quot;unit&amp;quot;: &amp;quot;messages&amp;quot;,
          &amp;quot;value&amp;quot;: 0.0,
          &amp;quot;valueInPerSec&amp;quot;: 0.0
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;size (in bytes) of messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068870445,
          &amp;quot;name&amp;quot;: &amp;quot;message.size&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827510,
          &amp;quot;unit&amp;quot;: &amp;quot;bytes&amp;quot;,
          &amp;quot;value&amp;quot;: 8.19825E+8,
          &amp;quot;valueInPerSec&amp;quot;: 19094561.546523817
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;size of ignored messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068827510,
          &amp;quot;name&amp;quot;: &amp;quot;ignored.message.size&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827510,
          &amp;quot;unit&amp;quot;: &amp;quot;bytes&amp;quot;,
          &amp;quot;value&amp;quot;: 0.0,
          &amp;quot;valueInPerSec&amp;quot;: 0.0
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;number of messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068870445,
          &amp;quot;name&amp;quot;: &amp;quot;message.number&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827508,
          &amp;quot;unit&amp;quot;: &amp;quot;messages&amp;quot;,
          &amp;quot;value&amp;quot;: 1275000.0,
          &amp;quot;valueInPerSec&amp;quot;: 29694.66893355381
        }
      ]
    }
  },
  &amp;quot;workerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;wk&amp;quot;
  },
  &amp;quot;tasksStatus&amp;quot;: [],
  &amp;quot;kind&amp;quot;: &amp;quot;source&amp;quot;,
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;start-a-connector&#34;&gt;start a connector&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/connectors/${name}/start?group=${group}&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Ohara will send a start request to specific worker cluster to start the
connector with stored settings, and then make a response to called. The
connector is executed async so the connector may be still in starting
after you retrieve the response. You can send 
&lt;a href=&#34;#get-info&#34;&gt;GET request&lt;/a&gt;
to see the state of connector. This request is idempotent so it is safe
to retry this command repeatedly.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use
&lt;a href=&#34;#get-info&#34;&gt;Get Connector info&lt;/a&gt; to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;stop&#34;&gt;stop a connector&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/connectors/${name}/stop?group=${group}&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Ohara will send a stop request to specific worker cluster to stop the
connector. The stopped connector will be removed from worker cluster.
The settings of connector is still kept by Ohara so you can start the
connector with same settings again in the future. If you want to delete
the connector totally, you should stop the connector and then

&lt;a href=&#34;#delete&#34;&gt;delete&lt;/a&gt; it. This
request is idempotent so it is safe to send this request repeatedly.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#get-info&#34;&gt;Get Connector info&lt;/a&gt; to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;pause-a-connector&#34;&gt;pause a connector&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/connectors/${name}/pause?group=${group}&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Pausing a connector is to disable connector to pull/push data from/to
source/sink. The connector is still alive in kafka. This request is
idempotent so it is safe to send this request repeatedly.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#get-info&#34;&gt;Get Connector info&lt;/a&gt; to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;resume-a-connector&#34;&gt;resume a connector&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/connectors/${name}/resume?group=${group}&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Resuming a connector is to enable connector to pull/push data from/to
source/sink. This request is idempotent so it is safe to retry this
command repeatedly.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#get-info&#34;&gt;Get Connector info&lt;/a&gt; to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Connector</title>
      <link>https://oharastream.github.io/en/docs/master/rest-api/connectors/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/master/rest-api/connectors/</guid>
      <description>&lt;p&gt;Connector is core of application in Ohara

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/pipelines/&#34;&gt;pipeline&lt;/a&gt;. Connector has
two type - source and sink. Source connector pulls data from another
system and then push to topic. By contrast, Sink connector pulls data
from topic and then push to another system. In order to use connector in

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/pipelines/&#34;&gt;pipeline&lt;/a&gt;, you have to
set up a connector settings in Ohara and then add it to

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/pipelines/&#34;&gt;pipeline&lt;/a&gt;. Of course,
the connector settings must belong to a existent connector in target
worker cluster. By default, worker cluster hosts only the official
connectors. If you have more custom requirement for connector, please
follow 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/custom_connector/&#34;&gt;custom connector guideline&lt;/a&gt;
to write your connector.&lt;/p&gt;
&lt;p&gt;Apart from custom settings, common settings are required by all
connectors. The common settings are shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the value of group is always &amp;ldquo;default&amp;rdquo;. The
legal character is number, lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the name of this connector. The legal
character is number, lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;connector.class (&lt;strong&gt;class&lt;/strong&gt;) &amp;mdash; class name of connector
implementation&lt;/li&gt;
&lt;li&gt;topicKeys(&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the source topics or target topics
for this connector&lt;/li&gt;
&lt;li&gt;columns (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the schema of data for this
connector
&lt;ul&gt;
&lt;li&gt;columns[i].name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; origin name of column&lt;/li&gt;
&lt;li&gt;columns[i].newName (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; new name of column&lt;/li&gt;
&lt;li&gt;columns[i].dataType (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the type used to convert
data&lt;/li&gt;
&lt;li&gt;columns[i].order (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; the order of this column&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;numberOfTasks (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; the number of tasks&lt;/li&gt;
&lt;li&gt;workerClusterKey (&lt;strong&gt;Object&lt;/strong&gt;) &amp;mdash; target worker cluster.
&lt;ul&gt;
&lt;li&gt;workerClusterKey.group (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the group of
cluster&lt;/li&gt;
&lt;li&gt;workerClusterKey.name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the name of cluster&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    the following forms are legal as well: (1) &lt;code&gt;{&amp;quot;name&amp;quot;: &amp;quot;n&amp;quot;}&lt;/code&gt;, (2) &lt;code&gt;&amp;quot;n&amp;quot;&lt;/code&gt;.
Both forms are converted to &lt;code&gt;{&amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;n&amp;quot;}&lt;/code&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ol start=&#34;8&#34;&gt;
&lt;li&gt;tags (&lt;strong&gt;object&lt;/strong&gt;) - the extra description to this object&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The following information are updated by Ohara:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; connector&amp;rsquo;s group&lt;/li&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; connector&amp;rsquo;s name&lt;/li&gt;
&lt;li&gt;lastModified (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; the last time to update this connector&lt;/li&gt;
&lt;li&gt;state (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the state of a started connector&lt;/li&gt;
&lt;li&gt;aliveNodes (&lt;strong&gt;Set(string)&lt;/strong&gt;) &amp;mdash; the nodes hosting this connector&lt;/li&gt;
&lt;li&gt;error (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the error message from a failed
connector. If the connector is fine or un-started, you won&amp;rsquo;t get
this field.&lt;/li&gt;
&lt;li&gt;tasksStatus (&lt;strong&gt;Array(object)&lt;/strong&gt;) &amp;mdash; the tasks status of this connector
&lt;ul&gt;
&lt;li&gt;tasksStatus[i].state (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the state of a started task.&lt;/li&gt;
&lt;li&gt;tasksStatus[i].nodeName (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the node hosting this task&lt;/li&gt;
&lt;li&gt;tasksStatus[i].error (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the error
message from a failed task. If the task is fine or un-started,
you won&amp;rsquo;t get this field.&lt;/li&gt;
&lt;li&gt;tasksStatus[i].coordinator (&lt;strong&gt;boolean&lt;/strong&gt;) &amp;mdash; true if this status
is coordinator. otherwise, false&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/custom_connector/#metrics&#34;&gt;nodeMetrics&lt;/a&gt; (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash;
the metrics from a running connector
&lt;ul&gt;
&lt;li&gt;meters (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the metrics in meter type
&lt;ul&gt;
&lt;li&gt;meters[i].name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the number of this meter
(normally, it is unique)&lt;/li&gt;
&lt;li&gt;meters[i].value (&lt;strong&gt;double&lt;/strong&gt;) &amp;mdash; the value in double&lt;/li&gt;
&lt;li&gt;meters[i].valueInPerSec (&lt;strong&gt;double&lt;/strong&gt;) &amp;mdash; the average value
in per second&lt;/li&gt;
&lt;li&gt;meters[i].unit (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the unit of value&lt;/li&gt;
&lt;li&gt;meters[i].document (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; human-readable
description to this meter&lt;/li&gt;
&lt;li&gt;meters[i].queryTime (&lt;strong&gt;Long&lt;/strong&gt;) &amp;mdash; the time we query this
meter from remote nodes&lt;/li&gt;
&lt;li&gt;meters[i].startTime (&lt;strong&gt;Long&lt;/strong&gt;) &amp;mdash; the time to start this
meter (not all services offer this record)&lt;/li&gt;
&lt;li&gt;meters[i].lastModified (&lt;strong&gt;Long&lt;/strong&gt;) &amp;mdash; the time of modifying
metrics&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The following keys are internal and protected so you can&amp;rsquo;t define them
in creating/updating connector.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;connectorKey &amp;mdash; It points to the really (group, name) for the
connector running in kafka.&lt;/li&gt;
&lt;li&gt;topics &amp;mdash; It points to the really topic names in kafka for the
connector running in kafka.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;create-settings&#34;&gt;create the settings of connector&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;POST /v0/connectors&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;It is ok to lack some common settings when creating settings for a
connector. However, it is illegal to start a connector with incomplete
settings. For example, storing the settings consisting of only
&lt;strong&gt;connector.name&lt;/strong&gt; is ok. But stating a connector with above incomplete
settings will introduce a error.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;:&amp;quot;perf&amp;quot;,
  &amp;quot;topicKeys&amp;quot;: [&amp;quot;t0&amp;quot;],
  &amp;quot;workerClusterKey&amp;quot;: &amp;quot;wk&amp;quot;,
  &amp;quot;connector.class&amp;quot;:&amp;quot;oharastream.ohara.connector.perf.PerfSource&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;header.converter&amp;quot;: &amp;quot;org.apache.kafka.connect.converters.ByteArrayConverter&amp;quot;,
  &amp;quot;author&amp;quot;: &amp;quot;root&amp;quot;,
  &amp;quot;topicKeys&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;t0&amp;quot;
    }
  ],
  &amp;quot;name&amp;quot;: &amp;quot;perf&amp;quot;,
  &amp;quot;check.rule&amp;quot;: &amp;quot;NONE&amp;quot;,
  &amp;quot;key.converter&amp;quot;: &amp;quot;org.apache.kafka.connect.converters.ByteArrayConverter&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1577282907085,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;value.converter&amp;quot;: &amp;quot;org.apache.kafka.connect.converters.ByteArrayConverter&amp;quot;,
  &amp;quot;perf.cell.length&amp;quot;: 10,
  &amp;quot;tasks.max&amp;quot;: 1,
  &amp;quot;perf.batch&amp;quot;: 10,
  &amp;quot;perf.frequency&amp;quot;: &amp;quot;1000 milliseconds&amp;quot;,
  &amp;quot;connector.class&amp;quot;: &amp;quot;oharastream.ohara.connector.perf.PerfSource&amp;quot;,
  &amp;quot;revision&amp;quot;: &amp;quot;baafe4a3d875e5e5028b686c4f74f26cfd8b1b66&amp;quot;,
  &amp;quot;version&amp;quot;: &amp;quot;0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;columns&amp;quot;: [],
  &amp;quot;nodeMetrics&amp;quot;: {
    &amp;quot;node00&amp;quot;: {
      &amp;quot;meters&amp;quot;: [
        {
          &amp;quot;document&amp;quot;: &amp;quot;number of ignored messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068827510,
          &amp;quot;name&amp;quot;: &amp;quot;ignored.message.number&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827510,
          &amp;quot;unit&amp;quot;: &amp;quot;messages&amp;quot;,
          &amp;quot;value&amp;quot;: 0.0,
          &amp;quot;valueInPerSec&amp;quot;: 0.0
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;size (in bytes) of messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068870445,
          &amp;quot;name&amp;quot;: &amp;quot;message.size&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827510,
          &amp;quot;unit&amp;quot;: &amp;quot;bytes&amp;quot;,
          &amp;quot;value&amp;quot;: 8.19825E+8,
          &amp;quot;valueInPerSec&amp;quot;: 19094561.546523817
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;size of ignored messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068827510,
          &amp;quot;name&amp;quot;: &amp;quot;ignored.message.size&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827510,
          &amp;quot;unit&amp;quot;: &amp;quot;bytes&amp;quot;,
          &amp;quot;value&amp;quot;: 0.0,
          &amp;quot;valueInPerSec&amp;quot;: 0.0
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;number of messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068870445,
          &amp;quot;name&amp;quot;: &amp;quot;message.number&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827508,
          &amp;quot;unit&amp;quot;: &amp;quot;messages&amp;quot;,
          &amp;quot;value&amp;quot;: 1275000.0,
          &amp;quot;valueInPerSec&amp;quot;: 29694.66893355381
        }
      ]
    }
  },
  &amp;quot;workerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;wk&amp;quot;
  },
  &amp;quot;tasksStatus&amp;quot;: [],
  &amp;quot;kind&amp;quot;: &amp;quot;source&amp;quot;,
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;update-the-settings-of-connector&#34;&gt;update the settings of connector&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/connectors/${name}?group=${group}&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    you cannot update a non-stopped connector.
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;topicKeys&amp;quot;: [
    &amp;quot;t1&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;header.converter&amp;quot;: &amp;quot;org.apache.kafka.connect.converters.ByteArrayConverter&amp;quot;,
  &amp;quot;author&amp;quot;: &amp;quot;root&amp;quot;,
  &amp;quot;topicKeys&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;t1&amp;quot;
    }
  ],
  &amp;quot;name&amp;quot;: &amp;quot;perf&amp;quot;,
  &amp;quot;check.rule&amp;quot;: &amp;quot;NONE&amp;quot;,
  &amp;quot;key.converter&amp;quot;: &amp;quot;org.apache.kafka.connect.converters.ByteArrayConverter&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1577283010533,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;value.converter&amp;quot;: &amp;quot;org.apache.kafka.connect.converters.ByteArrayConverter&amp;quot;,
  &amp;quot;perf.cell.length&amp;quot;: 10,
  &amp;quot;tasks.max&amp;quot;: 1,
  &amp;quot;perf.batch&amp;quot;: 10,
  &amp;quot;perf.frequency&amp;quot;: &amp;quot;1000 milliseconds&amp;quot;,
  &amp;quot;connector.class&amp;quot;: &amp;quot;oharastream.ohara.connector.perf.PerfSource&amp;quot;,
  &amp;quot;revision&amp;quot;: &amp;quot;baafe4a3d875e5e5028b686c4f74f26cfd8b1b66&amp;quot;,
  &amp;quot;version&amp;quot;: &amp;quot;0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;columns&amp;quot;: [],
  &amp;quot;nodeMetrics&amp;quot;: {
    &amp;quot;node00&amp;quot;: {
      &amp;quot;meters&amp;quot;: [
        {
          &amp;quot;document&amp;quot;: &amp;quot;number of ignored messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068827510,
          &amp;quot;name&amp;quot;: &amp;quot;ignored.message.number&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827510,
          &amp;quot;unit&amp;quot;: &amp;quot;messages&amp;quot;,
          &amp;quot;value&amp;quot;: 0.0,
          &amp;quot;valueInPerSec&amp;quot;: 0.0
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;size (in bytes) of messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068870445,
          &amp;quot;name&amp;quot;: &amp;quot;message.size&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827510,
          &amp;quot;unit&amp;quot;: &amp;quot;bytes&amp;quot;,
          &amp;quot;value&amp;quot;: 8.19825E+8,
          &amp;quot;valueInPerSec&amp;quot;: 19094561.546523817
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;size of ignored messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068827510,
          &amp;quot;name&amp;quot;: &amp;quot;ignored.message.size&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827510,
          &amp;quot;unit&amp;quot;: &amp;quot;bytes&amp;quot;,
          &amp;quot;value&amp;quot;: 0.0,
          &amp;quot;valueInPerSec&amp;quot;: 0.0
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;number of messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068870445,
          &amp;quot;name&amp;quot;: &amp;quot;message.number&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827508,
          &amp;quot;unit&amp;quot;: &amp;quot;messages&amp;quot;,
          &amp;quot;value&amp;quot;: 1275000.0,
          &amp;quot;valueInPerSec&amp;quot;: 29694.66893355381
        }
      ]
    }
  },
  &amp;quot;workerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;wk&amp;quot;
  },
  &amp;quot;tasksStatus&amp;quot;: [],
  &amp;quot;kind&amp;quot;: &amp;quot;source&amp;quot;,
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;list-information-of-all-connectors&#34;&gt;list information of all connectors&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/connectors&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;the accepted query keys are listed below.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;group&lt;/li&gt;
&lt;li&gt;name&lt;/li&gt;
&lt;li&gt;lastModified&lt;/li&gt;
&lt;li&gt;tags&lt;/li&gt;
&lt;li&gt;tag - this field is similar to tags but it addresses the &amp;ldquo;contain&amp;rdquo; behavior.&lt;/li&gt;
&lt;li&gt;key&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
  {
    &amp;quot;header.converter&amp;quot;: &amp;quot;org.apache.kafka.connect.converters.ByteArrayConverter&amp;quot;,
    &amp;quot;author&amp;quot;: &amp;quot;root&amp;quot;,
    &amp;quot;topicKeys&amp;quot;: [
      {
        &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
        &amp;quot;name&amp;quot;: &amp;quot;t1&amp;quot;
      }
    ],
    &amp;quot;name&amp;quot;: &amp;quot;perf&amp;quot;,
    &amp;quot;check.rule&amp;quot;: &amp;quot;NONE&amp;quot;,
    &amp;quot;key.converter&amp;quot;: &amp;quot;org.apache.kafka.connect.converters.ByteArrayConverter&amp;quot;,
    &amp;quot;lastModified&amp;quot;: 1577283010533,
    &amp;quot;tags&amp;quot;: {},
    &amp;quot;value.converter&amp;quot;: &amp;quot;org.apache.kafka.connect.converters.ByteArrayConverter&amp;quot;,
    &amp;quot;perf.cell.length&amp;quot;: 10,
    &amp;quot;tasks.max&amp;quot;: 1,
    &amp;quot;perf.batch&amp;quot;: 10,
    &amp;quot;perf.frequency&amp;quot;: &amp;quot;1000 milliseconds&amp;quot;,
    &amp;quot;connector.class&amp;quot;: &amp;quot;oharastream.ohara.connector.perf.PerfSource&amp;quot;,
    &amp;quot;revision&amp;quot;: &amp;quot;baafe4a3d875e5e5028b686c4f74f26cfd8b1b66&amp;quot;,
    &amp;quot;version&amp;quot;: &amp;quot;0.11.0-SNAPSHOT&amp;quot;,
    &amp;quot;columns&amp;quot;: [],
  &amp;quot;nodeMetrics&amp;quot;: {
    &amp;quot;node00&amp;quot;: {
      &amp;quot;meters&amp;quot;: [
        {
          &amp;quot;document&amp;quot;: &amp;quot;number of ignored messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068827510,
          &amp;quot;name&amp;quot;: &amp;quot;ignored.message.number&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827510,
          &amp;quot;unit&amp;quot;: &amp;quot;messages&amp;quot;,
          &amp;quot;value&amp;quot;: 0.0,
          &amp;quot;valueInPerSec&amp;quot;: 0.0
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;size (in bytes) of messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068870445,
          &amp;quot;name&amp;quot;: &amp;quot;message.size&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827510,
          &amp;quot;unit&amp;quot;: &amp;quot;bytes&amp;quot;,
          &amp;quot;value&amp;quot;: 8.19825E+8,
          &amp;quot;valueInPerSec&amp;quot;: 19094561.546523817
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;size of ignored messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068827510,
          &amp;quot;name&amp;quot;: &amp;quot;ignored.message.size&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827510,
          &amp;quot;unit&amp;quot;: &amp;quot;bytes&amp;quot;,
          &amp;quot;value&amp;quot;: 0.0,
          &amp;quot;valueInPerSec&amp;quot;: 0.0
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;number of messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068870445,
          &amp;quot;name&amp;quot;: &amp;quot;message.number&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827508,
          &amp;quot;unit&amp;quot;: &amp;quot;messages&amp;quot;,
          &amp;quot;value&amp;quot;: 1275000.0,
          &amp;quot;valueInPerSec&amp;quot;: 29694.66893355381
        }
      ]
    }
  },
    &amp;quot;workerClusterKey&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;wk&amp;quot;
    },
    &amp;quot;tasksStatus&amp;quot;: [],
    &amp;quot;kind&amp;quot;: &amp;quot;source&amp;quot;,
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;delete&#34;&gt;delete a connector&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;DELETE /v0/connectors/${name}?group=${group}&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Deleting the settings used by a running connector is not allowed. You
should 
&lt;a href=&#34;#stop&#34;&gt;stop&lt;/a&gt; connector before deleting it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;204 NoContent
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    It is ok to delete an jar from an nonexistent connector or a running
connector, and the response is 204 NoContent.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;get-info&#34;&gt;get information of connector&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/connectors/${name}?group=${group}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;header.converter&amp;quot;: &amp;quot;org.apache.kafka.connect.converters.ByteArrayConverter&amp;quot;,
  &amp;quot;author&amp;quot;: &amp;quot;root&amp;quot;,
  &amp;quot;topicKeys&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;t1&amp;quot;
    }
  ],
  &amp;quot;name&amp;quot;: &amp;quot;perf&amp;quot;,
  &amp;quot;check.rule&amp;quot;: &amp;quot;NONE&amp;quot;,
  &amp;quot;key.converter&amp;quot;: &amp;quot;org.apache.kafka.connect.converters.ByteArrayConverter&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1577283010533,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;value.converter&amp;quot;: &amp;quot;org.apache.kafka.connect.converters.ByteArrayConverter&amp;quot;,
  &amp;quot;perf.cell.length&amp;quot;: 10,
  &amp;quot;tasks.max&amp;quot;: 1,
  &amp;quot;perf.batch&amp;quot;: 10,
  &amp;quot;perf.frequency&amp;quot;: &amp;quot;1000 milliseconds&amp;quot;,
  &amp;quot;connector.class&amp;quot;: &amp;quot;oharastream.ohara.connector.perf.PerfSource&amp;quot;,
  &amp;quot;revision&amp;quot;: &amp;quot;baafe4a3d875e5e5028b686c4f74f26cfd8b1b66&amp;quot;,
  &amp;quot;version&amp;quot;: &amp;quot;0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;columns&amp;quot;: [],
  &amp;quot;nodeMetrics&amp;quot;: {
    &amp;quot;node00&amp;quot;: {
      &amp;quot;meters&amp;quot;: [
        {
          &amp;quot;document&amp;quot;: &amp;quot;number of ignored messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068827510,
          &amp;quot;name&amp;quot;: &amp;quot;ignored.message.number&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827510,
          &amp;quot;unit&amp;quot;: &amp;quot;messages&amp;quot;,
          &amp;quot;value&amp;quot;: 0.0,
          &amp;quot;valueInPerSec&amp;quot;: 0.0
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;size (in bytes) of messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068870445,
          &amp;quot;name&amp;quot;: &amp;quot;message.size&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827510,
          &amp;quot;unit&amp;quot;: &amp;quot;bytes&amp;quot;,
          &amp;quot;value&amp;quot;: 8.19825E+8,
          &amp;quot;valueInPerSec&amp;quot;: 19094561.546523817
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;size of ignored messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068827510,
          &amp;quot;name&amp;quot;: &amp;quot;ignored.message.size&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827510,
          &amp;quot;unit&amp;quot;: &amp;quot;bytes&amp;quot;,
          &amp;quot;value&amp;quot;: 0.0,
          &amp;quot;valueInPerSec&amp;quot;: 0.0
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;number of messages&amp;quot;,
          &amp;quot;lastModified&amp;quot;: 1585068870445,
          &amp;quot;name&amp;quot;: &amp;quot;message.number&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585068870341,
          &amp;quot;startTime&amp;quot;: 1585068827508,
          &amp;quot;unit&amp;quot;: &amp;quot;messages&amp;quot;,
          &amp;quot;value&amp;quot;: 1275000.0,
          &amp;quot;valueInPerSec&amp;quot;: 29694.66893355381
        }
      ]
    }
  },
  &amp;quot;workerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;wk&amp;quot;
  },
  &amp;quot;tasksStatus&amp;quot;: [],
  &amp;quot;kind&amp;quot;: &amp;quot;source&amp;quot;,
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;start-a-connector&#34;&gt;start a connector&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/connectors/${name}/start?group=${group}&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Ohara will send a start request to specific worker cluster to start the
connector with stored settings, and then make a response to called. The
connector is executed async so the connector may be still in starting
after you retrieve the response. You can send 
&lt;a href=&#34;#get-info&#34;&gt;GET request&lt;/a&gt;
to see the state of connector. This request is idempotent so it is safe
to retry this command repeatedly.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use
&lt;a href=&#34;#get-info&#34;&gt;Get Connector info&lt;/a&gt; to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;stop&#34;&gt;stop a connector&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/connectors/${name}/stop?group=${group}&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Ohara will send a stop request to specific worker cluster to stop the
connector. The stopped connector will be removed from worker cluster.
The settings of connector is still kept by Ohara so you can start the
connector with same settings again in the future. If you want to delete
the connector totally, you should stop the connector and then

&lt;a href=&#34;#delete&#34;&gt;delete&lt;/a&gt; it. This
request is idempotent so it is safe to send this request repeatedly.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#get-info&#34;&gt;Get Connector info&lt;/a&gt; to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;pause-a-connector&#34;&gt;pause a connector&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/connectors/${name}/pause?group=${group}&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Pausing a connector is to disable connector to pull/push data from/to
source/sink. The connector is still alive in kafka. This request is
idempotent so it is safe to send this request repeatedly.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#get-info&#34;&gt;Get Connector info&lt;/a&gt; to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;resume-a-connector&#34;&gt;resume a connector&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/connectors/${name}/resume?group=${group}&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Resuming a connector is to enable connector to pull/push data from/to
source/sink. This request is idempotent so it is safe to retry this
command repeatedly.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#get-info&#34;&gt;Get Connector info&lt;/a&gt; to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Container</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/rest-api/containers/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/rest-api/containers/</guid>
      <description>&lt;p&gt;Each processes managed by Ohara is based on docker container. In most
cases, user don&amp;rsquo;t need to know the details of containers since the
management of containers is on Ohara&amp;rsquo;s shoulder. However, Ohara
understand that we all have curious brain so Ohara supports to display
the container&amp;rsquo;s details of a running cluster. Noted that the context may
be changed between different release of Ohara. And the distinct
implementations of container manager possibly provide different context
of containers.&lt;/p&gt;
&lt;h2 id=&#34;retrieve-the-container-details-of-a-running-cluster&#34;&gt;retrieve the container details of a running cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/containers/$clusterName?group=$clusterGroup&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;strong&gt;cluster name&lt;/strong&gt; may be mapped to different services (of course,
it would be better to avoid using same name on different services),
hence, the returned JSON is in array type. The details of elements
are shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;clusterKey (&lt;strong&gt;Object&lt;/strong&gt;) &amp;mdash; cluster key&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;clusterType (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; cluster type&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;containers (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the container in this cluster&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;environments (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the environment variables of
container&lt;/li&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the name of container&lt;/li&gt;
&lt;li&gt;hostname (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; hostname of container&lt;/li&gt;
&lt;li&gt;size (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the disk size used by this container&lt;/li&gt;
&lt;li&gt;state (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the state of container&lt;/li&gt;
&lt;li&gt;portMappings (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the exported ports of
this container
&lt;ul&gt;
&lt;li&gt;portMappings[i].hostIp (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the network
interface of container host&lt;/li&gt;
&lt;li&gt;portMappings[i].hostPort (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; host port&lt;/li&gt;
&lt;li&gt;portMappings[i].containerPort (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; container
port&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;nodeName (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the node which host this container&lt;/li&gt;
&lt;li&gt;imageName (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the image used to create this
container&lt;/li&gt;
&lt;li&gt;id (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; container id&lt;/li&gt;
&lt;li&gt;kind (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; Ohara supports the DOCKER and K8S mode&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
  {
    &amp;quot;clusterKey&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;wk00&amp;quot;
    },
    &amp;quot;clusterType&amp;quot;: &amp;quot;worker&amp;quot;,
    &amp;quot;containers&amp;quot;: [
      {
        &amp;quot;environments&amp;quot;: {
          &amp;quot;KAFKA_JMX_OPTS&amp;quot;: &amp;quot;-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=41484 -Dcom.sun.management.jmxremote.rmi.port=41484 -Djava.rmi.server.hostname=ohara-release-test-00&amp;quot;,
          &amp;quot;KAFKA_HEAP_OPTS&amp;quot;: &amp;quot;-Xms1024M -Xmx1024M&amp;quot;,
          &amp;quot;WORKER_PLUGIN_URLS&amp;quot;: &amp;quot;&amp;quot;,
          &amp;quot;WORKER_SHARED_JAR_URLS&amp;quot;: &amp;quot;&amp;quot;
        },
        &amp;quot;name&amp;quot;: &amp;quot;default-wk00-worker-3b8c71a&amp;quot;,
        &amp;quot;hostname&amp;quot;: &amp;quot;wk00-worker-5739cbd&amp;quot;,
        &amp;quot;size&amp;quot;: -1,
        &amp;quot;state&amp;quot;: &amp;quot;RUNNING&amp;quot;,
        &amp;quot;portMappings&amp;quot;: [
          {
            &amp;quot;hostIp&amp;quot;: &amp;quot;10.2.10.30&amp;quot;,
            &amp;quot;hostPort&amp;quot;: 36789,
            &amp;quot;containerPort&amp;quot;: 36789
          },
          {
            &amp;quot;hostIp&amp;quot;: &amp;quot;10.2.10.30&amp;quot;,
            &amp;quot;hostPort&amp;quot;: 41484,
            &amp;quot;containerPort&amp;quot;: 41484
          }
        ],
        &amp;quot;nodeName&amp;quot;: &amp;quot;ohara-release-test-00&amp;quot;,
        &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/connect-worker:0.11.0-SNAPSHOT&amp;quot;,
        &amp;quot;id&amp;quot;: &amp;quot;2a3b3872-35ab-11ea-8a18-a29736512df3&amp;quot;,
        &amp;quot;kind&amp;quot;: &amp;quot;K8S&amp;quot;
      }
    ]
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Container</title>
      <link>https://oharastream.github.io/en/docs/master/rest-api/containers/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/master/rest-api/containers/</guid>
      <description>&lt;p&gt;Each processes managed by Ohara is based on docker container. In most
cases, user don&amp;rsquo;t need to know the details of containers since the
management of containers is on Ohara&amp;rsquo;s shoulder. However, Ohara
understand that we all have curious brain so Ohara supports to display
the container&amp;rsquo;s details of a running cluster. Noted that the context may
be changed between different release of Ohara. And the distinct
implementations of container manager possibly provide different context
of containers.&lt;/p&gt;
&lt;h2 id=&#34;retrieve-the-container-details-of-a-running-cluster&#34;&gt;retrieve the container details of a running cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/containers/$clusterName?group=$clusterGroup&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;strong&gt;cluster name&lt;/strong&gt; may be mapped to different services (of course,
it would be better to avoid using same name on different services),
hence, the returned JSON is in array type. The details of elements
are shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;clusterKey (&lt;strong&gt;Object&lt;/strong&gt;) &amp;mdash; cluster key&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;clusterType (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; cluster type&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;containers (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the container in this cluster&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;environments (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the environment variables of
container&lt;/li&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the name of container&lt;/li&gt;
&lt;li&gt;hostname (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; hostname of container&lt;/li&gt;
&lt;li&gt;size (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the disk size used by this container&lt;/li&gt;
&lt;li&gt;state (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the state of container&lt;/li&gt;
&lt;li&gt;portMappings (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the exported ports of
this container
&lt;ul&gt;
&lt;li&gt;portMappings[i].hostIp (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the network
interface of container host&lt;/li&gt;
&lt;li&gt;portMappings[i].hostPort (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; host port&lt;/li&gt;
&lt;li&gt;portMappings[i].containerPort (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; container
port&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;nodeName (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the node which host this container&lt;/li&gt;
&lt;li&gt;imageName (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the image used to create this
container&lt;/li&gt;
&lt;li&gt;id (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; container id&lt;/li&gt;
&lt;li&gt;kind (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; Ohara supports the DOCKER and K8S mode&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
  {
    &amp;quot;clusterKey&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;wk00&amp;quot;
    },
    &amp;quot;clusterType&amp;quot;: &amp;quot;worker&amp;quot;,
    &amp;quot;containers&amp;quot;: [
      {
        &amp;quot;environments&amp;quot;: {
          &amp;quot;KAFKA_JMX_OPTS&amp;quot;: &amp;quot;-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=41484 -Dcom.sun.management.jmxremote.rmi.port=41484 -Djava.rmi.server.hostname=ohara-release-test-00&amp;quot;,
          &amp;quot;KAFKA_HEAP_OPTS&amp;quot;: &amp;quot;-Xms1024M -Xmx1024M&amp;quot;,
          &amp;quot;WORKER_PLUGIN_URLS&amp;quot;: &amp;quot;&amp;quot;,
          &amp;quot;WORKER_SHARED_JAR_URLS&amp;quot;: &amp;quot;&amp;quot;
        },
        &amp;quot;name&amp;quot;: &amp;quot;default-wk00-worker-3b8c71a&amp;quot;,
        &amp;quot;hostname&amp;quot;: &amp;quot;wk00-worker-5739cbd&amp;quot;,
        &amp;quot;size&amp;quot;: -1,
        &amp;quot;state&amp;quot;: &amp;quot;RUNNING&amp;quot;,
        &amp;quot;portMappings&amp;quot;: [
          {
            &amp;quot;hostIp&amp;quot;: &amp;quot;10.2.10.30&amp;quot;,
            &amp;quot;hostPort&amp;quot;: 36789,
            &amp;quot;containerPort&amp;quot;: 36789
          },
          {
            &amp;quot;hostIp&amp;quot;: &amp;quot;10.2.10.30&amp;quot;,
            &amp;quot;hostPort&amp;quot;: 41484,
            &amp;quot;containerPort&amp;quot;: 41484
          }
        ],
        &amp;quot;nodeName&amp;quot;: &amp;quot;ohara-release-test-00&amp;quot;,
        &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/connect-worker:0.11.0-SNAPSHOT&amp;quot;,
        &amp;quot;id&amp;quot;: &amp;quot;2a3b3872-35ab-11ea-8a18-a29736512df3&amp;quot;,
        &amp;quot;kind&amp;quot;: &amp;quot;K8S&amp;quot;
      }
    ]
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Custom Connector Guideline</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/custom_connector/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/custom_connector/</guid>
      <description>&lt;p&gt;Ohara custom connector is based on

&lt;a href=&#34;https://docs.confluent.io/current/connect/managing/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;kafka connector&lt;/a&gt;.
It offers a platform that enables you to define some simple actions to
connect topic to any other system. You don&amp;rsquo;t need to worry the
application availability, data durability, or distribution anymore. All
you have to do is to write your custom connector, which can have only
the pull()/push() method, and then compile your code to a jar file.
After uploading your jar to Ohara, you are able to &lt;strong&gt;deploy&lt;/strong&gt; your
connector on the
[worker cluster]/en/docs/0.11.x/rest-api/workers/#rest-workers-create. By
leveraging Ohara connector framework, apart from the availability,
scalability, and durability, you can also monitor your connector for

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/logs/&#34;&gt;logs&lt;/a&gt; and

&lt;a href=&#34;#metrics&#34;&gt;metrics&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The following sections start to explain how to write a good connector on
Ohara. You don&amp;rsquo;t need to read it through if you are familiar with

&lt;a href=&#34;https://docs.confluent.io/current/connect/managing/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;kafka connector&lt;/a&gt;.
However, Ohara connector has some improvements which are not in

&lt;a href=&#34;https://docs.confluent.io/current/connect/managing/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;kafka connector&lt;/a&gt;
so it has worth of taking a look at

&lt;a href=&#34;#metrics&#34;&gt;metrics&lt;/a&gt; and

&lt;a href=&#34;#setting_definition.md&#34;&gt;setting definitions&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;connector-overview&#34;&gt;Connector Overview&lt;/h2&gt;
&lt;p&gt;Ohara connector is composed of

&lt;a href=&#34;#source-connector&#34;&gt;source connector&lt;/a&gt; and

&lt;a href=&#34;#sink-connector&#34;&gt;sink connector&lt;/a&gt; .

&lt;a href=&#34;#source-connector&#34;&gt;source connector&lt;/a&gt;
is used to pull data &lt;strong&gt;from external system to topic&lt;/strong&gt;. By
contrast, 
&lt;a href=&#34;#sink-connector&#34;&gt;sink connector&lt;/a&gt; is
used to pull data from &lt;strong&gt;topic to external system&lt;/strong&gt;. A
complete connector consists of &lt;strong&gt;SourceConnector&lt;/strong&gt; / &lt;strong&gt;SinkConnector&lt;/strong&gt;
and &lt;strong&gt;SourceTask&lt;/strong&gt; / &lt;strong&gt;SinkTask&lt;/strong&gt;. Worker cluster picks up a node to
host your source/sink connector and then distributes the source/sink
tasks across cluster.&lt;/p&gt;
&lt;p&gt;You must include Ohara jars before starting to write your custom
connector. Please include both of ohara-common and ohara-kafka in your
dependencies. The ohara-common contains many helper methods and common
data used in whole Ohara. The ohara-kafka offers a lot of beautiful APIs
to help you to access kafka and design custom connector.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-groovy&#34;&gt;repositories {
     maven {
         url &amp;quot;https://dl.bintray.com/oharastream/ohara&amp;quot;
     }
 }
implementation &amp;quot;oharastream.ohara:ohara-common:0.11.0-SNAPSHOT&amp;quot;
implementation &amp;quot;oharastream.ohara:ohara-kafka:0.11.0-SNAPSHOT&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The &lt;a href=&#34;https://github.com/oharastream/ohara/releases&#34;&gt;releases&lt;/a&gt; page shows the available version of Ohara
  &lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 id=&#34;datamodel&#34;&gt;Data Model&lt;/h2&gt;
&lt;p&gt;Ohara has defined a table structure data in code base. We call it
&lt;strong&gt;row&lt;/strong&gt;. A row is comprised of multiple &lt;strong&gt;cells&lt;/strong&gt;. Each cell has its
&lt;strong&gt;name&lt;/strong&gt;, &lt;strong&gt;value&lt;/strong&gt; and &lt;strong&gt;tags&lt;/strong&gt;. The value in cell is a generic type
which accepts any serializable type of value. Following is an example
that shows you how to convert a csv data to Ohara row.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;c0,c1,c2
v0,v1,v2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above data can be converted to Ohara row by following code.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import oharastream.ohara.common.data.Row;
import oharastream.ohara.common.data.Cell;
class ExampleOfRow {
    public static void main(String[] args) {
        Row row = Row.of(
                Cell.of(&amp;quot;c0&amp;quot;, &amp;quot;v0&amp;quot;),
                Cell.of(&amp;quot;c1&amp;quot;, &amp;quot;v1&amp;quot;),
                Cell.of(&amp;quot;c2&amp;quot;, &amp;quot;v2&amp;quot;)
                );
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;c0,c1,c2
v0,,v2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above data can be converted to Ohara row by following code.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import oharastream.ohara.common.data.Row;
import oharastream.ohara.common.data.Cell;
class ExampleOfRow {
    public static void main(String[] args) {
        Row row = Row.of(
                Cell.of(&amp;quot;c0&amp;quot;, &amp;quot;v0&amp;quot;),
                Cell.of(&amp;quot;c2&amp;quot;, &amp;quot;v2&amp;quot;)
                );
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Don&amp;rsquo;t worry about the serialization. Ohara offers default serializations
for following data types:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;string&lt;/li&gt;
&lt;li&gt;boolean&lt;/li&gt;
&lt;li&gt;short&lt;/li&gt;
&lt;li&gt;int&lt;/li&gt;
&lt;li&gt;long&lt;/li&gt;
&lt;li&gt;float&lt;/li&gt;
&lt;li&gt;double&lt;/li&gt;
&lt;li&gt;bytes&lt;/li&gt;
&lt;li&gt;serializable object&lt;/li&gt;
&lt;li&gt;row (a nested row is acceptable!)&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The default serializer is located at
&lt;a href=&#34;https://github.com/oharastream/ohara/blob/0.11.x/ohara-common/src/main/java/oharastream/ohara/common/data/Serializer.java&#34;&gt;Here&lt;/a&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;When you get the rows in the connector, you should follow the &lt;strong&gt;cell
setting&lt;/strong&gt; to generate the output. The &lt;strong&gt;cell setting&lt;/strong&gt; in Ohara is
called &lt;strong&gt;column&lt;/strong&gt;. It shows the metadata of a &lt;strong&gt;cell&lt;/strong&gt;. The metadata
consists of:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;origin column name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; you can match the cell by this name&lt;/li&gt;
&lt;li&gt;new column name &amp;mdash; the new name of output.&lt;/li&gt;
&lt;li&gt;type (&lt;strong&gt;DataType&lt;/strong&gt;) &amp;mdash; the type of output value. Whatever the
origin type of value, you should convert the value according this
type. Don&amp;rsquo;t worry the casting error. It is up to the user who pass
the wrong configuration.
&lt;ul&gt;
&lt;li&gt;string&lt;/li&gt;
&lt;li&gt;boolean&lt;/li&gt;
&lt;li&gt;short&lt;/li&gt;
&lt;li&gt;int&lt;/li&gt;
&lt;li&gt;long&lt;/li&gt;
&lt;li&gt;float&lt;/li&gt;
&lt;li&gt;double&lt;/li&gt;
&lt;li&gt;bytes&lt;/li&gt;
&lt;li&gt;serializable object&lt;/li&gt;
&lt;li&gt;row&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;order (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; the order of cells in output.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;An example of converting data according to columns.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import oharastream.ohara.common.data.Cell;
import oharastream.ohara.common.data.Column;
class ExampleOfConverting {
    public static Object hello(Column column, String rawValue) {
        switch (column.dataType) {
            case DataType.BOOLEAN:
                return Boolean.valueOf(rawValue);
            case DataType.STRING:
                return rawValue;
            case DataType.SHORT:
                return Short.valueOf(rawValue);
            case DataType.INT:
                return Integer.valueOf(rawValue);
            case DataType.FLOAT:
                return Float.valueOf(rawValue);
            case DataType.DOUBLE:
                return Double.valueOf(rawValue);
            default:
                throw new IllegalArgumentException(&amp;quot;unsupported type:&amp;quot; + column.dataType);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The type is a complicated issue since there are countless types in this
world. It is impossible to define a general solution to handle all types
so the final types of value is &lt;strong&gt;byte array&lt;/strong&gt; or &lt;strong&gt;serializable
object&lt;/strong&gt;. If the type you want to pass is not in official support, you
should define it as &lt;strong&gt;byte array&lt;/strong&gt; or &lt;strong&gt;serializable object&lt;/strong&gt; and then
process it in your connectors.&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Feel free to throw an exception when your connector encounters an unknown
type. Don&amp;rsquo;t swallow it and convert to a weird value, such as null or
empty. Throwing exception is better than generating corrupt data!
  &lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 id=&#34;source-connector&#34;&gt;Source Connector&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;Source connector is used to pull data from outside system and then push
processed data to Ohara topics. A basic implementation for a source
connector only includes four methods &amp;mdash; &lt;strong&gt;run&lt;/strong&gt;, &lt;strong&gt;terminate&lt;/strong&gt;,
&lt;strong&gt;taskClass&lt;/strong&gt;, and &lt;strong&gt;taskSetting&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class RowSourceConnector extends SourceConnector {
  /**
   * Returns the RowSourceTask implementation for this Connector.
   *
   * @return a RowSourceTask class
   */
  protected abstract Class&amp;lt;? extends RowSourceTask&amp;gt; taskClass();

  /**
   * Return the settings for source task.
   *
   * @param maxTasks number of tasks for this connector
   * @return a seq from settings
   */
  protected abstract List&amp;lt;TaskSetting&amp;gt; taskSetting(int maxTasks);

  /**
   * Start this Connector. This method will only be called on a clean Connector, i.e. it has either
   * just been instantiated and initialized or terminate() has been invoked.
   *
   * @param taskSetting configuration settings
   */
  protected abstract void run(TaskSetting taskSetting);

  /** stop this connector */
  protected abstract void terminate();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;source-start&#34;&gt;run(TaskSetting)&lt;/h3&gt;
&lt;p&gt;After instantizing a connector, the first method called by worker is
&lt;strong&gt;start()&lt;/strong&gt;. You should initialize your connector in &lt;strong&gt;start&lt;/strong&gt; method,
since it has a input parameter &lt;strong&gt;TaskSetting&lt;/strong&gt; carrying all settings,
such as target topics, connector name and user-defined configs, from
user. If you (connector developer) are a good friend of your connector
user, you can get (and cast it to expected type) config, which is
passed by connector user, from &lt;strong&gt;TaskSetting&lt;/strong&gt;. For example, a
connector user calls

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/connectors/#create-settings&#34;&gt;Connector API&lt;/a&gt;
to store a config k0-v0 (both of them are string type) for
your connector, and then you can get v0 via
TaskSetting.stringValue(&amp;ldquo;k0&amp;rdquo;).&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Don&amp;rsquo;t be afraid of throwing exception when you notice that input
parameters are incorrect. Throwing an exception can fail a connector
quickly and stop worker to distribute connector task across cluster. It
saves the time and resources.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;We all hate wrong configs, right? When you design the connector, you can
&lt;strong&gt;define&lt;/strong&gt; the 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/setting_definition/&#34;&gt;setting&lt;/a&gt; on your own initiative.
The 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/setting_definition/&#34;&gt;setting&lt;/a&gt; enable
worker to check the input configs before starting connector. It can&amp;rsquo;t
eliminate incorrect configs completely, but it save your time of
fighting against wrong configs (have a great time with your family)&lt;/p&gt;
&lt;h3 id=&#34;source-terminate&#34;&gt;terminate()&lt;/h3&gt;
&lt;p&gt;This method is invoked by calling

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/connectors/#stop&#34;&gt;STOP API&lt;/a&gt;. You can
release the resources allocated by connector, or email to shout
at someone. It is ok to throw an exception when you fails to &lt;strong&gt;stop&lt;/strong&gt;
the connector. Worker cluster will mark &lt;strong&gt;failure&lt;/strong&gt; on the connector,
and the world keeps running.&lt;/p&gt;
&lt;h3 id=&#34;source-taskclass&#34;&gt;taskClass()&lt;/h3&gt;
&lt;p&gt;This method returns the java class of

&lt;a href=&#34;#sourcetask&#34;&gt;RowSourceTask&lt;/a&gt;
implementation. It tells worker cluster which class should be created
to pull data from external system. Noted that connector and task may
not be created on same node (jvm) so you should NOT share any objects
between them (for example, make them to access a global variable).&lt;/p&gt;
&lt;h3 id=&#34;source-tasksetting&#34;&gt;taskSetting(int maxTasks)&lt;/h3&gt;
&lt;p&gt;Connector has to generate configs for each task. The value of
&lt;strong&gt;maxTasks&lt;/strong&gt; is configured by

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/connectors/&#34;&gt;Connector API&lt;/a&gt;. If
you prefer to make all tasks do identical job, you can just clone the
task config passe by 
&lt;a href=&#34;#source-start&#34;&gt;start&lt;/a&gt;. Or you
can prepare different configs for each task. Noted that the number of
configuration you return MUST be equal with input value - maxTasks.
Otherwise, you will get an exception when running your connector.&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    It would be better to do the final check to input configs in Connector
rather than Task. Producing a failure quickly save your time and
resources.
  &lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 id=&#34;sourcetask&#34;&gt;Source Task&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class RowSourceTask extends SourceTask {

  /**
   * Start the Task. This should handle any configuration parsing and one-time setup from the task.
   *
   * @param config initial configuration
   */
  protected abstract void run(TaskSetting config);

  /**
   * Signal this SourceTask to stop. In SourceTasks, this method only needs to signal to the task
   * that it should stop trying to poll for new data and interrupt any outstanding poll() requests.
   * It is not required that the task has fully stopped. Note that this method necessarily may be
   * invoked from a different thread than pollRecords() and commitOffsets()
   */
  protected abstract void terminate();
  /**
   * Poll this SourceTask for new records. This method should block if no data is currently
   * available.
   *
   * @return a array from RowSourceRecord
   */
  protected abstract List&amp;lt;RowSourceRecord&amp;gt; pollRecords();
}  
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;RowSourceTask is the unit of executing &lt;strong&gt;poll&lt;/strong&gt;. A connector can invoke
multiple tasks if you set &lt;strong&gt;tasks.max&lt;/strong&gt; be bigger than 1 via

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/connectors/&#34;&gt;Connector API&lt;/a&gt;.
RowSourceTask has the similar lifecycle to Source connector. Worker cluster
call &lt;strong&gt;start&lt;/strong&gt; to initialize a task and call &lt;strong&gt;stop&lt;/strong&gt; to terminate a
task.&lt;/p&gt;
&lt;h3 id=&#34;sourcetask-pullrecords&#34;&gt;pullRecords()&lt;/h3&gt;
&lt;p&gt;You can ignore all methods except for &lt;strong&gt;pollRecords&lt;/strong&gt;. Worker cluster
call &lt;strong&gt;pollRecords&lt;/strong&gt; regularly to get &lt;strong&gt;RowSourceRecord&lt;/strong&gt; s and then
save them to topics. Worker cluster does not care for your
implementation. All you have to do is to put your data in
&lt;strong&gt;RowSourceRecord&lt;/strong&gt;. RowSourceRecord is a complicated object having
many elements. Some elements are significant. For example,
&lt;strong&gt;partition&lt;/strong&gt; can impact the distribution of records. In order to be
the best friend of programmer, Ohara follows the fluent pattern to allow
you to create record through builder, and you can only fill the
required elements.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class ExampleOfRowSourceRecord {
    public static RowSourceRecord create(Row row, String topicName) {
        return RowSourceRecord.builder()
        .row(row)
        .topicName(topicName)
        .build();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You can read the java docs of RowSourceRecord.Builder to see which
default values are set for other (optional) elements.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;sourcetask-partition-offsets&#34;&gt;Partition and Offsets in Source&lt;/h3&gt;
&lt;p&gt;De-duplicating data is not a easy job. When you keep pulling data from
external system to topics, you always need a place to record which
data have not processed. Connector offers two specific objects for you
to record the &lt;strong&gt;offset&lt;/strong&gt; and &lt;strong&gt;partition&lt;/strong&gt; of your data. You can
define a &lt;strong&gt;partition&lt;/strong&gt; and a &lt;strong&gt;offset&lt;/strong&gt; for RowSourceRecord. The
durability is on Worker&amp;rsquo;s shoulder, and you are always doable to get
&lt;strong&gt;partition&lt;/strong&gt; and &lt;strong&gt;offset&lt;/strong&gt; back even if the connector fail or
shutdown.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class ExampleOfRowSourceContext {
    public static Map&amp;lt;String, ?&amp;gt; getOffset(Map&amp;lt;String, ?&amp;gt; partition) {
        return RowSourceContext.offset(partition);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Both of them are Map type with string key and primitive type. Using Map
is a workaround to record the offsets for different connectors. You can
view them as a &lt;strong&gt;flatten&lt;/strong&gt; json representation. For example, one of task
is handling file_a, and it has processed first line of file_a. Then
the pair of &lt;strong&gt;partition&lt;/strong&gt; and &lt;strong&gt;offset&lt;/strong&gt; look like&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;fileName&amp;quot;: &amp;quot;file_a&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;offset&amp;quot;: 1
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can convert above json to &lt;strong&gt;partition&lt;/strong&gt; and &lt;strong&gt;offset&lt;/strong&gt; and then put
them in &lt;strong&gt;RowSourceRecord&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class ExampleOfPartitionAndOffset {
    public static RowSourceRecord addPartitionAndOffset(RowSourceRecord.Builder builder, String fileName, int offset) {
        Map&amp;lt;String, String&amp;gt; partition = Map.of(&amp;quot;fileName&amp;quot;, fileName);
        Map&amp;lt;String, Integer&amp;gt; offset = Map.of(&amp;quot;offset&amp;quot;, 1);
        return builder.sourcePartition(partition)
        .sourceOffset(offset)
        .build();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A news of &lt;strong&gt;partition&lt;/strong&gt; and &lt;strong&gt;offset&lt;/strong&gt; is that they are not stored with
data in RowSourceRecord. If you want to know the commit of &lt;strong&gt;partition&lt;/strong&gt;
and &lt;strong&gt;offset&lt;/strong&gt;, you can override the &lt;strong&gt;commitOffsets()&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class RowSourceTask extends SourceTask {
  /**
   * Commit the offsets, up to the offsets that have been returned by pollRecords(). This method should
   * block until the commit is complete.
   *
   * &amp;lt;p&amp;gt;SourceTasks are not required to implement this functionality; Kafka Connect will record
   * offsets automatically. This hook is provided for systems that also need to store offsets
   * internally in their own system.
   */
  protected void commitOffsets() {
    // do nothing
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;sourcetask-handle-exception&#34;&gt;Handle Exception in pollRecords()&lt;/h3&gt;
&lt;p&gt;Throwing exception make connector in &lt;strong&gt;failure&lt;/strong&gt; state, and inactivate
connector until you restart it. Hence, you SHOULD catch and handle the
exception as best you can. However, swallowing all exception is also a
weired behavior. You SHOULD fails the connector when encountering
unrecoverable exception.&lt;/p&gt;
&lt;h3 id=&#34;blocking-action-is-unwelcome-in-pollrecords&#34;&gt;Blocking Action Is Unwelcome In pollRecords()&lt;/h3&gt;
&lt;p&gt;Task is executed on a separate thread and there are many remaining
processing for data after pollRecords(). Hence, you should NOT block
pollRecords(). On the contrary, returning an empty list can yield the
resource to remaining processing.&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Returning null results in same result. However, we all should hate null
so please take away null from your code.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;data-from-pollrecords-are-committed-async&#34;&gt;Data From pollRecords() Are Committed Async&lt;/h3&gt;
&lt;p&gt;You don&amp;rsquo;t expect that the data you generated are commit at once,
right? Committing data invokes a large latency since we need to sync
data to multiple nodes and result in many disk I/O. Worker has another
thread sending your data in background. If your connector needs to
know the time of committing data, you can override the
&lt;strong&gt;commitOffsetsRecord(RowSourceRecord)&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class RowSourceTask extends SourceTask {
  /**
   * Commit an individual RowSourceRecord when the callback from the producer client is received, or
   * if a record is filtered by a transformation. SourceTasks are not required to implement this
   * functionality; Kafka Connect will record offsets automatically. This hook is provided for
   * systems that also need to store offsets internally in their own system.
   *
   * @param record RowSourceRecord that was successfully sent via the producer.
   */
  protected void commitOffsetsRecord(RowSourceRecord record) {
    // do nothing
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;sink-connector&#34;&gt;Sink Connector&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class RowSinkConnector extends SinkConnector {

  /**
   * Start this Connector. This method will only be called on a clean Connector, i.e. it has either
   * just been instantiated and initialized or terminate() has been invoked.
   *
   * @param config configuration settings
   */
  protected abstract void run(TaskSetting config);

  /** stop this connector */
  protected abstract void terminate();

  /**
   * Returns the RowSinkTask implementation for this Connector.
   *
   * @return a RowSinkTask class
   */
  protected abstract Class&amp;lt;? extends RowSinkTask&amp;gt; taskClass();

  /**
   * Return the settings for source task. NOTED: It is illegal to assign different topics to
   * RowSinkTask
   *
   * @param maxTasks number of tasks for this connector
   * @return the settings for each tasks
   */
  protected abstract List&amp;lt;TaskSetting&amp;gt; taskSetting(int maxTasks);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Sink connector is similar to

&lt;a href=&#34;#source-connector&#34;&gt;source connector&lt;/a&gt;. It also have

&lt;a href=&#34;#source-start&#34;&gt;run(TaskSetting)&lt;/a&gt;,

&lt;a href=&#34;#source-terminate&#34;&gt;terminate()&lt;/a&gt;,

&lt;a href=&#34;#source-taskclass&#34;&gt;taskClass()&lt;/a&gt;,

&lt;a href=&#34;#source-tasksetting&#34;&gt;taskSetting(int maxTasks)&lt;/a&gt;,

&lt;a href=&#34;#sourcetask-partition-offsets&#34;&gt;partition and offsets&lt;/a&gt;.
The main difference between sink connector and source
connector is that sink connector do pull data from topic and then push
processed data to outside system. Hence, it does have

&lt;a href=&#34;#sinktask-put-records&#34;&gt;pullRecords&lt;/a&gt; rather than

&lt;a href=&#34;#sourcetask-pullrecords&#34;&gt;pullRecords&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Though sink connector and source connector have many identical methods,
you should NOT make a connector mixed sink and source. Because Both
connector are &lt;strong&gt;abstract&lt;/strong&gt; class, you can&amp;rsquo;t have a class extending both
of them in java.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Sink connector also has to provide the task class to worker cluster. The
sink task in Ohara is called &lt;strong&gt;RowSinkTask&lt;/strong&gt;. It is also distributed
across whole worker cluster when you run a sink connector.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;sink-task&#34;&gt;Sink Task&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class RowSinkTask extends SinkTask {

  /**
   * Start the Task. This should handle any configuration parsing and one-time setup from the task.
   *
   * @param config initial configuration
   */
  protected abstract void run(TaskSetting config);

  /**
   * Perform any cleanup to stop this task. In SinkTasks, this method is invoked only once
   * outstanding calls to other methods have completed (e.g., pullRecords() has returned) and a final
   * flush() and offset commit has completed. Implementations from this method should only need to
   * perform final cleanup operations, such as closing network connections to the sink system.
   */
  protected abstract void terminate();

  /**
   * Put the table record in the sink. Usually this should send the records to the sink
   * asynchronously and immediately return.
   *
   * @param records table record
   */
  protected abstract void pullRecords(List&amp;lt;RowSinkRecord&amp;gt; records);
}  
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;RowSinkTask is similar to 
&lt;a href=&#34;#sourcetask&#34;&gt;RowSourceTask&lt;/a&gt;
that both of them have &lt;strong&gt;run&lt;/strong&gt; and &lt;strong&gt;stop&lt;/strong&gt; phase. RowSinkTask is
executed by a separate thread on worker also.&lt;/p&gt;
&lt;h3 id=&#34;sinktask-put-records&#34;&gt;pullRecords(List&lt;RowSinkRecord&gt; records)&lt;/h3&gt;
&lt;p&gt;Worker invokes a separate thread to fetch data from topic and put the
data to sink task. The input data is called &lt;strong&gt;RowSinkRecord&lt;/strong&gt; which
carries not only row but also metadata.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;topicName (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; where the data come from&lt;/li&gt;
&lt;li&gt;Row (&lt;strong&gt;row&lt;/strong&gt;) &amp;mdash; input data&lt;/li&gt;
&lt;li&gt;partition (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; index of partition&lt;/li&gt;
&lt;li&gt;offset (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; offset in topic-partition&lt;/li&gt;
&lt;li&gt;timestamp (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; data timestamp&lt;/li&gt;
&lt;li&gt;TimestampType (&lt;strong&gt;enum&lt;/strong&gt;) &amp;mdash; the way of generating timestamp
&lt;ul&gt;
&lt;li&gt;NO_TIMESTAMP_TYPE - means timestamp is nothing for this data&lt;/li&gt;
&lt;li&gt;CREATE_TIME - the timestamp is provided by user or the time of sending this data&lt;/li&gt;
&lt;li&gt;LOG_APPEND_TIME - the timestamp is broker&amp;rsquo;s local time when the data is append&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;partition-and-offsets-in-sink&#34;&gt;Partition and Offsets In Sink&lt;/h3&gt;
&lt;p&gt;Sink task has a component, which is called &lt;strong&gt;RowSinkContext&lt;/strong&gt;, saving
the offset and partitions for input data. Commonly, it is not big news
to you since kafka has responsibility to manage data offset in
topic-partition to avoid losing data. However, if you have something
more than data lost, such as exactly once, you can manage the data
offset manually and then use RowSinkContext to change the offset of
input data.&lt;/p&gt;
&lt;h3 id=&#34;handle-exception-in-pullrecordslistrowsinkrecord&#34;&gt;Handle Exception In pullRecords(List&lt;RowSinkRecord&gt;)&lt;/h3&gt;
&lt;p&gt;Any thrown exception will make this connector failed and stopped. You
should handle the recoverable error and throw the exception which
obstruct connector from running.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public interface RowSinkContext {
  /**
   * Reset the consumer offsets for the given topic partitions. SinkTasks should use this if they
   * manage offsets in the sink data store rather than using Kafka consumer offsets. For example, an
   * HDFS connector might record offsets in HDFS to provide exactly once delivery. When the SinkTask
   * is started or a rebalance occurs, the task would reload offsets from HDFS and use this method
   * to reset the consumer to those offsets.
   *
   * &amp;lt;p&amp;gt;SinkTasks that do not manage their own offsets do not need to use this method.
   *
   * @param offsets map from offsets for topic partitions
   */
  void offset(Map&amp;lt;TopicPartition, Long&amp;gt; offsets);

  /**
   * Reset the consumer offsets for the given topic partition. SinkTasks should use if they manage
   * offsets in the sink data store rather than using Kafka consumer offsets. For example, an HDFS
   * connector might record offsets in HDFS to provide exactly once delivery. When the topic
   * partition is recovered the task would reload offsets from HDFS and use this method to reset the
   * consumer to the offset.
   *
   * &amp;lt;p&amp;gt;SinkTasks that do not manage their own offsets do not need to use this method.
   *
   * @param partition the topic partition to reset offset.
   * @param offset the offset to reset to.
   */
  default void offset(TopicPartition partition, Long offset) {
    this.offset(Map.of(partition, offset));
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Noted that data offset is a order in topic-partition so the input of
RowSinkContext.offset consists of topic name and partition.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;handle-exception-in-pullrecordslistrowsinkrecord-1&#34;&gt;Handle Exception In pullRecords(List&lt;RowSinkRecord&gt;)&lt;/h3&gt;
&lt;p&gt;see 
&lt;a href=&#34;#sourcetask-handle-exception&#34;&gt;handle exception in pollRecords()&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;commit-your-output-data-when-kafka-commit-input-data&#34;&gt;Commit Your Output Data When Kafka Commit Input Data&lt;/h3&gt;
&lt;p&gt;While feeding data into your sink task, Kafka also tries to commit
previous data that make the data disappear from you. The method
&lt;strong&gt;preCommitOffsets&lt;/strong&gt; is a callback of committing data offset. If you
want to manage the offsets, you can change what to commit by kafka.
Another use case is that you have some stuff which needs to be committed
also, and you can trigger the commit in this callback.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class RowSinkTask extends SinkTask {
  /**
   * Pre-commit hook invoked prior to an offset commit.
   *
   * &amp;lt;p&amp;gt;The default implementation simply return the offsets and is thus able to assume all offsets
   * are safe to commit.
   *
   * @param offsets the current offset state as from the last call to pullRecords, provided for convenience
   *     but could also be determined by tracking all offsets included in the RowSourceRecord&#39;s
   *     passed to pullRecords.
   * @return an empty map if Connect-managed offset commit is not desired, otherwise a map from
   *     offsets by topic-partition that are safe to commit.
   */
  protected Map&amp;lt;TopicPartition, TopicOffset&amp;gt; preCommitOffsets(Map&amp;lt;TopicPartition, TopicOffset&amp;gt; offsets) {
    return offsets;
  }
}  
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The offsets exceeding the latest consumed offset are discarded
  &lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 id=&#34;version&#34;&gt;Version&lt;/h2&gt;
&lt;p&gt;We all love to show how good we are. If you are a connector designer,
Ohara connector offers a way to show the version, revision and author
for a connector.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class RowSourceConnector extends SourceConnector {
  public String version() {
    return VersionUtils.VERSION;
  }
  public String author() {
    return VersionUtils.USER;
  }
  public String revision() {
     return VersionUtils.REVISION;
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The default value is version of build. You can override one of them or
all of them when writing connector. The version information of a
connector is showed by 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/workers/&#34;&gt;Worker APIs&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;div&gt;
    Don&amp;rsquo;t return &lt;strong&gt;null&lt;/strong&gt;, please!!!
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Version in Ohara connector is different to kafka connector. The later
only supports &lt;strong&gt;version&lt;/strong&gt; and it&amp;rsquo;s APIs show only &lt;strong&gt;version&lt;/strong&gt;. Hence,
you can&amp;rsquo;t get revision, author or other

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/setting_definition/&#34;&gt;settings&lt;/a&gt; through kafka APIs&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;metrics&#34;&gt;Metrics&lt;/h2&gt;
&lt;p&gt;We are live in a world filled with number, and so do connectors. While a
connector is running, Ohara collects many counts from the data flow for
the connector in background. All of counters (and other records which
will be introduced in the future) are called &lt;strong&gt;metrics&lt;/strong&gt;, and it can be
fetched by 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/connectors/&#34;&gt;Connector API&lt;/a&gt;.
Apart from official metrics, connector developers are also
able to build custom metrics for custom connectors, and all custom
metrics are also showed by 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/connectors/&#34;&gt;Connector API&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Ohara leverage JMX to offer the metrics APIs to connector. It means all
metrics you created are stored as Java beans and is accessible through
JMX service. That is why you have to define a port via

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/workers/&#34;&gt;Worker APIs&lt;/a&gt; for creating
a worker cluster. Although you can see all java mbeans via the JMX
client (such as JMC), Ohara still encourage you to apply

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/connectors/&#34;&gt;Connector API&lt;/a&gt; as it
offers a more readable format of metrics.&lt;/p&gt;
&lt;h3 id=&#34;counter&#34;&gt;Counter&lt;/h3&gt;
&lt;p&gt;Counter is a common use case for metrics that you can
increment/decrement/add/ a number atomically. A counter consists of
following members.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the group of this counter&lt;/li&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the name of this counter&lt;/li&gt;
&lt;li&gt;unit (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the unit of value&lt;/li&gt;
&lt;li&gt;document (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the document for this metrics&lt;/li&gt;
&lt;li&gt;startTime (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; the time to start this counter&lt;/li&gt;
&lt;li&gt;value (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; current value of count&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A example of creating a counter is shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class ExampleOfCreatingCounter {
  public static Counter sizeCounter(String group) {
    return Counter.builder()
        .group(group)
        .name(&amp;quot;row.size&amp;quot;)
        .unit(&amp;quot;bytes&amp;quot;)
        .document(&amp;quot;size (in bytes) of rows&amp;quot;)
        .startTime(CommonUtils.current())
        .value(0)
        .register();
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Though &lt;strong&gt;unit&lt;/strong&gt; and &lt;strong&gt;document&lt;/strong&gt; are declared optional, making them have
meaning description can help reader to understand the magic number from
your counter.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The counter created by connector always has the group same to id of
connector, since Ohara needs to find the counters for specific connector
in &lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/connectors/&#34;&gt;Connector API&lt;/a&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;official-metrics&#34;&gt;Official Metrics&lt;/h3&gt;
&lt;p&gt;There are two official metrics for connector - row counter and bytes
counter. The former is the number of processed rows, and the later is
the number of processed data. Both of them are updated when data are
pull/push from/to your connector. Normally, you don&amp;rsquo;t need to care for
them when designing connectors. However, you can read the source code in
ConnectorUtils.java to see how Ohara create official counters.&lt;/p&gt;
&lt;h3 id=&#34;create-your-own-counters&#34;&gt;Create Your Own Counters&lt;/h3&gt;
&lt;p&gt;In order to reduce your duplicate code, Ohara offers the
&lt;strong&gt;CounterBuilder&lt;/strong&gt; to all connectors. CounterBuilder is a wrap of
Counter.Builder with some pre-defined variables, and hence the creation
of CounterBuilder must be after initializing the connector/task.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class ExampleOfCreatingCustomBuilder {
  public static Counter custom(RowSinkTask task) {
    return task.counterBuilder()
      .unit(&amp;quot;bytes&amp;quot;)
      .document(&amp;quot;size (in bytes) of rows&amp;quot;)
      .startTime(CommonUtils.current())
      .value(0)
      .register();
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Ohara doesn&amp;rsquo;t obstruct you from using Counter directly. However, using
CounterBuilder make sure that your custom metrics are available in
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/connectors/&#34;&gt;Connector API&lt;/a&gt;.
  &lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 id=&#34;csv-sink&#34;&gt;Csv Sink Connector&lt;/h2&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/csv_sink_connector_arch.png&#34; &gt;


  &lt;img src=&#34;../img/csv_sink_connector_arch.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;Csv Sink connector inherits from 
&lt;a href=&#34;#sink-connector&#34;&gt;Row Sink Connector&lt;/a&gt;.
It also have 
&lt;a href=&#34;#source-start&#34;&gt;run(TaskSetting)&lt;/a&gt;,

&lt;a href=&#34;#source-terminate&#34;&gt;terminate()&lt;/a&gt;,

&lt;a href=&#34;#source-taskclass&#34;&gt;taskClass()&lt;/a&gt;,

&lt;a href=&#34;#source-tasksetting&#34;&gt;taskSetting(int maxTasks)&lt;/a&gt;,

&lt;a href=&#34;#sourcetask-partition-offsets&#34;&gt;partition and offsets&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The main difference between csv sink connector and row sink
connector is that csv sink connector already has some default
definitions.&lt;/p&gt;
&lt;p&gt;Below is a list of default definitions for CsvSinkConnector:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;TOPICS_DIR_DEFINITION: Read csv data from topic and then write to
this folder&lt;/li&gt;
&lt;li&gt;FLUSH_SIZE_DEFINITION: Number of records write to store before
invoking file commits&lt;/li&gt;
&lt;li&gt;ROTATE_INTERVAL_MS_DEFINITION: Commit file time&lt;/li&gt;
&lt;li&gt;FILE_NEED_HEADER_DEFINITION: File need header for flush data&lt;/li&gt;
&lt;li&gt;FILE_ENCODE_DEFINITION: File encode for write to file&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Connector developers can override &lt;strong&gt;customSettingDefinitions&lt;/strong&gt; to add
other additional definitions:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class CsvSinkConnector extends RowSinkConnector {
  /**
   * Define the configuration for the connector.
   *
   * @return The SettingDef for this connector.
   */
  protected List&amp;lt;SettingDef&amp;gt; customSettingDefinitions() {
    return List.of();
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;csv-sink-task&#34;&gt;Csv Sink Task&lt;/h2&gt;
&lt;p&gt;Ohara has a well-incubated task class. We call it &lt;strong&gt;CsvSinkTask&lt;/strong&gt;. As
long as your data format is CSV type, you can use id to develop a sink
connector to connect various file systems.&lt;/p&gt;
&lt;p&gt;We all know that to make a strong and robust connector, you have to take
care of a lot of details. In order to ensure that the connector works,
we must also prepare a lot of tests. Connector developers will spend a
lot of time on this.&lt;/p&gt;
&lt;p&gt;Therefore, we have encapsulated most of the logic in CsvSinkTask, which
hides a lot of complex behaviors. Just provide a 
&lt;a href=&#34;#storage&#34;&gt;Storage&lt;/a&gt;
implementation to complete a sink connector. You can save time to enjoy
other happy things.&lt;/p&gt;
&lt;p&gt;The following are the two methods you need to care about inherited
CsvSinkTask:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class CsvSinkTask extends RowSinkTask {
  /**
   * Returns the Storage implementation for this Task.
   *
   * @param setting initial settings
   * @return a Storage instance
   */
  public abstract Storage _storage(TaskSetting setting);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;_storagetasksetting-setting&#34;&gt;_storage(TaskSetting setting)&lt;/h3&gt;
&lt;p&gt;The goal of Task is to write the data to an external file system. For
example, if we want to store the output files on FTP server, connector
developers must provide an implementation of

&lt;a href=&#34;#storage&#34;&gt;Storage&lt;/a&gt; that can access FTP.&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The input parameter &lt;em&gt;TaskSetting&lt;/em&gt; carrying all settings.
see &lt;a href=&#34;#source-tasksetting&#34;&gt;TaskSetting&lt;/a&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;storage&#34;&gt;Storage&lt;/h2&gt;
&lt;p&gt;This interface defines some common methods for accessing the file
system, such as checking for the existence of a file, creating a new
file, or reading an exiting file, etc. Connector developers can follow
this interface to implement different file systems, such as FTP, HDFS,
SMB, Amazon S3, etc. So, just provide the implementation of Storage to
CsvSinkTask and you can implement a

&lt;a href=&#34;#sink-connector&#34;&gt;Sink Connector&lt;/a&gt; very quickly.&lt;/p&gt;
&lt;p&gt;Below we list the important methods in the Storage interface:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public interface Storage extends Releasable {
  /**
   * Returns whether an object exists.
   *
   * @param path the path to the object.
   * @return true if object exists, false otherwise.
   */
  boolean exists(String path);

  /**
   * Creates a new object in the given path.
   *
   * @param path the path of the object to be created.
   * @throws OharaFileAlreadyExistsException if a object of that path already exists.
   * @throws OharaException if the parent container does not exist.
   * @return an output stream associated with the new object.
   */
  OutputStream create(String path);

  /**
   * Open for reading an object at the given path.
   *
   * @param path the path of the object to be read.
   * @return an input stream with the requested object.
   */
  InputStream open(String path);

  /**
   * Move or rename a object from source path to target path.
   *
   * @param sourcePath the path to the object to move
   * @param targetPath the path to the target object
   * @return true if object have moved to target path , false otherwise.
   */
  boolean move(String sourcePath, String targetPath);

  /** Stop using this storage. */
  void close();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You can read the
&lt;a href=&#34;https://github.com/oharastream/ohara/blob/0.11.x/ohara-connector/src/main/scala/oharastream/ohara/connector/ftp/FtpStorage.scala&#34;&gt;FtpStorage&lt;/a&gt;
as an example to see how to implement your own Storage.
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Custom Connector Guideline</title>
      <link>https://oharastream.github.io/en/docs/master/custom_connector/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/master/custom_connector/</guid>
      <description>&lt;p&gt;Ohara custom connector is based on

&lt;a href=&#34;https://docs.confluent.io/current/connect/managing/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;kafka connector&lt;/a&gt;.
It offers a platform that enables you to define some simple actions to
connect topic to any other system. You don&amp;rsquo;t need to worry the
application availability, data durability, or distribution anymore. All
you have to do is to write your custom connector, which can have only
the pull()/push() method, and then compile your code to a jar file.
After uploading your jar to Ohara, you are able to &lt;strong&gt;deploy&lt;/strong&gt; your
connector on the
[worker cluster]/en/docs/master/rest-api/workers/#rest-workers-create. By
leveraging Ohara connector framework, apart from the availability,
scalability, and durability, you can also monitor your connector for

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/logs/&#34;&gt;logs&lt;/a&gt; and

&lt;a href=&#34;#metrics&#34;&gt;metrics&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The following sections start to explain how to write a good connector on
Ohara. You don&amp;rsquo;t need to read it through if you are familiar with

&lt;a href=&#34;https://docs.confluent.io/current/connect/managing/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;kafka connector&lt;/a&gt;.
However, Ohara connector has some improvements which are not in

&lt;a href=&#34;https://docs.confluent.io/current/connect/managing/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;kafka connector&lt;/a&gt;
so it has worth of taking a look at

&lt;a href=&#34;#metrics&#34;&gt;metrics&lt;/a&gt; and

&lt;a href=&#34;#setting_definition.md&#34;&gt;setting definitions&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;connector-overview&#34;&gt;Connector Overview&lt;/h2&gt;
&lt;p&gt;Ohara connector is composed of

&lt;a href=&#34;#source-connector&#34;&gt;source connector&lt;/a&gt; and

&lt;a href=&#34;#sink-connector&#34;&gt;sink connector&lt;/a&gt; .

&lt;a href=&#34;#source-connector&#34;&gt;source connector&lt;/a&gt;
is used to pull data &lt;strong&gt;from external system to topic&lt;/strong&gt;. By
contrast, 
&lt;a href=&#34;#sink-connector&#34;&gt;sink connector&lt;/a&gt; is
used to pull data from &lt;strong&gt;topic to external system&lt;/strong&gt;. A
complete connector consists of &lt;strong&gt;SourceConnector&lt;/strong&gt; / &lt;strong&gt;SinkConnector&lt;/strong&gt;
and &lt;strong&gt;SourceTask&lt;/strong&gt; / &lt;strong&gt;SinkTask&lt;/strong&gt;. Worker cluster picks up a node to
host your source/sink connector and then distributes the source/sink
tasks across cluster.&lt;/p&gt;
&lt;p&gt;You must include Ohara jars before starting to write your custom
connector. Please include both of ohara-common and ohara-kafka in your
dependencies. The ohara-common contains many helper methods and common
data used in whole Ohara. The ohara-kafka offers a lot of beautiful APIs
to help you to access kafka and design custom connector.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-groovy&#34;&gt;repositories {
     maven {
         url &amp;quot;https://dl.bintray.com/oharastream/ohara&amp;quot;
     }
 }
implementation &amp;quot;oharastream.ohara:ohara-common:0.11.0-SNAPSHOT&amp;quot;
implementation &amp;quot;oharastream.ohara:ohara-kafka:0.11.0-SNAPSHOT&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The &lt;a href=&#34;https://github.com/oharastream/ohara/releases&#34;&gt;releases&lt;/a&gt; page shows the available version of Ohara
  &lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 id=&#34;datamodel&#34;&gt;Data Model&lt;/h2&gt;
&lt;p&gt;Ohara has defined a table structure data in code base. We call it
&lt;strong&gt;row&lt;/strong&gt;. A row is comprised of multiple &lt;strong&gt;cells&lt;/strong&gt;. Each cell has its
&lt;strong&gt;name&lt;/strong&gt;, &lt;strong&gt;value&lt;/strong&gt; and &lt;strong&gt;tags&lt;/strong&gt;. The value in cell is a generic type
which accepts any serializable type of value. Following is an example
that shows you how to convert a csv data to Ohara row.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;c0,c1,c2
v0,v1,v2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above data can be converted to Ohara row by following code.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import oharastream.ohara.common.data.Row;
import oharastream.ohara.common.data.Cell;
class ExampleOfRow {
    public static void main(String[] args) {
        Row row = Row.of(
                Cell.of(&amp;quot;c0&amp;quot;, &amp;quot;v0&amp;quot;),
                Cell.of(&amp;quot;c1&amp;quot;, &amp;quot;v1&amp;quot;),
                Cell.of(&amp;quot;c2&amp;quot;, &amp;quot;v2&amp;quot;)
                );
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;c0,c1,c2
v0,,v2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above data can be converted to Ohara row by following code.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import oharastream.ohara.common.data.Row;
import oharastream.ohara.common.data.Cell;
class ExampleOfRow {
    public static void main(String[] args) {
        Row row = Row.of(
                Cell.of(&amp;quot;c0&amp;quot;, &amp;quot;v0&amp;quot;),
                Cell.of(&amp;quot;c2&amp;quot;, &amp;quot;v2&amp;quot;)
                );
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Don&amp;rsquo;t worry about the serialization. Ohara offers default serializations
for following data types:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;string&lt;/li&gt;
&lt;li&gt;boolean&lt;/li&gt;
&lt;li&gt;short&lt;/li&gt;
&lt;li&gt;int&lt;/li&gt;
&lt;li&gt;long&lt;/li&gt;
&lt;li&gt;float&lt;/li&gt;
&lt;li&gt;double&lt;/li&gt;
&lt;li&gt;bytes&lt;/li&gt;
&lt;li&gt;serializable object&lt;/li&gt;
&lt;li&gt;row (a nested row is acceptable!)&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The default serializer is located at
&lt;a href=&#34;https://github.com/oharastream/ohara/blob/master/ohara-common/src/main/java/oharastream/ohara/common/data/Serializer.java&#34;&gt;Here&lt;/a&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;When you get the rows in the connector, you should follow the &lt;strong&gt;cell
setting&lt;/strong&gt; to generate the output. The &lt;strong&gt;cell setting&lt;/strong&gt; in Ohara is
called &lt;strong&gt;column&lt;/strong&gt;. It shows the metadata of a &lt;strong&gt;cell&lt;/strong&gt;. The metadata
consists of:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;origin column name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; you can match the cell by this name&lt;/li&gt;
&lt;li&gt;new column name &amp;mdash; the new name of output.&lt;/li&gt;
&lt;li&gt;type (&lt;strong&gt;DataType&lt;/strong&gt;) &amp;mdash; the type of output value. Whatever the
origin type of value, you should convert the value according this
type. Don&amp;rsquo;t worry the casting error. It is up to the user who pass
the wrong configuration.
&lt;ul&gt;
&lt;li&gt;string&lt;/li&gt;
&lt;li&gt;boolean&lt;/li&gt;
&lt;li&gt;short&lt;/li&gt;
&lt;li&gt;int&lt;/li&gt;
&lt;li&gt;long&lt;/li&gt;
&lt;li&gt;float&lt;/li&gt;
&lt;li&gt;double&lt;/li&gt;
&lt;li&gt;bytes&lt;/li&gt;
&lt;li&gt;serializable object&lt;/li&gt;
&lt;li&gt;row&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;order (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; the order of cells in output.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;An example of converting data according to columns.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import oharastream.ohara.common.data.Cell;
import oharastream.ohara.common.data.Column;
class ExampleOfConverting {
    public static Object hello(Column column, String rawValue) {
        switch (column.dataType) {
            case DataType.BOOLEAN:
                return Boolean.valueOf(rawValue);
            case DataType.STRING:
                return rawValue;
            case DataType.SHORT:
                return Short.valueOf(rawValue);
            case DataType.INT:
                return Integer.valueOf(rawValue);
            case DataType.FLOAT:
                return Float.valueOf(rawValue);
            case DataType.DOUBLE:
                return Double.valueOf(rawValue);
            default:
                throw new IllegalArgumentException(&amp;quot;unsupported type:&amp;quot; + column.dataType);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The type is a complicated issue since there are countless types in this
world. It is impossible to define a general solution to handle all types
so the final types of value is &lt;strong&gt;byte array&lt;/strong&gt; or &lt;strong&gt;serializable
object&lt;/strong&gt;. If the type you want to pass is not in official support, you
should define it as &lt;strong&gt;byte array&lt;/strong&gt; or &lt;strong&gt;serializable object&lt;/strong&gt; and then
process it in your connectors.&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Feel free to throw an exception when your connector encounters an unknown
type. Don&amp;rsquo;t swallow it and convert to a weird value, such as null or
empty. Throwing exception is better than generating corrupt data!
  &lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 id=&#34;source-connector&#34;&gt;Source Connector&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;Source connector is used to pull data from outside system and then push
processed data to Ohara topics. A basic implementation for a source
connector only includes four methods &amp;mdash; &lt;strong&gt;run&lt;/strong&gt;, &lt;strong&gt;terminate&lt;/strong&gt;,
&lt;strong&gt;taskClass&lt;/strong&gt;, and &lt;strong&gt;taskSetting&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class RowSourceConnector extends SourceConnector {
  /**
   * Returns the RowSourceTask implementation for this Connector.
   *
   * @return a RowSourceTask class
   */
  protected abstract Class&amp;lt;? extends RowSourceTask&amp;gt; taskClass();

  /**
   * Return the settings for source task.
   *
   * @param maxTasks number of tasks for this connector
   * @return a seq from settings
   */
  protected abstract List&amp;lt;TaskSetting&amp;gt; taskSetting(int maxTasks);

  /**
   * Start this Connector. This method will only be called on a clean Connector, i.e. it has either
   * just been instantiated and initialized or terminate() has been invoked.
   *
   * @param taskSetting configuration settings
   */
  protected abstract void run(TaskSetting taskSetting);

  /** stop this connector */
  protected abstract void terminate();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;source-start&#34;&gt;run(TaskSetting)&lt;/h3&gt;
&lt;p&gt;After instantizing a connector, the first method called by worker is
&lt;strong&gt;start()&lt;/strong&gt;. You should initialize your connector in &lt;strong&gt;start&lt;/strong&gt; method,
since it has a input parameter &lt;strong&gt;TaskSetting&lt;/strong&gt; carrying all settings,
such as target topics, connector name and user-defined configs, from
user. If you (connector developer) are a good friend of your connector
user, you can get (and cast it to expected type) config, which is
passed by connector user, from &lt;strong&gt;TaskSetting&lt;/strong&gt;. For example, a
connector user calls

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/connectors/#create-settings&#34;&gt;Connector API&lt;/a&gt;
to store a config k0-v0 (both of them are string type) for
your connector, and then you can get v0 via
TaskSetting.stringValue(&amp;ldquo;k0&amp;rdquo;).&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Don&amp;rsquo;t be afraid of throwing exception when you notice that input
parameters are incorrect. Throwing an exception can fail a connector
quickly and stop worker to distribute connector task across cluster. It
saves the time and resources.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;We all hate wrong configs, right? When you design the connector, you can
&lt;strong&gt;define&lt;/strong&gt; the 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/setting_definition/&#34;&gt;setting&lt;/a&gt; on your own initiative.
The 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/setting_definition/&#34;&gt;setting&lt;/a&gt; enable
worker to check the input configs before starting connector. It can&amp;rsquo;t
eliminate incorrect configs completely, but it save your time of
fighting against wrong configs (have a great time with your family)&lt;/p&gt;
&lt;h3 id=&#34;source-terminate&#34;&gt;terminate()&lt;/h3&gt;
&lt;p&gt;This method is invoked by calling

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/connectors/#stop&#34;&gt;STOP API&lt;/a&gt;. You can
release the resources allocated by connector, or email to shout
at someone. It is ok to throw an exception when you fails to &lt;strong&gt;stop&lt;/strong&gt;
the connector. Worker cluster will mark &lt;strong&gt;failure&lt;/strong&gt; on the connector,
and the world keeps running.&lt;/p&gt;
&lt;h3 id=&#34;source-taskclass&#34;&gt;taskClass()&lt;/h3&gt;
&lt;p&gt;This method returns the java class of

&lt;a href=&#34;#sourcetask&#34;&gt;RowSourceTask&lt;/a&gt;
implementation. It tells worker cluster which class should be created
to pull data from external system. Noted that connector and task may
not be created on same node (jvm) so you should NOT share any objects
between them (for example, make them to access a global variable).&lt;/p&gt;
&lt;h3 id=&#34;source-tasksetting&#34;&gt;taskSetting(int maxTasks)&lt;/h3&gt;
&lt;p&gt;Connector has to generate configs for each task. The value of
&lt;strong&gt;maxTasks&lt;/strong&gt; is configured by

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/connectors/&#34;&gt;Connector API&lt;/a&gt;. If
you prefer to make all tasks do identical job, you can just clone the
task config passe by 
&lt;a href=&#34;#source-start&#34;&gt;start&lt;/a&gt;. Or you
can prepare different configs for each task. Noted that the number of
configuration you return MUST be equal with input value - maxTasks.
Otherwise, you will get an exception when running your connector.&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    It would be better to do the final check to input configs in Connector
rather than Task. Producing a failure quickly save your time and
resources.
  &lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 id=&#34;sourcetask&#34;&gt;Source Task&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class RowSourceTask extends SourceTask {

  /**
   * Start the Task. This should handle any configuration parsing and one-time setup from the task.
   *
   * @param config initial configuration
   */
  protected abstract void run(TaskSetting config);

  /**
   * Signal this SourceTask to stop. In SourceTasks, this method only needs to signal to the task
   * that it should stop trying to poll for new data and interrupt any outstanding poll() requests.
   * It is not required that the task has fully stopped. Note that this method necessarily may be
   * invoked from a different thread than pollRecords() and commitOffsets()
   */
  protected abstract void terminate();
  /**
   * Poll this SourceTask for new records. This method should block if no data is currently
   * available.
   *
   * @return a array from RowSourceRecord
   */
  protected abstract List&amp;lt;RowSourceRecord&amp;gt; pollRecords();
}  
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;RowSourceTask is the unit of executing &lt;strong&gt;poll&lt;/strong&gt;. A connector can invoke
multiple tasks if you set &lt;strong&gt;tasks.max&lt;/strong&gt; be bigger than 1 via

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/connectors/&#34;&gt;Connector API&lt;/a&gt;.
RowSourceTask has the similar lifecycle to Source connector. Worker cluster
call &lt;strong&gt;start&lt;/strong&gt; to initialize a task and call &lt;strong&gt;stop&lt;/strong&gt; to terminate a
task.&lt;/p&gt;
&lt;h3 id=&#34;sourcetask-pullrecords&#34;&gt;pullRecords()&lt;/h3&gt;
&lt;p&gt;You can ignore all methods except for &lt;strong&gt;pollRecords&lt;/strong&gt;. Worker cluster
call &lt;strong&gt;pollRecords&lt;/strong&gt; regularly to get &lt;strong&gt;RowSourceRecord&lt;/strong&gt; s and then
save them to topics. Worker cluster does not care for your
implementation. All you have to do is to put your data in
&lt;strong&gt;RowSourceRecord&lt;/strong&gt;. RowSourceRecord is a complicated object having
many elements. Some elements are significant. For example,
&lt;strong&gt;partition&lt;/strong&gt; can impact the distribution of records. In order to be
the best friend of programmer, Ohara follows the fluent pattern to allow
you to create record through builder, and you can only fill the
required elements.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class ExampleOfRowSourceRecord {
    public static RowSourceRecord create(Row row, String topicName) {
        return RowSourceRecord.builder()
        .row(row)
        .topicName(topicName)
        .build();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You can read the java docs of RowSourceRecord.Builder to see which
default values are set for other (optional) elements.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;sourcetask-partition-offsets&#34;&gt;Partition and Offsets in Source&lt;/h3&gt;
&lt;p&gt;De-duplicating data is not a easy job. When you keep pulling data from
external system to topics, you always need a place to record which
data have not processed. Connector offers two specific objects for you
to record the &lt;strong&gt;offset&lt;/strong&gt; and &lt;strong&gt;partition&lt;/strong&gt; of your data. You can
define a &lt;strong&gt;partition&lt;/strong&gt; and a &lt;strong&gt;offset&lt;/strong&gt; for RowSourceRecord. The
durability is on Worker&amp;rsquo;s shoulder, and you are always doable to get
&lt;strong&gt;partition&lt;/strong&gt; and &lt;strong&gt;offset&lt;/strong&gt; back even if the connector fail or
shutdown.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class ExampleOfRowSourceContext {
    public static Map&amp;lt;String, ?&amp;gt; getOffset(Map&amp;lt;String, ?&amp;gt; partition) {
        return RowSourceContext.offset(partition);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Both of them are Map type with string key and primitive type. Using Map
is a workaround to record the offsets for different connectors. You can
view them as a &lt;strong&gt;flatten&lt;/strong&gt; json representation. For example, one of task
is handling file_a, and it has processed first line of file_a. Then
the pair of &lt;strong&gt;partition&lt;/strong&gt; and &lt;strong&gt;offset&lt;/strong&gt; look like&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;fileName&amp;quot;: &amp;quot;file_a&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;offset&amp;quot;: 1
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can convert above json to &lt;strong&gt;partition&lt;/strong&gt; and &lt;strong&gt;offset&lt;/strong&gt; and then put
them in &lt;strong&gt;RowSourceRecord&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class ExampleOfPartitionAndOffset {
    public static RowSourceRecord addPartitionAndOffset(RowSourceRecord.Builder builder, String fileName, int offset) {
        Map&amp;lt;String, String&amp;gt; partition = Map.of(&amp;quot;fileName&amp;quot;, fileName);
        Map&amp;lt;String, Integer&amp;gt; offset = Map.of(&amp;quot;offset&amp;quot;, 1);
        return builder.sourcePartition(partition)
        .sourceOffset(offset)
        .build();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A news of &lt;strong&gt;partition&lt;/strong&gt; and &lt;strong&gt;offset&lt;/strong&gt; is that they are not stored with
data in RowSourceRecord. If you want to know the commit of &lt;strong&gt;partition&lt;/strong&gt;
and &lt;strong&gt;offset&lt;/strong&gt;, you can override the &lt;strong&gt;commitOffsets()&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class RowSourceTask extends SourceTask {
  /**
   * Commit the offsets, up to the offsets that have been returned by pollRecords(). This method should
   * block until the commit is complete.
   *
   * &amp;lt;p&amp;gt;SourceTasks are not required to implement this functionality; Kafka Connect will record
   * offsets automatically. This hook is provided for systems that also need to store offsets
   * internally in their own system.
   */
  protected void commitOffsets() {
    // do nothing
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;sourcetask-handle-exception&#34;&gt;Handle Exception in pollRecords()&lt;/h3&gt;
&lt;p&gt;Throwing exception make connector in &lt;strong&gt;failure&lt;/strong&gt; state, and inactivate
connector until you restart it. Hence, you SHOULD catch and handle the
exception as best you can. However, swallowing all exception is also a
weired behavior. You SHOULD fails the connector when encountering
unrecoverable exception.&lt;/p&gt;
&lt;h3 id=&#34;blocking-action-is-unwelcome-in-pollrecords&#34;&gt;Blocking Action Is Unwelcome In pollRecords()&lt;/h3&gt;
&lt;p&gt;Task is executed on a separate thread and there are many remaining
processing for data after pollRecords(). Hence, you should NOT block
pollRecords(). On the contrary, returning an empty list can yield the
resource to remaining processing.&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Returning null results in same result. However, we all should hate null
so please take away null from your code.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;data-from-pollrecords-are-committed-async&#34;&gt;Data From pollRecords() Are Committed Async&lt;/h3&gt;
&lt;p&gt;You don&amp;rsquo;t expect that the data you generated are commit at once,
right? Committing data invokes a large latency since we need to sync
data to multiple nodes and result in many disk I/O. Worker has another
thread sending your data in background. If your connector needs to
know the time of committing data, you can override the
&lt;strong&gt;commitOffsetsRecord(RowSourceRecord)&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class RowSourceTask extends SourceTask {
  /**
   * Commit an individual RowSourceRecord when the callback from the producer client is received, or
   * if a record is filtered by a transformation. SourceTasks are not required to implement this
   * functionality; Kafka Connect will record offsets automatically. This hook is provided for
   * systems that also need to store offsets internally in their own system.
   *
   * @param record RowSourceRecord that was successfully sent via the producer.
   */
  protected void commitOffsetsRecord(RowSourceRecord record) {
    // do nothing
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;sink-connector&#34;&gt;Sink Connector&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class RowSinkConnector extends SinkConnector {

  /**
   * Start this Connector. This method will only be called on a clean Connector, i.e. it has either
   * just been instantiated and initialized or terminate() has been invoked.
   *
   * @param config configuration settings
   */
  protected abstract void run(TaskSetting config);

  /** stop this connector */
  protected abstract void terminate();

  /**
   * Returns the RowSinkTask implementation for this Connector.
   *
   * @return a RowSinkTask class
   */
  protected abstract Class&amp;lt;? extends RowSinkTask&amp;gt; taskClass();

  /**
   * Return the settings for source task. NOTED: It is illegal to assign different topics to
   * RowSinkTask
   *
   * @param maxTasks number of tasks for this connector
   * @return the settings for each tasks
   */
  protected abstract List&amp;lt;TaskSetting&amp;gt; taskSetting(int maxTasks);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Sink connector is similar to

&lt;a href=&#34;#source-connector&#34;&gt;source connector&lt;/a&gt;. It also have

&lt;a href=&#34;#source-start&#34;&gt;run(TaskSetting)&lt;/a&gt;,

&lt;a href=&#34;#source-terminate&#34;&gt;terminate()&lt;/a&gt;,

&lt;a href=&#34;#source-taskclass&#34;&gt;taskClass()&lt;/a&gt;,

&lt;a href=&#34;#source-tasksetting&#34;&gt;taskSetting(int maxTasks)&lt;/a&gt;,

&lt;a href=&#34;#sourcetask-partition-offsets&#34;&gt;partition and offsets&lt;/a&gt;.
The main difference between sink connector and source
connector is that sink connector do pull data from topic and then push
processed data to outside system. Hence, it does have

&lt;a href=&#34;#sinktask-put-records&#34;&gt;pullRecords&lt;/a&gt; rather than

&lt;a href=&#34;#sourcetask-pullrecords&#34;&gt;pullRecords&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Though sink connector and source connector have many identical methods,
you should NOT make a connector mixed sink and source. Because Both
connector are &lt;strong&gt;abstract&lt;/strong&gt; class, you can&amp;rsquo;t have a class extending both
of them in java.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Sink connector also has to provide the task class to worker cluster. The
sink task in Ohara is called &lt;strong&gt;RowSinkTask&lt;/strong&gt;. It is also distributed
across whole worker cluster when you run a sink connector.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;sink-task&#34;&gt;Sink Task&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class RowSinkTask extends SinkTask {

  /**
   * Start the Task. This should handle any configuration parsing and one-time setup from the task.
   *
   * @param config initial configuration
   */
  protected abstract void run(TaskSetting config);

  /**
   * Perform any cleanup to stop this task. In SinkTasks, this method is invoked only once
   * outstanding calls to other methods have completed (e.g., pullRecords() has returned) and a final
   * flush() and offset commit has completed. Implementations from this method should only need to
   * perform final cleanup operations, such as closing network connections to the sink system.
   */
  protected abstract void terminate();

  /**
   * Put the table record in the sink. Usually this should send the records to the sink
   * asynchronously and immediately return.
   *
   * @param records table record
   */
  protected abstract void pullRecords(List&amp;lt;RowSinkRecord&amp;gt; records);
}  
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;RowSinkTask is similar to 
&lt;a href=&#34;#sourcetask&#34;&gt;RowSourceTask&lt;/a&gt;
that both of them have &lt;strong&gt;run&lt;/strong&gt; and &lt;strong&gt;stop&lt;/strong&gt; phase. RowSinkTask is
executed by a separate thread on worker also.&lt;/p&gt;
&lt;h3 id=&#34;sinktask-put-records&#34;&gt;pullRecords(List&lt;RowSinkRecord&gt; records)&lt;/h3&gt;
&lt;p&gt;Worker invokes a separate thread to fetch data from topic and put the
data to sink task. The input data is called &lt;strong&gt;RowSinkRecord&lt;/strong&gt; which
carries not only row but also metadata.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;topicName (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; where the data come from&lt;/li&gt;
&lt;li&gt;Row (&lt;strong&gt;row&lt;/strong&gt;) &amp;mdash; input data&lt;/li&gt;
&lt;li&gt;partition (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; index of partition&lt;/li&gt;
&lt;li&gt;offset (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; offset in topic-partition&lt;/li&gt;
&lt;li&gt;timestamp (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; data timestamp&lt;/li&gt;
&lt;li&gt;TimestampType (&lt;strong&gt;enum&lt;/strong&gt;) &amp;mdash; the way of generating timestamp
&lt;ul&gt;
&lt;li&gt;NO_TIMESTAMP_TYPE - means timestamp is nothing for this data&lt;/li&gt;
&lt;li&gt;CREATE_TIME - the timestamp is provided by user or the time of sending this data&lt;/li&gt;
&lt;li&gt;LOG_APPEND_TIME - the timestamp is broker&amp;rsquo;s local time when the data is append&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;partition-and-offsets-in-sink&#34;&gt;Partition and Offsets In Sink&lt;/h3&gt;
&lt;p&gt;Sink task has a component, which is called &lt;strong&gt;RowSinkContext&lt;/strong&gt;, saving
the offset and partitions for input data. Commonly, it is not big news
to you since kafka has responsibility to manage data offset in
topic-partition to avoid losing data. However, if you have something
more than data lost, such as exactly once, you can manage the data
offset manually and then use RowSinkContext to change the offset of
input data.&lt;/p&gt;
&lt;h3 id=&#34;handle-exception-in-pullrecordslistrowsinkrecord&#34;&gt;Handle Exception In pullRecords(List&lt;RowSinkRecord&gt;)&lt;/h3&gt;
&lt;p&gt;Any thrown exception will make this connector failed and stopped. You
should handle the recoverable error and throw the exception which
obstruct connector from running.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public interface RowSinkContext {
  /**
   * Reset the consumer offsets for the given topic partitions. SinkTasks should use this if they
   * manage offsets in the sink data store rather than using Kafka consumer offsets. For example, an
   * HDFS connector might record offsets in HDFS to provide exactly once delivery. When the SinkTask
   * is started or a rebalance occurs, the task would reload offsets from HDFS and use this method
   * to reset the consumer to those offsets.
   *
   * &amp;lt;p&amp;gt;SinkTasks that do not manage their own offsets do not need to use this method.
   *
   * @param offsets map from offsets for topic partitions
   */
  void offset(Map&amp;lt;TopicPartition, Long&amp;gt; offsets);

  /**
   * Reset the consumer offsets for the given topic partition. SinkTasks should use if they manage
   * offsets in the sink data store rather than using Kafka consumer offsets. For example, an HDFS
   * connector might record offsets in HDFS to provide exactly once delivery. When the topic
   * partition is recovered the task would reload offsets from HDFS and use this method to reset the
   * consumer to the offset.
   *
   * &amp;lt;p&amp;gt;SinkTasks that do not manage their own offsets do not need to use this method.
   *
   * @param partition the topic partition to reset offset.
   * @param offset the offset to reset to.
   */
  default void offset(TopicPartition partition, Long offset) {
    this.offset(Map.of(partition, offset));
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Noted that data offset is a order in topic-partition so the input of
RowSinkContext.offset consists of topic name and partition.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;handle-exception-in-pullrecordslistrowsinkrecord-1&#34;&gt;Handle Exception In pullRecords(List&lt;RowSinkRecord&gt;)&lt;/h3&gt;
&lt;p&gt;see 
&lt;a href=&#34;#sourcetask-handle-exception&#34;&gt;handle exception in pollRecords()&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;commit-your-output-data-when-kafka-commit-input-data&#34;&gt;Commit Your Output Data When Kafka Commit Input Data&lt;/h3&gt;
&lt;p&gt;While feeding data into your sink task, Kafka also tries to commit
previous data that make the data disappear from you. The method
&lt;strong&gt;preCommitOffsets&lt;/strong&gt; is a callback of committing data offset. If you
want to manage the offsets, you can change what to commit by kafka.
Another use case is that you have some stuff which needs to be committed
also, and you can trigger the commit in this callback.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class RowSinkTask extends SinkTask {
  /**
   * Pre-commit hook invoked prior to an offset commit.
   *
   * &amp;lt;p&amp;gt;The default implementation simply return the offsets and is thus able to assume all offsets
   * are safe to commit.
   *
   * @param offsets the current offset state as from the last call to pullRecords, provided for convenience
   *     but could also be determined by tracking all offsets included in the RowSourceRecord&#39;s
   *     passed to pullRecords.
   * @return an empty map if Connect-managed offset commit is not desired, otherwise a map from
   *     offsets by topic-partition that are safe to commit.
   */
  protected Map&amp;lt;TopicPartition, TopicOffset&amp;gt; preCommitOffsets(Map&amp;lt;TopicPartition, TopicOffset&amp;gt; offsets) {
    return offsets;
  }
}  
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The offsets exceeding the latest consumed offset are discarded
  &lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 id=&#34;version&#34;&gt;Version&lt;/h2&gt;
&lt;p&gt;We all love to show how good we are. If you are a connector designer,
Ohara connector offers a way to show the version, revision and author
for a connector.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class RowSourceConnector extends SourceConnector {
  public String version() {
    return VersionUtils.VERSION;
  }
  public String author() {
    return VersionUtils.USER;
  }
  public String revision() {
     return VersionUtils.REVISION;
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The default value is version of build. You can override one of them or
all of them when writing connector. The version information of a
connector is showed by 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/workers/&#34;&gt;Worker APIs&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;div&gt;
    Don&amp;rsquo;t return &lt;strong&gt;null&lt;/strong&gt;, please!!!
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Version in Ohara connector is different to kafka connector. The later
only supports &lt;strong&gt;version&lt;/strong&gt; and it&amp;rsquo;s APIs show only &lt;strong&gt;version&lt;/strong&gt;. Hence,
you can&amp;rsquo;t get revision, author or other

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/setting_definition/&#34;&gt;settings&lt;/a&gt; through kafka APIs&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;metrics&#34;&gt;Metrics&lt;/h2&gt;
&lt;p&gt;We are live in a world filled with number, and so do connectors. While a
connector is running, Ohara collects many counts from the data flow for
the connector in background. All of counters (and other records which
will be introduced in the future) are called &lt;strong&gt;metrics&lt;/strong&gt;, and it can be
fetched by 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/connectors/&#34;&gt;Connector API&lt;/a&gt;.
Apart from official metrics, connector developers are also
able to build custom metrics for custom connectors, and all custom
metrics are also showed by 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/connectors/&#34;&gt;Connector API&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Ohara leverage JMX to offer the metrics APIs to connector. It means all
metrics you created are stored as Java beans and is accessible through
JMX service. That is why you have to define a port via

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/workers/&#34;&gt;Worker APIs&lt;/a&gt; for creating
a worker cluster. Although you can see all java mbeans via the JMX
client (such as JMC), Ohara still encourage you to apply

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/connectors/&#34;&gt;Connector API&lt;/a&gt; as it
offers a more readable format of metrics.&lt;/p&gt;
&lt;h3 id=&#34;counter&#34;&gt;Counter&lt;/h3&gt;
&lt;p&gt;Counter is a common use case for metrics that you can
increment/decrement/add/ a number atomically. A counter consists of
following members.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the group of this counter&lt;/li&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the name of this counter&lt;/li&gt;
&lt;li&gt;unit (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the unit of value&lt;/li&gt;
&lt;li&gt;document (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the document for this metrics&lt;/li&gt;
&lt;li&gt;startTime (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; the time to start this counter&lt;/li&gt;
&lt;li&gt;value (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; current value of count&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A example of creating a counter is shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class ExampleOfCreatingCounter {
  public static Counter sizeCounter(String group) {
    return Counter.builder()
        .group(group)
        .name(&amp;quot;row.size&amp;quot;)
        .unit(&amp;quot;bytes&amp;quot;)
        .document(&amp;quot;size (in bytes) of rows&amp;quot;)
        .startTime(CommonUtils.current())
        .value(0)
        .register();
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Though &lt;strong&gt;unit&lt;/strong&gt; and &lt;strong&gt;document&lt;/strong&gt; are declared optional, making them have
meaning description can help reader to understand the magic number from
your counter.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The counter created by connector always has the group same to id of
connector, since Ohara needs to find the counters for specific connector
in &lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/connectors/&#34;&gt;Connector API&lt;/a&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;official-metrics&#34;&gt;Official Metrics&lt;/h3&gt;
&lt;p&gt;There are two official metrics for connector - row counter and bytes
counter. The former is the number of processed rows, and the later is
the number of processed data. Both of them are updated when data are
pull/push from/to your connector. Normally, you don&amp;rsquo;t need to care for
them when designing connectors. However, you can read the source code in
ConnectorUtils.java to see how Ohara create official counters.&lt;/p&gt;
&lt;h3 id=&#34;create-your-own-counters&#34;&gt;Create Your Own Counters&lt;/h3&gt;
&lt;p&gt;In order to reduce your duplicate code, Ohara offers the
&lt;strong&gt;CounterBuilder&lt;/strong&gt; to all connectors. CounterBuilder is a wrap of
Counter.Builder with some pre-defined variables, and hence the creation
of CounterBuilder must be after initializing the connector/task.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class ExampleOfCreatingCustomBuilder {
  public static Counter custom(RowSinkTask task) {
    return task.counterBuilder()
      .unit(&amp;quot;bytes&amp;quot;)
      .document(&amp;quot;size (in bytes) of rows&amp;quot;)
      .startTime(CommonUtils.current())
      .value(0)
      .register();
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Ohara doesn&amp;rsquo;t obstruct you from using Counter directly. However, using
CounterBuilder make sure that your custom metrics are available in
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/connectors/&#34;&gt;Connector API&lt;/a&gt;.
  &lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 id=&#34;csv-sink&#34;&gt;Csv Sink Connector&lt;/h2&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/csv_sink_connector_arch.png&#34; &gt;


  &lt;img src=&#34;../img/csv_sink_connector_arch.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;Csv Sink connector inherits from 
&lt;a href=&#34;#sink-connector&#34;&gt;Row Sink Connector&lt;/a&gt;.
It also have 
&lt;a href=&#34;#source-start&#34;&gt;run(TaskSetting)&lt;/a&gt;,

&lt;a href=&#34;#source-terminate&#34;&gt;terminate()&lt;/a&gt;,

&lt;a href=&#34;#source-taskclass&#34;&gt;taskClass()&lt;/a&gt;,

&lt;a href=&#34;#source-tasksetting&#34;&gt;taskSetting(int maxTasks)&lt;/a&gt;,

&lt;a href=&#34;#sourcetask-partition-offsets&#34;&gt;partition and offsets&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The main difference between csv sink connector and row sink
connector is that csv sink connector already has some default
definitions.&lt;/p&gt;
&lt;p&gt;Below is a list of default definitions for CsvSinkConnector:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;TOPICS_DIR_DEFINITION: Read csv data from topic and then write to
this folder&lt;/li&gt;
&lt;li&gt;FLUSH_SIZE_DEFINITION: Number of records write to store before
invoking file commits&lt;/li&gt;
&lt;li&gt;ROTATE_INTERVAL_MS_DEFINITION: Commit file time&lt;/li&gt;
&lt;li&gt;FILE_NEED_HEADER_DEFINITION: File need header for flush data&lt;/li&gt;
&lt;li&gt;FILE_ENCODE_DEFINITION: File encode for write to file&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Connector developers can override &lt;strong&gt;customSettingDefinitions&lt;/strong&gt; to add
other additional definitions:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class CsvSinkConnector extends RowSinkConnector {
  /**
   * Define the configuration for the connector.
   *
   * @return The SettingDef for this connector.
   */
  protected List&amp;lt;SettingDef&amp;gt; customSettingDefinitions() {
    return List.of();
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;csv-sink-task&#34;&gt;Csv Sink Task&lt;/h2&gt;
&lt;p&gt;Ohara has a well-incubated task class. We call it &lt;strong&gt;CsvSinkTask&lt;/strong&gt;. As
long as your data format is CSV type, you can use id to develop a sink
connector to connect various file systems.&lt;/p&gt;
&lt;p&gt;We all know that to make a strong and robust connector, you have to take
care of a lot of details. In order to ensure that the connector works,
we must also prepare a lot of tests. Connector developers will spend a
lot of time on this.&lt;/p&gt;
&lt;p&gt;Therefore, we have encapsulated most of the logic in CsvSinkTask, which
hides a lot of complex behaviors. Just provide a 
&lt;a href=&#34;#storage&#34;&gt;Storage&lt;/a&gt;
implementation to complete a sink connector. You can save time to enjoy
other happy things.&lt;/p&gt;
&lt;p&gt;The following are the two methods you need to care about inherited
CsvSinkTask:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class CsvSinkTask extends RowSinkTask {
  /**
   * Returns the Storage implementation for this Task.
   *
   * @param setting initial settings
   * @return a Storage instance
   */
  public abstract Storage _storage(TaskSetting setting);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;_storagetasksetting-setting&#34;&gt;_storage(TaskSetting setting)&lt;/h3&gt;
&lt;p&gt;The goal of Task is to write the data to an external file system. For
example, if we want to store the output files on FTP server, connector
developers must provide an implementation of

&lt;a href=&#34;#storage&#34;&gt;Storage&lt;/a&gt; that can access FTP.&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The input parameter &lt;em&gt;TaskSetting&lt;/em&gt; carrying all settings.
see &lt;a href=&#34;#source-tasksetting&#34;&gt;TaskSetting&lt;/a&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;storage&#34;&gt;Storage&lt;/h2&gt;
&lt;p&gt;This interface defines some common methods for accessing the file
system, such as checking for the existence of a file, creating a new
file, or reading an exiting file, etc. Connector developers can follow
this interface to implement different file systems, such as FTP, HDFS,
SMB, Amazon S3, etc. So, just provide the implementation of Storage to
CsvSinkTask and you can implement a

&lt;a href=&#34;#sink-connector&#34;&gt;Sink Connector&lt;/a&gt; very quickly.&lt;/p&gt;
&lt;p&gt;Below we list the important methods in the Storage interface:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public interface Storage extends Releasable {
  /**
   * Returns whether an object exists.
   *
   * @param path the path to the object.
   * @return true if object exists, false otherwise.
   */
  boolean exists(String path);

  /**
   * Creates a new object in the given path.
   *
   * @param path the path of the object to be created.
   * @throws OharaFileAlreadyExistsException if a object of that path already exists.
   * @throws OharaException if the parent container does not exist.
   * @return an output stream associated with the new object.
   */
  OutputStream create(String path);

  /**
   * Open for reading an object at the given path.
   *
   * @param path the path of the object to be read.
   * @return an input stream with the requested object.
   */
  InputStream open(String path);

  /**
   * Move or rename a object from source path to target path.
   *
   * @param sourcePath the path to the object to move
   * @param targetPath the path to the target object
   * @return true if object have moved to target path , false otherwise.
   */
  boolean move(String sourcePath, String targetPath);

  /** Stop using this storage. */
  void close();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You can read the
&lt;a href=&#34;https://github.com/oharastream/ohara/blob/master/ohara-connector/src/main/scala/oharastream/ohara/connector/ftp/FtpStorage.scala&#34;&gt;FtpStorage&lt;/a&gt;
as an example to see how to implement your own Storage.
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Custom Stream Guideline</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/custom_stream/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/custom_stream/</guid>
      <description>&lt;p&gt;Ohara stream is an unparalleled wrap of 
&lt;a href=&#34;https://kafka.apache.org/documentation/streams&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;kafka streams&lt;/a&gt; which gives you
a straightforward thought to design your streaming flow. It offers a
simple way to implement and define actions to process data between
topics. You only have to write your logic in

&lt;a href=&#34;#start-method&#34;&gt;start()&lt;/a&gt; method and
compile your code to a jar file. After jar file is compiled
successfully, you can &lt;strong&gt;deploy&lt;/strong&gt; your jar file to Ohara, run it, and
monitor your stream by 
&lt;a href=&#34;#logs&#34;&gt;logs&lt;/a&gt; and 
&lt;a href=&#34;#metrics&#34;&gt;metrics&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The following sections will describe how to write a stream application
in Ohara.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;ohara-stream-overview&#34;&gt;Ohara Stream Overview&lt;/h2&gt;
&lt;p&gt;Ohara stream is a wrap of 
&lt;a href=&#34;https://kafka.apache.org/documentation/streams&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;kafka
streams&lt;/a&gt; and provided an
entry of interface class 
&lt;a href=&#34;#stream-entry&#34;&gt;Stream&lt;/a&gt; to define user custom streaming code.
A normal stream application will use 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/custom_connector/#datamodel&#34;&gt;Row&lt;/a&gt;
as data type to interactive topics in Ohara.&lt;/p&gt;
&lt;p&gt;Before writing your stream, you should download the ohara dependencies
first. Ohara includes many powerful tools for developer but not all
tools are requisite in designing stream. The required dependencies are
shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-groovy&#34;&gt;repositories {
     maven {
         url &amp;quot;https://dl.bintray.com/oharastream/ohara&amp;quot;
     }
 }
implementation &amp;quot;oharastream.ohara:ohara-stream:0.11.0-SNAPSHOT&amp;quot;
implementation &amp;quot;oharastream.ohara:ohara-common:0.11.0-SNAPSHOT&amp;quot;
implementation &amp;quot;oharastream.ohara:ohara-kafka:0.11.0-SNAPSHOT&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The &lt;a href=&#34;https://github.com/oharastream/ohara/releases&#34;&gt;releases&lt;/a&gt; page shows the available version of ohara
  &lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 id=&#34;stream-entry&#34;&gt;Stream Entry &lt;/h2&gt;
&lt;p&gt;We will automatically find your custom class which should be extended by
&lt;strong&gt;oharastream.ohara.stream.Stream&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In Ohara environment, the required parameters are defined in Ohara UI.
You only need to initial the &lt;code&gt;OStream&lt;/code&gt; as following:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;OStream&amp;lt;Row&amp;gt; ostream = OStream.builder().toOharaEnvStream();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A base implementation for a custom stream only need to include

&lt;a href=&#34;#start-method&#34;&gt;start()&lt;/a&gt; method,
but you could include other methods which are described below for your
convenience.&lt;/p&gt;
&lt;p&gt;The following example is a simple stream application which can run in
Ohara. Note that this example simply starts the stream application
without doing any transformation but writing data, i.e., the target
topic will have same data as the source topic.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class SimpleApplicationForOharaEnv extends Stream {

  @Override
  public void start(OStream&amp;lt;Row&amp;gt; ostream, StreamDefinitions streamSetting) {
    ostream.start();
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The following methods we provided belongs to Ohara Stream, which has
many powerful and friendly features. Native Kafka Streams API does not
have these methods.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;init-method&#34;&gt;init() method&lt;/h3&gt;
&lt;p&gt;After we find the user custom class, the first method will be called by
Stream is &lt;strong&gt;init()&lt;/strong&gt;. This is an optional method that can be used for
user to initialize some external data source connections or input
parameters.&lt;/p&gt;
&lt;h3 id=&#34;config-method&#34;&gt;config() method&lt;/h3&gt;
&lt;p&gt;In a stream application, you may want to configure your own parameters.
We support a method here to help you define a custom streamSetting list
in stream. The details of streamSetting are list

&lt;a href=&#34;#setting-definitions&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In the following example, we want to add a custom definition which is
used to define &amp;ldquo;join topic&amp;rdquo;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Override
public StreamDefinitions config() {
 return StreamDefinitions
   // add a definition of &amp;quot;filter name&amp;quot; in &amp;quot;default&amp;quot; group
   .with(SettingDef.builder().key(&amp;quot;filterName&amp;quot;).group(&amp;quot;default&amp;quot;).build());
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After define the definition, you can use it in 
&lt;a href=&#34;#start-method&#34;&gt;start()&lt;/a&gt; method&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    This method is optional. We will append all the definitions you provide
in this method to the stream default definitions. That is, the absent
config() method means you only need the default definitions.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;start-method&#34;&gt;start(OStream&lt;Row&gt;, StreamDefinitions) method&lt;/h3&gt;
&lt;p&gt;This method will be called after 
&lt;a href=&#34;#init-method&#34;&gt;init()&lt;/a&gt;.
Normally, you could only define start() method for most cases in Ohara. We
encourage user to use &lt;strong&gt;source connector&lt;/strong&gt;
(see 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/custom_connector/#source-connector&#34;&gt;Source Connector&lt;/a&gt; section)
for importing external data source to Ohara and use topic data as custom
stream data source in start() method.&lt;/p&gt;
&lt;p&gt;We provide two arguments in this method:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;OStream &amp;mdash; the entry class of ohara stream&lt;br&gt;
OStream (a.k.a. ohara stream) helps you to construct your
application and use all the powerful APIs in Stream.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;StreamDefinitions &amp;mdash; the definitions of ohara stream&lt;br&gt;
from the definition you can use &lt;em&gt;StreamDefinitions.string()&lt;/em&gt; to get the value from the

&lt;a href=&#34;#config-method&#34;&gt;config method&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The return value is wrap in a Java object &lt;strong&gt;Optional&lt;/strong&gt;, you need to
decide whether the value is present or not.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;For example:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Override
public void start(OStream&amp;lt;Row&amp;gt; ostream, StreamDefinitions streamSetting) {
 ostream
   .map(row -&amp;gt; Row.of(row.cell(&amp;quot;name&amp;quot;), row.cell(&amp;quot;age&amp;quot;)))
   // use the previous defined definition in config()
   .filter(row -&amp;gt; row.cell(streamSetting.string(&amp;quot;filterName&amp;quot;).get()).value() != null)
   .map(row -&amp;gt; Row.of(Cell.of(&amp;quot;name&amp;quot;, row.cell(&amp;quot;name&amp;quot;).value().toString().toUpperCase())))
   .start();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above code does the following transformations:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;pick cell of the header: &lt;code&gt;name&lt;/code&gt;, &lt;code&gt;age&lt;/code&gt; from each row&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;filter out that if &lt;code&gt;filterName&lt;/code&gt; is null &amp;mdash;
here we get the value from &lt;strong&gt;filterName&lt;/strong&gt; of definitions. the value you should update by

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/streams/#update&#34;&gt;Stream update api&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;PUT /v0/streams/XXX&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
 &amp;quot;filterName&amp;quot;: &amp;quot;name&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;convert the cell of &lt;code&gt;name&lt;/code&gt; to upperCase&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;From now on, you can use the 
&lt;a href=&#34;#java-api&#34;&gt;Stream Java API&lt;/a&gt; to
design your own application, happy coding!&lt;/p&gt;
&lt;h2 id=&#34;java-api&#34;&gt;Stream Java API &lt;/h2&gt;
&lt;p&gt;In Stream, we provide three different classes for developers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OStream: define the functions for operating streaming data (each row record one-by-one)&lt;/li&gt;
&lt;li&gt;OGroupedStream: define the functions for operating grouped streaming data&lt;/li&gt;
&lt;li&gt;OTable: define the functions for operating table data (changelog for same key of row record)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The above classes will be auto converted when you use the correspond
functions; You should not worry about the usage of which class is
right to use. All the starting point of development is just &lt;strong&gt;OStream&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Below we list the available functions in each class (See more information in javadoc):&lt;/p&gt;
&lt;h3 id=&#34;ostream&#34;&gt;OStream&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;constructTable(String topicName)&lt;/p&gt;
&lt;p&gt;Create a OTable with specified topicName from current OStream.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;filter(Predicate predicate)&lt;/p&gt;
&lt;p&gt;Create a new OStream that filter by the given predicate.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;through(String topicName, int partitions)&lt;/p&gt;
&lt;p&gt;Transfer this OStream to specify topic and use the required
partition number.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;leftJoin(String joinTopicName, Conditions conditions, ValueJoiner joiner)&lt;/p&gt;
&lt;p&gt;Join this OStream with required joinTopicName and conditions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;map(ValueMapper mapper)&lt;/p&gt;
&lt;p&gt;Transform the value of each record to a new value of the output record.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;groupByKey(List keys)&lt;/p&gt;
&lt;p&gt;Group the records by key to a OGroupedStream.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;foreach(ForeachAction action)&lt;/p&gt;
&lt;p&gt;Perform an action on each record of OStream.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;start()&lt;/p&gt;
&lt;p&gt;Run this stream application.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;stop()&lt;/p&gt;
&lt;p&gt;Stop this stream application.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;describe()&lt;/p&gt;
&lt;p&gt;Describe the topology of this stream.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;getPoneglyph()&lt;/p&gt;
&lt;p&gt;Get the Ohara format Poneglyph from topology.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ogroupedstream&#34;&gt;OGroupedStream&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;count()&lt;/p&gt;
&lt;p&gt;Count the number of records in this OGroupedStream and return the
count value.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;reduce(final Reducer reducer)&lt;/p&gt;
&lt;p&gt;Combine the values of each record in this OGroupedStream by the
grouped key.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;otable&#34;&gt;OTable&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;toOStream()&lt;/p&gt;
&lt;p&gt;Convert this OTable to OStream&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;stream-examples&#34;&gt;Stream Examples&lt;/h2&gt;
&lt;p&gt;Below we provide some examples that demonstrate how to develop your own
stream applications. More description of each example could be found in
javadoc.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/oharastream/ohara/blob/0.11.x/ohara-stream/src/test/java/oharastream/ohara/stream/examples/WordCountExample.java&#34;&gt;WordCount&lt;/a&gt;:
count the words in &amp;ldquo;word&amp;rdquo; column&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/oharastream/ohara/blob/0.11.x/ohara-stream/src/test/java/oharastream/ohara/stream/examples/PageViewRegionExample.java&#34;&gt;PageViewRegion&lt;/a&gt;:
count the views by each region&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/oharastream/ohara/blob/0.11.x/ohara-stream/src/test/java/oharastream/ohara/stream/examples/SumExample.java&#34;&gt;Sum&lt;/a&gt;:
sum odd numbers in &amp;ldquo;number&amp;rdquo; column&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;setting-definitions&#34;&gt;Stream Definitions&lt;/h2&gt;
&lt;p&gt;Stream stores a list of

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/setting_definition/&#34;&gt;SettingDef&lt;/a&gt;, which
is StreamDefinitions, in the data store. By default, we will keep the
following definitions in the &amp;ldquo;core&amp;rdquo; group and generate the definition
in stream API :&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;DefaultConfigs.BROKER_DEFINITION : The broker list&lt;/li&gt;
&lt;li&gt;DefaultConfigs.IMAGE_NAME_DEFINITION : The image name&lt;/li&gt;
&lt;li&gt;DefaultConfigs.NAME_DEFINITION : The stream application name&lt;/li&gt;
&lt;li&gt;DefaultConfigs.GROUP_DEFINITION : The stream group name&lt;/li&gt;
&lt;li&gt;DefaultConfigs.FROM_TOPICS_DEFINITION : The from topic&lt;/li&gt;
&lt;li&gt;DefaultConfigs.TO_TOPICS_DEFINITION : The to topic&lt;/li&gt;
&lt;li&gt;DefaultConfigs.JMX_PORT_DEFINITION : The exposed jmx port&lt;/li&gt;
&lt;li&gt;DefaultConfigs.NODE_NAMES_DEFINITION : The node name list&lt;/li&gt;
&lt;li&gt;DefaultConfigs.VERSION_DEFINITION : The version of stream&lt;/li&gt;
&lt;li&gt;DefaultConfigs.REVISION_DEFINITION : The revision of stream&lt;/li&gt;
&lt;li&gt;DefaultConfigs.AUTHOR_DEFINITION : The author of stream&lt;/li&gt;
&lt;li&gt;DefaultConfigs.TAGS_DEFINITION : The tags of stream&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Any other definition except above list will be treated as a custom
definition. You can define:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder().key(joinTopic).group(&amp;quot;default&amp;quot;).build()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;as a definition that is listed in &amp;ldquo;default&amp;rdquo; group, or&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder().key(otherKey).group(&amp;quot;common&amp;quot;).build()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;as a definition that is listed in the &amp;ldquo;common&amp;rdquo; group.&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Any group category will generate a new &amp;ldquo;tab&amp;rdquo; in Ohara-Manager.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The value of each definition will be kept in environment of stream
running container, and you should set the value by

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/streams/#update&#34;&gt;stream api&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;metrics&#34;&gt;Metrics&lt;/h2&gt;
&lt;p&gt;When a stream application is running, Ohara automatically collects some
metrics data from the stream in the background. The metrics data here
means 
&lt;a href=&#34;#official-metrics&#34;&gt;official metrics&lt;/a&gt; which contains

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/custom_connector/#counter&#34;&gt;Counters&lt;/a&gt; for now
(other type of metrics will be introduced in the future). The metrics
data could be fetched by 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/streams/&#34;&gt;Stream APIs&lt;/a&gt;.
Developers will be able to implement their own custom
metrics in the foreseeable future.&lt;/p&gt;
&lt;p&gt;Ohara leverages JMX to offer the metrics data to stream. It means that
all metrics you have created are stored as Java beans and accessible
through JMX service. The stream will expose a port via

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/streams/&#34;&gt;Stream APIs&lt;/a&gt; for other JMX
client tool used, such as JMC, but we still encourage you to use

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/streams/&#34;&gt;Stream APIs&lt;/a&gt; as it offers a
more readable format of metrics.&lt;/p&gt;
&lt;h3 id=&#34;official-metrics&#34;&gt;Official Metrics&lt;/h3&gt;
&lt;p&gt;There are two type of official metrics for stream:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;consumed topic records (counter)&lt;/li&gt;
&lt;li&gt;produced topic records (counter)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A normal stream will connect to two topics, one is the source topic that
stream will consume from, and the other is the target topic that stream
will produce to. We use prefix words (&lt;strong&gt;TOPIC_IN&lt;/strong&gt;, &lt;strong&gt;TOPIC_OUT&lt;/strong&gt;) in
the response data (
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/streams/&#34;&gt;Stream APIs&lt;/a&gt;)
in order to improve readabilities of those types. You don&amp;rsquo;t
need to worry about the implementation of these official metrics, but
you can still read the

&lt;a href=&#34;https://github.com/oharastream/ohara/blob/0.11.x/ohara-stream/src/main/java/oharastream/ohara/stream/metric/MetricFactory.java&#34;&gt;source code&lt;/a&gt;
to see how Ohara creates official metrics.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;logs&#34;&gt;Logs&lt;/h2&gt;
&lt;p&gt;Will be implemented in the near future. Also see issue: 
&lt;a href=&#34;https://github.com/oharastream/ohara/issues/962

&#34;&gt;#962&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Custom Stream Guideline</title>
      <link>https://oharastream.github.io/en/docs/master/custom_stream/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/master/custom_stream/</guid>
      <description>&lt;p&gt;Ohara stream is an unparalleled wrap of 
&lt;a href=&#34;https://kafka.apache.org/documentation/streams&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;kafka streams&lt;/a&gt; which gives you
a straightforward thought to design your streaming flow. It offers a
simple way to implement and define actions to process data between
topics. You only have to write your logic in

&lt;a href=&#34;#start-method&#34;&gt;start()&lt;/a&gt; method and
compile your code to a jar file. After jar file is compiled
successfully, you can &lt;strong&gt;deploy&lt;/strong&gt; your jar file to Ohara, run it, and
monitor your stream by 
&lt;a href=&#34;#logs&#34;&gt;logs&lt;/a&gt; and 
&lt;a href=&#34;#metrics&#34;&gt;metrics&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The following sections will describe how to write a stream application
in Ohara.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;ohara-stream-overview&#34;&gt;Ohara Stream Overview&lt;/h2&gt;
&lt;p&gt;Ohara stream is a wrap of 
&lt;a href=&#34;https://kafka.apache.org/documentation/streams&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;kafka
streams&lt;/a&gt; and provided an
entry of interface class 
&lt;a href=&#34;#stream-entry&#34;&gt;Stream&lt;/a&gt; to define user custom streaming code.
A normal stream application will use 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/custom_connector/#datamodel&#34;&gt;Row&lt;/a&gt;
as data type to interactive topics in Ohara.&lt;/p&gt;
&lt;p&gt;Before writing your stream, you should download the ohara dependencies
first. Ohara includes many powerful tools for developer but not all
tools are requisite in designing stream. The required dependencies are
shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-groovy&#34;&gt;repositories {
     maven {
         url &amp;quot;https://dl.bintray.com/oharastream/ohara&amp;quot;
     }
 }
implementation &amp;quot;oharastream.ohara:ohara-stream:0.11.0-SNAPSHOT&amp;quot;
implementation &amp;quot;oharastream.ohara:ohara-common:0.11.0-SNAPSHOT&amp;quot;
implementation &amp;quot;oharastream.ohara:ohara-kafka:0.11.0-SNAPSHOT&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The &lt;a href=&#34;https://github.com/oharastream/ohara/releases&#34;&gt;releases&lt;/a&gt; page shows the available version of ohara
  &lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 id=&#34;stream-entry&#34;&gt;Stream Entry &lt;/h2&gt;
&lt;p&gt;We will automatically find your custom class which should be extended by
&lt;strong&gt;oharastream.ohara.stream.Stream&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In Ohara environment, the required parameters are defined in Ohara UI.
You only need to initial the &lt;code&gt;OStream&lt;/code&gt; as following:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;OStream&amp;lt;Row&amp;gt; ostream = OStream.builder().toOharaEnvStream();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A base implementation for a custom stream only need to include

&lt;a href=&#34;#start-method&#34;&gt;start()&lt;/a&gt; method,
but you could include other methods which are described below for your
convenience.&lt;/p&gt;
&lt;p&gt;The following example is a simple stream application which can run in
Ohara. Note that this example simply starts the stream application
without doing any transformation but writing data, i.e., the target
topic will have same data as the source topic.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class SimpleApplicationForOharaEnv extends Stream {

  @Override
  public void start(OStream&amp;lt;Row&amp;gt; ostream, StreamDefinitions streamSetting) {
    ostream.start();
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The following methods we provided belongs to Ohara Stream, which has
many powerful and friendly features. Native Kafka Streams API does not
have these methods.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;init-method&#34;&gt;init() method&lt;/h3&gt;
&lt;p&gt;After we find the user custom class, the first method will be called by
Stream is &lt;strong&gt;init()&lt;/strong&gt;. This is an optional method that can be used for
user to initialize some external data source connections or input
parameters.&lt;/p&gt;
&lt;h3 id=&#34;config-method&#34;&gt;config() method&lt;/h3&gt;
&lt;p&gt;In a stream application, you may want to configure your own parameters.
We support a method here to help you define a custom streamSetting list
in stream. The details of streamSetting are list

&lt;a href=&#34;#setting-definitions&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In the following example, we want to add a custom definition which is
used to define &amp;ldquo;join topic&amp;rdquo;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Override
public StreamDefinitions config() {
 return StreamDefinitions
   // add a definition of &amp;quot;filter name&amp;quot; in &amp;quot;default&amp;quot; group
   .with(SettingDef.builder().key(&amp;quot;filterName&amp;quot;).group(&amp;quot;default&amp;quot;).build());
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After define the definition, you can use it in 
&lt;a href=&#34;#start-method&#34;&gt;start()&lt;/a&gt; method&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    This method is optional. We will append all the definitions you provide
in this method to the stream default definitions. That is, the absent
config() method means you only need the default definitions.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;start-method&#34;&gt;start(OStream&lt;Row&gt;, StreamDefinitions) method&lt;/h3&gt;
&lt;p&gt;This method will be called after 
&lt;a href=&#34;#init-method&#34;&gt;init()&lt;/a&gt;.
Normally, you could only define start() method for most cases in Ohara. We
encourage user to use &lt;strong&gt;source connector&lt;/strong&gt;
(see 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/custom_connector/#source-connector&#34;&gt;Source Connector&lt;/a&gt; section)
for importing external data source to Ohara and use topic data as custom
stream data source in start() method.&lt;/p&gt;
&lt;p&gt;We provide two arguments in this method:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;OStream &amp;mdash; the entry class of ohara stream&lt;br&gt;
OStream (a.k.a. ohara stream) helps you to construct your
application and use all the powerful APIs in Stream.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;StreamDefinitions &amp;mdash; the definitions of ohara stream&lt;br&gt;
from the definition you can use &lt;em&gt;StreamDefinitions.string()&lt;/em&gt; to get the value from the

&lt;a href=&#34;#config-method&#34;&gt;config method&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The return value is wrap in a Java object &lt;strong&gt;Optional&lt;/strong&gt;, you need to
decide whether the value is present or not.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;For example:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Override
public void start(OStream&amp;lt;Row&amp;gt; ostream, StreamDefinitions streamSetting) {
 ostream
   .map(row -&amp;gt; Row.of(row.cell(&amp;quot;name&amp;quot;), row.cell(&amp;quot;age&amp;quot;)))
   // use the previous defined definition in config()
   .filter(row -&amp;gt; row.cell(streamSetting.string(&amp;quot;filterName&amp;quot;).get()).value() != null)
   .map(row -&amp;gt; Row.of(Cell.of(&amp;quot;name&amp;quot;, row.cell(&amp;quot;name&amp;quot;).value().toString().toUpperCase())))
   .start();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above code does the following transformations:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;pick cell of the header: &lt;code&gt;name&lt;/code&gt;, &lt;code&gt;age&lt;/code&gt; from each row&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;filter out that if &lt;code&gt;filterName&lt;/code&gt; is null &amp;mdash;
here we get the value from &lt;strong&gt;filterName&lt;/strong&gt; of definitions. the value you should update by

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/streams/#update&#34;&gt;Stream update api&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;PUT /v0/streams/XXX&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
 &amp;quot;filterName&amp;quot;: &amp;quot;name&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;convert the cell of &lt;code&gt;name&lt;/code&gt; to upperCase&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;From now on, you can use the 
&lt;a href=&#34;#java-api&#34;&gt;Stream Java API&lt;/a&gt; to
design your own application, happy coding!&lt;/p&gt;
&lt;h2 id=&#34;java-api&#34;&gt;Stream Java API &lt;/h2&gt;
&lt;p&gt;In Stream, we provide three different classes for developers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OStream: define the functions for operating streaming data (each row record one-by-one)&lt;/li&gt;
&lt;li&gt;OGroupedStream: define the functions for operating grouped streaming data&lt;/li&gt;
&lt;li&gt;OTable: define the functions for operating table data (changelog for same key of row record)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The above classes will be auto converted when you use the correspond
functions; You should not worry about the usage of which class is
right to use. All the starting point of development is just &lt;strong&gt;OStream&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Below we list the available functions in each class (See more information in javadoc):&lt;/p&gt;
&lt;h3 id=&#34;ostream&#34;&gt;OStream&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;constructTable(String topicName)&lt;/p&gt;
&lt;p&gt;Create a OTable with specified topicName from current OStream.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;filter(Predicate predicate)&lt;/p&gt;
&lt;p&gt;Create a new OStream that filter by the given predicate.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;through(String topicName, int partitions)&lt;/p&gt;
&lt;p&gt;Transfer this OStream to specify topic and use the required
partition number.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;leftJoin(String joinTopicName, Conditions conditions, ValueJoiner joiner)&lt;/p&gt;
&lt;p&gt;Join this OStream with required joinTopicName and conditions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;map(ValueMapper mapper)&lt;/p&gt;
&lt;p&gt;Transform the value of each record to a new value of the output record.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;groupByKey(List keys)&lt;/p&gt;
&lt;p&gt;Group the records by key to a OGroupedStream.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;foreach(ForeachAction action)&lt;/p&gt;
&lt;p&gt;Perform an action on each record of OStream.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;start()&lt;/p&gt;
&lt;p&gt;Run this stream application.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;stop()&lt;/p&gt;
&lt;p&gt;Stop this stream application.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;describe()&lt;/p&gt;
&lt;p&gt;Describe the topology of this stream.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;getPoneglyph()&lt;/p&gt;
&lt;p&gt;Get the Ohara format Poneglyph from topology.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ogroupedstream&#34;&gt;OGroupedStream&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;count()&lt;/p&gt;
&lt;p&gt;Count the number of records in this OGroupedStream and return the
count value.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;reduce(final Reducer reducer)&lt;/p&gt;
&lt;p&gt;Combine the values of each record in this OGroupedStream by the
grouped key.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;otable&#34;&gt;OTable&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;toOStream()&lt;/p&gt;
&lt;p&gt;Convert this OTable to OStream&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;stream-examples&#34;&gt;Stream Examples&lt;/h2&gt;
&lt;p&gt;Below we provide some examples that demonstrate how to develop your own
stream applications. More description of each example could be found in
javadoc.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/oharastream/ohara/blob/master/ohara-stream/src/test/java/oharastream/ohara/stream/examples/WordCountExample.java&#34;&gt;WordCount&lt;/a&gt;:
count the words in &amp;ldquo;word&amp;rdquo; column&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/oharastream/ohara/blob/master/ohara-stream/src/test/java/oharastream/ohara/stream/examples/PageViewRegionExample.java&#34;&gt;PageViewRegion&lt;/a&gt;:
count the views by each region&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/oharastream/ohara/blob/master/ohara-stream/src/test/java/oharastream/ohara/stream/examples/SumExample.java&#34;&gt;Sum&lt;/a&gt;:
sum odd numbers in &amp;ldquo;number&amp;rdquo; column&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;setting-definitions&#34;&gt;Stream Definitions&lt;/h2&gt;
&lt;p&gt;Stream stores a list of

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/setting_definition/&#34;&gt;SettingDef&lt;/a&gt;, which
is StreamDefinitions, in the data store. By default, we will keep the
following definitions in the &amp;ldquo;core&amp;rdquo; group and generate the definition
in stream API :&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;DefaultConfigs.BROKER_DEFINITION : The broker list&lt;/li&gt;
&lt;li&gt;DefaultConfigs.IMAGE_NAME_DEFINITION : The image name&lt;/li&gt;
&lt;li&gt;DefaultConfigs.NAME_DEFINITION : The stream application name&lt;/li&gt;
&lt;li&gt;DefaultConfigs.GROUP_DEFINITION : The stream group name&lt;/li&gt;
&lt;li&gt;DefaultConfigs.FROM_TOPICS_DEFINITION : The from topic&lt;/li&gt;
&lt;li&gt;DefaultConfigs.TO_TOPICS_DEFINITION : The to topic&lt;/li&gt;
&lt;li&gt;DefaultConfigs.JMX_PORT_DEFINITION : The exposed jmx port&lt;/li&gt;
&lt;li&gt;DefaultConfigs.NODE_NAMES_DEFINITION : The node name list&lt;/li&gt;
&lt;li&gt;DefaultConfigs.VERSION_DEFINITION : The version of stream&lt;/li&gt;
&lt;li&gt;DefaultConfigs.REVISION_DEFINITION : The revision of stream&lt;/li&gt;
&lt;li&gt;DefaultConfigs.AUTHOR_DEFINITION : The author of stream&lt;/li&gt;
&lt;li&gt;DefaultConfigs.TAGS_DEFINITION : The tags of stream&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Any other definition except above list will be treated as a custom
definition. You can define:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder().key(joinTopic).group(&amp;quot;default&amp;quot;).build()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;as a definition that is listed in &amp;ldquo;default&amp;rdquo; group, or&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder().key(otherKey).group(&amp;quot;common&amp;quot;).build()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;as a definition that is listed in the &amp;ldquo;common&amp;rdquo; group.&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Any group category will generate a new &amp;ldquo;tab&amp;rdquo; in Ohara-Manager.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The value of each definition will be kept in environment of stream
running container, and you should set the value by

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/streams/#update&#34;&gt;stream api&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;metrics&#34;&gt;Metrics&lt;/h2&gt;
&lt;p&gt;When a stream application is running, Ohara automatically collects some
metrics data from the stream in the background. The metrics data here
means 
&lt;a href=&#34;#official-metrics&#34;&gt;official metrics&lt;/a&gt; which contains

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/custom_connector/#counter&#34;&gt;Counters&lt;/a&gt; for now
(other type of metrics will be introduced in the future). The metrics
data could be fetched by 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/streams/&#34;&gt;Stream APIs&lt;/a&gt;.
Developers will be able to implement their own custom
metrics in the foreseeable future.&lt;/p&gt;
&lt;p&gt;Ohara leverages JMX to offer the metrics data to stream. It means that
all metrics you have created are stored as Java beans and accessible
through JMX service. The stream will expose a port via

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/streams/&#34;&gt;Stream APIs&lt;/a&gt; for other JMX
client tool used, such as JMC, but we still encourage you to use

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/streams/&#34;&gt;Stream APIs&lt;/a&gt; as it offers a
more readable format of metrics.&lt;/p&gt;
&lt;h3 id=&#34;official-metrics&#34;&gt;Official Metrics&lt;/h3&gt;
&lt;p&gt;There are two type of official metrics for stream:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;consumed topic records (counter)&lt;/li&gt;
&lt;li&gt;produced topic records (counter)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A normal stream will connect to two topics, one is the source topic that
stream will consume from, and the other is the target topic that stream
will produce to. We use prefix words (&lt;strong&gt;TOPIC_IN&lt;/strong&gt;, &lt;strong&gt;TOPIC_OUT&lt;/strong&gt;) in
the response data (
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/streams/&#34;&gt;Stream APIs&lt;/a&gt;)
in order to improve readabilities of those types. You don&amp;rsquo;t
need to worry about the implementation of these official metrics, but
you can still read the

&lt;a href=&#34;https://github.com/oharastream/ohara/blob/master/ohara-stream/src/main/java/oharastream/ohara/stream/metric/MetricFactory.java&#34;&gt;source code&lt;/a&gt;
to see how Ohara creates official metrics.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;logs&#34;&gt;Logs&lt;/h2&gt;
&lt;p&gt;Will be implemented in the near future. Also see issue: 
&lt;a href=&#34;https://github.com/oharastream/ohara/issues/962

&#34;&gt;#962&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Files</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/rest-api/files/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/rest-api/files/</guid>
      <description>&lt;p&gt;Ohara encourages user to write custom application if the official
applications can satisfy requirements for your use case. Jar APIs is a
useful entry of putting your jar on Ohara and then start related
services with it. For example,

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/workers/#rest-workers-create&#34;&gt;Worker APIs&lt;/a&gt; accept
a &lt;strong&gt;sharedJarKeys&lt;/strong&gt; element which can carry the jar name pointing to an
existent jar in Ohara. The worker cluster will load all connectors of
the input jar, and then you are able to use the connectors on the worker
cluster.&lt;/p&gt;
&lt;p&gt;The File API upload jar file to use by the

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/workers/&#34;&gt;Worker&lt;/a&gt; and 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/streams/&#34;&gt;Stream&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The file used by a worker or stream can&amp;rsquo;t be either updated or deleted.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The properties stored by Ohara are shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the file name without extension. The legal
character is number, lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the group name (we use this field to separate
different workspaces). The legal character is number, lowercase
alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;size (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; file size&lt;/li&gt;
&lt;li&gt;url (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; url to download this jar from Ohara
Configurator. Noted not all jars are downloadable to user.&lt;/li&gt;
&lt;li&gt;lastModified (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; the time of uploading this file&lt;/li&gt;
&lt;li&gt;tags (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the user defined parameters&lt;/li&gt;
&lt;li&gt;bytes (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; read file content to bytes&lt;/li&gt;
&lt;li&gt;classInfos (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the information of available
classes in this file
&lt;ul&gt;
&lt;li&gt;classInfos[i].className &amp;mdash; the name of this class&lt;/li&gt;
&lt;li&gt;classInfos[i].classType &amp;mdash; the type of this class. for example,
topic, source connector, sink connector or stream app&lt;/li&gt;
&lt;li&gt;classInfos[i].settingDefinitions &amp;mdash; the definitions of this
class&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The field &amp;ldquo;classInfos&amp;rdquo; is empty if the file is NOT a valid jar.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;upload-a-file-to-ohara&#34;&gt;upload a file to Ohara&lt;/h2&gt;
&lt;p&gt;Upload a file to Ohara with field name : &amp;ldquo;jar&amp;rdquo; and group name : &amp;ldquo;group&amp;rdquo;
the text field &amp;ldquo;group&amp;rdquo; could be empty and we will generate a random
string.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;POST /v0/files&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Request
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;Content-Type: multipart/form-data
file=&amp;quot;ohara-it-stream.jar&amp;quot;
group=&amp;quot;default&amp;quot;
tags={}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You have to specify the file name since it is a part of metadata
stored by Ohara. Noted, the later uploaded file can overwrite the
older one
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;ohara-it-stream.jar&amp;quot;,
  &amp;quot;size&amp;quot;: 1896,
  &amp;quot;url&amp;quot;: &amp;quot;http://localhost:12345/v0/downloadFiles/default/ohara-it-stream.jar&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1578967196525,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;classInfos&amp;quot;: [
    {
      &amp;quot;classType&amp;quot;: &amp;quot;stream&amp;quot;,
      &amp;quot;className&amp;quot;: &amp;quot;oharastream.ohara.it.stream.DumbStream&amp;quot;,
      &amp;quot;settingDefinitions&amp;quot;: [
        {
          &amp;quot;blacklist&amp;quot;: [],
          &amp;quot;reference&amp;quot;: &amp;quot;BROKER_CLUSTER&amp;quot;,
          &amp;quot;displayName&amp;quot;: &amp;quot;Broker cluster key&amp;quot;,
          &amp;quot;regex&amp;quot;: null,
          &amp;quot;internal&amp;quot;: false,
          &amp;quot;permission&amp;quot;: &amp;quot;EDITABLE&amp;quot;,
          &amp;quot;documentation&amp;quot;: &amp;quot;the key of broker cluster used to transfer data for this stream&amp;quot;,
          &amp;quot;necessary&amp;quot;: &amp;quot;REQUIRED&amp;quot;,
          &amp;quot;valueType&amp;quot;: &amp;quot;OBJECT_KEY&amp;quot;,
          &amp;quot;tableKeys&amp;quot;: [],
          &amp;quot;orderInGroup&amp;quot;: 0,
          &amp;quot;key&amp;quot;: &amp;quot;brokerClusterKey&amp;quot;,
          &amp;quot;defaultValue&amp;quot;: null,
          &amp;quot;recommendedValues&amp;quot;: [],
          &amp;quot;group&amp;quot;: &amp;quot;core&amp;quot;
        }
      ]
    }
  ],
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;list-all-jars&#34;&gt;list all jars&lt;/h2&gt;
&lt;p&gt;Get all jars from specific group of query parameter. If no query
parameter, wll return all jars.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;GET /v0/files?group=default&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
  {
    &amp;quot;name&amp;quot;: &amp;quot;ohara-it-stream.jar&amp;quot;,
    &amp;quot;size&amp;quot;: 1896,
    &amp;quot;url&amp;quot;: &amp;quot;http://localhost:5000/v0/downloadFiles/default/ohara-it-stream.jar&amp;quot;,
    &amp;quot;lastModified&amp;quot;: 1578973197877,
    &amp;quot;tags&amp;quot;: {},
    &amp;quot;classInfos&amp;quot;: [
      {
        &amp;quot;classType&amp;quot;: &amp;quot;stream&amp;quot;,
        &amp;quot;className&amp;quot;: &amp;quot;oharastream.ohara.it.stream.DumbStream&amp;quot;,
        &amp;quot;settingDefinitions&amp;quot;: [
          {
            &amp;quot;blacklist&amp;quot;: [],
            &amp;quot;reference&amp;quot;: &amp;quot;BROKER_CLUSTER&amp;quot;,
            &amp;quot;displayName&amp;quot;: &amp;quot;Broker cluster key&amp;quot;,
            &amp;quot;regex&amp;quot;: null,
            &amp;quot;internal&amp;quot;: false,
            &amp;quot;permission&amp;quot;: &amp;quot;EDITABLE&amp;quot;,
            &amp;quot;documentation&amp;quot;: &amp;quot;the key of broker cluster used to transfer data for this stream&amp;quot;,
            &amp;quot;necessary&amp;quot;: &amp;quot;REQUIRED&amp;quot;,
            &amp;quot;valueType&amp;quot;: &amp;quot;OBJECT_KEY&amp;quot;,
            &amp;quot;tableKeys&amp;quot;: [],
            &amp;quot;orderInGroup&amp;quot;: 0,
            &amp;quot;key&amp;quot;: &amp;quot;brokerClusterKey&amp;quot;,
            &amp;quot;defaultValue&amp;quot;: null,
            &amp;quot;recommendedValues&amp;quot;: [],
            &amp;quot;group&amp;quot;: &amp;quot;core&amp;quot;
          },
        ]
      }
    ],
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;delete-a-file&#34;&gt;delete a file&lt;/h2&gt;
&lt;p&gt;Delete a file with specific name and group. Note: the query parameter
must exist.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;DELETE /v0/files/$name?group=default&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;204 NoContent
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    It is ok to delete a nonexistent jar, and the response is 204
NoContent. If you delete a file is used by other services, you also
break the scalability of service as you can&amp;rsquo;t run the jar on any new
nodes
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;get-a-file&#34;&gt;get a file&lt;/h2&gt;
&lt;p&gt;Get a file with specific name and group. Note: the query parameter must
exists.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;GET /v0/files/$name?group=default&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;ohara-it-stream.jar&amp;quot;,
  &amp;quot;size&amp;quot;: 1896,
  &amp;quot;url&amp;quot;: &amp;quot;http://localhost:5000/v0/downloadFiles/default/ohara-it-stream.jar&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1578973197877,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;classInfos&amp;quot;: [
    {
      &amp;quot;classType&amp;quot;: &amp;quot;stream&amp;quot;,
      &amp;quot;className&amp;quot;: &amp;quot;oharastream.ohara.it.stream.DumbStream&amp;quot;,
      &amp;quot;settingDefinitions&amp;quot;: [
        {
          &amp;quot;blacklist&amp;quot;: [],
          &amp;quot;reference&amp;quot;: &amp;quot;BROKER_CLUSTER&amp;quot;,
          &amp;quot;displayName&amp;quot;: &amp;quot;Broker cluster key&amp;quot;,
          &amp;quot;regex&amp;quot;: null,
          &amp;quot;internal&amp;quot;: false,
          &amp;quot;permission&amp;quot;: &amp;quot;EDITABLE&amp;quot;,
          &amp;quot;documentation&amp;quot;: &amp;quot;the key of broker cluster used to transfer data for this stream&amp;quot;,
          &amp;quot;necessary&amp;quot;: &amp;quot;REQUIRED&amp;quot;,
          &amp;quot;valueType&amp;quot;: &amp;quot;OBJECT_KEY&amp;quot;,
          &amp;quot;tableKeys&amp;quot;: [],
          &amp;quot;orderInGroup&amp;quot;: 0,
          &amp;quot;key&amp;quot;: &amp;quot;brokerClusterKey&amp;quot;,
          &amp;quot;defaultValue&amp;quot;: null,
          &amp;quot;recommendedValues&amp;quot;: [],
          &amp;quot;group&amp;quot;: &amp;quot;core&amp;quot;
        }
      ]
    }
  ],
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;update-tags-of-file&#34;&gt;update tags of file&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/files/$name?group=default&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;tags&amp;quot;: {
    &amp;quot;a&amp;quot;: &amp;quot;b&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    it returns error code if input group/name are not associated to an
existent file.
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;ohara-it-stream.jar&amp;quot;,
  &amp;quot;size&amp;quot;: 1896,
  &amp;quot;url&amp;quot;: &amp;quot;http://localhost:5000/v0/downloadFiles/default/ohara-it-stream.jar&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1578974415307,
  &amp;quot;tags&amp;quot;: {
    &amp;quot;a&amp;quot;: &amp;quot;b&amp;quot;
  },
  &amp;quot;classInfos&amp;quot;: [
    {
      &amp;quot;classType&amp;quot;: &amp;quot;stream&amp;quot;,
      &amp;quot;className&amp;quot;: &amp;quot;oharastream.ohara.it.stream.DumbStream&amp;quot;,
      &amp;quot;settingDefinitions&amp;quot;: [
        {
          &amp;quot;blacklist&amp;quot;: [],
          &amp;quot;reference&amp;quot;: &amp;quot;BROKER_CLUSTER&amp;quot;,
          &amp;quot;displayName&amp;quot;: &amp;quot;Broker cluster key&amp;quot;,
          &amp;quot;regex&amp;quot;: null,
          &amp;quot;internal&amp;quot;: false,
          &amp;quot;permission&amp;quot;: &amp;quot;EDITABLE&amp;quot;,
          &amp;quot;documentation&amp;quot;: &amp;quot;the key of broker cluster used to transfer data for this stream&amp;quot;,
          &amp;quot;necessary&amp;quot;: &amp;quot;REQUIRED&amp;quot;,
          &amp;quot;valueType&amp;quot;: &amp;quot;OBJECT_KEY&amp;quot;,
          &amp;quot;tableKeys&amp;quot;: [],
          &amp;quot;orderInGroup&amp;quot;: 0,
          &amp;quot;key&amp;quot;: &amp;quot;brokerClusterKey&amp;quot;,
          &amp;quot;defaultValue&amp;quot;: null,
          &amp;quot;recommendedValues&amp;quot;: [],
          &amp;quot;group&amp;quot;: &amp;quot;core&amp;quot;
        }
      ]
    }
  ],
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Files</title>
      <link>https://oharastream.github.io/en/docs/master/rest-api/files/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/master/rest-api/files/</guid>
      <description>&lt;p&gt;Ohara encourages user to write custom application if the official
applications can satisfy requirements for your use case. Jar APIs is a
useful entry of putting your jar on Ohara and then start related
services with it. For example,

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/workers/#rest-workers-create&#34;&gt;Worker APIs&lt;/a&gt; accept
a &lt;strong&gt;sharedJarKeys&lt;/strong&gt; element which can carry the jar name pointing to an
existent jar in Ohara. The worker cluster will load all connectors of
the input jar, and then you are able to use the connectors on the worker
cluster.&lt;/p&gt;
&lt;p&gt;The File API upload jar file to use by the

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/workers/&#34;&gt;Worker&lt;/a&gt; and 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/streams/&#34;&gt;Stream&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The file used by a worker or stream can&amp;rsquo;t be either updated or deleted.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The properties stored by Ohara are shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the file name without extension. The legal
character is number, lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the group name (we use this field to separate
different workspaces). The legal character is number, lowercase
alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;size (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; file size&lt;/li&gt;
&lt;li&gt;url (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; url to download this jar from Ohara
Configurator. Noted not all jars are downloadable to user.&lt;/li&gt;
&lt;li&gt;lastModified (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; the time of uploading this file&lt;/li&gt;
&lt;li&gt;tags (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the user defined parameters&lt;/li&gt;
&lt;li&gt;bytes (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; read file content to bytes&lt;/li&gt;
&lt;li&gt;classInfos (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the information of available
classes in this file
&lt;ul&gt;
&lt;li&gt;classInfos[i].className &amp;mdash; the name of this class&lt;/li&gt;
&lt;li&gt;classInfos[i].classType &amp;mdash; the type of this class. for example,
topic, source connector, sink connector or stream app&lt;/li&gt;
&lt;li&gt;classInfos[i].settingDefinitions &amp;mdash; the definitions of this
class&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The field &amp;ldquo;classInfos&amp;rdquo; is empty if the file is NOT a valid jar.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;upload-a-file-to-ohara&#34;&gt;upload a file to Ohara&lt;/h2&gt;
&lt;p&gt;Upload a file to Ohara with field name : &amp;ldquo;jar&amp;rdquo; and group name : &amp;ldquo;group&amp;rdquo;
the text field &amp;ldquo;group&amp;rdquo; could be empty and we will generate a random
string.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;POST /v0/files&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Request
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;Content-Type: multipart/form-data
file=&amp;quot;ohara-it-stream.jar&amp;quot;
group=&amp;quot;default&amp;quot;
tags={}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You have to specify the file name since it is a part of metadata
stored by Ohara. Noted, the later uploaded file can overwrite the
older one
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;ohara-it-stream.jar&amp;quot;,
  &amp;quot;size&amp;quot;: 1896,
  &amp;quot;url&amp;quot;: &amp;quot;http://localhost:12345/v0/downloadFiles/default/ohara-it-stream.jar&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1578967196525,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;classInfos&amp;quot;: [
    {
      &amp;quot;classType&amp;quot;: &amp;quot;stream&amp;quot;,
      &amp;quot;className&amp;quot;: &amp;quot;oharastream.ohara.it.stream.DumbStream&amp;quot;,
      &amp;quot;settingDefinitions&amp;quot;: [
        {
          &amp;quot;blacklist&amp;quot;: [],
          &amp;quot;reference&amp;quot;: &amp;quot;BROKER_CLUSTER&amp;quot;,
          &amp;quot;displayName&amp;quot;: &amp;quot;Broker cluster key&amp;quot;,
          &amp;quot;regex&amp;quot;: null,
          &amp;quot;internal&amp;quot;: false,
          &amp;quot;permission&amp;quot;: &amp;quot;EDITABLE&amp;quot;,
          &amp;quot;documentation&amp;quot;: &amp;quot;the key of broker cluster used to transfer data for this stream&amp;quot;,
          &amp;quot;necessary&amp;quot;: &amp;quot;REQUIRED&amp;quot;,
          &amp;quot;valueType&amp;quot;: &amp;quot;OBJECT_KEY&amp;quot;,
          &amp;quot;tableKeys&amp;quot;: [],
          &amp;quot;orderInGroup&amp;quot;: 0,
          &amp;quot;key&amp;quot;: &amp;quot;brokerClusterKey&amp;quot;,
          &amp;quot;defaultValue&amp;quot;: null,
          &amp;quot;recommendedValues&amp;quot;: [],
          &amp;quot;group&amp;quot;: &amp;quot;core&amp;quot;
        }
      ]
    }
  ],
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;list-all-jars&#34;&gt;list all jars&lt;/h2&gt;
&lt;p&gt;Get all jars from specific group of query parameter. If no query
parameter, wll return all jars.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;GET /v0/files?group=default&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
  {
    &amp;quot;name&amp;quot;: &amp;quot;ohara-it-stream.jar&amp;quot;,
    &amp;quot;size&amp;quot;: 1896,
    &amp;quot;url&amp;quot;: &amp;quot;http://localhost:5000/v0/downloadFiles/default/ohara-it-stream.jar&amp;quot;,
    &amp;quot;lastModified&amp;quot;: 1578973197877,
    &amp;quot;tags&amp;quot;: {},
    &amp;quot;classInfos&amp;quot;: [
      {
        &amp;quot;classType&amp;quot;: &amp;quot;stream&amp;quot;,
        &amp;quot;className&amp;quot;: &amp;quot;oharastream.ohara.it.stream.DumbStream&amp;quot;,
        &amp;quot;settingDefinitions&amp;quot;: [
          {
            &amp;quot;blacklist&amp;quot;: [],
            &amp;quot;reference&amp;quot;: &amp;quot;BROKER_CLUSTER&amp;quot;,
            &amp;quot;displayName&amp;quot;: &amp;quot;Broker cluster key&amp;quot;,
            &amp;quot;regex&amp;quot;: null,
            &amp;quot;internal&amp;quot;: false,
            &amp;quot;permission&amp;quot;: &amp;quot;EDITABLE&amp;quot;,
            &amp;quot;documentation&amp;quot;: &amp;quot;the key of broker cluster used to transfer data for this stream&amp;quot;,
            &amp;quot;necessary&amp;quot;: &amp;quot;REQUIRED&amp;quot;,
            &amp;quot;valueType&amp;quot;: &amp;quot;OBJECT_KEY&amp;quot;,
            &amp;quot;tableKeys&amp;quot;: [],
            &amp;quot;orderInGroup&amp;quot;: 0,
            &amp;quot;key&amp;quot;: &amp;quot;brokerClusterKey&amp;quot;,
            &amp;quot;defaultValue&amp;quot;: null,
            &amp;quot;recommendedValues&amp;quot;: [],
            &amp;quot;group&amp;quot;: &amp;quot;core&amp;quot;
          },
        ]
      }
    ],
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;delete-a-file&#34;&gt;delete a file&lt;/h2&gt;
&lt;p&gt;Delete a file with specific name and group. Note: the query parameter
must exist.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;DELETE /v0/files/$name?group=default&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;204 NoContent
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    It is ok to delete a nonexistent jar, and the response is 204
NoContent. If you delete a file is used by other services, you also
break the scalability of service as you can&amp;rsquo;t run the jar on any new
nodes
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;get-a-file&#34;&gt;get a file&lt;/h2&gt;
&lt;p&gt;Get a file with specific name and group. Note: the query parameter must
exists.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;GET /v0/files/$name?group=default&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;ohara-it-stream.jar&amp;quot;,
  &amp;quot;size&amp;quot;: 1896,
  &amp;quot;url&amp;quot;: &amp;quot;http://localhost:5000/v0/downloadFiles/default/ohara-it-stream.jar&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1578973197877,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;classInfos&amp;quot;: [
    {
      &amp;quot;classType&amp;quot;: &amp;quot;stream&amp;quot;,
      &amp;quot;className&amp;quot;: &amp;quot;oharastream.ohara.it.stream.DumbStream&amp;quot;,
      &amp;quot;settingDefinitions&amp;quot;: [
        {
          &amp;quot;blacklist&amp;quot;: [],
          &amp;quot;reference&amp;quot;: &amp;quot;BROKER_CLUSTER&amp;quot;,
          &amp;quot;displayName&amp;quot;: &amp;quot;Broker cluster key&amp;quot;,
          &amp;quot;regex&amp;quot;: null,
          &amp;quot;internal&amp;quot;: false,
          &amp;quot;permission&amp;quot;: &amp;quot;EDITABLE&amp;quot;,
          &amp;quot;documentation&amp;quot;: &amp;quot;the key of broker cluster used to transfer data for this stream&amp;quot;,
          &amp;quot;necessary&amp;quot;: &amp;quot;REQUIRED&amp;quot;,
          &amp;quot;valueType&amp;quot;: &amp;quot;OBJECT_KEY&amp;quot;,
          &amp;quot;tableKeys&amp;quot;: [],
          &amp;quot;orderInGroup&amp;quot;: 0,
          &amp;quot;key&amp;quot;: &amp;quot;brokerClusterKey&amp;quot;,
          &amp;quot;defaultValue&amp;quot;: null,
          &amp;quot;recommendedValues&amp;quot;: [],
          &amp;quot;group&amp;quot;: &amp;quot;core&amp;quot;
        }
      ]
    }
  ],
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;update-tags-of-file&#34;&gt;update tags of file&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/files/$name?group=default&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;tags&amp;quot;: {
    &amp;quot;a&amp;quot;: &amp;quot;b&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    it returns error code if input group/name are not associated to an
existent file.
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;ohara-it-stream.jar&amp;quot;,
  &amp;quot;size&amp;quot;: 1896,
  &amp;quot;url&amp;quot;: &amp;quot;http://localhost:5000/v0/downloadFiles/default/ohara-it-stream.jar&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1578974415307,
  &amp;quot;tags&amp;quot;: {
    &amp;quot;a&amp;quot;: &amp;quot;b&amp;quot;
  },
  &amp;quot;classInfos&amp;quot;: [
    {
      &amp;quot;classType&amp;quot;: &amp;quot;stream&amp;quot;,
      &amp;quot;className&amp;quot;: &amp;quot;oharastream.ohara.it.stream.DumbStream&amp;quot;,
      &amp;quot;settingDefinitions&amp;quot;: [
        {
          &amp;quot;blacklist&amp;quot;: [],
          &amp;quot;reference&amp;quot;: &amp;quot;BROKER_CLUSTER&amp;quot;,
          &amp;quot;displayName&amp;quot;: &amp;quot;Broker cluster key&amp;quot;,
          &amp;quot;regex&amp;quot;: null,
          &amp;quot;internal&amp;quot;: false,
          &amp;quot;permission&amp;quot;: &amp;quot;EDITABLE&amp;quot;,
          &amp;quot;documentation&amp;quot;: &amp;quot;the key of broker cluster used to transfer data for this stream&amp;quot;,
          &amp;quot;necessary&amp;quot;: &amp;quot;REQUIRED&amp;quot;,
          &amp;quot;valueType&amp;quot;: &amp;quot;OBJECT_KEY&amp;quot;,
          &amp;quot;tableKeys&amp;quot;: [],
          &amp;quot;orderInGroup&amp;quot;: 0,
          &amp;quot;key&amp;quot;: &amp;quot;brokerClusterKey&amp;quot;,
          &amp;quot;defaultValue&amp;quot;: null,
          &amp;quot;recommendedValues&amp;quot;: [],
          &amp;quot;group&amp;quot;: &amp;quot;core&amp;quot;
        }
      ]
    }
  ],
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Inspect</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/rest-api/inspect/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/rest-api/inspect/</guid>
      <description>&lt;p&gt;Inspect APIs is a powerful tool that it enable you to &amp;ldquo;see&amp;rdquo; what in
the target via Configurator. For example, you can get the definitions
from specific image, or you can see what connectors or stream app in the
specific file.&lt;/p&gt;
&lt;h2 id=&#34;get-ohara-configurator-info&#34;&gt;get Ohara Configurator info&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/inspect/configurator&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;the format of response of Ohara Configurator is shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;versionInfo (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; version details of Ohara Configurator
&lt;ul&gt;
&lt;li&gt;branch (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the branch name of Ohara Configurator&lt;/li&gt;
&lt;li&gt;version (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the release version of Ohara
Configurator&lt;/li&gt;
&lt;li&gt;revision (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; commit hash of Ohara Configurator. You
can trace the hash code via

&lt;a href=&#34;https://github.com/oharastream/ohara/commits/master&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;user (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the release manager of Ohara Configurator.&lt;/li&gt;
&lt;li&gt;date (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the date of releasing Ohara Configurator.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;mode (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the mode of this configurator. There are three
modes now:
&lt;ul&gt;
&lt;li&gt;K8S: k8s mode is for the production.&lt;/li&gt;
&lt;li&gt;SSH: ssh is useful to simple env.&lt;/li&gt;
&lt;li&gt;FAKE: fake mode is used to test APIs.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;versionInfo&amp;quot;: {
    &amp;quot;branch&amp;quot;: &amp;quot;0.10.0&amp;quot;,
    &amp;quot;revision&amp;quot;: &amp;quot;b303f3c2e52647ee5e79e55f9d74a5e51238a92c&amp;quot;,
    &amp;quot;version&amp;quot;: &amp;quot;0.11.0-SNAPSHOT&amp;quot;,
    &amp;quot;date&amp;quot;: &amp;quot;2020-01-08 06:05:47&amp;quot;,
    &amp;quot;user&amp;quot;: &amp;quot;root&amp;quot;
  },
  &amp;quot;mode&amp;quot;: &amp;quot;K8S&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;get-zookeeperbrokerworkerstream-info&#34;&gt;get zookeeper/broker/worker/stream info&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/inspect/$service&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This API used to fetch the definitions for specific cluster service. The
following fields are returned.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;imageName (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the image name of service&lt;/li&gt;
&lt;li&gt;settingDefinitions (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the available settings
for this service (see 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/setting_definition/&#34;&gt;setting&lt;/a&gt;)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;the available variables for $service are shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;zookeeper&lt;/li&gt;
&lt;li&gt;broker&lt;/li&gt;
&lt;li&gt;worker&lt;/li&gt;
&lt;li&gt;stream&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/zookeeper:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;settingDefinitions&amp;quot;: [
    {
       &amp;quot;blacklist&amp;quot;: [],
       &amp;quot;reference&amp;quot;: &amp;quot;NONE&amp;quot;,
       &amp;quot;displayName&amp;quot;: &amp;quot;peerPort&amp;quot;,
       &amp;quot;regex&amp;quot;: null,
       &amp;quot;internal&amp;quot;: false,
       &amp;quot;permission&amp;quot;: &amp;quot;EDITABLE&amp;quot;,
       &amp;quot;documentation&amp;quot;: &amp;quot;the port exposed to each quorum&amp;quot;,
       &amp;quot;necessary&amp;quot;: &amp;quot;RANDOM_DEFAULT&amp;quot;,
       &amp;quot;valueType&amp;quot;: &amp;quot;BINDING_PORT&amp;quot;,
       &amp;quot;tableKeys&amp;quot;: [],
       &amp;quot;orderInGroup&amp;quot;: 10,
       &amp;quot;key&amp;quot;: &amp;quot;peerPort&amp;quot;,
       &amp;quot;defaultValue&amp;quot;: null,
       &amp;quot;recommendedValues&amp;quot;: [],
       &amp;quot;group&amp;quot;: &amp;quot;core&amp;quot;
    },
  ],
  &amp;quot;classInfos&amp;quot;: []
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;get-running-zookeeperbrokerworkerstream-info&#34;&gt;get running zookeeper/broker/worker/stream info&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/inspect/$service/$name?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This API used to fetch the definitions for specific cluster service and
the definitions of available classes in the service. The following
fields are returned.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;imageName (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the image name of service&lt;/li&gt;
&lt;li&gt;settingDefinitions (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the available settings
for this service (see 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/setting_definition/&#34;&gt;setting&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;classInfos (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the information available classes
in this service
&lt;ul&gt;
&lt;li&gt;classInfos[i].className &amp;mdash; the name of this class&lt;/li&gt;
&lt;li&gt;classInfos[i].classType &amp;mdash; the type of this class. for example,
topic, source connector, sink connector or stream app&lt;/li&gt;
&lt;li&gt;classInfos[i].settingDefinitions &amp;mdash; the definitions of this
class&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;the available variables for $service are shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;zookeeper&lt;/li&gt;
&lt;li&gt;broker&lt;/li&gt;
&lt;li&gt;worker&lt;/li&gt;
&lt;li&gt;stream&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/broker:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;settingDefinitions&amp;quot;: [
    {
      &amp;quot;blacklist&amp;quot;: [],
      &amp;quot;reference&amp;quot;: &amp;quot;NONE&amp;quot;,
      &amp;quot;displayName&amp;quot;: &amp;quot;xmx&amp;quot;,
      &amp;quot;regex&amp;quot;: null,
      &amp;quot;internal&amp;quot;: false,
      &amp;quot;permission&amp;quot;: &amp;quot;EDITABLE&amp;quot;,
      &amp;quot;documentation&amp;quot;: &amp;quot;maximum memory allocation (in MB)&amp;quot;,
      &amp;quot;necessary&amp;quot;: &amp;quot;OPTIONAL_WITH_DEFAULT&amp;quot;,
      &amp;quot;valueType&amp;quot;: &amp;quot;POSITIVE_LONG&amp;quot;,
      &amp;quot;tableKeys&amp;quot;: [],
      &amp;quot;orderInGroup&amp;quot;: 8,
      &amp;quot;key&amp;quot;: &amp;quot;xmx&amp;quot;,
      &amp;quot;defaultValue&amp;quot;: 1024,
      &amp;quot;recommendedValues&amp;quot;: [],
      &amp;quot;group&amp;quot;: &amp;quot;core&amp;quot;
    }
  ],
  &amp;quot;classInfos&amp;quot;: [
    {
      &amp;quot;classType&amp;quot;: &amp;quot;topic&amp;quot;,
      &amp;quot;className&amp;quot;: &amp;quot;N/A&amp;quot;,
      &amp;quot;settingDefinitions&amp;quot;: [
        {
          &amp;quot;blacklist&amp;quot;: [],
          &amp;quot;reference&amp;quot;: &amp;quot;NONE&amp;quot;,
          &amp;quot;displayName&amp;quot;: &amp;quot;numberOfPartitions&amp;quot;,
          &amp;quot;regex&amp;quot;: null,
          &amp;quot;internal&amp;quot;: false,
          &amp;quot;permission&amp;quot;: &amp;quot;EDITABLE&amp;quot;,
          &amp;quot;documentation&amp;quot;: &amp;quot;the number of partitions&amp;quot;,
          &amp;quot;necessary&amp;quot;: &amp;quot;OPTIONAL_WITH_DEFAULT&amp;quot;,
          &amp;quot;valueType&amp;quot;: &amp;quot;POSITIVE_INT&amp;quot;,
          &amp;quot;tableKeys&amp;quot;: [],
          &amp;quot;orderInGroup&amp;quot;: 4,
          &amp;quot;key&amp;quot;: &amp;quot;numberOfPartitions&amp;quot;,
          &amp;quot;defaultValue&amp;quot;: 1,
          &amp;quot;recommendedValues&amp;quot;: [],
          &amp;quot;group&amp;quot;: &amp;quot;core&amp;quot;
        }
      ]
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;query-database&#34;&gt;Query Database&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;POST /v0/inspect/rdb&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This API returns the table details of a relational database. This API
invokes a running connector on worker cluster to fetch database
information and return to Ohara Configurator. You should deploy suitable
jdbc driver on worker cluster before using this API. Otherwise, you will
get a exception returned by Ohara Configurator. The query consists of
following fields.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;url (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; jdbc url&lt;/li&gt;
&lt;li&gt;user (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; user who can access target database&lt;/li&gt;
&lt;li&gt;password (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; password which can access target database&lt;/li&gt;
&lt;li&gt;workerClusterKey (&lt;strong&gt;Object&lt;/strong&gt;) &amp;mdash; target worker cluster.
&lt;ul&gt;
&lt;li&gt;workerClusterKey.group (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the group of
cluster&lt;/li&gt;
&lt;li&gt;workerClusterKey.name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the name of cluster&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    the following forms are legal as well: (1) &lt;code&gt;{&amp;quot;name&amp;quot;: &amp;quot;n&amp;quot;}&lt;/code&gt;, (2) &lt;code&gt;&amp;quot;n&amp;quot;&lt;/code&gt;.
Both forms are converted to &lt;code&gt;{&amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;n&amp;quot;}&lt;/code&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;catalogPattern (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; filter returned tables
according to catalog&lt;/li&gt;
&lt;li&gt;schemaPattern (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; filter returned tables
according to schema&lt;/li&gt;
&lt;li&gt;tableName (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; filter returned tables according
to name&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;url&amp;quot;: &amp;quot;jdbc:postgresql://localhost:5432/postgres&amp;quot;,
  &amp;quot;user&amp;quot;: &amp;quot;ohara&amp;quot;,
  &amp;quot;password&amp;quot;: &amp;quot;123456&amp;quot;,
  &amp;quot;workerClusterKey&amp;quot;: &amp;quot;wk00&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; database name&lt;/li&gt;
&lt;li&gt;tables (&lt;strong&gt;array(object)&lt;/strong&gt;)
&lt;ul&gt;
&lt;li&gt;tables[i].catalogPattern (&lt;strong&gt;option(object)&lt;/strong&gt;) &amp;mdash; table&amp;rsquo;s
catalog pattern&lt;/li&gt;
&lt;li&gt;tables[i].schemaPattern (&lt;strong&gt;option(object)&lt;/strong&gt;) &amp;mdash; table&amp;rsquo;s
schema pattern&lt;/li&gt;
&lt;li&gt;tables[i].name (&lt;strong&gt;option(object)&lt;/strong&gt;) &amp;mdash; table&amp;rsquo;s name&lt;/li&gt;
&lt;li&gt;tables[i].columns (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; table&amp;rsquo;s columns
&lt;ul&gt;
&lt;li&gt;tables[i].columns[j].name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; column&amp;rsquo;s
columns&lt;/li&gt;
&lt;li&gt;tables[i].columns[j].dataType (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash;
column&amp;rsquo;s data type&lt;/li&gt;
&lt;li&gt;tables[i].columns[j].pk (&lt;strong&gt;boolean&lt;/strong&gt;) &amp;mdash; true if
this column is pk. otherwise false&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;postgresql&amp;quot;,
  &amp;quot;tables&amp;quot;: [
    {
      &amp;quot;schemaPattern&amp;quot;: &amp;quot;public&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;table1&amp;quot;,
      &amp;quot;columns&amp;quot;: [
        {
          &amp;quot;name&amp;quot;: &amp;quot;column1&amp;quot;,
          &amp;quot;dataType&amp;quot;: &amp;quot;timestamp&amp;quot;,
          &amp;quot;pk&amp;quot;: false
        },
        {
          &amp;quot;name&amp;quot;: &amp;quot;column2&amp;quot;,
          &amp;quot;dataType&amp;quot;: &amp;quot;varchar&amp;quot;,
          &amp;quot;pk&amp;quot;: true
        }
      ]
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;query-topic&#34;&gt;Query Topic&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;POST /v0/inspect/topic/$name?group=$group&amp;amp;timeout=$timeout&amp;amp;limit=$limit&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Fetch the latest data from a topic. the query arguments are shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;timeout (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; break the fetch if this timeout is reached&lt;/li&gt;
&lt;li&gt;limit (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; the number of messages in topic&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;the response includes following items.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;messages (&lt;strong&gt;Array(Object)&lt;/strong&gt;) &amp;mdash; messages&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;messages[i].partition (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; the index of partition&lt;/li&gt;
&lt;li&gt;messages[i].offset (&lt;strong&gt;Long&lt;/strong&gt;) &amp;mdash; the offset of this message&lt;/li&gt;
&lt;li&gt;messages[i].sourceClass (&lt;strong&gt;Option(String)&lt;/strong&gt;) &amp;mdash; class name of
the component which generate this data&lt;/li&gt;
&lt;li&gt;messages[i].sourceKey (&lt;strong&gt;Option(Object)&lt;/strong&gt;) &amp;mdash; object key of the
component which generate this data&lt;/li&gt;
&lt;li&gt;messages[i].value (&lt;strong&gt;Option(Object)&lt;/strong&gt;) &amp;mdash; the value of this
message&lt;/li&gt;
&lt;li&gt;messages[i].error (&lt;strong&gt;Option(String)&lt;/strong&gt;) &amp;mdash; error message happen
in failing to parse value&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;messages&amp;quot;: [
    {
      &amp;quot;sourceKey&amp;quot;: {
        &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
        &amp;quot;name&amp;quot;: &amp;quot;perf&amp;quot;
      },
      &amp;quot;sourceClass&amp;quot;: &amp;quot;oharastream.ohara.connector.perf.PerfSourceTask&amp;quot;,
      &amp;quot;partition&amp;quot;: 0,
      &amp;quot;offset&amp;quot;: 0,
      &amp;quot;value&amp;quot;: {
        &amp;quot;a&amp;quot;: &amp;quot;c54e2f3477&amp;quot;,
        &amp;quot;b&amp;quot;: &amp;quot;32ae422fb5&amp;quot;,
        &amp;quot;c&amp;quot;: &amp;quot;53e448ab80&amp;quot;,
        &amp;quot;tags&amp;quot;: []
      }
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;query-file&#34;&gt;Query File&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the file name without extension&lt;/li&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the group name (we use this field to separate
different workspaces)&lt;/li&gt;
&lt;li&gt;size (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; file size&lt;/li&gt;
&lt;li&gt;tags (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the extra description to this object&lt;/li&gt;
&lt;li&gt;lastModified (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; the time of uploading this file&lt;/li&gt;
&lt;li&gt;classInfos (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the information of available
classes in this file&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;classInfos[i].className &amp;mdash; the name of this class&lt;/li&gt;
&lt;li&gt;classInfos[i].classType &amp;mdash; the type of this class. for example,
topic, source connector, sink connector or stream app&lt;/li&gt;
&lt;li&gt;classInfos[i].settingDefinitions &amp;mdash; the definitions of this
class&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;POST /v0/inspect/files&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;Content-Type: multipart/form-data
file=&amp;quot;ohara-it-sink.jar&amp;quot;
group=&amp;quot;default&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;ohara-it-sink.jar&amp;quot;,
  &amp;quot;size&amp;quot;: 7902,
  &amp;quot;lastModified&amp;quot;: 1579055900202,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;classInfos&amp;quot;: [
    {
      &amp;quot;classType&amp;quot;: &amp;quot;sink&amp;quot;,
      &amp;quot;className&amp;quot;: &amp;quot;oharastream.ohara.it.connector.IncludeAllTypesSinkConnector&amp;quot;,
      &amp;quot;settingDefinitions&amp;quot;: [
        {
          &amp;quot;blacklist&amp;quot;: [],
          &amp;quot;reference&amp;quot;: &amp;quot;NONE&amp;quot;,
          &amp;quot;displayName&amp;quot;: &amp;quot;kind&amp;quot;,
          &amp;quot;regex&amp;quot;: null,
          &amp;quot;internal&amp;quot;: false,
          &amp;quot;permission&amp;quot;: &amp;quot;READ_ONLY&amp;quot;,
          &amp;quot;documentation&amp;quot;: &amp;quot;kind of connector&amp;quot;,
          &amp;quot;necessary&amp;quot;: &amp;quot;OPTIONAL_WITH_DEFAULT&amp;quot;,
          &amp;quot;valueType&amp;quot;: &amp;quot;STRING&amp;quot;,
          &amp;quot;tableKeys&amp;quot;: [],
          &amp;quot;orderInGroup&amp;quot;: 13,
          &amp;quot;key&amp;quot;: &amp;quot;kind&amp;quot;,
          &amp;quot;defaultValue&amp;quot;: &amp;quot;sink&amp;quot;,
          &amp;quot;recommendedValues&amp;quot;: [],
          &amp;quot;group&amp;quot;: &amp;quot;core&amp;quot;
        }
      ]
    }
  ],
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Inspect</title>
      <link>https://oharastream.github.io/en/docs/master/rest-api/inspect/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/master/rest-api/inspect/</guid>
      <description>&lt;p&gt;Inspect APIs is a powerful tool that it enable you to &amp;ldquo;see&amp;rdquo; what in
the target via Configurator. For example, you can get the definitions
from specific image, or you can see what connectors or stream app in the
specific file.&lt;/p&gt;
&lt;h2 id=&#34;get-ohara-configurator-info&#34;&gt;get Ohara Configurator info&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/inspect/configurator&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;the format of response of Ohara Configurator is shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;versionInfo (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; version details of Ohara Configurator
&lt;ul&gt;
&lt;li&gt;branch (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the branch name of Ohara Configurator&lt;/li&gt;
&lt;li&gt;version (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the release version of Ohara
Configurator&lt;/li&gt;
&lt;li&gt;revision (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; commit hash of Ohara Configurator. You
can trace the hash code via

&lt;a href=&#34;https://github.com/oharastream/ohara/commits/master&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;user (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the release manager of Ohara Configurator.&lt;/li&gt;
&lt;li&gt;date (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the date of releasing Ohara Configurator.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;mode (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the mode of this configurator. There are three
modes now:
&lt;ul&gt;
&lt;li&gt;K8S: k8s mode is for the production.&lt;/li&gt;
&lt;li&gt;SSH: ssh is useful to simple env.&lt;/li&gt;
&lt;li&gt;FAKE: fake mode is used to test APIs.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;versionInfo&amp;quot;: {
    &amp;quot;branch&amp;quot;: &amp;quot;0.10.0&amp;quot;,
    &amp;quot;revision&amp;quot;: &amp;quot;b303f3c2e52647ee5e79e55f9d74a5e51238a92c&amp;quot;,
    &amp;quot;version&amp;quot;: &amp;quot;0.11.0-SNAPSHOT&amp;quot;,
    &amp;quot;date&amp;quot;: &amp;quot;2020-01-08 06:05:47&amp;quot;,
    &amp;quot;user&amp;quot;: &amp;quot;root&amp;quot;
  },
  &amp;quot;mode&amp;quot;: &amp;quot;K8S&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;get-zookeeperbrokerworkerstream-info&#34;&gt;get zookeeper/broker/worker/stream info&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/inspect/$service&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This API used to fetch the definitions for specific cluster service. The
following fields are returned.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;imageName (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the image name of service&lt;/li&gt;
&lt;li&gt;settingDefinitions (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the available settings
for this service (see 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/setting_definition/&#34;&gt;setting&lt;/a&gt;)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;the available variables for $service are shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;zookeeper&lt;/li&gt;
&lt;li&gt;broker&lt;/li&gt;
&lt;li&gt;worker&lt;/li&gt;
&lt;li&gt;stream&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/zookeeper:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;settingDefinitions&amp;quot;: [
    {
       &amp;quot;blacklist&amp;quot;: [],
       &amp;quot;reference&amp;quot;: &amp;quot;NONE&amp;quot;,
       &amp;quot;displayName&amp;quot;: &amp;quot;peerPort&amp;quot;,
       &amp;quot;regex&amp;quot;: null,
       &amp;quot;internal&amp;quot;: false,
       &amp;quot;permission&amp;quot;: &amp;quot;EDITABLE&amp;quot;,
       &amp;quot;documentation&amp;quot;: &amp;quot;the port exposed to each quorum&amp;quot;,
       &amp;quot;necessary&amp;quot;: &amp;quot;RANDOM_DEFAULT&amp;quot;,
       &amp;quot;valueType&amp;quot;: &amp;quot;BINDING_PORT&amp;quot;,
       &amp;quot;tableKeys&amp;quot;: [],
       &amp;quot;orderInGroup&amp;quot;: 10,
       &amp;quot;key&amp;quot;: &amp;quot;peerPort&amp;quot;,
       &amp;quot;defaultValue&amp;quot;: null,
       &amp;quot;recommendedValues&amp;quot;: [],
       &amp;quot;group&amp;quot;: &amp;quot;core&amp;quot;
    },
  ],
  &amp;quot;classInfos&amp;quot;: []
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;get-running-zookeeperbrokerworkerstream-info&#34;&gt;get running zookeeper/broker/worker/stream info&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/inspect/$service/$name?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This API used to fetch the definitions for specific cluster service and
the definitions of available classes in the service. The following
fields are returned.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;imageName (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the image name of service&lt;/li&gt;
&lt;li&gt;settingDefinitions (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the available settings
for this service (see 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/setting_definition/&#34;&gt;setting&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;classInfos (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the information available classes
in this service
&lt;ul&gt;
&lt;li&gt;classInfos[i].className &amp;mdash; the name of this class&lt;/li&gt;
&lt;li&gt;classInfos[i].classType &amp;mdash; the type of this class. for example,
topic, source connector, sink connector or stream app&lt;/li&gt;
&lt;li&gt;classInfos[i].settingDefinitions &amp;mdash; the definitions of this
class&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;the available variables for $service are shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;zookeeper&lt;/li&gt;
&lt;li&gt;broker&lt;/li&gt;
&lt;li&gt;worker&lt;/li&gt;
&lt;li&gt;stream&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/broker:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;settingDefinitions&amp;quot;: [
    {
      &amp;quot;blacklist&amp;quot;: [],
      &amp;quot;reference&amp;quot;: &amp;quot;NONE&amp;quot;,
      &amp;quot;displayName&amp;quot;: &amp;quot;xmx&amp;quot;,
      &amp;quot;regex&amp;quot;: null,
      &amp;quot;internal&amp;quot;: false,
      &amp;quot;permission&amp;quot;: &amp;quot;EDITABLE&amp;quot;,
      &amp;quot;documentation&amp;quot;: &amp;quot;maximum memory allocation (in MB)&amp;quot;,
      &amp;quot;necessary&amp;quot;: &amp;quot;OPTIONAL_WITH_DEFAULT&amp;quot;,
      &amp;quot;valueType&amp;quot;: &amp;quot;POSITIVE_LONG&amp;quot;,
      &amp;quot;tableKeys&amp;quot;: [],
      &amp;quot;orderInGroup&amp;quot;: 8,
      &amp;quot;key&amp;quot;: &amp;quot;xmx&amp;quot;,
      &amp;quot;defaultValue&amp;quot;: 1024,
      &amp;quot;recommendedValues&amp;quot;: [],
      &amp;quot;group&amp;quot;: &amp;quot;core&amp;quot;
    }
  ],
  &amp;quot;classInfos&amp;quot;: [
    {
      &amp;quot;classType&amp;quot;: &amp;quot;topic&amp;quot;,
      &amp;quot;className&amp;quot;: &amp;quot;N/A&amp;quot;,
      &amp;quot;settingDefinitions&amp;quot;: [
        {
          &amp;quot;blacklist&amp;quot;: [],
          &amp;quot;reference&amp;quot;: &amp;quot;NONE&amp;quot;,
          &amp;quot;displayName&amp;quot;: &amp;quot;numberOfPartitions&amp;quot;,
          &amp;quot;regex&amp;quot;: null,
          &amp;quot;internal&amp;quot;: false,
          &amp;quot;permission&amp;quot;: &amp;quot;EDITABLE&amp;quot;,
          &amp;quot;documentation&amp;quot;: &amp;quot;the number of partitions&amp;quot;,
          &amp;quot;necessary&amp;quot;: &amp;quot;OPTIONAL_WITH_DEFAULT&amp;quot;,
          &amp;quot;valueType&amp;quot;: &amp;quot;POSITIVE_INT&amp;quot;,
          &amp;quot;tableKeys&amp;quot;: [],
          &amp;quot;orderInGroup&amp;quot;: 4,
          &amp;quot;key&amp;quot;: &amp;quot;numberOfPartitions&amp;quot;,
          &amp;quot;defaultValue&amp;quot;: 1,
          &amp;quot;recommendedValues&amp;quot;: [],
          &amp;quot;group&amp;quot;: &amp;quot;core&amp;quot;
        }
      ]
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;query-database&#34;&gt;Query Database&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;POST /v0/inspect/rdb&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This API returns the table details of a relational database. This API
invokes a running connector on worker cluster to fetch database
information and return to Ohara Configurator. You should deploy suitable
jdbc driver on worker cluster before using this API. Otherwise, you will
get a exception returned by Ohara Configurator. The query consists of
following fields.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;url (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; jdbc url&lt;/li&gt;
&lt;li&gt;user (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; user who can access target database&lt;/li&gt;
&lt;li&gt;password (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; password which can access target database&lt;/li&gt;
&lt;li&gt;workerClusterKey (&lt;strong&gt;Object&lt;/strong&gt;) &amp;mdash; target worker cluster.
&lt;ul&gt;
&lt;li&gt;workerClusterKey.group (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the group of
cluster&lt;/li&gt;
&lt;li&gt;workerClusterKey.name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the name of cluster&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    the following forms are legal as well: (1) &lt;code&gt;{&amp;quot;name&amp;quot;: &amp;quot;n&amp;quot;}&lt;/code&gt;, (2) &lt;code&gt;&amp;quot;n&amp;quot;&lt;/code&gt;.
Both forms are converted to &lt;code&gt;{&amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;n&amp;quot;}&lt;/code&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;catalogPattern (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; filter returned tables
according to catalog&lt;/li&gt;
&lt;li&gt;schemaPattern (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; filter returned tables
according to schema&lt;/li&gt;
&lt;li&gt;tableName (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; filter returned tables according
to name&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;url&amp;quot;: &amp;quot;jdbc:postgresql://localhost:5432/postgres&amp;quot;,
  &amp;quot;user&amp;quot;: &amp;quot;ohara&amp;quot;,
  &amp;quot;password&amp;quot;: &amp;quot;123456&amp;quot;,
  &amp;quot;workerClusterKey&amp;quot;: &amp;quot;wk00&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; database name&lt;/li&gt;
&lt;li&gt;tables (&lt;strong&gt;array(object)&lt;/strong&gt;)
&lt;ul&gt;
&lt;li&gt;tables[i].catalogPattern (&lt;strong&gt;option(object)&lt;/strong&gt;) &amp;mdash; table&amp;rsquo;s
catalog pattern&lt;/li&gt;
&lt;li&gt;tables[i].schemaPattern (&lt;strong&gt;option(object)&lt;/strong&gt;) &amp;mdash; table&amp;rsquo;s
schema pattern&lt;/li&gt;
&lt;li&gt;tables[i].name (&lt;strong&gt;option(object)&lt;/strong&gt;) &amp;mdash; table&amp;rsquo;s name&lt;/li&gt;
&lt;li&gt;tables[i].columns (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; table&amp;rsquo;s columns
&lt;ul&gt;
&lt;li&gt;tables[i].columns[j].name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; column&amp;rsquo;s
columns&lt;/li&gt;
&lt;li&gt;tables[i].columns[j].dataType (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash;
column&amp;rsquo;s data type&lt;/li&gt;
&lt;li&gt;tables[i].columns[j].pk (&lt;strong&gt;boolean&lt;/strong&gt;) &amp;mdash; true if
this column is pk. otherwise false&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;postgresql&amp;quot;,
  &amp;quot;tables&amp;quot;: [
    {
      &amp;quot;schemaPattern&amp;quot;: &amp;quot;public&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;table1&amp;quot;,
      &amp;quot;columns&amp;quot;: [
        {
          &amp;quot;name&amp;quot;: &amp;quot;column1&amp;quot;,
          &amp;quot;dataType&amp;quot;: &amp;quot;timestamp&amp;quot;,
          &amp;quot;pk&amp;quot;: false
        },
        {
          &amp;quot;name&amp;quot;: &amp;quot;column2&amp;quot;,
          &amp;quot;dataType&amp;quot;: &amp;quot;varchar&amp;quot;,
          &amp;quot;pk&amp;quot;: true
        }
      ]
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;query-topic&#34;&gt;Query Topic&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;POST /v0/inspect/topic/$name?group=$group&amp;amp;timeout=$timeout&amp;amp;limit=$limit&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Fetch the latest data from a topic. the query arguments are shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;timeout (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; break the fetch if this timeout is reached&lt;/li&gt;
&lt;li&gt;limit (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; the number of messages in topic&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;the response includes following items.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;messages (&lt;strong&gt;Array(Object)&lt;/strong&gt;) &amp;mdash; messages&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;messages[i].partition (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; the index of partition&lt;/li&gt;
&lt;li&gt;messages[i].offset (&lt;strong&gt;Long&lt;/strong&gt;) &amp;mdash; the offset of this message&lt;/li&gt;
&lt;li&gt;messages[i].sourceClass (&lt;strong&gt;Option(String)&lt;/strong&gt;) &amp;mdash; class name of
the component which generate this data&lt;/li&gt;
&lt;li&gt;messages[i].sourceKey (&lt;strong&gt;Option(Object)&lt;/strong&gt;) &amp;mdash; object key of the
component which generate this data&lt;/li&gt;
&lt;li&gt;messages[i].value (&lt;strong&gt;Option(Object)&lt;/strong&gt;) &amp;mdash; the value of this
message&lt;/li&gt;
&lt;li&gt;messages[i].error (&lt;strong&gt;Option(String)&lt;/strong&gt;) &amp;mdash; error message happen
in failing to parse value&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;messages&amp;quot;: [
    {
      &amp;quot;sourceKey&amp;quot;: {
        &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
        &amp;quot;name&amp;quot;: &amp;quot;perf&amp;quot;
      },
      &amp;quot;sourceClass&amp;quot;: &amp;quot;oharastream.ohara.connector.perf.PerfSourceTask&amp;quot;,
      &amp;quot;partition&amp;quot;: 0,
      &amp;quot;offset&amp;quot;: 0,
      &amp;quot;value&amp;quot;: {
        &amp;quot;a&amp;quot;: &amp;quot;c54e2f3477&amp;quot;,
        &amp;quot;b&amp;quot;: &amp;quot;32ae422fb5&amp;quot;,
        &amp;quot;c&amp;quot;: &amp;quot;53e448ab80&amp;quot;,
        &amp;quot;tags&amp;quot;: []
      }
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;query-file&#34;&gt;Query File&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the file name without extension&lt;/li&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the group name (we use this field to separate
different workspaces)&lt;/li&gt;
&lt;li&gt;size (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; file size&lt;/li&gt;
&lt;li&gt;tags (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the extra description to this object&lt;/li&gt;
&lt;li&gt;lastModified (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; the time of uploading this file&lt;/li&gt;
&lt;li&gt;classInfos (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the information of available
classes in this file&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;classInfos[i].className &amp;mdash; the name of this class&lt;/li&gt;
&lt;li&gt;classInfos[i].classType &amp;mdash; the type of this class. for example,
topic, source connector, sink connector or stream app&lt;/li&gt;
&lt;li&gt;classInfos[i].settingDefinitions &amp;mdash; the definitions of this
class&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;POST /v0/inspect/files&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;Content-Type: multipart/form-data
file=&amp;quot;ohara-it-sink.jar&amp;quot;
group=&amp;quot;default&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;ohara-it-sink.jar&amp;quot;,
  &amp;quot;size&amp;quot;: 7902,
  &amp;quot;lastModified&amp;quot;: 1579055900202,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;classInfos&amp;quot;: [
    {
      &amp;quot;classType&amp;quot;: &amp;quot;sink&amp;quot;,
      &amp;quot;className&amp;quot;: &amp;quot;oharastream.ohara.it.connector.IncludeAllTypesSinkConnector&amp;quot;,
      &amp;quot;settingDefinitions&amp;quot;: [
        {
          &amp;quot;blacklist&amp;quot;: [],
          &amp;quot;reference&amp;quot;: &amp;quot;NONE&amp;quot;,
          &amp;quot;displayName&amp;quot;: &amp;quot;kind&amp;quot;,
          &amp;quot;regex&amp;quot;: null,
          &amp;quot;internal&amp;quot;: false,
          &amp;quot;permission&amp;quot;: &amp;quot;READ_ONLY&amp;quot;,
          &amp;quot;documentation&amp;quot;: &amp;quot;kind of connector&amp;quot;,
          &amp;quot;necessary&amp;quot;: &amp;quot;OPTIONAL_WITH_DEFAULT&amp;quot;,
          &amp;quot;valueType&amp;quot;: &amp;quot;STRING&amp;quot;,
          &amp;quot;tableKeys&amp;quot;: [],
          &amp;quot;orderInGroup&amp;quot;: 13,
          &amp;quot;key&amp;quot;: &amp;quot;kind&amp;quot;,
          &amp;quot;defaultValue&amp;quot;: &amp;quot;sink&amp;quot;,
          &amp;quot;recommendedValues&amp;quot;: [],
          &amp;quot;group&amp;quot;: &amp;quot;core&amp;quot;
        }
      ]
    }
  ],
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Logs</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/rest-api/logs/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/rest-api/logs/</guid>
      <description>&lt;p&gt;This world is beautiful but not safe. Even though Ohara shoulders the
blame for simplifying your life, there is a slim chance that something
don&amp;rsquo;t work well in Ohara. The Logs APIs, which are engineers&amp;rsquo; best
friend, open a door to observe the logs of running cluster.&lt;/p&gt;
&lt;p&gt;The available query parameters are shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;sinceSeconds (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; show the logs since relative time&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;It collects output from all containers&amp;rsquo; of a cluster and then format them
to JSON representation which has following elements.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;clusterKey (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; cluster key
&lt;ul&gt;
&lt;li&gt;clusterKey.group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; cluster group&lt;/li&gt;
&lt;li&gt;clusterKey.name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; cluster name&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;logs (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; log of each container
&lt;ul&gt;
&lt;li&gt;logs[i].hostname &amp;mdash; hostname&lt;/li&gt;
&lt;li&gt;logs[i].value &amp;mdash; total log of a container&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;get-the-log-of-a-running-cluster&#34;&gt;get the log of a running cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/logs/$clusterType/$clusterName?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;clusterType (&lt;strong&gt;string&lt;/strong&gt;)
&lt;ul&gt;
&lt;li&gt;zookeepers&lt;/li&gt;
&lt;li&gt;brokers&lt;/li&gt;
&lt;li&gt;workers&lt;/li&gt;
&lt;li&gt;streams&lt;/li&gt;
&lt;li&gt;shabondis&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;clusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;zk&amp;quot;
  },
  &amp;quot;logs&amp;quot;: [
    {
      &amp;quot;hostname&amp;quot;: &amp;quot;node00&amp;quot;,
      &amp;quot;value&amp;quot;: &amp;quot;2020-01-14 10:15:42,146 [myid:] - INFO [main:QuorumPeerConfig@136&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;get-the-since-seconds-log&#34;&gt;get the since seconds log&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/logs/$clusterType/$clusterName?group=$group&amp;amp;sinceSeconds=$relativeSeconds&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;clusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;zk&amp;quot;
  },
  &amp;quot;logs&amp;quot;: [
    {
      &amp;quot;hostname&amp;quot;: &amp;quot;ohara-release-test-00&amp;quot;,
      &amp;quot;value&amp;quot;: &amp;quot;2020-01-15 02:00:43,090 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100000761180000 type:setData cxid:0x11a zxid:0x9e txntype:-1 reqpath:n/a Error Path:/config/topics/default-topic0 Error:KeeperErrorCode = NoNode for /config/topics/default-topic0\n&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;get-the-log-of-configurator&#34;&gt;get the log of Configurator&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/logs/configurator&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;clusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;N/A&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;node00&amp;quot;
  },
  &amp;quot;logs&amp;quot;: [
    {
      &amp;quot;hostname&amp;quot;: &amp;quot;node00&amp;quot;,
      &amp;quot;value&amp;quot;: &amp;quot;2020-01-10 09:43:02,669 INFO  [main] configurator.Configurator$(391): start a configurator built on hostname:ohara-release-test-00 and port:5000\n2020-01-10 09:43:02,676 INFO  [main] configurator.Configurator$(393): enter ctrl+c to terminate the configurator&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    the Configurator MUST run on docker container and the node hosting
Configurator MUST be added to Configurator via
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/nodes/&#34;&gt;Node APIs&lt;/a&gt;
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Logs</title>
      <link>https://oharastream.github.io/en/docs/master/rest-api/logs/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/master/rest-api/logs/</guid>
      <description>&lt;p&gt;This world is beautiful but not safe. Even though Ohara shoulders the
blame for simplifying your life, there is a slim chance that something
don&amp;rsquo;t work well in Ohara. The Logs APIs, which are engineers&amp;rsquo; best
friend, open a door to observe the logs of running cluster.&lt;/p&gt;
&lt;p&gt;The available query parameters are shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;sinceSeconds (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; show the logs since relative time&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;It collects output from all containers&amp;rsquo; of a cluster and then format them
to JSON representation which has following elements.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;clusterKey (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; cluster key
&lt;ul&gt;
&lt;li&gt;clusterKey.group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; cluster group&lt;/li&gt;
&lt;li&gt;clusterKey.name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; cluster name&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;logs (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; log of each container
&lt;ul&gt;
&lt;li&gt;logs[i].hostname &amp;mdash; hostname&lt;/li&gt;
&lt;li&gt;logs[i].value &amp;mdash; total log of a container&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;get-the-log-of-a-running-cluster&#34;&gt;get the log of a running cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/logs/$clusterType/$clusterName?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;clusterType (&lt;strong&gt;string&lt;/strong&gt;)
&lt;ul&gt;
&lt;li&gt;zookeepers&lt;/li&gt;
&lt;li&gt;brokers&lt;/li&gt;
&lt;li&gt;workers&lt;/li&gt;
&lt;li&gt;streams&lt;/li&gt;
&lt;li&gt;shabondis&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;clusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;zk&amp;quot;
  },
  &amp;quot;logs&amp;quot;: [
    {
      &amp;quot;hostname&amp;quot;: &amp;quot;node00&amp;quot;,
      &amp;quot;value&amp;quot;: &amp;quot;2020-01-14 10:15:42,146 [myid:] - INFO [main:QuorumPeerConfig@136&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;get-the-since-seconds-log&#34;&gt;get the since seconds log&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/logs/$clusterType/$clusterName?group=$group&amp;amp;sinceSeconds=$relativeSeconds&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;clusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;zk&amp;quot;
  },
  &amp;quot;logs&amp;quot;: [
    {
      &amp;quot;hostname&amp;quot;: &amp;quot;ohara-release-test-00&amp;quot;,
      &amp;quot;value&amp;quot;: &amp;quot;2020-01-15 02:00:43,090 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100000761180000 type:setData cxid:0x11a zxid:0x9e txntype:-1 reqpath:n/a Error Path:/config/topics/default-topic0 Error:KeeperErrorCode = NoNode for /config/topics/default-topic0\n&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;get-the-log-of-configurator&#34;&gt;get the log of Configurator&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/logs/configurator&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;clusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;N/A&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;node00&amp;quot;
  },
  &amp;quot;logs&amp;quot;: [
    {
      &amp;quot;hostname&amp;quot;: &amp;quot;node00&amp;quot;,
      &amp;quot;value&amp;quot;: &amp;quot;2020-01-10 09:43:02,669 INFO  [main] configurator.Configurator$(391): start a configurator built on hostname:ohara-release-test-00 and port:5000\n2020-01-10 09:43:02,676 INFO  [main] configurator.Configurator$(393): enter ctrl+c to terminate the configurator&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    the Configurator MUST run on docker container and the node hosting
Configurator MUST be added to Configurator via
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/nodes/&#34;&gt;Node APIs&lt;/a&gt;
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Node</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/rest-api/nodes/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/rest-api/nodes/</guid>
      <description>&lt;p&gt;Node is the basic unit of running service. It can be either physical
machine or vm. In section

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/zookeepers/&#34;&gt;zookeeper&lt;/a&gt;,

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/brokers/&#34;&gt;Broker&lt;/a&gt; and

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/workers/&#34;&gt;Worker&lt;/a&gt;, you will see many
requests demanding you to fill the node name to build the services.
Currently, Ohara requires the node added to Ohara should pre-install
following services.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;docker (18.09+)&lt;/li&gt;
&lt;li&gt;ssh server&lt;/li&gt;
&lt;li&gt;k8s (only if you want to k8s to host containers)&lt;/li&gt;
&lt;li&gt;official Ohara images
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://cloud.docker.com/u/oharastream/repository/docker/oharastream/zookeeper&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;oharastream/zookeeper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://cloud.docker.com/u/oharastream/repository/docker/oharastream/broker&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;oharastream/broker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://cloud.docker.com/u/oharastream/repository/docker/oharastream/connect-worker&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;oharastream/connect-worker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://cloud.docker.com/u/oharastream/repository/docker/oharastream/stream&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;oharastream/stream&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The version (tag) depends on which Ohara you used. It would be better to
use the same version to Ohara. For example, the version of Ohara
configurator you are running is 0.11.0-SNAPSHOT, then the official images you should
download is &lt;code&gt;oharastream/xxxx:0.11.0-SNAPSHOT&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The properties used by describing a node are shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;hostname (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; hostname of node. The legal character is
number, lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/p&gt;
&lt;p&gt;This hostname must be available on you DNS. It will cause a lot of
troubles if Ohara Configurator is unable to connect to remote node
via this hostname.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;port (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; ssh port of node&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;user (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; ssh account&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;password (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; ssh password&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;tags (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the extra description to this object&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The following information are updated at run-time.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;services (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the services hosted by this node
&lt;ul&gt;
&lt;li&gt;services[i].name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; service name (configurator,
zookeeper, broker, connect-worker and stream)&lt;/li&gt;
&lt;li&gt;services[i].clusterKeys (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the keys of
this service&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;resources (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the available resources of this
node
&lt;ul&gt;
&lt;li&gt;resources[i].name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the resource name&lt;/li&gt;
&lt;li&gt;resources[i].value (&lt;strong&gt;number&lt;/strong&gt;) &amp;mdash; the &amp;ldquo;pure&amp;rdquo; number of
resource&lt;/li&gt;
&lt;li&gt;resources[i].used (&lt;strong&gt;option(double)&lt;/strong&gt;) &amp;mdash; the used &amp;ldquo;value&amp;rdquo;
in percentage. Noted: this value may be null if the impl is
unable to calculate the used resource.&lt;/li&gt;
&lt;li&gt;resources[i].unit (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the description of the
&amp;ldquo;value&amp;rdquo; unit&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;state (&lt;strong&gt;String&lt;/strong&gt;) &amp;mdash; &amp;ldquo;available&amp;rdquo; means this node works well.
otherwise, &amp;ldquo;unavailable&amp;rdquo; is returned&lt;/li&gt;
&lt;li&gt;error (&lt;strong&gt;option(String)&lt;/strong&gt;) &amp;mdash; the description to the unavailable
node&lt;/li&gt;
&lt;li&gt;lastModified (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; the last time to update this node&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;store-a-node&#34;&gt;store a node&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;POST /v0/nodes&lt;/em&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;hostname (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; hostname of node&lt;/li&gt;
&lt;li&gt;port (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; ssh port of node&lt;/li&gt;
&lt;li&gt;user (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; ssh account&lt;/li&gt;
&lt;li&gt;password (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; ssh password&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;hostname&amp;quot;: &amp;quot;node00&amp;quot;,
  &amp;quot;port&amp;quot;: 22,
  &amp;quot;user&amp;quot;: &amp;quot;abc&amp;quot;,
  &amp;quot;password&amp;quot;: &amp;quot;pwd&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;services&amp;quot;: [
    {
      &amp;quot;name&amp;quot;: &amp;quot;zookeeper&amp;quot;,
      &amp;quot;clusterKeys&amp;quot;: []
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;broker&amp;quot;,
      &amp;quot;clusterKeys&amp;quot;: []
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;connect-worker&amp;quot;,
      &amp;quot;clusterKeys&amp;quot;: []
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;stream&amp;quot;,
      &amp;quot;clusterKeys&amp;quot;: []
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;configurator&amp;quot;,
      &amp;quot;clusterKeys&amp;quot;: [
        {
            &amp;quot;group&amp;quot;: &amp;quot;N/A&amp;quot;,
            &amp;quot;name&amp;quot;: &amp;quot;node00&amp;quot;
        }
      ]
    }
  ],
  &amp;quot;hostname&amp;quot;: &amp;quot;node00&amp;quot;,
  &amp;quot;state&amp;quot;: &amp;quot;AVAILABLE&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1578627668686,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;port&amp;quot;: 22,
  &amp;quot;resources&amp;quot;: [
    {
      &amp;quot;name&amp;quot;: &amp;quot;CPU&amp;quot;,
      &amp;quot;value&amp;quot;: 6.0,
      &amp;quot;unit&amp;quot;: &amp;quot;cores&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Memory&amp;quot;,
      &amp;quot;value&amp;quot;: 10.496479034423828,
      &amp;quot;unit&amp;quot;: &amp;quot;GB&amp;quot;
    }
  ],
  &amp;quot;user&amp;quot;: &amp;quot;abc&amp;quot;,
  &amp;quot;password&amp;quot;: &amp;quot;pwd&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;update-a-node&#34;&gt;update a node&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/nodes/${name}&lt;/em&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;hostname (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; hostname of node&lt;/li&gt;
&lt;li&gt;port (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; ssh port of node&lt;/li&gt;
&lt;li&gt;user (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; ssh account&lt;/li&gt;
&lt;li&gt;password (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; ssh password&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Example Request
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;port&amp;quot;: 9999
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    An new node will be created if your input name does not exist
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    the update request will clear the validation report attached to this
node
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;services&amp;quot;: [
    {
      &amp;quot;name&amp;quot;: &amp;quot;zookeeper&amp;quot;,
      &amp;quot;clusterKeys&amp;quot;: []
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;broker&amp;quot;,
      &amp;quot;clusterKeys&amp;quot;: []
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;connect-worker&amp;quot;,
      &amp;quot;clusterKeys&amp;quot;: []
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;stream&amp;quot;,
      &amp;quot;clusterKeys&amp;quot;: []
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;configurator&amp;quot;,
      &amp;quot;clusterKeys&amp;quot;: [
        {
            &amp;quot;group&amp;quot;: &amp;quot;N/A&amp;quot;,
            &amp;quot;name&amp;quot;: &amp;quot;node00&amp;quot;
        }
      ]
    }
  ],
  &amp;quot;hostname&amp;quot;: &amp;quot;node00&amp;quot;,
  &amp;quot;state&amp;quot;: &amp;quot;AVAILABLE&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1578627668686,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;port&amp;quot;: 9999,
  &amp;quot;resources&amp;quot;: [
    {
      &amp;quot;name&amp;quot;: &amp;quot;CPU&amp;quot;,
      &amp;quot;value&amp;quot;: 6.0,
      &amp;quot;unit&amp;quot;: &amp;quot;cores&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Memory&amp;quot;,
      &amp;quot;value&amp;quot;: 10.496479034423828,
      &amp;quot;unit&amp;quot;: &amp;quot;GB&amp;quot;
    }
  ],
  &amp;quot;user&amp;quot;: &amp;quot;abc&amp;quot;,
  &amp;quot;password&amp;quot;: &amp;quot;pwd&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;list-all-nodes-stored-in-ohara&#34;&gt;list all nodes stored in Ohara&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/nodes&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
  {
    &amp;quot;services&amp;quot;: [
      {
        &amp;quot;name&amp;quot;: &amp;quot;zookeeper&amp;quot;,
        &amp;quot;clusterKeys&amp;quot;: []
      },
      {
        &amp;quot;name&amp;quot;: &amp;quot;broker&amp;quot;,
        &amp;quot;clusterKeys&amp;quot;: []
      },
      {
        &amp;quot;name&amp;quot;: &amp;quot;connect-worker&amp;quot;,
        &amp;quot;clusterKeys&amp;quot;: []
      },
      {
        &amp;quot;name&amp;quot;: &amp;quot;stream&amp;quot;,
        &amp;quot;clusterKeys&amp;quot;: []
      },
      {
        &amp;quot;name&amp;quot;: &amp;quot;configurator&amp;quot;,
        &amp;quot;clusterKeys&amp;quot;: [
          {
              &amp;quot;group&amp;quot;: &amp;quot;N/A&amp;quot;,
              &amp;quot;name&amp;quot;: &amp;quot;node00&amp;quot;
          }
        ]
      }
    ],
    &amp;quot;hostname&amp;quot;: &amp;quot;node00&amp;quot;,
    &amp;quot;state&amp;quot;: &amp;quot;AVAILABLE&amp;quot;,
    &amp;quot;lastModified&amp;quot;: 1578627668686,
    &amp;quot;tags&amp;quot;: {},
    &amp;quot;port&amp;quot;: 22,
    &amp;quot;resources&amp;quot;: [
      {
        &amp;quot;name&amp;quot;: &amp;quot;CPU&amp;quot;,
        &amp;quot;value&amp;quot;: 6.0,
        &amp;quot;unit&amp;quot;: &amp;quot;cores&amp;quot;
      },
      {
        &amp;quot;name&amp;quot;: &amp;quot;Memory&amp;quot;,
        &amp;quot;value&amp;quot;: 10.496479034423828,
        &amp;quot;unit&amp;quot;: &amp;quot;GB&amp;quot;
      }
    ],
    &amp;quot;user&amp;quot;: &amp;quot;abc&amp;quot;,
    &amp;quot;password&amp;quot;: &amp;quot;pwd&amp;quot;
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;delete-a-node&#34;&gt;delete a node&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;DELETE /v0/nodes/${name}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;204 NoContent
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    It is ok to delete a nonexistent pipeline, and the response is
204 NoContent. However, it is disallowed to remove a node which is
running service. If you do want to delete the node from Ohara,
please stop all services from the node.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;get-a-node&#34;&gt;get a node&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/nodes/${name}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;services&amp;quot;: [
    {
      &amp;quot;name&amp;quot;: &amp;quot;zookeeper&amp;quot;,
      &amp;quot;clusterKeys&amp;quot;: []
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;broker&amp;quot;,
      &amp;quot;clusterKeys&amp;quot;: []
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;connect-worker&amp;quot;,
      &amp;quot;clusterKeys&amp;quot;: []
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;stream&amp;quot;,
      &amp;quot;clusterKeys&amp;quot;: []
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;configurator&amp;quot;,
      &amp;quot;clusterKeys&amp;quot;: [
        {
            &amp;quot;group&amp;quot;: &amp;quot;N/A&amp;quot;,
            &amp;quot;name&amp;quot;: &amp;quot;node00&amp;quot;
        }
      ]
    }
  ],
  &amp;quot;hostname&amp;quot;: &amp;quot;node00&amp;quot;,
  &amp;quot;state&amp;quot;: &amp;quot;AVAILABLE&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1578627668686,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;port&amp;quot;: 22,
  &amp;quot;resources&amp;quot;: [
    {
      &amp;quot;name&amp;quot;: &amp;quot;CPU&amp;quot;,
      &amp;quot;value&amp;quot;: 6.0,
      &amp;quot;unit&amp;quot;: &amp;quot;cores&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Memory&amp;quot;,
      &amp;quot;value&amp;quot;: 10.496479034423828,
      &amp;quot;unit&amp;quot;: &amp;quot;GB&amp;quot;
    }
  ],
  &amp;quot;user&amp;quot;: &amp;quot;abc&amp;quot;,
  &amp;quot;password&amp;quot;: &amp;quot;pwd&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Node</title>
      <link>https://oharastream.github.io/en/docs/master/rest-api/nodes/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/master/rest-api/nodes/</guid>
      <description>&lt;p&gt;Node is the basic unit of running service. It can be either physical
machine or vm. In section

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/zookeepers/&#34;&gt;zookeeper&lt;/a&gt;,

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/brokers/&#34;&gt;Broker&lt;/a&gt; and

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/workers/&#34;&gt;Worker&lt;/a&gt;, you will see many
requests demanding you to fill the node name to build the services.
Currently, Ohara requires the node added to Ohara should pre-install
following services.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;docker (18.09+)&lt;/li&gt;
&lt;li&gt;ssh server&lt;/li&gt;
&lt;li&gt;k8s (only if you want to k8s to host containers)&lt;/li&gt;
&lt;li&gt;official Ohara images
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://cloud.docker.com/u/oharastream/repository/docker/oharastream/zookeeper&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;oharastream/zookeeper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://cloud.docker.com/u/oharastream/repository/docker/oharastream/broker&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;oharastream/broker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://cloud.docker.com/u/oharastream/repository/docker/oharastream/connect-worker&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;oharastream/connect-worker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://cloud.docker.com/u/oharastream/repository/docker/oharastream/stream&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;oharastream/stream&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The version (tag) depends on which Ohara you used. It would be better to
use the same version to Ohara. For example, the version of Ohara
configurator you are running is 0.11.0-SNAPSHOT, then the official images you should
download is &lt;code&gt;oharastream/xxxx:0.11.0-SNAPSHOT&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The properties used by describing a node are shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;hostname (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; hostname of node. The legal character is
number, lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/p&gt;
&lt;p&gt;This hostname must be available on you DNS. It will cause a lot of
troubles if Ohara Configurator is unable to connect to remote node
via this hostname.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;port (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; ssh port of node&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;user (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; ssh account&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;password (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; ssh password&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;tags (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the extra description to this object&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The following information are updated at run-time.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;services (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the services hosted by this node
&lt;ul&gt;
&lt;li&gt;services[i].name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; service name (configurator,
zookeeper, broker, connect-worker and stream)&lt;/li&gt;
&lt;li&gt;services[i].clusterKeys (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the keys of
this service&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;resources (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the available resources of this
node
&lt;ul&gt;
&lt;li&gt;resources[i].name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the resource name&lt;/li&gt;
&lt;li&gt;resources[i].value (&lt;strong&gt;number&lt;/strong&gt;) &amp;mdash; the &amp;ldquo;pure&amp;rdquo; number of
resource&lt;/li&gt;
&lt;li&gt;resources[i].used (&lt;strong&gt;option(double)&lt;/strong&gt;) &amp;mdash; the used &amp;ldquo;value&amp;rdquo;
in percentage. Noted: this value may be null if the impl is
unable to calculate the used resource.&lt;/li&gt;
&lt;li&gt;resources[i].unit (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the description of the
&amp;ldquo;value&amp;rdquo; unit&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;state (&lt;strong&gt;String&lt;/strong&gt;) &amp;mdash; &amp;ldquo;available&amp;rdquo; means this node works well.
otherwise, &amp;ldquo;unavailable&amp;rdquo; is returned&lt;/li&gt;
&lt;li&gt;error (&lt;strong&gt;option(String)&lt;/strong&gt;) &amp;mdash; the description to the unavailable
node&lt;/li&gt;
&lt;li&gt;lastModified (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; the last time to update this node&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;store-a-node&#34;&gt;store a node&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;POST /v0/nodes&lt;/em&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;hostname (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; hostname of node&lt;/li&gt;
&lt;li&gt;port (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; ssh port of node&lt;/li&gt;
&lt;li&gt;user (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; ssh account&lt;/li&gt;
&lt;li&gt;password (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; ssh password&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;hostname&amp;quot;: &amp;quot;node00&amp;quot;,
  &amp;quot;port&amp;quot;: 22,
  &amp;quot;user&amp;quot;: &amp;quot;abc&amp;quot;,
  &amp;quot;password&amp;quot;: &amp;quot;pwd&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;services&amp;quot;: [
    {
      &amp;quot;name&amp;quot;: &amp;quot;zookeeper&amp;quot;,
      &amp;quot;clusterKeys&amp;quot;: []
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;broker&amp;quot;,
      &amp;quot;clusterKeys&amp;quot;: []
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;connect-worker&amp;quot;,
      &amp;quot;clusterKeys&amp;quot;: []
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;stream&amp;quot;,
      &amp;quot;clusterKeys&amp;quot;: []
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;configurator&amp;quot;,
      &amp;quot;clusterKeys&amp;quot;: [
        {
            &amp;quot;group&amp;quot;: &amp;quot;N/A&amp;quot;,
            &amp;quot;name&amp;quot;: &amp;quot;node00&amp;quot;
        }
      ]
    }
  ],
  &amp;quot;hostname&amp;quot;: &amp;quot;node00&amp;quot;,
  &amp;quot;state&amp;quot;: &amp;quot;AVAILABLE&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1578627668686,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;port&amp;quot;: 22,
  &amp;quot;resources&amp;quot;: [
    {
      &amp;quot;name&amp;quot;: &amp;quot;CPU&amp;quot;,
      &amp;quot;value&amp;quot;: 6.0,
      &amp;quot;unit&amp;quot;: &amp;quot;cores&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Memory&amp;quot;,
      &amp;quot;value&amp;quot;: 10.496479034423828,
      &amp;quot;unit&amp;quot;: &amp;quot;GB&amp;quot;
    }
  ],
  &amp;quot;user&amp;quot;: &amp;quot;abc&amp;quot;,
  &amp;quot;password&amp;quot;: &amp;quot;pwd&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;update-a-node&#34;&gt;update a node&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/nodes/${name}&lt;/em&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;hostname (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; hostname of node&lt;/li&gt;
&lt;li&gt;port (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; ssh port of node&lt;/li&gt;
&lt;li&gt;user (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; ssh account&lt;/li&gt;
&lt;li&gt;password (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; ssh password&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Example Request
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;port&amp;quot;: 9999
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    An new node will be created if your input name does not exist
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    the update request will clear the validation report attached to this
node
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;services&amp;quot;: [
    {
      &amp;quot;name&amp;quot;: &amp;quot;zookeeper&amp;quot;,
      &amp;quot;clusterKeys&amp;quot;: []
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;broker&amp;quot;,
      &amp;quot;clusterKeys&amp;quot;: []
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;connect-worker&amp;quot;,
      &amp;quot;clusterKeys&amp;quot;: []
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;stream&amp;quot;,
      &amp;quot;clusterKeys&amp;quot;: []
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;configurator&amp;quot;,
      &amp;quot;clusterKeys&amp;quot;: [
        {
            &amp;quot;group&amp;quot;: &amp;quot;N/A&amp;quot;,
            &amp;quot;name&amp;quot;: &amp;quot;node00&amp;quot;
        }
      ]
    }
  ],
  &amp;quot;hostname&amp;quot;: &amp;quot;node00&amp;quot;,
  &amp;quot;state&amp;quot;: &amp;quot;AVAILABLE&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1578627668686,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;port&amp;quot;: 9999,
  &amp;quot;resources&amp;quot;: [
    {
      &amp;quot;name&amp;quot;: &amp;quot;CPU&amp;quot;,
      &amp;quot;value&amp;quot;: 6.0,
      &amp;quot;unit&amp;quot;: &amp;quot;cores&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Memory&amp;quot;,
      &amp;quot;value&amp;quot;: 10.496479034423828,
      &amp;quot;unit&amp;quot;: &amp;quot;GB&amp;quot;
    }
  ],
  &amp;quot;user&amp;quot;: &amp;quot;abc&amp;quot;,
  &amp;quot;password&amp;quot;: &amp;quot;pwd&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;list-all-nodes-stored-in-ohara&#34;&gt;list all nodes stored in Ohara&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/nodes&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
  {
    &amp;quot;services&amp;quot;: [
      {
        &amp;quot;name&amp;quot;: &amp;quot;zookeeper&amp;quot;,
        &amp;quot;clusterKeys&amp;quot;: []
      },
      {
        &amp;quot;name&amp;quot;: &amp;quot;broker&amp;quot;,
        &amp;quot;clusterKeys&amp;quot;: []
      },
      {
        &amp;quot;name&amp;quot;: &amp;quot;connect-worker&amp;quot;,
        &amp;quot;clusterKeys&amp;quot;: []
      },
      {
        &amp;quot;name&amp;quot;: &amp;quot;stream&amp;quot;,
        &amp;quot;clusterKeys&amp;quot;: []
      },
      {
        &amp;quot;name&amp;quot;: &amp;quot;configurator&amp;quot;,
        &amp;quot;clusterKeys&amp;quot;: [
          {
              &amp;quot;group&amp;quot;: &amp;quot;N/A&amp;quot;,
              &amp;quot;name&amp;quot;: &amp;quot;node00&amp;quot;
          }
        ]
      }
    ],
    &amp;quot;hostname&amp;quot;: &amp;quot;node00&amp;quot;,
    &amp;quot;state&amp;quot;: &amp;quot;AVAILABLE&amp;quot;,
    &amp;quot;lastModified&amp;quot;: 1578627668686,
    &amp;quot;tags&amp;quot;: {},
    &amp;quot;port&amp;quot;: 22,
    &amp;quot;resources&amp;quot;: [
      {
        &amp;quot;name&amp;quot;: &amp;quot;CPU&amp;quot;,
        &amp;quot;value&amp;quot;: 6.0,
        &amp;quot;unit&amp;quot;: &amp;quot;cores&amp;quot;
      },
      {
        &amp;quot;name&amp;quot;: &amp;quot;Memory&amp;quot;,
        &amp;quot;value&amp;quot;: 10.496479034423828,
        &amp;quot;unit&amp;quot;: &amp;quot;GB&amp;quot;
      }
    ],
    &amp;quot;user&amp;quot;: &amp;quot;abc&amp;quot;,
    &amp;quot;password&amp;quot;: &amp;quot;pwd&amp;quot;
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;delete-a-node&#34;&gt;delete a node&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;DELETE /v0/nodes/${name}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;204 NoContent
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    It is ok to delete a nonexistent pipeline, and the response is
204 NoContent. However, it is disallowed to remove a node which is
running service. If you do want to delete the node from Ohara,
please stop all services from the node.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;get-a-node&#34;&gt;get a node&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/nodes/${name}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;services&amp;quot;: [
    {
      &amp;quot;name&amp;quot;: &amp;quot;zookeeper&amp;quot;,
      &amp;quot;clusterKeys&amp;quot;: []
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;broker&amp;quot;,
      &amp;quot;clusterKeys&amp;quot;: []
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;connect-worker&amp;quot;,
      &amp;quot;clusterKeys&amp;quot;: []
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;stream&amp;quot;,
      &amp;quot;clusterKeys&amp;quot;: []
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;configurator&amp;quot;,
      &amp;quot;clusterKeys&amp;quot;: [
        {
            &amp;quot;group&amp;quot;: &amp;quot;N/A&amp;quot;,
            &amp;quot;name&amp;quot;: &amp;quot;node00&amp;quot;
        }
      ]
    }
  ],
  &amp;quot;hostname&amp;quot;: &amp;quot;node00&amp;quot;,
  &amp;quot;state&amp;quot;: &amp;quot;AVAILABLE&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1578627668686,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;port&amp;quot;: 22,
  &amp;quot;resources&amp;quot;: [
    {
      &amp;quot;name&amp;quot;: &amp;quot;CPU&amp;quot;,
      &amp;quot;value&amp;quot;: 6.0,
      &amp;quot;unit&amp;quot;: &amp;quot;cores&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Memory&amp;quot;,
      &amp;quot;value&amp;quot;: 10.496479034423828,
      &amp;quot;unit&amp;quot;: &amp;quot;GB&amp;quot;
    }
  ],
  &amp;quot;user&amp;quot;: &amp;quot;abc&amp;quot;,
  &amp;quot;password&amp;quot;: &amp;quot;pwd&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Object</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/rest-api/objects/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/rest-api/objects/</guid>
      <description>&lt;p&gt;Object APIs offer a way to store anything to Configurator. It is useful
when you have something temporary and you have no other way to store
them.&lt;/p&gt;
&lt;p&gt;Similar to other APIs, the required fields are &amp;ldquo;name&amp;rdquo; and &amp;ldquo;group&amp;rdquo;.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; name of object. The legal character is number,
lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; group of object. The legal character is
number, lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;tags (&lt;strong&gt;option(object)&lt;/strong&gt;) &amp;mdash; the extra description to this object&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The following information are updated at run-time.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;lastModified (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; the last time to update this node&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;store-a-object&#34;&gt;store a object&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;POST /v0/objects&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;n0&amp;quot;,
  &amp;quot;k&amp;quot;: &amp;quot;v&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;n0&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1579071742763,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;k&amp;quot;: &amp;quot;v&amp;quot;,
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;update-a-object&#34;&gt;update a object&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/objects/${name}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;k0&amp;quot;: &amp;quot;v0&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;n0&amp;quot;,
  &amp;quot;k0&amp;quot;: &amp;quot;v0&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1579072298657,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;k&amp;quot;: &amp;quot;v&amp;quot;,
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;list-all-objects&#34;&gt;list all objects&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/objects&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
  {
    &amp;quot;name&amp;quot;: &amp;quot;n0&amp;quot;,
    &amp;quot;k0&amp;quot;: &amp;quot;v1000000&amp;quot;,
    &amp;quot;lastModified&amp;quot;: 1579072345437,
    &amp;quot;tags&amp;quot;: {},
    &amp;quot;k&amp;quot;: &amp;quot;v&amp;quot;,
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;delete-a-node&#34;&gt;delete a node&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;DELETE /v0/objects/${name}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;204 NoContent
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;get-a-object&#34;&gt;get a object&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/objects/${name}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;n0&amp;quot;,
  &amp;quot;k0&amp;quot;: &amp;quot;v0&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1579072345437,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;k&amp;quot;: &amp;quot;v&amp;quot;,
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Object</title>
      <link>https://oharastream.github.io/en/docs/master/rest-api/objects/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/master/rest-api/objects/</guid>
      <description>&lt;p&gt;Object APIs offer a way to store anything to Configurator. It is useful
when you have something temporary and you have no other way to store
them.&lt;/p&gt;
&lt;p&gt;Similar to other APIs, the required fields are &amp;ldquo;name&amp;rdquo; and &amp;ldquo;group&amp;rdquo;.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; name of object. The legal character is number,
lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; group of object. The legal character is
number, lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;tags (&lt;strong&gt;option(object)&lt;/strong&gt;) &amp;mdash; the extra description to this object&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The following information are updated at run-time.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;lastModified (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; the last time to update this node&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;store-a-object&#34;&gt;store a object&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;POST /v0/objects&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;n0&amp;quot;,
  &amp;quot;k&amp;quot;: &amp;quot;v&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;n0&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1579071742763,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;k&amp;quot;: &amp;quot;v&amp;quot;,
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;update-a-object&#34;&gt;update a object&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/objects/${name}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;k0&amp;quot;: &amp;quot;v0&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;n0&amp;quot;,
  &amp;quot;k0&amp;quot;: &amp;quot;v0&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1579072298657,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;k&amp;quot;: &amp;quot;v&amp;quot;,
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;list-all-objects&#34;&gt;list all objects&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/objects&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
  {
    &amp;quot;name&amp;quot;: &amp;quot;n0&amp;quot;,
    &amp;quot;k0&amp;quot;: &amp;quot;v1000000&amp;quot;,
    &amp;quot;lastModified&amp;quot;: 1579072345437,
    &amp;quot;tags&amp;quot;: {},
    &amp;quot;k&amp;quot;: &amp;quot;v&amp;quot;,
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;delete-a-node&#34;&gt;delete a node&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;DELETE /v0/objects/${name}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;204 NoContent
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;get-a-object&#34;&gt;get a object&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/objects/${name}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;n0&amp;quot;,
  &amp;quot;k0&amp;quot;: &amp;quot;v0&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1579072345437,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;k&amp;quot;: &amp;quot;v&amp;quot;,
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Pipeline</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/rest-api/pipelines/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/rest-api/pipelines/</guid>
      <description>&lt;p&gt;Pipeline APIs are born of Ohara manager which needs a way to store the
relationship of components in streaming. The relationship in pipeline is
made up of multi &lt;strong&gt;endpoints&lt;/strong&gt;. Each &lt;strong&gt;endpoint&lt;/strong&gt; describe a component.
For example, you have a 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/topics/&#34;&gt;topic&lt;/a&gt;
as source so you can describe the relationship via following
endpoints.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;endpoints&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;,
      &amp;quot;kind&amp;quot;: &amp;quot;topic&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The objects grouped by pipeline should be existent. Otherwise, pipeline
will ignore them in generating object abstracts.&lt;/p&gt;
&lt;p&gt;The objects grouped by pipeline don&amp;rsquo;t need to located on the same
cluster hierarchy. Grouping a topic, which is placed at broker_0, and a
topic, which is located at broker_1, is valid. However, the object
based on a dead cluster will get an abstract with error state.&lt;/p&gt;
&lt;p&gt;The properties used in generating pipeline are shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; pipeline&amp;rsquo;s group. The legal character is
number, lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; pipeline&amp;rsquo;s name. The legal character is
number, lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;endpoints (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the relationship between objects
&lt;ul&gt;
&lt;li&gt;endpoints[i].group (&lt;strong&gt;String&lt;/strong&gt;) &amp;mdash; the group of this endpoint&lt;/li&gt;
&lt;li&gt;endpoints[i].name (&lt;strong&gt;String&lt;/strong&gt;) &amp;mdash; the name of this endpoint&lt;/li&gt;
&lt;li&gt;endpoints[i].kind (&lt;strong&gt;String&lt;/strong&gt;) &amp;mdash; the kind of this endpoint&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;tags (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the extra description to this object&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Following information are written by Ohara.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;lastModified (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; the last time to update this pipeline&lt;/li&gt;
&lt;li&gt;objects (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the abstract of all objects
mentioned by pipeline
&lt;ul&gt;
&lt;li&gt;objects[i].name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; object&amp;rsquo;s name&lt;/li&gt;
&lt;li&gt;objects[i].kind (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the type of this object. for
instance, 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/topics/&#34;&gt;topic&lt;/a&gt;,

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/connectors/&#34;&gt;connector&lt;/a&gt;, and

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/streams/&#34;&gt;stream&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;objects[i].className (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; object&amp;rsquo;s implementation.
Normally, it shows the full name of a java class&lt;/li&gt;
&lt;li&gt;objects[i].state (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the state of object.
If the object can&amp;rsquo;t have state (eg, 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/topics/&#34;&gt;topic&lt;/a&gt;),
you won&amp;rsquo;t see this field&lt;/li&gt;
&lt;li&gt;objects[i].error (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the error message of
this object&lt;/li&gt;
&lt;li&gt;objects[i].lastModified (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; the last time to update
this object&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/custom_connector/#metrics&#34;&gt;nodeMetrics&lt;/a&gt; (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash;
the metrics from this object. Not all objects in pipeline have metrics!&lt;/li&gt;
&lt;li&gt;meters (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the metrics in meter type&lt;/li&gt;
&lt;li&gt;meters[i].value (&lt;strong&gt;double&lt;/strong&gt;) &amp;mdash; the number stored in meter&lt;/li&gt;
&lt;li&gt;meters[i].unit (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; unit for value&lt;/li&gt;
&lt;li&gt;meters[i].document (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; document of this meter&lt;/li&gt;
&lt;li&gt;meters[i].queryTime (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; the time of query metrics
from remote machine&lt;/li&gt;
&lt;li&gt;meters[i].startTime (&lt;strong&gt;option(long)&lt;/strong&gt;) &amp;mdash; the time of record
generated in remote machine&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;jarKeys (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the jars used by the objects in
pipeline.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;create-a-pipeline&#34;&gt;create a pipeline&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;POST /v0/pipelines&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The following example creates a pipeline with a

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/topics/&#34;&gt;topic&lt;/a&gt; and 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/connectors/&#34;&gt;connector&lt;/a&gt;.
The 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/topics/&#34;&gt;topic&lt;/a&gt; is created on 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/brokers/&#34;&gt;broker cluster&lt;/a&gt;
but the 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/connectors/&#34;&gt;connector&lt;/a&gt; isn&amp;rsquo;t.
Hence, the response from server shows that it fails to find the status
of the 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/connectors/&#34;&gt;connector&lt;/a&gt;. That
is to say, it is ok to add un-running 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/connectors/&#34;&gt;connector&lt;/a&gt; to pipeline.&lt;/p&gt;
&lt;p&gt;Allow setting the not exists object for the endpoint. The object
resposne value is empty.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request 1 - Running single topic example&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;pipeline0&amp;quot;,
  &amp;quot;endpoints&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;,
      &amp;quot;kind&amp;quot;: &amp;quot;topic&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response 1&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;pipeline0&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1578639344607,
  &amp;quot;endpoints&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;,
      &amp;quot;kind&amp;quot;: &amp;quot;topic&amp;quot;
    }
  ],
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;objects&amp;quot;: [
    {
      &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;,
      &amp;quot;state&amp;quot;: &amp;quot;RUNNING&amp;quot;,
      &amp;quot;lastModified&amp;quot;: 1578635914746,
      &amp;quot;tags&amp;quot;: {},
      &amp;quot;nodeMetrics&amp;quot;: [],
      &amp;quot;kind&amp;quot;: &amp;quot;topic&amp;quot;,
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
    }
  ],
  &amp;quot;jarKeys&amp;quot;: [],
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Request 2 - Running topic and perf connector example&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;pipeline1&amp;quot;,
  &amp;quot;endpoints&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;,
      &amp;quot;kind&amp;quot;: &amp;quot;topic&amp;quot;
    },
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;perf&amp;quot;,
      &amp;quot;kind&amp;quot;: &amp;quot;connector&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response 2&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;pipeline1&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1578649709850,
  &amp;quot;endpoints&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;,
      &amp;quot;kind&amp;quot;: &amp;quot;topic&amp;quot;
    },
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;perf&amp;quot;,
      &amp;quot;kind&amp;quot;: &amp;quot;connector&amp;quot;
    }
  ],
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;objects&amp;quot;: [
    {
      &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;,
      &amp;quot;state&amp;quot;: &amp;quot;RUNNING&amp;quot;,
      &amp;quot;lastModified&amp;quot;: 1578649564486,
      &amp;quot;tags&amp;quot;: {},
      &amp;quot;nodeMetrics&amp;quot;: [],
      &amp;quot;kind&amp;quot;: &amp;quot;topic&amp;quot;,
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;perf&amp;quot;,
      &amp;quot;state&amp;quot;: &amp;quot;RUNNING&amp;quot;,
      &amp;quot;lastModified&amp;quot;: 1578649620960,
      &amp;quot;tags&amp;quot;: {},
      &amp;quot;className&amp;quot;: &amp;quot;oharastream.ohara.connector.perf.PerfSource&amp;quot;,
      &amp;quot;nodeMetrics&amp;quot;: [],
      &amp;quot;kind&amp;quot;: &amp;quot;source&amp;quot;,
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
    }
  ],
  &amp;quot;jarKeys&amp;quot;: [],
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;update-a-pipeline&#34;&gt;update a pipeline&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/pipelines/$name&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Request
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;endpoints&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic1&amp;quot;,
      &amp;quot;kind&amp;quot;: &amp;quot;topic&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    This API creates a new pipeline for you if the input name does not exist!
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;pipeline0&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1578641282237,
  &amp;quot;endpoints&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic1&amp;quot;,
      &amp;quot;kind&amp;quot;: &amp;quot;topic&amp;quot;
    }
  ],
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;objects&amp;quot;: [
    {
      &amp;quot;name&amp;quot;: &amp;quot;topic1&amp;quot;,
      &amp;quot;state&amp;quot;: &amp;quot;RUNNING&amp;quot;,
      &amp;quot;lastModified&amp;quot;: 1578641231579,
      &amp;quot;tags&amp;quot;: {},
      &amp;quot;nodeMetrics&amp;quot;: [],
      &amp;quot;kind&amp;quot;: &amp;quot;topic&amp;quot;,
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
    }
  ],
  &amp;quot;jarKeys&amp;quot;: [],
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;list-all-pipelines&#34;&gt;list all pipelines&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/pipelines&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Listing all pipelines is a expensive operation as it invokes a iteration
to all objects stored in pipeline. The loop will do a lot of checks and
fetch status, metrics and log from backend clusters. If you have the
name of pipeline, please use 
&lt;a href=&#34;#get&#34;&gt;GET&lt;/a&gt; to fetch
details of &lt;strong&gt;single&lt;/strong&gt; pipeline.&lt;/p&gt;
&lt;p&gt;the accepted query keys are listed below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;group&lt;/li&gt;
&lt;li&gt;name&lt;/li&gt;
&lt;li&gt;jarKeys&lt;/li&gt;
&lt;li&gt;lastModified&lt;/li&gt;
&lt;li&gt;tags&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
  {
    &amp;quot;name&amp;quot;: &amp;quot;pipeline0&amp;quot;,
    &amp;quot;lastModified&amp;quot;: 1578641282237,
    &amp;quot;endpoints&amp;quot;: [
      {
        &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
        &amp;quot;name&amp;quot;: &amp;quot;topic1&amp;quot;,
        &amp;quot;kind&amp;quot;: &amp;quot;topic&amp;quot;
      }
    ],
    &amp;quot;tags&amp;quot;: {},
    &amp;quot;objects&amp;quot;: [
      {
        &amp;quot;name&amp;quot;: &amp;quot;topic1&amp;quot;,
        &amp;quot;state&amp;quot;: &amp;quot;RUNNING&amp;quot;,
        &amp;quot;lastModified&amp;quot;: 1578641231579,
        &amp;quot;tags&amp;quot;: {},
        &amp;quot;nodeMetrics&amp;quot;: [],
        &amp;quot;kind&amp;quot;: &amp;quot;topic&amp;quot;,
          &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
        }
    ],
    &amp;quot;jarKeys&amp;quot;: [],
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;GET /v0/pipelines?name=${pipelineName}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
  {
    &amp;quot;name&amp;quot;: &amp;quot;pipeline0&amp;quot;,
    &amp;quot;lastModified&amp;quot;: 1578647223700,
    &amp;quot;endpoints&amp;quot;: [
      {
        &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
        &amp;quot;name&amp;quot;: &amp;quot;topic1&amp;quot;,
        &amp;quot;kind&amp;quot;: &amp;quot;topic&amp;quot;
      }
    ],
    &amp;quot;tags&amp;quot;: {},
    &amp;quot;objects&amp;quot;: [],
    &amp;quot;jarKeys&amp;quot;: [],
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;delete-a-pipeline&#34;&gt;delete a pipeline&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;DELETE /v0/pipelines/$name&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Deleting a pipeline does not delete the objects related to the pipeline.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;204 NoContent
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    It is ok to delete a nonexistent pipeline, and the response is
204 NoContent. However, it is illegal to remove a pipeline having
any running objects
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;get&#34;&gt;get a pipeline&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/pipelines/$name&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;pipeline0&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1578647223700,
  &amp;quot;endpoints&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic1&amp;quot;,
      &amp;quot;kind&amp;quot;: &amp;quot;topic&amp;quot;
    }
  ],
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;objects&amp;quot;: [],
  &amp;quot;jarKeys&amp;quot;: [],
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The field &amp;ldquo;objects&amp;rdquo; displays only existent endpoints.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;refresh-a-pipeline&#34;&gt;refresh a pipeline&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/pipelines/$name/refresh&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Requires Ohara Configurator to cleanup nonexistent objects of pipeline.
Pipeline is a group of objects and it contains, sometimes, some
nonexistent objects. Those nonexistent objects won&amp;rsquo;t hurt our services
but it may be ugly and weird to read. Hence, the (helper) API do a
background cleanup for your pipeline. The cleanup rules are shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;the endpoint having nonexistent &amp;ldquo;from&amp;rdquo; is removed&lt;/li&gt;
&lt;li&gt;the objects in &amp;ldquo;to&amp;rdquo; get removed&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#get&#34;&gt;Get pipeline&lt;/a&gt; to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Pipeline</title>
      <link>https://oharastream.github.io/en/docs/master/rest-api/pipelines/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/master/rest-api/pipelines/</guid>
      <description>&lt;p&gt;Pipeline APIs are born of Ohara manager which needs a way to store the
relationship of components in streaming. The relationship in pipeline is
made up of multi &lt;strong&gt;endpoints&lt;/strong&gt;. Each &lt;strong&gt;endpoint&lt;/strong&gt; describe a component.
For example, you have a 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/topics/&#34;&gt;topic&lt;/a&gt;
as source so you can describe the relationship via following
endpoints.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;endpoints&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;,
      &amp;quot;kind&amp;quot;: &amp;quot;topic&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The objects grouped by pipeline should be existent. Otherwise, pipeline
will ignore them in generating object abstracts.&lt;/p&gt;
&lt;p&gt;The objects grouped by pipeline don&amp;rsquo;t need to located on the same
cluster hierarchy. Grouping a topic, which is placed at broker_0, and a
topic, which is located at broker_1, is valid. However, the object
based on a dead cluster will get an abstract with error state.&lt;/p&gt;
&lt;p&gt;The properties used in generating pipeline are shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; pipeline&amp;rsquo;s group. The legal character is
number, lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; pipeline&amp;rsquo;s name. The legal character is
number, lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;endpoints (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the relationship between objects
&lt;ul&gt;
&lt;li&gt;endpoints[i].group (&lt;strong&gt;String&lt;/strong&gt;) &amp;mdash; the group of this endpoint&lt;/li&gt;
&lt;li&gt;endpoints[i].name (&lt;strong&gt;String&lt;/strong&gt;) &amp;mdash; the name of this endpoint&lt;/li&gt;
&lt;li&gt;endpoints[i].kind (&lt;strong&gt;String&lt;/strong&gt;) &amp;mdash; the kind of this endpoint&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;tags (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the extra description to this object&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Following information are written by Ohara.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;lastModified (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; the last time to update this pipeline&lt;/li&gt;
&lt;li&gt;objects (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the abstract of all objects
mentioned by pipeline
&lt;ul&gt;
&lt;li&gt;objects[i].name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; object&amp;rsquo;s name&lt;/li&gt;
&lt;li&gt;objects[i].kind (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the type of this object. for
instance, 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/topics/&#34;&gt;topic&lt;/a&gt;,

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/connectors/&#34;&gt;connector&lt;/a&gt;, and

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/streams/&#34;&gt;stream&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;objects[i].className (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; object&amp;rsquo;s implementation.
Normally, it shows the full name of a java class&lt;/li&gt;
&lt;li&gt;objects[i].state (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the state of object.
If the object can&amp;rsquo;t have state (eg, 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/topics/&#34;&gt;topic&lt;/a&gt;),
you won&amp;rsquo;t see this field&lt;/li&gt;
&lt;li&gt;objects[i].error (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the error message of
this object&lt;/li&gt;
&lt;li&gt;objects[i].lastModified (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; the last time to update
this object&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/custom_connector/#metrics&#34;&gt;nodeMetrics&lt;/a&gt; (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash;
the metrics from this object. Not all objects in pipeline have metrics!&lt;/li&gt;
&lt;li&gt;meters (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the metrics in meter type&lt;/li&gt;
&lt;li&gt;meters[i].value (&lt;strong&gt;double&lt;/strong&gt;) &amp;mdash; the number stored in meter&lt;/li&gt;
&lt;li&gt;meters[i].unit (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; unit for value&lt;/li&gt;
&lt;li&gt;meters[i].document (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; document of this meter&lt;/li&gt;
&lt;li&gt;meters[i].queryTime (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; the time of query metrics
from remote machine&lt;/li&gt;
&lt;li&gt;meters[i].startTime (&lt;strong&gt;option(long)&lt;/strong&gt;) &amp;mdash; the time of record
generated in remote machine&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;jarKeys (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the jars used by the objects in
pipeline.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;create-a-pipeline&#34;&gt;create a pipeline&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;POST /v0/pipelines&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The following example creates a pipeline with a

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/topics/&#34;&gt;topic&lt;/a&gt; and 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/connectors/&#34;&gt;connector&lt;/a&gt;.
The 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/topics/&#34;&gt;topic&lt;/a&gt; is created on 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/brokers/&#34;&gt;broker cluster&lt;/a&gt;
but the 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/connectors/&#34;&gt;connector&lt;/a&gt; isn&amp;rsquo;t.
Hence, the response from server shows that it fails to find the status
of the 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/connectors/&#34;&gt;connector&lt;/a&gt;. That
is to say, it is ok to add un-running 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/connectors/&#34;&gt;connector&lt;/a&gt; to pipeline.&lt;/p&gt;
&lt;p&gt;Allow setting the not exists object for the endpoint. The object
resposne value is empty.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request 1 - Running single topic example&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;pipeline0&amp;quot;,
  &amp;quot;endpoints&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;,
      &amp;quot;kind&amp;quot;: &amp;quot;topic&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response 1&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;pipeline0&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1578639344607,
  &amp;quot;endpoints&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;,
      &amp;quot;kind&amp;quot;: &amp;quot;topic&amp;quot;
    }
  ],
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;objects&amp;quot;: [
    {
      &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;,
      &amp;quot;state&amp;quot;: &amp;quot;RUNNING&amp;quot;,
      &amp;quot;lastModified&amp;quot;: 1578635914746,
      &amp;quot;tags&amp;quot;: {},
      &amp;quot;nodeMetrics&amp;quot;: [],
      &amp;quot;kind&amp;quot;: &amp;quot;topic&amp;quot;,
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
    }
  ],
  &amp;quot;jarKeys&amp;quot;: [],
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Request 2 - Running topic and perf connector example&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;pipeline1&amp;quot;,
  &amp;quot;endpoints&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;,
      &amp;quot;kind&amp;quot;: &amp;quot;topic&amp;quot;
    },
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;perf&amp;quot;,
      &amp;quot;kind&amp;quot;: &amp;quot;connector&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response 2&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;pipeline1&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1578649709850,
  &amp;quot;endpoints&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;,
      &amp;quot;kind&amp;quot;: &amp;quot;topic&amp;quot;
    },
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;perf&amp;quot;,
      &amp;quot;kind&amp;quot;: &amp;quot;connector&amp;quot;
    }
  ],
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;objects&amp;quot;: [
    {
      &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;,
      &amp;quot;state&amp;quot;: &amp;quot;RUNNING&amp;quot;,
      &amp;quot;lastModified&amp;quot;: 1578649564486,
      &amp;quot;tags&amp;quot;: {},
      &amp;quot;nodeMetrics&amp;quot;: [],
      &amp;quot;kind&amp;quot;: &amp;quot;topic&amp;quot;,
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;perf&amp;quot;,
      &amp;quot;state&amp;quot;: &amp;quot;RUNNING&amp;quot;,
      &amp;quot;lastModified&amp;quot;: 1578649620960,
      &amp;quot;tags&amp;quot;: {},
      &amp;quot;className&amp;quot;: &amp;quot;oharastream.ohara.connector.perf.PerfSource&amp;quot;,
      &amp;quot;nodeMetrics&amp;quot;: [],
      &amp;quot;kind&amp;quot;: &amp;quot;source&amp;quot;,
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
    }
  ],
  &amp;quot;jarKeys&amp;quot;: [],
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;update-a-pipeline&#34;&gt;update a pipeline&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/pipelines/$name&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Request
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;endpoints&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic1&amp;quot;,
      &amp;quot;kind&amp;quot;: &amp;quot;topic&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    This API creates a new pipeline for you if the input name does not exist!
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;pipeline0&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1578641282237,
  &amp;quot;endpoints&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic1&amp;quot;,
      &amp;quot;kind&amp;quot;: &amp;quot;topic&amp;quot;
    }
  ],
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;objects&amp;quot;: [
    {
      &amp;quot;name&amp;quot;: &amp;quot;topic1&amp;quot;,
      &amp;quot;state&amp;quot;: &amp;quot;RUNNING&amp;quot;,
      &amp;quot;lastModified&amp;quot;: 1578641231579,
      &amp;quot;tags&amp;quot;: {},
      &amp;quot;nodeMetrics&amp;quot;: [],
      &amp;quot;kind&amp;quot;: &amp;quot;topic&amp;quot;,
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
    }
  ],
  &amp;quot;jarKeys&amp;quot;: [],
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;list-all-pipelines&#34;&gt;list all pipelines&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/pipelines&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Listing all pipelines is a expensive operation as it invokes a iteration
to all objects stored in pipeline. The loop will do a lot of checks and
fetch status, metrics and log from backend clusters. If you have the
name of pipeline, please use 
&lt;a href=&#34;#get&#34;&gt;GET&lt;/a&gt; to fetch
details of &lt;strong&gt;single&lt;/strong&gt; pipeline.&lt;/p&gt;
&lt;p&gt;the accepted query keys are listed below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;group&lt;/li&gt;
&lt;li&gt;name&lt;/li&gt;
&lt;li&gt;jarKeys&lt;/li&gt;
&lt;li&gt;lastModified&lt;/li&gt;
&lt;li&gt;tags&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
  {
    &amp;quot;name&amp;quot;: &amp;quot;pipeline0&amp;quot;,
    &amp;quot;lastModified&amp;quot;: 1578641282237,
    &amp;quot;endpoints&amp;quot;: [
      {
        &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
        &amp;quot;name&amp;quot;: &amp;quot;topic1&amp;quot;,
        &amp;quot;kind&amp;quot;: &amp;quot;topic&amp;quot;
      }
    ],
    &amp;quot;tags&amp;quot;: {},
    &amp;quot;objects&amp;quot;: [
      {
        &amp;quot;name&amp;quot;: &amp;quot;topic1&amp;quot;,
        &amp;quot;state&amp;quot;: &amp;quot;RUNNING&amp;quot;,
        &amp;quot;lastModified&amp;quot;: 1578641231579,
        &amp;quot;tags&amp;quot;: {},
        &amp;quot;nodeMetrics&amp;quot;: [],
        &amp;quot;kind&amp;quot;: &amp;quot;topic&amp;quot;,
          &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
        }
    ],
    &amp;quot;jarKeys&amp;quot;: [],
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;GET /v0/pipelines?name=${pipelineName}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
  {
    &amp;quot;name&amp;quot;: &amp;quot;pipeline0&amp;quot;,
    &amp;quot;lastModified&amp;quot;: 1578647223700,
    &amp;quot;endpoints&amp;quot;: [
      {
        &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
        &amp;quot;name&amp;quot;: &amp;quot;topic1&amp;quot;,
        &amp;quot;kind&amp;quot;: &amp;quot;topic&amp;quot;
      }
    ],
    &amp;quot;tags&amp;quot;: {},
    &amp;quot;objects&amp;quot;: [],
    &amp;quot;jarKeys&amp;quot;: [],
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;delete-a-pipeline&#34;&gt;delete a pipeline&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;DELETE /v0/pipelines/$name&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Deleting a pipeline does not delete the objects related to the pipeline.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;204 NoContent
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    It is ok to delete a nonexistent pipeline, and the response is
204 NoContent. However, it is illegal to remove a pipeline having
any running objects
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;get&#34;&gt;get a pipeline&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/pipelines/$name&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;pipeline0&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1578647223700,
  &amp;quot;endpoints&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic1&amp;quot;,
      &amp;quot;kind&amp;quot;: &amp;quot;topic&amp;quot;
    }
  ],
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;objects&amp;quot;: [],
  &amp;quot;jarKeys&amp;quot;: [],
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The field &amp;ldquo;objects&amp;rdquo; displays only existent endpoints.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;refresh-a-pipeline&#34;&gt;refresh a pipeline&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/pipelines/$name/refresh&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Requires Ohara Configurator to cleanup nonexistent objects of pipeline.
Pipeline is a group of objects and it contains, sometimes, some
nonexistent objects. Those nonexistent objects won&amp;rsquo;t hurt our services
but it may be ugly and weird to read. Hence, the (helper) API do a
background cleanup for your pipeline. The cleanup rules are shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;the endpoint having nonexistent &amp;ldquo;from&amp;rdquo; is removed&lt;/li&gt;
&lt;li&gt;the objects in &amp;ldquo;to&amp;rdquo; get removed&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#get&#34;&gt;Get pipeline&lt;/a&gt; to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Shabondi</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/rest-api/shabondis/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/rest-api/shabondis/</guid>
      <description>&lt;p&gt;Shabondi service play the role of a http proxy service in the Pipeline.
Just like connector, there have two kinds of Shabondi service:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source: &lt;strong&gt;Shabondi source service&lt;/strong&gt; receives data from http request
and then writes the data into the linked topic.&lt;/li&gt;
&lt;li&gt;Sink: Users can use http request to read topic data through
&lt;strong&gt;Shabondi sink service&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following are common setting both Shabondi source and sink:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the value of group is always &amp;ldquo;default&amp;rdquo;. The
legal character is number, lowercase alphanumeric characters, or &lt;code&gt;.&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the name of this connector. The legal
character is number, lowercase alphanumeric characters, or &lt;code&gt;.&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;brokerClusterKey (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the broker cluster used to store
data generated by this worker cluster
&lt;ul&gt;
&lt;li&gt;brokerClusterKey.group (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the group of
cluster&lt;/li&gt;
&lt;li&gt;brokerClusterKey.name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the name of cluster&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    the following forms are legal as well: (1) &lt;code&gt;{&amp;quot;name&amp;quot;: &amp;quot;n&amp;quot;}&lt;/code&gt;, (2) &lt;code&gt;&amp;quot;n&amp;quot;&lt;/code&gt;.
Both forms are converted to &lt;code&gt;{&amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;n&amp;quot;}&lt;/code&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;shabondi.class (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; class name of Shabondi service, only
the following two class names are legal:
&lt;ul&gt;
&lt;li&gt;Shabondi source: &lt;code&gt;oharastream.ohara.shabondi.ShabondiSource&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Shabondi sink: &lt;code&gt;oharastream.ohara.shabondi.ShabondiSink&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;shabondi.client.port (&lt;strong&gt;int&lt;/strong&gt;) - The Shabondi service client port&lt;/li&gt;
&lt;li&gt;imageName (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; docker image&lt;/li&gt;
&lt;li&gt;nodeNames &lt;strong&gt;array(string)&lt;/strong&gt; - The nodes that running this Shabondi.
Currently, Shabondi not support multiple nodes deployment. So
nodeNames only can be contained one node when start shabondi
service, otherwise you&amp;rsquo;ll get an error.&lt;/li&gt;
&lt;li&gt;tags (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the extra parameter for this object&lt;/li&gt;
&lt;li&gt;routes (&lt;strong&gt;object&lt;/strong&gt;) -&lt;/li&gt;
&lt;li&gt;jmxPort (&lt;strong&gt;int&lt;/strong&gt;) - the JVM jmx port for Shabondi service&lt;/li&gt;
&lt;li&gt;xms (&lt;strong&gt;int&lt;/strong&gt;) - the initial memory allocation pool for JVM&lt;/li&gt;
&lt;li&gt;xmx (&lt;strong&gt;int&lt;/strong&gt;) - the maximum memory allocation pool for JVM&lt;/li&gt;
&lt;li&gt;author (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash;&lt;/li&gt;
&lt;li&gt;revision (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash;&lt;/li&gt;
&lt;li&gt;version (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Shabondi Source only settings&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;shabondi.source.toTopics (&lt;strong&gt;array(object)&lt;/strong&gt;) - The topic which
Shabondi source service would write the data to.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Shabondi Sink only settings&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;shabondi.sink.fromTopics (&lt;strong&gt;array(object)&lt;/strong&gt;) - The topic which
Shabondi sink service would read the data from.&lt;/li&gt;
&lt;li&gt;shabondi.sink.group.idletime (&lt;strong&gt;duration&lt;/strong&gt;) - The maximum idle
time of each sink data group.&lt;/li&gt;
&lt;li&gt;shabondi.sink.poll.timeout(&lt;strong&gt;duration&lt;/strong&gt;) - The maximum time of
each consumer poll.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The following information are updated by Ohara&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;lastModified (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; the last time to update this
shabondi service&lt;/li&gt;
&lt;li&gt;state (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the state of a started shabondi
service&lt;/li&gt;
&lt;li&gt;aliveNodes (&lt;strong&gt;Set(string)&lt;/strong&gt;) &amp;mdash; the nodes hosting this shabondi
service&lt;/li&gt;
&lt;li&gt;error (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the error message from a failed
shabondi service. If the a shabondi service is fine or
un-started, you won&amp;rsquo;t get this field.&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/custom_connector/#metrics&#34;&gt;nodeMetrics&lt;/a&gt; (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash;
the metrics from a running connector
&lt;ul&gt;
&lt;li&gt;meters (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the metrics in meter type
&lt;ul&gt;
&lt;li&gt;meters[i].name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the number of this meter
(normally, it is unique)&lt;/li&gt;
&lt;li&gt;meters[i].value (&lt;strong&gt;double&lt;/strong&gt;) &amp;mdash; the value in double&lt;/li&gt;
&lt;li&gt;meters[i].valueInPerSec (&lt;strong&gt;double&lt;/strong&gt;) &amp;mdash; the average
value in per second&lt;/li&gt;
&lt;li&gt;meters[i].unit (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the unit of value&lt;/li&gt;
&lt;li&gt;meters[i].document (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; human-readable
description to this meter&lt;/li&gt;
&lt;li&gt;meters[i].queryTime (&lt;strong&gt;Long&lt;/strong&gt;) &amp;mdash; the time we query
this meter from remote nodes&lt;/li&gt;
&lt;li&gt;meters[i].startTime (&lt;strong&gt;Long&lt;/strong&gt;) &amp;mdash; the time to start
this meter (not all services offer this record)&lt;/li&gt;
&lt;li&gt;meters[i].lastModified (&lt;strong&gt;Long&lt;/strong&gt;) &amp;mdash; the time of
modifying metrics&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;list-all&#34;&gt;List settings of all Shabondi services&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/shabondis&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
  {
    &amp;quot;author&amp;quot;: &amp;quot;root&amp;quot;,
    &amp;quot;brokerClusterKey&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;group0&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;bk00&amp;quot;
    },
    &amp;quot;name&amp;quot;: &amp;quot;shabondi0&amp;quot;,
    &amp;quot;xms&amp;quot;: 1024,
    &amp;quot;routes&amp;quot;: {},
    &amp;quot;state&amp;quot;: &amp;quot;RUNNING&amp;quot;,
    &amp;quot;lastModified&amp;quot;: 1587100361274,
    &amp;quot;shabondi.client.port&amp;quot;: 58456,
    &amp;quot;shabondi.source.toTopics&amp;quot;: [
      {
        &amp;quot;group&amp;quot;: &amp;quot;group0&amp;quot;,
        &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;
      }
    ],
    &amp;quot;tags&amp;quot;: {},
    &amp;quot;xmx&amp;quot;: 1024,
    &amp;quot;shabondi.class&amp;quot;: &amp;quot;oharastream.ohara.shabondi.ShabondiSource&amp;quot;,
    &amp;quot;nodeMetrics&amp;quot;: {
      &amp;quot;node00&amp;quot;: {
        &amp;quot;meters&amp;quot;: [
          {
            &amp;quot;document&amp;quot;: &amp;quot;The number of received rows&amp;quot;,
            &amp;quot;lastModified&amp;quot;: 1587100347637,
            &amp;quot;name&amp;quot;: &amp;quot;total-rows&amp;quot;,
            &amp;quot;queryTime&amp;quot;: 1587100360577,
            &amp;quot;startTime&amp;quot;: 1587100347637,
            &amp;quot;unit&amp;quot;: &amp;quot;row&amp;quot;,
            &amp;quot;value&amp;quot;: 0.0,
            &amp;quot;valueInPerSec&amp;quot;: 0.0
          }
        ]
      }
    },
    &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/shabondi:0.11.0-SNAPSHOT&amp;quot;,
    &amp;quot;revision&amp;quot;: &amp;quot;7cb25202c5308095546e5a6a2b96480d9d3104e1&amp;quot;,
    &amp;quot;version&amp;quot;: &amp;quot;0.11.0-SNAPSHOT&amp;quot;,
    &amp;quot;aliveNodes&amp;quot;: [
      &amp;quot;node00&amp;quot;
    ],
    &amp;quot;jmxPort&amp;quot;: 56586,
    &amp;quot;kind&amp;quot;: &amp;quot;source&amp;quot;,
    &amp;quot;group&amp;quot;: &amp;quot;group0&amp;quot;,
    &amp;quot;nodeNames&amp;quot;: [
      &amp;quot;node00&amp;quot;
    ]
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;create&#34;&gt;Create the settings of a Shabondi service&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;POST /v0/shabondis&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;shabondi0&amp;quot;,
  &amp;quot;group&amp;quot;: &amp;quot;group0&amp;quot;,
  &amp;quot;shabondi.class&amp;quot;: &amp;quot;oharastream.ohara.shabondi.ShabondiSource&amp;quot;,
  &amp;quot;shabondi.client.port&amp;quot;: 58456,
  &amp;quot;shabondi.source.toTopics&amp;quot;: [
    {&amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;,&amp;quot;group&amp;quot;: &amp;quot;group0&amp;quot;}
  ],
  &amp;quot;brokerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;group0&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;bk00&amp;quot;
  },
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;author&amp;quot;: &amp;quot;root&amp;quot;,
  &amp;quot;brokerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;group0&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;bk00&amp;quot;
  },
  &amp;quot;name&amp;quot;: &amp;quot;shabondi0&amp;quot;,
  &amp;quot;xms&amp;quot;: 1024,
  &amp;quot;routes&amp;quot;: {},
  &amp;quot;lastModified&amp;quot;: 1587101035977,
  &amp;quot;shabondi.client.port&amp;quot;: 58456,
  &amp;quot;shabondi.source.toTopics&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;group0&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;
    }
  ],
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;xmx&amp;quot;: 1024,
  &amp;quot;shabondi.class&amp;quot;: &amp;quot;oharastream.ohara.shabondi.ShabondiSource&amp;quot;,
  &amp;quot;nodeMetrics&amp;quot;: {},
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/shabondi:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;revision&amp;quot;: &amp;quot;7cb25202c5308095546e5a6a2b96480d9d3104e1&amp;quot;,
  &amp;quot;version&amp;quot;: &amp;quot;0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;aliveNodes&amp;quot;: [],
  &amp;quot;jmxPort&amp;quot;: 56726,
  &amp;quot;kind&amp;quot;: &amp;quot;source&amp;quot;,
  &amp;quot;group&amp;quot;: &amp;quot;group0&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;get&#34;&gt;Get the settings of a Shabondi service&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/shabondis/${name}?group=${group}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;author&amp;quot;: &amp;quot;vitojeng&amp;quot;,
  &amp;quot;brokerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;group0&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;bk00&amp;quot;
  },
  &amp;quot;name&amp;quot;: &amp;quot;shabondi0&amp;quot;,
  &amp;quot;xms&amp;quot;: 1024,
  &amp;quot;routes&amp;quot;: {},
  &amp;quot;lastModified&amp;quot;: 1587101035977,
  &amp;quot;shabondi.client.port&amp;quot;: 58456,
  &amp;quot;shabondi.source.toTopics&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;group0&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;
    }
  ],
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;xmx&amp;quot;: 1024,
  &amp;quot;shabondi.class&amp;quot;: &amp;quot;oharastream.ohara.shabondi.ShabondiSource&amp;quot;,
  &amp;quot;nodeMetrics&amp;quot;: {},
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/shabondi:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;revision&amp;quot;: &amp;quot;7cb25202c5308095546e5a6a2b96480d9d3104e1&amp;quot;,
  &amp;quot;version&amp;quot;: &amp;quot;0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;aliveNodes&amp;quot;: [],
  &amp;quot;jmxPort&amp;quot;: 56726,
  &amp;quot;kind&amp;quot;: &amp;quot;source&amp;quot;,
  &amp;quot;group&amp;quot;: &amp;quot;group0&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;update&#34;&gt;Update the settings of a Shabondi service&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/shabondis/${name}?group=${group}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;shabondi.client.port&amp;quot;: 96456
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;author&amp;quot;: &amp;quot;vitojeng&amp;quot;,
  &amp;quot;brokerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;group0&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;bk00&amp;quot;
  },
  &amp;quot;name&amp;quot;: &amp;quot;shabondi0&amp;quot;,
  &amp;quot;xms&amp;quot;: 1024,
  &amp;quot;routes&amp;quot;: {},
  &amp;quot;lastModified&amp;quot;: 1587106367767,
  &amp;quot;shabondi.client.port&amp;quot;: 38400,
  &amp;quot;shabondi.source.toTopics&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;group0&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;
    }
  ],
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;xmx&amp;quot;: 1024,
  &amp;quot;shabondi.class&amp;quot;: &amp;quot;oharastream.ohara.shabondi.ShabondiSource&amp;quot;,
  &amp;quot;nodeMetrics&amp;quot;: {},
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/shabondi:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;revision&amp;quot;: &amp;quot;7cb25202c5308095546e5a6a2b96480d9d3104e1&amp;quot;,
  &amp;quot;version&amp;quot;: &amp;quot;0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;aliveNodes&amp;quot;: [],
  &amp;quot;jmxPort&amp;quot;: 56726,
  &amp;quot;kind&amp;quot;: &amp;quot;source&amp;quot;,
  &amp;quot;group&amp;quot;: &amp;quot;group0&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;delete&#34;&gt;Delete the settings of Shabondi&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;DELETE /v0/shabondis/${name}?group=${group}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    It is ok to delete an nonexistent properties, and the response is
204 NoContent.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;start&#34;&gt;Start a Shabondi service&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/shabondis/${name}/start?group=${group}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#get&#34;&gt;get shabondi&lt;/a&gt; to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;stop&#34;&gt;Stop a Shabondi service&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/shabondis/${name}/stop?group=${group}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#get&#34;&gt;get shabondi&lt;/a&gt; to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Shabondi</title>
      <link>https://oharastream.github.io/en/docs/master/rest-api/shabondis/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/master/rest-api/shabondis/</guid>
      <description>&lt;p&gt;Shabondi service play the role of a http proxy service in the Pipeline.
Just like connector, there have two kinds of Shabondi service:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source: &lt;strong&gt;Shabondi source service&lt;/strong&gt; receives data from http request
and then writes the data into the linked topic.&lt;/li&gt;
&lt;li&gt;Sink: Users can use http request to read topic data through
&lt;strong&gt;Shabondi sink service&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following are common setting both Shabondi source and sink:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the value of group is always &amp;ldquo;default&amp;rdquo;. The
legal character is number, lowercase alphanumeric characters, or &lt;code&gt;.&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the name of this connector. The legal
character is number, lowercase alphanumeric characters, or &lt;code&gt;.&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;brokerClusterKey (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the broker cluster used to store
data generated by this worker cluster
&lt;ul&gt;
&lt;li&gt;brokerClusterKey.group (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the group of
cluster&lt;/li&gt;
&lt;li&gt;brokerClusterKey.name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the name of cluster&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    the following forms are legal as well: (1) &lt;code&gt;{&amp;quot;name&amp;quot;: &amp;quot;n&amp;quot;}&lt;/code&gt;, (2) &lt;code&gt;&amp;quot;n&amp;quot;&lt;/code&gt;.
Both forms are converted to &lt;code&gt;{&amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;n&amp;quot;}&lt;/code&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;shabondi.class (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; class name of Shabondi service, only
the following two class names are legal:
&lt;ul&gt;
&lt;li&gt;Shabondi source: &lt;code&gt;oharastream.ohara.shabondi.ShabondiSource&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Shabondi sink: &lt;code&gt;oharastream.ohara.shabondi.ShabondiSink&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;shabondi.client.port (&lt;strong&gt;int&lt;/strong&gt;) - The Shabondi service client port&lt;/li&gt;
&lt;li&gt;imageName (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; docker image&lt;/li&gt;
&lt;li&gt;nodeNames &lt;strong&gt;array(string)&lt;/strong&gt; - The nodes that running this Shabondi.
Currently, Shabondi not support multiple nodes deployment. So
nodeNames only can be contained one node when start shabondi
service, otherwise you&amp;rsquo;ll get an error.&lt;/li&gt;
&lt;li&gt;tags (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the extra parameter for this object&lt;/li&gt;
&lt;li&gt;routes (&lt;strong&gt;object&lt;/strong&gt;) -&lt;/li&gt;
&lt;li&gt;jmxPort (&lt;strong&gt;int&lt;/strong&gt;) - the JVM jmx port for Shabondi service&lt;/li&gt;
&lt;li&gt;xms (&lt;strong&gt;int&lt;/strong&gt;) - the initial memory allocation pool for JVM&lt;/li&gt;
&lt;li&gt;xmx (&lt;strong&gt;int&lt;/strong&gt;) - the maximum memory allocation pool for JVM&lt;/li&gt;
&lt;li&gt;author (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash;&lt;/li&gt;
&lt;li&gt;revision (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash;&lt;/li&gt;
&lt;li&gt;version (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Shabondi Source only settings&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;shabondi.source.toTopics (&lt;strong&gt;array(object)&lt;/strong&gt;) - The topic which
Shabondi source service would write the data to.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Shabondi Sink only settings&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;shabondi.sink.fromTopics (&lt;strong&gt;array(object)&lt;/strong&gt;) - The topic which
Shabondi sink service would read the data from.&lt;/li&gt;
&lt;li&gt;shabondi.sink.group.idletime (&lt;strong&gt;duration&lt;/strong&gt;) - The maximum idle
time of each sink data group.&lt;/li&gt;
&lt;li&gt;shabondi.sink.poll.timeout(&lt;strong&gt;duration&lt;/strong&gt;) - The maximum time of
each consumer poll.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The following information are updated by Ohara&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;lastModified (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; the last time to update this
shabondi service&lt;/li&gt;
&lt;li&gt;state (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the state of a started shabondi
service&lt;/li&gt;
&lt;li&gt;aliveNodes (&lt;strong&gt;Set(string)&lt;/strong&gt;) &amp;mdash; the nodes hosting this shabondi
service&lt;/li&gt;
&lt;li&gt;error (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the error message from a failed
shabondi service. If the a shabondi service is fine or
un-started, you won&amp;rsquo;t get this field.&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/custom_connector/#metrics&#34;&gt;nodeMetrics&lt;/a&gt; (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash;
the metrics from a running connector
&lt;ul&gt;
&lt;li&gt;meters (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the metrics in meter type
&lt;ul&gt;
&lt;li&gt;meters[i].name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the number of this meter
(normally, it is unique)&lt;/li&gt;
&lt;li&gt;meters[i].value (&lt;strong&gt;double&lt;/strong&gt;) &amp;mdash; the value in double&lt;/li&gt;
&lt;li&gt;meters[i].valueInPerSec (&lt;strong&gt;double&lt;/strong&gt;) &amp;mdash; the average
value in per second&lt;/li&gt;
&lt;li&gt;meters[i].unit (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the unit of value&lt;/li&gt;
&lt;li&gt;meters[i].document (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; human-readable
description to this meter&lt;/li&gt;
&lt;li&gt;meters[i].queryTime (&lt;strong&gt;Long&lt;/strong&gt;) &amp;mdash; the time we query
this meter from remote nodes&lt;/li&gt;
&lt;li&gt;meters[i].startTime (&lt;strong&gt;Long&lt;/strong&gt;) &amp;mdash; the time to start
this meter (not all services offer this record)&lt;/li&gt;
&lt;li&gt;meters[i].lastModified (&lt;strong&gt;Long&lt;/strong&gt;) &amp;mdash; the time of
modifying metrics&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;list-all&#34;&gt;List settings of all Shabondi services&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/shabondis&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
  {
    &amp;quot;author&amp;quot;: &amp;quot;root&amp;quot;,
    &amp;quot;brokerClusterKey&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;group0&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;bk00&amp;quot;
    },
    &amp;quot;name&amp;quot;: &amp;quot;shabondi0&amp;quot;,
    &amp;quot;xms&amp;quot;: 1024,
    &amp;quot;routes&amp;quot;: {},
    &amp;quot;state&amp;quot;: &amp;quot;RUNNING&amp;quot;,
    &amp;quot;lastModified&amp;quot;: 1587100361274,
    &amp;quot;shabondi.client.port&amp;quot;: 58456,
    &amp;quot;shabondi.source.toTopics&amp;quot;: [
      {
        &amp;quot;group&amp;quot;: &amp;quot;group0&amp;quot;,
        &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;
      }
    ],
    &amp;quot;tags&amp;quot;: {},
    &amp;quot;xmx&amp;quot;: 1024,
    &amp;quot;shabondi.class&amp;quot;: &amp;quot;oharastream.ohara.shabondi.ShabondiSource&amp;quot;,
    &amp;quot;nodeMetrics&amp;quot;: {
      &amp;quot;node00&amp;quot;: {
        &amp;quot;meters&amp;quot;: [
          {
            &amp;quot;document&amp;quot;: &amp;quot;The number of received rows&amp;quot;,
            &amp;quot;lastModified&amp;quot;: 1587100347637,
            &amp;quot;name&amp;quot;: &amp;quot;total-rows&amp;quot;,
            &amp;quot;queryTime&amp;quot;: 1587100360577,
            &amp;quot;startTime&amp;quot;: 1587100347637,
            &amp;quot;unit&amp;quot;: &amp;quot;row&amp;quot;,
            &amp;quot;value&amp;quot;: 0.0,
            &amp;quot;valueInPerSec&amp;quot;: 0.0
          }
        ]
      }
    },
    &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/shabondi:0.11.0-SNAPSHOT&amp;quot;,
    &amp;quot;revision&amp;quot;: &amp;quot;7cb25202c5308095546e5a6a2b96480d9d3104e1&amp;quot;,
    &amp;quot;version&amp;quot;: &amp;quot;0.11.0-SNAPSHOT&amp;quot;,
    &amp;quot;aliveNodes&amp;quot;: [
      &amp;quot;node00&amp;quot;
    ],
    &amp;quot;jmxPort&amp;quot;: 56586,
    &amp;quot;kind&amp;quot;: &amp;quot;source&amp;quot;,
    &amp;quot;group&amp;quot;: &amp;quot;group0&amp;quot;,
    &amp;quot;nodeNames&amp;quot;: [
      &amp;quot;node00&amp;quot;
    ]
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;create&#34;&gt;Create the settings of a Shabondi service&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;POST /v0/shabondis&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;shabondi0&amp;quot;,
  &amp;quot;group&amp;quot;: &amp;quot;group0&amp;quot;,
  &amp;quot;shabondi.class&amp;quot;: &amp;quot;oharastream.ohara.shabondi.ShabondiSource&amp;quot;,
  &amp;quot;shabondi.client.port&amp;quot;: 58456,
  &amp;quot;shabondi.source.toTopics&amp;quot;: [
    {&amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;,&amp;quot;group&amp;quot;: &amp;quot;group0&amp;quot;}
  ],
  &amp;quot;brokerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;group0&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;bk00&amp;quot;
  },
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;author&amp;quot;: &amp;quot;root&amp;quot;,
  &amp;quot;brokerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;group0&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;bk00&amp;quot;
  },
  &amp;quot;name&amp;quot;: &amp;quot;shabondi0&amp;quot;,
  &amp;quot;xms&amp;quot;: 1024,
  &amp;quot;routes&amp;quot;: {},
  &amp;quot;lastModified&amp;quot;: 1587101035977,
  &amp;quot;shabondi.client.port&amp;quot;: 58456,
  &amp;quot;shabondi.source.toTopics&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;group0&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;
    }
  ],
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;xmx&amp;quot;: 1024,
  &amp;quot;shabondi.class&amp;quot;: &amp;quot;oharastream.ohara.shabondi.ShabondiSource&amp;quot;,
  &amp;quot;nodeMetrics&amp;quot;: {},
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/shabondi:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;revision&amp;quot;: &amp;quot;7cb25202c5308095546e5a6a2b96480d9d3104e1&amp;quot;,
  &amp;quot;version&amp;quot;: &amp;quot;0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;aliveNodes&amp;quot;: [],
  &amp;quot;jmxPort&amp;quot;: 56726,
  &amp;quot;kind&amp;quot;: &amp;quot;source&amp;quot;,
  &amp;quot;group&amp;quot;: &amp;quot;group0&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;get&#34;&gt;Get the settings of a Shabondi service&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/shabondis/${name}?group=${group}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;author&amp;quot;: &amp;quot;vitojeng&amp;quot;,
  &amp;quot;brokerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;group0&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;bk00&amp;quot;
  },
  &amp;quot;name&amp;quot;: &amp;quot;shabondi0&amp;quot;,
  &amp;quot;xms&amp;quot;: 1024,
  &amp;quot;routes&amp;quot;: {},
  &amp;quot;lastModified&amp;quot;: 1587101035977,
  &amp;quot;shabondi.client.port&amp;quot;: 58456,
  &amp;quot;shabondi.source.toTopics&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;group0&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;
    }
  ],
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;xmx&amp;quot;: 1024,
  &amp;quot;shabondi.class&amp;quot;: &amp;quot;oharastream.ohara.shabondi.ShabondiSource&amp;quot;,
  &amp;quot;nodeMetrics&amp;quot;: {},
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/shabondi:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;revision&amp;quot;: &amp;quot;7cb25202c5308095546e5a6a2b96480d9d3104e1&amp;quot;,
  &amp;quot;version&amp;quot;: &amp;quot;0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;aliveNodes&amp;quot;: [],
  &amp;quot;jmxPort&amp;quot;: 56726,
  &amp;quot;kind&amp;quot;: &amp;quot;source&amp;quot;,
  &amp;quot;group&amp;quot;: &amp;quot;group0&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;update&#34;&gt;Update the settings of a Shabondi service&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/shabondis/${name}?group=${group}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;shabondi.client.port&amp;quot;: 96456
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;author&amp;quot;: &amp;quot;vitojeng&amp;quot;,
  &amp;quot;brokerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;group0&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;bk00&amp;quot;
  },
  &amp;quot;name&amp;quot;: &amp;quot;shabondi0&amp;quot;,
  &amp;quot;xms&amp;quot;: 1024,
  &amp;quot;routes&amp;quot;: {},
  &amp;quot;lastModified&amp;quot;: 1587106367767,
  &amp;quot;shabondi.client.port&amp;quot;: 38400,
  &amp;quot;shabondi.source.toTopics&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;group0&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;
    }
  ],
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;xmx&amp;quot;: 1024,
  &amp;quot;shabondi.class&amp;quot;: &amp;quot;oharastream.ohara.shabondi.ShabondiSource&amp;quot;,
  &amp;quot;nodeMetrics&amp;quot;: {},
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/shabondi:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;revision&amp;quot;: &amp;quot;7cb25202c5308095546e5a6a2b96480d9d3104e1&amp;quot;,
  &amp;quot;version&amp;quot;: &amp;quot;0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;aliveNodes&amp;quot;: [],
  &amp;quot;jmxPort&amp;quot;: 56726,
  &amp;quot;kind&amp;quot;: &amp;quot;source&amp;quot;,
  &amp;quot;group&amp;quot;: &amp;quot;group0&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;delete&#34;&gt;Delete the settings of Shabondi&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;DELETE /v0/shabondis/${name}?group=${group}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    It is ok to delete an nonexistent properties, and the response is
204 NoContent.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;start&#34;&gt;Start a Shabondi service&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/shabondis/${name}/start?group=${group}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#get&#34;&gt;get shabondi&lt;/a&gt; to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;stop&#34;&gt;Stop a Shabondi service&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/shabondis/${name}/stop?group=${group}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#get&#34;&gt;get shabondi&lt;/a&gt; to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Stream</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/rest-api/streams/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/rest-api/streams/</guid>
      <description>&lt;p&gt;Ohara Stream is a unparalleled wrap of kafka streaming. It leverages and
enhances 
&lt;a href=&#34;https://kafka.apache.org/documentation/streams&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kafka Streams&lt;/a&gt;
to make developer easily design and implement the streaming application.
More details of developing streaming application is in

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/custom_stream/&#34;&gt;custom stream guideline&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Assume that you have completed a streaming application via Ohara Java
APIs, and you have generated a jar including your streaming code. By
Ohara Restful APIs, you are enable to control, deploy, and monitor your
streaming application. As with cluster APIs, Ohara leverages docker
container to host streaming application. Of course, you can apply your
favor container management tool including simple (based on ssh) and k8s
when you are starting Ohara.&lt;/p&gt;
&lt;p&gt;Before stating to use restful APIs, please ensure that all nodes have
downloaded the 
&lt;a href=&#34;https://cloud.docker.com/u/oharastream/repository/docker/oharastream/stream&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Stream image&lt;/a&gt;.
The jar you uploaded to run streaming application will be included in
the image and then executes as a docker container.
The 
&lt;a href=&#34;https://cloud.docker.com/u/oharastream/repository/docker/oharastream/stream&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Stream image&lt;/a&gt;
is kept in each node so don&amp;rsquo;t worry about the network. We all hate
re-download everything when running services.&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    If you implement the Ohara stream application, you must pack to jar
file and use the File API upload jar file then setting the jarKey to
create the Stream API.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The following information of Stream are updated by Ohara.&lt;/p&gt;
&lt;h2 id=&#34;stored-data&#34;&gt;stream stored data&lt;/h2&gt;
&lt;p&gt;The following are common settings to a stream app.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; cluster name. The legal character is number,
lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; cluster group. The legal character is number,
lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;jarKey (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the used jar key&lt;/li&gt;
&lt;li&gt;jmxPort (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; expose port for jmx&lt;/li&gt;
&lt;li&gt;className (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the class to be executed. This field is optional
and Configurator will pick up a class from the input jar. However, it throw
exception if there are many available classes in the jar file.&lt;/li&gt;
&lt;li&gt;from (&lt;strong&gt;array(TopicKey)&lt;/strong&gt;) &amp;mdash; source topic&lt;/li&gt;
&lt;li&gt;to (&lt;strong&gt;array(TopicKey)&lt;/strong&gt;) &amp;mdash; target topic&lt;/li&gt;
&lt;li&gt;nodeNames (&lt;strong&gt;array(string)&lt;/strong&gt;) &amp;mdash; the nodes running the stream
process&lt;/li&gt;
&lt;li&gt;brokerClusterKey (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the broker cluster key used for
stream running
&lt;ul&gt;
&lt;li&gt;brokerClusterKey.group (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the group of
broker cluster&lt;/li&gt;
&lt;li&gt;brokerClusterKey.name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the name of broker
cluster&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    the following forms are legal as well: (1) &lt;code&gt;{&amp;quot;name&amp;quot;: &amp;quot;n&amp;quot;}&lt;/code&gt;, (2) &lt;code&gt;&amp;quot;n&amp;quot;&lt;/code&gt;.
Both forms are converted to &lt;code&gt;{&amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;n&amp;quot;}&lt;/code&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ol start=&#34;10&#34;&gt;
&lt;li&gt;tags (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the user defined parameters&lt;/li&gt;
&lt;li&gt;aliveNodes (&lt;strong&gt;array(string)&lt;/strong&gt;) &amp;mdash; the nodes that host the running
containers of stream cluster&lt;/li&gt;
&lt;li&gt;state (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; only started/failed stream has state
(DEAD if all containers are not running, else RUNNING)&lt;/li&gt;
&lt;li&gt;error (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the error message from a failed
stream. If the stream is fine or un-started, you won&amp;rsquo;t get this
field.&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/custom_connector/#metrics&#34;&gt;nodeMetrics&lt;/a&gt; (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash;
the metrics from this stream.
&lt;ul&gt;
&lt;li&gt;meters (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the metrics in meter type
&lt;ul&gt;
&lt;li&gt;meters[i].value (&lt;strong&gt;double&lt;/strong&gt;) &amp;mdash; the number stored in meter&lt;/li&gt;
&lt;li&gt;meters[i].unit (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; unit for value&lt;/li&gt;
&lt;li&gt;meters[i].document (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; document of this meter&lt;/li&gt;
&lt;li&gt;meters[i].queryTime (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; the time of query
metrics from remote machine&lt;/li&gt;
&lt;li&gt;meters[i].startTime (&lt;strong&gt;option(long)&lt;/strong&gt;) &amp;mdash; the time of
record generated in remote machine&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;lastModified (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; last modified this jar time&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;create&#34;&gt;create properties of specific stream&lt;/h2&gt;
&lt;p&gt;Create the properties of a stream.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;POST /v0/streams&lt;/em&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; new stream name. This is the object unique
name ; default is random string.&lt;/li&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; group name for current stream ; default value
is &amp;ldquo;default&amp;rdquo;&lt;/li&gt;
&lt;li&gt;imageName (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; image name of stream used to ; default is
oharastream/stream:0.11.0-SNAPSHOT&lt;/li&gt;
&lt;li&gt;nodeNames (&lt;strong&gt;array(string)&lt;/strong&gt;) &amp;mdash; node name list of stream used to ;
default is empty&lt;/li&gt;
&lt;li&gt;tags (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; a key-value map of user defined data ; default
is empty&lt;/li&gt;
&lt;li&gt;jarKey (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the used jar key
&lt;ul&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the group name of this jar&lt;/li&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the name of this jar&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;brokerClusterKey (&lt;strong&gt;option(object)&lt;/strong&gt;) &amp;mdash; the broker cluster used
for stream running ; default we will auto fill this parameter for
you if you don&amp;rsquo;t specify it and there only exists one broker
cluster.&lt;/li&gt;
&lt;li&gt;jmxPort (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; expose port for jmx ; default is random port&lt;/li&gt;
&lt;li&gt;from (&lt;strong&gt;array(TopicKey)&lt;/strong&gt;) &amp;mdash; source topic ; default is empty array&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;Currently, stream uses a &amp;ldquo;single flow&amp;rdquo; for users to define their
own data flow, we need a better structure to support multiple
topics.&lt;/p&gt;
&lt;p&gt;We only support one topic for current version. We will throw
exception in start api if you assign more than 1 topic. We will
support multiple topics on issue [#688](&lt;a href=&#34;https://github.com/oharastream/ohara/issues/688&#34;&gt;https://github.com/oharastream/ohara/issues/688&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;)&lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ol start=&#34;10&#34;&gt;
&lt;li&gt;to (&lt;strong&gt;array(TopicKey)&lt;/strong&gt;) &amp;mdash; target topic ; default is empty array&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;Currently, stream uses a &amp;ldquo;single flow&amp;rdquo; for users to define their
own data flow, we need a better structure to support multiple
topics.&lt;/p&gt;
&lt;p&gt;We only support one topic for current version. We will throw
exception in start api if you assign more than 1 topic. We will
support multiple topics on issue [#688](&lt;a href=&#34;https://github.com/oharastream/ohara/issues/688&#34;&gt;https://github.com/oharastream/ohara/issues/688&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;)&lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;streamtest1&amp;quot;,
  &amp;quot;brokerClusterKey&amp;quot;: &amp;quot;bk&amp;quot;,
  &amp;quot;jarKey&amp;quot;: &amp;quot;ohara-it-stream.jar&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [&amp;quot;node00&amp;quot;],
  &amp;quot;from&amp;quot;: [&amp;quot;topic0&amp;quot;],
  &amp;quot;to&amp;quot;: [&amp;quot;topic1&amp;quot;]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;p&gt;Response format is as 
&lt;a href=&#34;#stored-data&#34;&gt;stream stored format&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;author&amp;quot;: &amp;quot;root&amp;quot;,
  &amp;quot;brokerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;bk&amp;quot;
  },
  &amp;quot;name&amp;quot;: &amp;quot;streamtest1&amp;quot;,
  &amp;quot;xms&amp;quot;: 1024,
  &amp;quot;routes&amp;quot;: {},
  &amp;quot;lastModified&amp;quot;: 1579145546218,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;xmx&amp;quot;: 1024,
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/stream:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;jarKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;ohara-it-stream.jar&amp;quot;
  },
  &amp;quot;to&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic1&amp;quot;
    }
  ],
  &amp;quot;revision&amp;quot;: &amp;quot;b303f3c2e52647ee5e79e55f9d74a5e51238a92c&amp;quot;,
  &amp;quot;version&amp;quot;: &amp;quot;0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;aliveNodes&amp;quot;: [],
  &amp;quot;stream.class&amp;quot;: &amp;quot;oharastream.ohara.it.stream.DumbStream&amp;quot;,
  &amp;quot;from&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;
    }
  ],
  &amp;quot;nodeMetrics&amp;quot;: [],
  &amp;quot;jmxPort&amp;quot;: 44914,
  &amp;quot;kind&amp;quot;: &amp;quot;stream&amp;quot;,
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The stream, which is just created, does not have any metrics.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;get&#34;&gt;get information from a specific stream cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/streams/${name}?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;p&gt;Response format is as 
&lt;a href=&#34;#stored-data&#34;&gt;stream stored format&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;author&amp;quot;: &amp;quot;root&amp;quot;,
  &amp;quot;brokerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;bk&amp;quot;
  },
  &amp;quot;name&amp;quot;: &amp;quot;streamtest1&amp;quot;,
  &amp;quot;xms&amp;quot;: 1024,
  &amp;quot;routes&amp;quot;: {},
  &amp;quot;lastModified&amp;quot;: 1579145546218,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;xmx&amp;quot;: 1024,
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/stream:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;jarKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;ohara-it-stream.jar&amp;quot;
  },
  &amp;quot;to&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic1&amp;quot;
    }
  ],
  &amp;quot;revision&amp;quot;: &amp;quot;b303f3c2e52647ee5e79e55f9d74a5e51238a92c&amp;quot;,
  &amp;quot;version&amp;quot;: &amp;quot;0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;aliveNodes&amp;quot;: [],
  &amp;quot;stream.class&amp;quot;: &amp;quot;oharastream.ohara.it.stream.DumbStream&amp;quot;,
  &amp;quot;from&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;
    }
  ],
  &amp;quot;nodeMetrics&amp;quot;: [],
  &amp;quot;jmxPort&amp;quot;: 44914,
  &amp;quot;kind&amp;quot;: &amp;quot;stream&amp;quot;,
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;list-information-of-stream-cluster&#34;&gt;list information of stream cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/streams&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;the accepted query keys are listed below&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;author&lt;/li&gt;
&lt;li&gt;group&lt;/li&gt;
&lt;li&gt;name&lt;/li&gt;
&lt;li&gt;lastModified&lt;/li&gt;
&lt;li&gt;tags&lt;/li&gt;
&lt;li&gt;state&lt;/li&gt;
&lt;li&gt;aliveNodes&lt;/li&gt;
&lt;li&gt;key&lt;/li&gt;
&lt;li&gt;version&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;p&gt;Response format is as 
&lt;a href=&#34;#stored-data&#34;&gt;stream stored format&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
  {
    &amp;quot;author&amp;quot;: &amp;quot;root&amp;quot;,
    &amp;quot;brokerClusterKey&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;bk&amp;quot;
    },
    &amp;quot;name&amp;quot;: &amp;quot;streamtest1&amp;quot;,
    &amp;quot;xms&amp;quot;: 1024,
    &amp;quot;routes&amp;quot;: {},
    &amp;quot;lastModified&amp;quot;: 1579145546218,
    &amp;quot;tags&amp;quot;: {},
    &amp;quot;xmx&amp;quot;: 1024,
    &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/stream:0.11.0-SNAPSHOT&amp;quot;,
    &amp;quot;jarKey&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;ohara-it-stream.jar&amp;quot;
    },
    &amp;quot;to&amp;quot;: [
      {
        &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
        &amp;quot;name&amp;quot;: &amp;quot;topic1&amp;quot;
      }
    ],
    &amp;quot;revision&amp;quot;: &amp;quot;b303f3c2e52647ee5e79e55f9d74a5e51238a92c&amp;quot;,
    &amp;quot;version&amp;quot;: &amp;quot;0.11.0-SNAPSHOT&amp;quot;,
    &amp;quot;aliveNodes&amp;quot;: [],
    &amp;quot;stream.class&amp;quot;: &amp;quot;oharastream.ohara.it.stream.DumbStream&amp;quot;,
    &amp;quot;from&amp;quot;: [
      {
        &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
        &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;
      }
    ],
    &amp;quot;nodeMetrics&amp;quot;: [],
    &amp;quot;jmxPort&amp;quot;: 44914,
    &amp;quot;kind&amp;quot;: &amp;quot;stream&amp;quot;,
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;nodeNames&amp;quot;: [
      &amp;quot;node00&amp;quot;
    ]
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;update&#34;&gt;update properties of specific stream&lt;/h2&gt;
&lt;p&gt;Update the properties of a non-started stream.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/streams/${name}?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    If the required stream (group, name) was not exists, we will try to use
this request as &lt;a href=&#34;#create&#34;&gt;create stream&lt;/a&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ol&gt;
&lt;li&gt;imageName (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; image name of stream used to.&lt;/li&gt;
&lt;li&gt;nodeNames (&lt;strong&gt;option(array(string))&lt;/strong&gt;) &amp;mdash; node name list of stream
used to.&lt;/li&gt;
&lt;li&gt;tags (&lt;strong&gt;option(object)&lt;/strong&gt;) &amp;mdash; a key-value map of user defined data.&lt;/li&gt;
&lt;li&gt;jarKey (&lt;strong&gt;option(option(object))&lt;/strong&gt;) &amp;mdash; the used jar key
&lt;ul&gt;
&lt;li&gt;group (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the group name of this jar&lt;/li&gt;
&lt;li&gt;name (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the name without extension of this
jar&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;jmxPort (&lt;strong&gt;option(int)&lt;/strong&gt;) &amp;mdash; expose port for jmx.&lt;/li&gt;
&lt;li&gt;from (&lt;strong&gt;option(array(string))&lt;/strong&gt;) &amp;mdash; source topic.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;Currently, stream uses a &amp;ldquo;single flow&amp;rdquo; for users to define their
own data flow, we need a better structure to support multiple
topics.&lt;/p&gt;
&lt;p&gt;we only support one topic for current version. We will throw
exception in start api if you assign more than 1 topic. We will
support multiple topics on issue [#688](&lt;a href=&#34;https://github.com/oharastream/ohara/issues/688&#34;&gt;https://github.com/oharastream/ohara/issues/688&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;)&lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ol start=&#34;7&#34;&gt;
&lt;li&gt;to (&lt;strong&gt;option(array(string))&lt;/strong&gt;) &amp;mdash; target topic.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;Currently, stream uses a &amp;ldquo;single flow&amp;rdquo; for users to define their
own data flow, we need a better structure to support multiple
topics.&lt;/p&gt;
&lt;p&gt;we only support one topic for current version. We will throw
exception in start api if you assign more than 1 topic. We will
support multiple topics on issue [#688](&lt;a href=&#34;https://github.com/oharastream/ohara/issues/688&#34;&gt;https://github.com/oharastream/ohara/issues/688&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;)&lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;from&amp;quot;: [&amp;quot;topic2&amp;quot;],
  &amp;quot;to&amp;quot;: [&amp;quot;topic3&amp;quot;],
  &amp;quot;jarKey&amp;quot;: &amp;quot;ohara-it-stream.jar&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [&amp;quot;node01&amp;quot;]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;p&gt;Response format is as 
&lt;a href=&#34;#stored-data&#34;&gt;stream stored format&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;author&amp;quot;: &amp;quot;root&amp;quot;,
  &amp;quot;brokerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;bk&amp;quot;
  },
  &amp;quot;name&amp;quot;: &amp;quot;streamtest1&amp;quot;,
  &amp;quot;xms&amp;quot;: 1024,
  &amp;quot;routes&amp;quot;: {},
  &amp;quot;lastModified&amp;quot;: 1579153777586,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;xmx&amp;quot;: 1024,
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/stream:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;jarKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;ohara-it-stream.jar&amp;quot;
  },
  &amp;quot;to&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic3&amp;quot;
    }
  ],
  &amp;quot;revision&amp;quot;: &amp;quot;b303f3c2e52647ee5e79e55f9d74a5e51238a92c&amp;quot;,
  &amp;quot;version&amp;quot;: &amp;quot;0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;aliveNodes&amp;quot;: [],
  &amp;quot;stream.class&amp;quot;: &amp;quot;oharastream.ohara.it.stream.DumbStream&amp;quot;,
  &amp;quot;from&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic2&amp;quot;
    }
  ],
  &amp;quot;nodeMetrics&amp;quot;: [],
  &amp;quot;jmxPort&amp;quot;: 44914,
  &amp;quot;kind&amp;quot;: &amp;quot;stream&amp;quot;,
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node01&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;delete-properties-of-specific-stream&#34;&gt;delete properties of specific stream&lt;/h2&gt;
&lt;p&gt;Delete the properties of a non-started stream. This api only remove the
stream component which is stored in pipeline.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;DELETE /v0/streams/${name}?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;204 NoContent
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    It is ok to delete an nonexistent properties, and the response is
204 NoContent.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;start-a-stream&#34;&gt;start a Stream&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/streams/${name}/start?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#get&#34;&gt;get stream&lt;/a&gt; to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;stop&#34;&gt;stop a Stream&lt;/h2&gt;
&lt;p&gt;This action will graceful stop and remove all docker containers belong
to this stream. Note: successful stop stream will have no status.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/streams/${name}/stop?group=$group[&amp;amp;force=true]&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Query Parameters
&lt;ol&gt;
&lt;li&gt;force (&lt;strong&gt;boolean&lt;/strong&gt;) &amp;mdash; true if you don&amp;rsquo;t want to wait the
graceful shutdown (it can save your time but may damage your
data).&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#get&#34;&gt;get stream&lt;/a&gt; to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;get-topology-tree-graph-from-specific-stream&#34;&gt;get topology tree graph from specific stream&lt;/h2&gt;
&lt;p&gt;[TODO] This is not implemented yet !&lt;/p&gt;
&lt;p&gt;&lt;em&gt;GET /v0/streams/view/${name}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;jarInfo (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the upload jar information&lt;/li&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the stream name&lt;/li&gt;
&lt;li&gt;poneglyph (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the stream topology tree graph
&lt;ul&gt;
&lt;li&gt;steles (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the topology collection
&lt;ul&gt;
&lt;li&gt;steles[i].kind (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; this component
kind (SOURCE, PROCESSOR, or SINK)&lt;/li&gt;
&lt;li&gt;steles[i].key (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; this component kind with order&lt;/li&gt;
&lt;li&gt;steles[i].name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; depend on kind, the name is
&lt;ul&gt;
&lt;li&gt;SOURCE &amp;mdash; source topic name&lt;/li&gt;
&lt;li&gt;PROCESSOR &amp;mdash; the function name&lt;/li&gt;
&lt;li&gt;SINK &amp;mdash; target topic name&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;steles[i].from (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the prior
component key (could be empty if this is the first
component)&lt;/li&gt;
&lt;li&gt;steles[i].to (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the posterior
component key (could be empty if this is the final
component)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;jarInfo&amp;quot;: {
    &amp;quot;name&amp;quot;: &amp;quot;stream-app&amp;quot;,
    &amp;quot;group&amp;quot;: &amp;quot;wk01&amp;quot;,
    &amp;quot;size&amp;quot;: 1234,
    &amp;quot;lastModified&amp;quot;: 1542102595892
  },
  &amp;quot;name&amp;quot;: &amp;quot;my-app&amp;quot;,
  &amp;quot;poneglyph&amp;quot;: {
    &amp;quot;steles&amp;quot;: [
      {
        &amp;quot;kind&amp;quot;: &amp;quot;SOURCE&amp;quot;,
        &amp;quot;key&amp;quot; : &amp;quot;SOURCE-0&amp;quot;,
        &amp;quot;name&amp;quot;: &amp;quot;stream-in&amp;quot;,
        &amp;quot;from&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;to&amp;quot;: &amp;quot;PROCESSOR-1&amp;quot;
      },
      {
        &amp;quot;kind&amp;quot;: &amp;quot;PROCESSOR&amp;quot;,
        &amp;quot;key&amp;quot; : &amp;quot;PROCESSOR-1&amp;quot;,
        &amp;quot;name&amp;quot;: &amp;quot;filter&amp;quot;,
        &amp;quot;from&amp;quot;: &amp;quot;SOURCE-0&amp;quot;,
        &amp;quot;to&amp;quot;: &amp;quot;PROCESSOR-2&amp;quot;
      },
      {
        &amp;quot;kind&amp;quot;: &amp;quot;PROCESSOR&amp;quot;,
        &amp;quot;key&amp;quot; : &amp;quot;PROCESSOR-2&amp;quot;,
        &amp;quot;name&amp;quot;: &amp;quot;mapvalues&amp;quot;,
        &amp;quot;from&amp;quot;: &amp;quot;PROCESSOR-1&amp;quot;,
        &amp;quot;to&amp;quot;: &amp;quot;SINK-3&amp;quot;
      },
      {
        &amp;quot;kind&amp;quot;: &amp;quot;SINK&amp;quot;,
        &amp;quot;key&amp;quot; : &amp;quot;SINK-3&amp;quot;,
        &amp;quot;name&amp;quot;: &amp;quot;stream-out&amp;quot;,
        &amp;quot;from&amp;quot;: &amp;quot;PROCESSOR-2&amp;quot;,
        &amp;quot;to&amp;quot;: &amp;quot;&amp;quot;
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Stream</title>
      <link>https://oharastream.github.io/en/docs/master/rest-api/streams/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/master/rest-api/streams/</guid>
      <description>&lt;p&gt;Ohara Stream is a unparalleled wrap of kafka streaming. It leverages and
enhances 
&lt;a href=&#34;https://kafka.apache.org/documentation/streams&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kafka Streams&lt;/a&gt;
to make developer easily design and implement the streaming application.
More details of developing streaming application is in

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/custom_stream/&#34;&gt;custom stream guideline&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Assume that you have completed a streaming application via Ohara Java
APIs, and you have generated a jar including your streaming code. By
Ohara Restful APIs, you are enable to control, deploy, and monitor your
streaming application. As with cluster APIs, Ohara leverages docker
container to host streaming application. Of course, you can apply your
favor container management tool including simple (based on ssh) and k8s
when you are starting Ohara.&lt;/p&gt;
&lt;p&gt;Before stating to use restful APIs, please ensure that all nodes have
downloaded the 
&lt;a href=&#34;https://cloud.docker.com/u/oharastream/repository/docker/oharastream/stream&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Stream image&lt;/a&gt;.
The jar you uploaded to run streaming application will be included in
the image and then executes as a docker container.
The 
&lt;a href=&#34;https://cloud.docker.com/u/oharastream/repository/docker/oharastream/stream&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Stream image&lt;/a&gt;
is kept in each node so don&amp;rsquo;t worry about the network. We all hate
re-download everything when running services.&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    If you implement the Ohara stream application, you must pack to jar
file and use the File API upload jar file then setting the jarKey to
create the Stream API.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The following information of Stream are updated by Ohara.&lt;/p&gt;
&lt;h2 id=&#34;stored-data&#34;&gt;stream stored data&lt;/h2&gt;
&lt;p&gt;The following are common settings to a stream app.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; cluster name. The legal character is number,
lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; cluster group. The legal character is number,
lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;jarKey (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the used jar key&lt;/li&gt;
&lt;li&gt;jmxPort (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; expose port for jmx&lt;/li&gt;
&lt;li&gt;className (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the class to be executed. This field is optional
and Configurator will pick up a class from the input jar. However, it throw
exception if there are many available classes in the jar file.&lt;/li&gt;
&lt;li&gt;from (&lt;strong&gt;array(TopicKey)&lt;/strong&gt;) &amp;mdash; source topic&lt;/li&gt;
&lt;li&gt;to (&lt;strong&gt;array(TopicKey)&lt;/strong&gt;) &amp;mdash; target topic&lt;/li&gt;
&lt;li&gt;nodeNames (&lt;strong&gt;array(string)&lt;/strong&gt;) &amp;mdash; the nodes running the stream
process&lt;/li&gt;
&lt;li&gt;brokerClusterKey (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the broker cluster key used for
stream running
&lt;ul&gt;
&lt;li&gt;brokerClusterKey.group (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the group of
broker cluster&lt;/li&gt;
&lt;li&gt;brokerClusterKey.name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the name of broker
cluster&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    the following forms are legal as well: (1) &lt;code&gt;{&amp;quot;name&amp;quot;: &amp;quot;n&amp;quot;}&lt;/code&gt;, (2) &lt;code&gt;&amp;quot;n&amp;quot;&lt;/code&gt;.
Both forms are converted to &lt;code&gt;{&amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;n&amp;quot;}&lt;/code&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ol start=&#34;10&#34;&gt;
&lt;li&gt;tags (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the user defined parameters&lt;/li&gt;
&lt;li&gt;aliveNodes (&lt;strong&gt;array(string)&lt;/strong&gt;) &amp;mdash; the nodes that host the running
containers of stream cluster&lt;/li&gt;
&lt;li&gt;state (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; only started/failed stream has state
(DEAD if all containers are not running, else RUNNING)&lt;/li&gt;
&lt;li&gt;error (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the error message from a failed
stream. If the stream is fine or un-started, you won&amp;rsquo;t get this
field.&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/custom_connector/#metrics&#34;&gt;nodeMetrics&lt;/a&gt; (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash;
the metrics from this stream.
&lt;ul&gt;
&lt;li&gt;meters (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the metrics in meter type
&lt;ul&gt;
&lt;li&gt;meters[i].value (&lt;strong&gt;double&lt;/strong&gt;) &amp;mdash; the number stored in meter&lt;/li&gt;
&lt;li&gt;meters[i].unit (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; unit for value&lt;/li&gt;
&lt;li&gt;meters[i].document (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; document of this meter&lt;/li&gt;
&lt;li&gt;meters[i].queryTime (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; the time of query
metrics from remote machine&lt;/li&gt;
&lt;li&gt;meters[i].startTime (&lt;strong&gt;option(long)&lt;/strong&gt;) &amp;mdash; the time of
record generated in remote machine&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;lastModified (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; last modified this jar time&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;create&#34;&gt;create properties of specific stream&lt;/h2&gt;
&lt;p&gt;Create the properties of a stream.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;POST /v0/streams&lt;/em&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; new stream name. This is the object unique
name ; default is random string.&lt;/li&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; group name for current stream ; default value
is &amp;ldquo;default&amp;rdquo;&lt;/li&gt;
&lt;li&gt;imageName (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; image name of stream used to ; default is
oharastream/stream:0.11.0-SNAPSHOT&lt;/li&gt;
&lt;li&gt;nodeNames (&lt;strong&gt;array(string)&lt;/strong&gt;) &amp;mdash; node name list of stream used to ;
default is empty&lt;/li&gt;
&lt;li&gt;tags (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; a key-value map of user defined data ; default
is empty&lt;/li&gt;
&lt;li&gt;jarKey (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the used jar key
&lt;ul&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the group name of this jar&lt;/li&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the name of this jar&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;brokerClusterKey (&lt;strong&gt;option(object)&lt;/strong&gt;) &amp;mdash; the broker cluster used
for stream running ; default we will auto fill this parameter for
you if you don&amp;rsquo;t specify it and there only exists one broker
cluster.&lt;/li&gt;
&lt;li&gt;jmxPort (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; expose port for jmx ; default is random port&lt;/li&gt;
&lt;li&gt;from (&lt;strong&gt;array(TopicKey)&lt;/strong&gt;) &amp;mdash; source topic ; default is empty array&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;Currently, stream uses a &amp;ldquo;single flow&amp;rdquo; for users to define their
own data flow, we need a better structure to support multiple
topics.&lt;/p&gt;
&lt;p&gt;We only support one topic for current version. We will throw
exception in start api if you assign more than 1 topic. We will
support multiple topics on issue [#688](&lt;a href=&#34;https://github.com/oharastream/ohara/issues/688&#34;&gt;https://github.com/oharastream/ohara/issues/688&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;)&lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ol start=&#34;10&#34;&gt;
&lt;li&gt;to (&lt;strong&gt;array(TopicKey)&lt;/strong&gt;) &amp;mdash; target topic ; default is empty array&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;Currently, stream uses a &amp;ldquo;single flow&amp;rdquo; for users to define their
own data flow, we need a better structure to support multiple
topics.&lt;/p&gt;
&lt;p&gt;We only support one topic for current version. We will throw
exception in start api if you assign more than 1 topic. We will
support multiple topics on issue [#688](&lt;a href=&#34;https://github.com/oharastream/ohara/issues/688&#34;&gt;https://github.com/oharastream/ohara/issues/688&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;)&lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;streamtest1&amp;quot;,
  &amp;quot;brokerClusterKey&amp;quot;: &amp;quot;bk&amp;quot;,
  &amp;quot;jarKey&amp;quot;: &amp;quot;ohara-it-stream.jar&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [&amp;quot;node00&amp;quot;],
  &amp;quot;from&amp;quot;: [&amp;quot;topic0&amp;quot;],
  &amp;quot;to&amp;quot;: [&amp;quot;topic1&amp;quot;]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;p&gt;Response format is as 
&lt;a href=&#34;#stored-data&#34;&gt;stream stored format&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;author&amp;quot;: &amp;quot;root&amp;quot;,
  &amp;quot;brokerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;bk&amp;quot;
  },
  &amp;quot;name&amp;quot;: &amp;quot;streamtest1&amp;quot;,
  &amp;quot;xms&amp;quot;: 1024,
  &amp;quot;routes&amp;quot;: {},
  &amp;quot;lastModified&amp;quot;: 1579145546218,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;xmx&amp;quot;: 1024,
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/stream:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;jarKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;ohara-it-stream.jar&amp;quot;
  },
  &amp;quot;to&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic1&amp;quot;
    }
  ],
  &amp;quot;revision&amp;quot;: &amp;quot;b303f3c2e52647ee5e79e55f9d74a5e51238a92c&amp;quot;,
  &amp;quot;version&amp;quot;: &amp;quot;0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;aliveNodes&amp;quot;: [],
  &amp;quot;stream.class&amp;quot;: &amp;quot;oharastream.ohara.it.stream.DumbStream&amp;quot;,
  &amp;quot;from&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;
    }
  ],
  &amp;quot;nodeMetrics&amp;quot;: [],
  &amp;quot;jmxPort&amp;quot;: 44914,
  &amp;quot;kind&amp;quot;: &amp;quot;stream&amp;quot;,
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The stream, which is just created, does not have any metrics.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;get&#34;&gt;get information from a specific stream cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/streams/${name}?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;p&gt;Response format is as 
&lt;a href=&#34;#stored-data&#34;&gt;stream stored format&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;author&amp;quot;: &amp;quot;root&amp;quot;,
  &amp;quot;brokerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;bk&amp;quot;
  },
  &amp;quot;name&amp;quot;: &amp;quot;streamtest1&amp;quot;,
  &amp;quot;xms&amp;quot;: 1024,
  &amp;quot;routes&amp;quot;: {},
  &amp;quot;lastModified&amp;quot;: 1579145546218,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;xmx&amp;quot;: 1024,
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/stream:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;jarKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;ohara-it-stream.jar&amp;quot;
  },
  &amp;quot;to&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic1&amp;quot;
    }
  ],
  &amp;quot;revision&amp;quot;: &amp;quot;b303f3c2e52647ee5e79e55f9d74a5e51238a92c&amp;quot;,
  &amp;quot;version&amp;quot;: &amp;quot;0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;aliveNodes&amp;quot;: [],
  &amp;quot;stream.class&amp;quot;: &amp;quot;oharastream.ohara.it.stream.DumbStream&amp;quot;,
  &amp;quot;from&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;
    }
  ],
  &amp;quot;nodeMetrics&amp;quot;: [],
  &amp;quot;jmxPort&amp;quot;: 44914,
  &amp;quot;kind&amp;quot;: &amp;quot;stream&amp;quot;,
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;list-information-of-stream-cluster&#34;&gt;list information of stream cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/streams&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;the accepted query keys are listed below&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;author&lt;/li&gt;
&lt;li&gt;group&lt;/li&gt;
&lt;li&gt;name&lt;/li&gt;
&lt;li&gt;lastModified&lt;/li&gt;
&lt;li&gt;tags&lt;/li&gt;
&lt;li&gt;state&lt;/li&gt;
&lt;li&gt;aliveNodes&lt;/li&gt;
&lt;li&gt;key&lt;/li&gt;
&lt;li&gt;version&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;p&gt;Response format is as 
&lt;a href=&#34;#stored-data&#34;&gt;stream stored format&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
  {
    &amp;quot;author&amp;quot;: &amp;quot;root&amp;quot;,
    &amp;quot;brokerClusterKey&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;bk&amp;quot;
    },
    &amp;quot;name&amp;quot;: &amp;quot;streamtest1&amp;quot;,
    &amp;quot;xms&amp;quot;: 1024,
    &amp;quot;routes&amp;quot;: {},
    &amp;quot;lastModified&amp;quot;: 1579145546218,
    &amp;quot;tags&amp;quot;: {},
    &amp;quot;xmx&amp;quot;: 1024,
    &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/stream:0.11.0-SNAPSHOT&amp;quot;,
    &amp;quot;jarKey&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;ohara-it-stream.jar&amp;quot;
    },
    &amp;quot;to&amp;quot;: [
      {
        &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
        &amp;quot;name&amp;quot;: &amp;quot;topic1&amp;quot;
      }
    ],
    &amp;quot;revision&amp;quot;: &amp;quot;b303f3c2e52647ee5e79e55f9d74a5e51238a92c&amp;quot;,
    &amp;quot;version&amp;quot;: &amp;quot;0.11.0-SNAPSHOT&amp;quot;,
    &amp;quot;aliveNodes&amp;quot;: [],
    &amp;quot;stream.class&amp;quot;: &amp;quot;oharastream.ohara.it.stream.DumbStream&amp;quot;,
    &amp;quot;from&amp;quot;: [
      {
        &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
        &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;
      }
    ],
    &amp;quot;nodeMetrics&amp;quot;: [],
    &amp;quot;jmxPort&amp;quot;: 44914,
    &amp;quot;kind&amp;quot;: &amp;quot;stream&amp;quot;,
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;nodeNames&amp;quot;: [
      &amp;quot;node00&amp;quot;
    ]
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;update&#34;&gt;update properties of specific stream&lt;/h2&gt;
&lt;p&gt;Update the properties of a non-started stream.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/streams/${name}?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    If the required stream (group, name) was not exists, we will try to use
this request as &lt;a href=&#34;#create&#34;&gt;create stream&lt;/a&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ol&gt;
&lt;li&gt;imageName (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; image name of stream used to.&lt;/li&gt;
&lt;li&gt;nodeNames (&lt;strong&gt;option(array(string))&lt;/strong&gt;) &amp;mdash; node name list of stream
used to.&lt;/li&gt;
&lt;li&gt;tags (&lt;strong&gt;option(object)&lt;/strong&gt;) &amp;mdash; a key-value map of user defined data.&lt;/li&gt;
&lt;li&gt;jarKey (&lt;strong&gt;option(option(object))&lt;/strong&gt;) &amp;mdash; the used jar key
&lt;ul&gt;
&lt;li&gt;group (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the group name of this jar&lt;/li&gt;
&lt;li&gt;name (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the name without extension of this
jar&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;jmxPort (&lt;strong&gt;option(int)&lt;/strong&gt;) &amp;mdash; expose port for jmx.&lt;/li&gt;
&lt;li&gt;from (&lt;strong&gt;option(array(string))&lt;/strong&gt;) &amp;mdash; source topic.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;Currently, stream uses a &amp;ldquo;single flow&amp;rdquo; for users to define their
own data flow, we need a better structure to support multiple
topics.&lt;/p&gt;
&lt;p&gt;we only support one topic for current version. We will throw
exception in start api if you assign more than 1 topic. We will
support multiple topics on issue [#688](&lt;a href=&#34;https://github.com/oharastream/ohara/issues/688&#34;&gt;https://github.com/oharastream/ohara/issues/688&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;)&lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ol start=&#34;7&#34;&gt;
&lt;li&gt;to (&lt;strong&gt;option(array(string))&lt;/strong&gt;) &amp;mdash; target topic.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;Currently, stream uses a &amp;ldquo;single flow&amp;rdquo; for users to define their
own data flow, we need a better structure to support multiple
topics.&lt;/p&gt;
&lt;p&gt;we only support one topic for current version. We will throw
exception in start api if you assign more than 1 topic. We will
support multiple topics on issue [#688](&lt;a href=&#34;https://github.com/oharastream/ohara/issues/688&#34;&gt;https://github.com/oharastream/ohara/issues/688&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;)&lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;from&amp;quot;: [&amp;quot;topic2&amp;quot;],
  &amp;quot;to&amp;quot;: [&amp;quot;topic3&amp;quot;],
  &amp;quot;jarKey&amp;quot;: &amp;quot;ohara-it-stream.jar&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [&amp;quot;node01&amp;quot;]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;p&gt;Response format is as 
&lt;a href=&#34;#stored-data&#34;&gt;stream stored format&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;author&amp;quot;: &amp;quot;root&amp;quot;,
  &amp;quot;brokerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;bk&amp;quot;
  },
  &amp;quot;name&amp;quot;: &amp;quot;streamtest1&amp;quot;,
  &amp;quot;xms&amp;quot;: 1024,
  &amp;quot;routes&amp;quot;: {},
  &amp;quot;lastModified&amp;quot;: 1579153777586,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;xmx&amp;quot;: 1024,
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/stream:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;jarKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;ohara-it-stream.jar&amp;quot;
  },
  &amp;quot;to&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic3&amp;quot;
    }
  ],
  &amp;quot;revision&amp;quot;: &amp;quot;b303f3c2e52647ee5e79e55f9d74a5e51238a92c&amp;quot;,
  &amp;quot;version&amp;quot;: &amp;quot;0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;aliveNodes&amp;quot;: [],
  &amp;quot;stream.class&amp;quot;: &amp;quot;oharastream.ohara.it.stream.DumbStream&amp;quot;,
  &amp;quot;from&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;topic2&amp;quot;
    }
  ],
  &amp;quot;nodeMetrics&amp;quot;: [],
  &amp;quot;jmxPort&amp;quot;: 44914,
  &amp;quot;kind&amp;quot;: &amp;quot;stream&amp;quot;,
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node01&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;delete-properties-of-specific-stream&#34;&gt;delete properties of specific stream&lt;/h2&gt;
&lt;p&gt;Delete the properties of a non-started stream. This api only remove the
stream component which is stored in pipeline.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;DELETE /v0/streams/${name}?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;204 NoContent
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    It is ok to delete an nonexistent properties, and the response is
204 NoContent.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;start-a-stream&#34;&gt;start a Stream&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/streams/${name}/start?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#get&#34;&gt;get stream&lt;/a&gt; to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;stop&#34;&gt;stop a Stream&lt;/h2&gt;
&lt;p&gt;This action will graceful stop and remove all docker containers belong
to this stream. Note: successful stop stream will have no status.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/streams/${name}/stop?group=$group[&amp;amp;force=true]&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Query Parameters
&lt;ol&gt;
&lt;li&gt;force (&lt;strong&gt;boolean&lt;/strong&gt;) &amp;mdash; true if you don&amp;rsquo;t want to wait the
graceful shutdown (it can save your time but may damage your
data).&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#get&#34;&gt;get stream&lt;/a&gt; to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;get-topology-tree-graph-from-specific-stream&#34;&gt;get topology tree graph from specific stream&lt;/h2&gt;
&lt;p&gt;[TODO] This is not implemented yet !&lt;/p&gt;
&lt;p&gt;&lt;em&gt;GET /v0/streams/view/${name}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;jarInfo (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the upload jar information&lt;/li&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the stream name&lt;/li&gt;
&lt;li&gt;poneglyph (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the stream topology tree graph
&lt;ul&gt;
&lt;li&gt;steles (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the topology collection
&lt;ul&gt;
&lt;li&gt;steles[i].kind (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; this component
kind (SOURCE, PROCESSOR, or SINK)&lt;/li&gt;
&lt;li&gt;steles[i].key (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; this component kind with order&lt;/li&gt;
&lt;li&gt;steles[i].name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; depend on kind, the name is
&lt;ul&gt;
&lt;li&gt;SOURCE &amp;mdash; source topic name&lt;/li&gt;
&lt;li&gt;PROCESSOR &amp;mdash; the function name&lt;/li&gt;
&lt;li&gt;SINK &amp;mdash; target topic name&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;steles[i].from (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the prior
component key (could be empty if this is the first
component)&lt;/li&gt;
&lt;li&gt;steles[i].to (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the posterior
component key (could be empty if this is the final
component)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;jarInfo&amp;quot;: {
    &amp;quot;name&amp;quot;: &amp;quot;stream-app&amp;quot;,
    &amp;quot;group&amp;quot;: &amp;quot;wk01&amp;quot;,
    &amp;quot;size&amp;quot;: 1234,
    &amp;quot;lastModified&amp;quot;: 1542102595892
  },
  &amp;quot;name&amp;quot;: &amp;quot;my-app&amp;quot;,
  &amp;quot;poneglyph&amp;quot;: {
    &amp;quot;steles&amp;quot;: [
      {
        &amp;quot;kind&amp;quot;: &amp;quot;SOURCE&amp;quot;,
        &amp;quot;key&amp;quot; : &amp;quot;SOURCE-0&amp;quot;,
        &amp;quot;name&amp;quot;: &amp;quot;stream-in&amp;quot;,
        &amp;quot;from&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;to&amp;quot;: &amp;quot;PROCESSOR-1&amp;quot;
      },
      {
        &amp;quot;kind&amp;quot;: &amp;quot;PROCESSOR&amp;quot;,
        &amp;quot;key&amp;quot; : &amp;quot;PROCESSOR-1&amp;quot;,
        &amp;quot;name&amp;quot;: &amp;quot;filter&amp;quot;,
        &amp;quot;from&amp;quot;: &amp;quot;SOURCE-0&amp;quot;,
        &amp;quot;to&amp;quot;: &amp;quot;PROCESSOR-2&amp;quot;
      },
      {
        &amp;quot;kind&amp;quot;: &amp;quot;PROCESSOR&amp;quot;,
        &amp;quot;key&amp;quot; : &amp;quot;PROCESSOR-2&amp;quot;,
        &amp;quot;name&amp;quot;: &amp;quot;mapvalues&amp;quot;,
        &amp;quot;from&amp;quot;: &amp;quot;PROCESSOR-1&amp;quot;,
        &amp;quot;to&amp;quot;: &amp;quot;SINK-3&amp;quot;
      },
      {
        &amp;quot;kind&amp;quot;: &amp;quot;SINK&amp;quot;,
        &amp;quot;key&amp;quot; : &amp;quot;SINK-3&amp;quot;,
        &amp;quot;name&amp;quot;: &amp;quot;stream-out&amp;quot;,
        &amp;quot;from&amp;quot;: &amp;quot;PROCESSOR-2&amp;quot;,
        &amp;quot;to&amp;quot;: &amp;quot;&amp;quot;
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Topic</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/rest-api/topics/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/rest-api/topics/</guid>
      <description>&lt;p&gt;Ohara topic is based on kafka topic. It means the creation of topic on
ohara will invoke a creation of kafka also. Also, the delete to Ohara
topic also invoke a delete request to kafka. The common properties in
topic are shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) - topic group. The legal character is number,
lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) - topic name. The legal character is number,
lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;brokerClusterKey (&lt;strong&gt;Object&lt;/strong&gt;) - target broker cluster.
&lt;ul&gt;
&lt;li&gt;brokerClusterKey.group (&lt;strong&gt;option(string)&lt;/strong&gt;) - the group of
cluster&lt;/li&gt;
&lt;li&gt;brokerClusterKey.name (&lt;strong&gt;string&lt;/strong&gt;) - the name of cluster&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
  &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    the following forms are legal as well: (1) &lt;code&gt;{&amp;quot;name&amp;quot;: &amp;quot;n&amp;quot;}&lt;/code&gt;, (2) &lt;code&gt;&amp;quot;n&amp;quot;&lt;/code&gt;.
Both forms are converted to &lt;code&gt;{&amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;n&amp;quot;}&lt;/code&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;numberOfReplications (&lt;strong&gt;option(int)&lt;/strong&gt;) - the number of
replications&lt;/li&gt;
&lt;li&gt;numberOfPartitions (&lt;strong&gt;option(int)&lt;/strong&gt;)- the number of partitions for
this topic&lt;/li&gt;
&lt;li&gt;tags (&lt;strong&gt;option(object)&lt;/strong&gt;) - the extra description to this object&lt;/li&gt;
&lt;/ol&gt;
  &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;ol&gt;
&lt;li&gt;The name must be unique in a broker cluster.&lt;/li&gt;
&lt;li&gt;There are many other available configs which are useful in
creating topic. Please ref &lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/brokers/&#34;&gt;broker clusters&lt;/a&gt;
to see how to retrieve the available configs for specific broker
cluster.&lt;/li&gt;
&lt;/ol&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The following information are tagged by Ohara.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;state (&lt;strong&gt;option(string)&lt;/strong&gt;) - state of a running topic. nothing if
the topic is not running.&lt;/li&gt;
&lt;li&gt;partitionInfos (&lt;strong&gt;Array(object)&lt;/strong&gt;) - the details of partitions.
&lt;ul&gt;
&lt;li&gt;index (&lt;strong&gt;int&lt;/strong&gt;) - the index of partition&lt;/li&gt;
&lt;li&gt;leaderNode (&lt;strong&gt;String&lt;/strong&gt;) - the leader (node) of this partition&lt;/li&gt;
&lt;li&gt;replicaNodes (&lt;strong&gt;Array(String)&lt;/strong&gt;) - the nodes hosting the
replica for this partition&lt;/li&gt;
&lt;li&gt;inSyncReplicaNodes (&lt;strong&gt;Array(String)&lt;/strong&gt;) - the nodes which have
fetched the newest data from leader&lt;/li&gt;
&lt;li&gt;beginningOffset (&lt;strong&gt;long&lt;/strong&gt;) - the beginning offset&lt;/li&gt;
&lt;li&gt;endOffset (&lt;strong&gt;endOffset&lt;/strong&gt;) - the latest offset (Normally, it is
the latest commit data)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) - the group value is always &amp;ldquo;default&amp;rdquo;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#metrics&#34;&gt;nodeMetrics&lt;/a&gt; (&lt;strong&gt;object&lt;/strong&gt;) -
the metrics number of a running topic&lt;/li&gt;
&lt;li&gt;lastModified (&lt;strong&gt;long&lt;/strong&gt;) - the last time to update this ftp
information&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;store-a-topic-properties&#34;&gt;store a topic properties&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;POST /v0/topics&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;ol&gt;
&lt;li&gt;the name you pass to Ohara is used to build topic on kafka, and it
is restricted by Kafka ([a-zA-Z0-9._-])&lt;/li&gt;
&lt;li&gt;the ignored fields will
be auto-completed by Ohara Configurator. Also, you could update/replace
it by UPDATE request later.&lt;/li&gt;
&lt;li&gt;this API does NOT create a topic on
broker cluster. Instead, you should send START request to run a topic on
broker cluster actually&lt;/li&gt;
&lt;li&gt;There are many other available configs which
are useful in creating topic. Please ref
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/brokers/&#34;&gt;broker clusters&lt;/a&gt; to see
how to retrieve the available configs for specific broker cluster.&lt;/li&gt;
&lt;/ol&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;brokerClusterKey&amp;quot;: &amp;quot;bk&amp;quot;,
  &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;,
  &amp;quot;numberOfReplications&amp;quot;: 1,
  &amp;quot;numberOfPartitions&amp;quot;: 1
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;brokerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;bk&amp;quot;
  },
  &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;,
  &amp;quot;partitionInfos&amp;quot;: [],
  &amp;quot;lastModified&amp;quot;: 1578537142950,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;numberOfReplications&amp;quot;: 1,
  &amp;quot;nodeMetrics&amp;quot;: {
    &amp;quot;node00&amp;quot;: {
      &amp;quot;meters&amp;quot;: [
        {
          &amp;quot;document&amp;quot;: &amp;quot;BytesInPerSec&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;BytesInPerSec&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585069111069,
          &amp;quot;unit&amp;quot;: &amp;quot;bytes / SECONDS&amp;quot;,
          &amp;quot;value&amp;quot;: 2143210885
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;MessagesInPerSec&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;MessagesInPerSec&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585069111069,
          &amp;quot;unit&amp;quot;: &amp;quot;messages / SECONDS&amp;quot;,
          &amp;quot;value&amp;quot;: 2810000.0
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;TotalProduceRequestsPerSec&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;TotalProduceRequestsPerSec&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585069111069,
          &amp;quot;unit&amp;quot;: &amp;quot;requests / SECONDS&amp;quot;,
          &amp;quot;value&amp;quot;: 137416.0
        }
      ]
    }
  },
  &amp;quot;group&amp;quot;:&amp;quot;default&amp;quot;,
  &amp;quot;numberOfPartitions&amp;quot;: 1
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The topic, which is just created, does not have any metrics.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;update-a-topic-properties&#34;&gt;update a topic properties&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/topics/${name}?group=${group}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;numberOfPartitions&amp;quot;: 3
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;brokerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;bk&amp;quot;
  },
  &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;,
  &amp;quot;partitionInfos&amp;quot;: [],
  &amp;quot;lastModified&amp;quot;: 1578537915735,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;numberOfReplications&amp;quot;: 1,
  &amp;quot;nodeMetrics&amp;quot;: {
    &amp;quot;node00&amp;quot;: {
      &amp;quot;meters&amp;quot;: [
        {
          &amp;quot;document&amp;quot;: &amp;quot;BytesInPerSec&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;BytesInPerSec&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585069111069,
          &amp;quot;unit&amp;quot;: &amp;quot;bytes / SECONDS&amp;quot;,
          &amp;quot;value&amp;quot;: 2143210885
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;MessagesInPerSec&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;MessagesInPerSec&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585069111069,
          &amp;quot;unit&amp;quot;: &amp;quot;messages / SECONDS&amp;quot;,
          &amp;quot;value&amp;quot;: 2810000.0
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;TotalProduceRequestsPerSec&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;TotalProduceRequestsPerSec&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585069111069,
          &amp;quot;unit&amp;quot;: &amp;quot;requests / SECONDS&amp;quot;,
          &amp;quot;value&amp;quot;: 137416.0
        }
      ]
    }
  },
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;numberOfPartitions&amp;quot;: 3
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;list-all-topics-properties&#34;&gt;list all topics properties&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/topics?${key}=${value}&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;the accepted query keys are listed below.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;group&lt;/li&gt;
&lt;li&gt;name&lt;/li&gt;
&lt;li&gt;state&lt;/li&gt;
&lt;li&gt;lastModified&lt;/li&gt;
&lt;li&gt;tags&lt;/li&gt;
&lt;li&gt;tag: this field is similar to tags but it addresses the &amp;ldquo;contain&amp;rdquo; behavior.&lt;/li&gt;
&lt;li&gt;key&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Using &amp;ldquo;NONE&amp;rdquo; represents the nonexistence of state.
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
  {
    &amp;quot;brokerClusterKey&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;bk&amp;quot;
    },
    &amp;quot;name&amp;quot;: &amp;quot;topic1&amp;quot;,
    &amp;quot;partitionInfos&amp;quot;: [],
    &amp;quot;lastModified&amp;quot;: 1578537915735,
    &amp;quot;tags&amp;quot;: {},
    &amp;quot;numberOfReplications&amp;quot;: 1,
  &amp;quot;nodeMetrics&amp;quot;: {
    &amp;quot;node00&amp;quot;: {
      &amp;quot;meters&amp;quot;: [
        {
          &amp;quot;document&amp;quot;: &amp;quot;BytesInPerSec&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;BytesInPerSec&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585069111069,
          &amp;quot;unit&amp;quot;: &amp;quot;bytes / SECONDS&amp;quot;,
          &amp;quot;value&amp;quot;: 2143210885
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;MessagesInPerSec&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;MessagesInPerSec&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585069111069,
          &amp;quot;unit&amp;quot;: &amp;quot;messages / SECONDS&amp;quot;,
          &amp;quot;value&amp;quot;: 2810000.0
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;TotalProduceRequestsPerSec&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;TotalProduceRequestsPerSec&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585069111069,
          &amp;quot;unit&amp;quot;: &amp;quot;requests / SECONDS&amp;quot;,
          &amp;quot;value&amp;quot;: 137416.0
        }
      ]
    }
  },
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;numberOfPartitions&amp;quot;: 3
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;delete-a-topic-properties&#34;&gt;delete a topic properties&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;DELETE /v0/topics/${name}?group=${group}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;204 NoContent
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    It is ok to delete a nonexistent topic, and the response is &lt;strong&gt;204 NoContent&lt;/strong&gt;.
You must be stopped the delete topic.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;get&#34;&gt;get a topic properties&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/topics/${name}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;brokerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;bk&amp;quot;
  },
  &amp;quot;name&amp;quot;: &amp;quot;topic1&amp;quot;,
  &amp;quot;partitionInfos&amp;quot;: [],
  &amp;quot;lastModified&amp;quot;: 1578537915735,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;numberOfReplications&amp;quot;: 1,
  &amp;quot;nodeMetrics&amp;quot;: {
    &amp;quot;node00&amp;quot;: {
      &amp;quot;meters&amp;quot;: [
        {
          &amp;quot;document&amp;quot;: &amp;quot;BytesInPerSec&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;BytesInPerSec&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585069111069,
          &amp;quot;unit&amp;quot;: &amp;quot;bytes / SECONDS&amp;quot;,
          &amp;quot;value&amp;quot;: 2143210885
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;MessagesInPerSec&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;MessagesInPerSec&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585069111069,
          &amp;quot;unit&amp;quot;: &amp;quot;messages / SECONDS&amp;quot;,
          &amp;quot;value&amp;quot;: 2810000.0
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;TotalProduceRequestsPerSec&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;TotalProduceRequestsPerSec&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585069111069,
          &amp;quot;unit&amp;quot;: &amp;quot;requests / SECONDS&amp;quot;,
          &amp;quot;value&amp;quot;: 137416.0
        }
      ]
    }
  },
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;numberOfPartitions&amp;quot;: 3
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;start-a-topic-on-remote-broker-cluster&#34;&gt;start a topic on remote broker cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/topics/${name}/start&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#get&#34;&gt;Get Topic info&lt;/a&gt; to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;stop-a-topic-from-remote-broker-cluster&#34;&gt;stop a topic from remote broker cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/topics/${name}/stop&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    the topic will lose all data after stopping.
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#get&#34;&gt;Get Topic info&lt;/a&gt; to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Topic</title>
      <link>https://oharastream.github.io/en/docs/master/rest-api/topics/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/master/rest-api/topics/</guid>
      <description>&lt;p&gt;Ohara topic is based on kafka topic. It means the creation of topic on
ohara will invoke a creation of kafka also. Also, the delete to Ohara
topic also invoke a delete request to kafka. The common properties in
topic are shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) - topic group. The legal character is number,
lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) - topic name. The legal character is number,
lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;brokerClusterKey (&lt;strong&gt;Object&lt;/strong&gt;) - target broker cluster.
&lt;ul&gt;
&lt;li&gt;brokerClusterKey.group (&lt;strong&gt;option(string)&lt;/strong&gt;) - the group of
cluster&lt;/li&gt;
&lt;li&gt;brokerClusterKey.name (&lt;strong&gt;string&lt;/strong&gt;) - the name of cluster&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
  &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    the following forms are legal as well: (1) &lt;code&gt;{&amp;quot;name&amp;quot;: &amp;quot;n&amp;quot;}&lt;/code&gt;, (2) &lt;code&gt;&amp;quot;n&amp;quot;&lt;/code&gt;.
Both forms are converted to &lt;code&gt;{&amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;n&amp;quot;}&lt;/code&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;numberOfReplications (&lt;strong&gt;option(int)&lt;/strong&gt;) - the number of
replications&lt;/li&gt;
&lt;li&gt;numberOfPartitions (&lt;strong&gt;option(int)&lt;/strong&gt;)- the number of partitions for
this topic&lt;/li&gt;
&lt;li&gt;tags (&lt;strong&gt;option(object)&lt;/strong&gt;) - the extra description to this object&lt;/li&gt;
&lt;/ol&gt;
  &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;ol&gt;
&lt;li&gt;The name must be unique in a broker cluster.&lt;/li&gt;
&lt;li&gt;There are many other available configs which are useful in
creating topic. Please ref &lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/brokers/&#34;&gt;broker clusters&lt;/a&gt;
to see how to retrieve the available configs for specific broker
cluster.&lt;/li&gt;
&lt;/ol&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The following information are tagged by Ohara.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;state (&lt;strong&gt;option(string)&lt;/strong&gt;) - state of a running topic. nothing if
the topic is not running.&lt;/li&gt;
&lt;li&gt;partitionInfos (&lt;strong&gt;Array(object)&lt;/strong&gt;) - the details of partitions.
&lt;ul&gt;
&lt;li&gt;index (&lt;strong&gt;int&lt;/strong&gt;) - the index of partition&lt;/li&gt;
&lt;li&gt;leaderNode (&lt;strong&gt;String&lt;/strong&gt;) - the leader (node) of this partition&lt;/li&gt;
&lt;li&gt;replicaNodes (&lt;strong&gt;Array(String)&lt;/strong&gt;) - the nodes hosting the
replica for this partition&lt;/li&gt;
&lt;li&gt;inSyncReplicaNodes (&lt;strong&gt;Array(String)&lt;/strong&gt;) - the nodes which have
fetched the newest data from leader&lt;/li&gt;
&lt;li&gt;beginningOffset (&lt;strong&gt;long&lt;/strong&gt;) - the beginning offset&lt;/li&gt;
&lt;li&gt;endOffset (&lt;strong&gt;endOffset&lt;/strong&gt;) - the latest offset (Normally, it is
the latest commit data)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) - the group value is always &amp;ldquo;default&amp;rdquo;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#metrics&#34;&gt;nodeMetrics&lt;/a&gt; (&lt;strong&gt;object&lt;/strong&gt;) -
the metrics number of a running topic&lt;/li&gt;
&lt;li&gt;lastModified (&lt;strong&gt;long&lt;/strong&gt;) - the last time to update this ftp
information&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;store-a-topic-properties&#34;&gt;store a topic properties&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;POST /v0/topics&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;ol&gt;
&lt;li&gt;the name you pass to Ohara is used to build topic on kafka, and it
is restricted by Kafka ([a-zA-Z0-9._-])&lt;/li&gt;
&lt;li&gt;the ignored fields will
be auto-completed by Ohara Configurator. Also, you could update/replace
it by UPDATE request later.&lt;/li&gt;
&lt;li&gt;this API does NOT create a topic on
broker cluster. Instead, you should send START request to run a topic on
broker cluster actually&lt;/li&gt;
&lt;li&gt;There are many other available configs which
are useful in creating topic. Please ref
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/brokers/&#34;&gt;broker clusters&lt;/a&gt; to see
how to retrieve the available configs for specific broker cluster.&lt;/li&gt;
&lt;/ol&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;brokerClusterKey&amp;quot;: &amp;quot;bk&amp;quot;,
  &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;,
  &amp;quot;numberOfReplications&amp;quot;: 1,
  &amp;quot;numberOfPartitions&amp;quot;: 1
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;brokerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;bk&amp;quot;
  },
  &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;,
  &amp;quot;partitionInfos&amp;quot;: [],
  &amp;quot;lastModified&amp;quot;: 1578537142950,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;numberOfReplications&amp;quot;: 1,
  &amp;quot;nodeMetrics&amp;quot;: {
    &amp;quot;node00&amp;quot;: {
      &amp;quot;meters&amp;quot;: [
        {
          &amp;quot;document&amp;quot;: &amp;quot;BytesInPerSec&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;BytesInPerSec&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585069111069,
          &amp;quot;unit&amp;quot;: &amp;quot;bytes / SECONDS&amp;quot;,
          &amp;quot;value&amp;quot;: 2143210885
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;MessagesInPerSec&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;MessagesInPerSec&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585069111069,
          &amp;quot;unit&amp;quot;: &amp;quot;messages / SECONDS&amp;quot;,
          &amp;quot;value&amp;quot;: 2810000.0
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;TotalProduceRequestsPerSec&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;TotalProduceRequestsPerSec&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585069111069,
          &amp;quot;unit&amp;quot;: &amp;quot;requests / SECONDS&amp;quot;,
          &amp;quot;value&amp;quot;: 137416.0
        }
      ]
    }
  },
  &amp;quot;group&amp;quot;:&amp;quot;default&amp;quot;,
  &amp;quot;numberOfPartitions&amp;quot;: 1
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The topic, which is just created, does not have any metrics.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;update-a-topic-properties&#34;&gt;update a topic properties&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/topics/${name}?group=${group}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;numberOfPartitions&amp;quot;: 3
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;brokerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;bk&amp;quot;
  },
  &amp;quot;name&amp;quot;: &amp;quot;topic0&amp;quot;,
  &amp;quot;partitionInfos&amp;quot;: [],
  &amp;quot;lastModified&amp;quot;: 1578537915735,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;numberOfReplications&amp;quot;: 1,
  &amp;quot;nodeMetrics&amp;quot;: {
    &amp;quot;node00&amp;quot;: {
      &amp;quot;meters&amp;quot;: [
        {
          &amp;quot;document&amp;quot;: &amp;quot;BytesInPerSec&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;BytesInPerSec&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585069111069,
          &amp;quot;unit&amp;quot;: &amp;quot;bytes / SECONDS&amp;quot;,
          &amp;quot;value&amp;quot;: 2143210885
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;MessagesInPerSec&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;MessagesInPerSec&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585069111069,
          &amp;quot;unit&amp;quot;: &amp;quot;messages / SECONDS&amp;quot;,
          &amp;quot;value&amp;quot;: 2810000.0
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;TotalProduceRequestsPerSec&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;TotalProduceRequestsPerSec&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585069111069,
          &amp;quot;unit&amp;quot;: &amp;quot;requests / SECONDS&amp;quot;,
          &amp;quot;value&amp;quot;: 137416.0
        }
      ]
    }
  },
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;numberOfPartitions&amp;quot;: 3
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;list-all-topics-properties&#34;&gt;list all topics properties&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/topics?${key}=${value}&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;the accepted query keys are listed below.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;group&lt;/li&gt;
&lt;li&gt;name&lt;/li&gt;
&lt;li&gt;state&lt;/li&gt;
&lt;li&gt;lastModified&lt;/li&gt;
&lt;li&gt;tags&lt;/li&gt;
&lt;li&gt;tag: this field is similar to tags but it addresses the &amp;ldquo;contain&amp;rdquo; behavior.&lt;/li&gt;
&lt;li&gt;key&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Using &amp;ldquo;NONE&amp;rdquo; represents the nonexistence of state.
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
  {
    &amp;quot;brokerClusterKey&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;bk&amp;quot;
    },
    &amp;quot;name&amp;quot;: &amp;quot;topic1&amp;quot;,
    &amp;quot;partitionInfos&amp;quot;: [],
    &amp;quot;lastModified&amp;quot;: 1578537915735,
    &amp;quot;tags&amp;quot;: {},
    &amp;quot;numberOfReplications&amp;quot;: 1,
  &amp;quot;nodeMetrics&amp;quot;: {
    &amp;quot;node00&amp;quot;: {
      &amp;quot;meters&amp;quot;: [
        {
          &amp;quot;document&amp;quot;: &amp;quot;BytesInPerSec&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;BytesInPerSec&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585069111069,
          &amp;quot;unit&amp;quot;: &amp;quot;bytes / SECONDS&amp;quot;,
          &amp;quot;value&amp;quot;: 2143210885
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;MessagesInPerSec&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;MessagesInPerSec&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585069111069,
          &amp;quot;unit&amp;quot;: &amp;quot;messages / SECONDS&amp;quot;,
          &amp;quot;value&amp;quot;: 2810000.0
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;TotalProduceRequestsPerSec&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;TotalProduceRequestsPerSec&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585069111069,
          &amp;quot;unit&amp;quot;: &amp;quot;requests / SECONDS&amp;quot;,
          &amp;quot;value&amp;quot;: 137416.0
        }
      ]
    }
  },
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;numberOfPartitions&amp;quot;: 3
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;delete-a-topic-properties&#34;&gt;delete a topic properties&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;DELETE /v0/topics/${name}?group=${group}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;204 NoContent
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    It is ok to delete a nonexistent topic, and the response is &lt;strong&gt;204 NoContent&lt;/strong&gt;.
You must be stopped the delete topic.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;get&#34;&gt;get a topic properties&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/topics/${name}&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;brokerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;bk&amp;quot;
  },
  &amp;quot;name&amp;quot;: &amp;quot;topic1&amp;quot;,
  &amp;quot;partitionInfos&amp;quot;: [],
  &amp;quot;lastModified&amp;quot;: 1578537915735,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;numberOfReplications&amp;quot;: 1,
  &amp;quot;nodeMetrics&amp;quot;: {
    &amp;quot;node00&amp;quot;: {
      &amp;quot;meters&amp;quot;: [
        {
          &amp;quot;document&amp;quot;: &amp;quot;BytesInPerSec&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;BytesInPerSec&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585069111069,
          &amp;quot;unit&amp;quot;: &amp;quot;bytes / SECONDS&amp;quot;,
          &amp;quot;value&amp;quot;: 2143210885
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;MessagesInPerSec&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;MessagesInPerSec&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585069111069,
          &amp;quot;unit&amp;quot;: &amp;quot;messages / SECONDS&amp;quot;,
          &amp;quot;value&amp;quot;: 2810000.0
        },
        {
          &amp;quot;document&amp;quot;: &amp;quot;TotalProduceRequestsPerSec&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;TotalProduceRequestsPerSec&amp;quot;,
          &amp;quot;queryTime&amp;quot;: 1585069111069,
          &amp;quot;unit&amp;quot;: &amp;quot;requests / SECONDS&amp;quot;,
          &amp;quot;value&amp;quot;: 137416.0
        }
      ]
    }
  },
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;numberOfPartitions&amp;quot;: 3
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;start-a-topic-on-remote-broker-cluster&#34;&gt;start a topic on remote broker cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/topics/${name}/start&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#get&#34;&gt;Get Topic info&lt;/a&gt; to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;stop-a-topic-from-remote-broker-cluster&#34;&gt;stop a topic from remote broker cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/topics/${name}/stop&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    the topic will lose all data after stopping.
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#get&#34;&gt;Get Topic info&lt;/a&gt; to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Validation</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/rest-api/validate/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/rest-api/validate/</guid>
      <description>&lt;p&gt;Notwithstanding we have read a lot of document and guideline, there is a
chance to input incorrect request or settings when operating Ohara.
Hence, Ohara provides a serial APIs used to validate request/settings
before you do use them to start service. Noted that not all
request/settings are validated by Ohara configurator. If the
request/settings is used by other system (for example, kafka), Ohara
automatically bypass the validation request to target system and then
wrap the result to JSON representation.&lt;/p&gt;
&lt;h2 id=&#34;validate-the-connector-settings&#34;&gt;Validate the connector settings&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/validate/connector&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Before starting a connector, you can send the settings to test whether
all settings are available for the specific connector. Ohara is not in
charge of settings validation. Connector MUST define its setting via

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/setting_definition/&#34;&gt;setting definitions&lt;/a&gt;.
Ohara configurator only repackage the request to kafka
format and then collect the validation result from kafka.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;p&gt;The request format is same as 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/connectors/#create-settings&#34;&gt;connector request&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;p&gt;If target connector has defined the settings correctly, kafka is
doable to validate each setting of request. Ohara configurator
collect the result and then generate the following report.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;errorCount&amp;quot;: 0,
  &amp;quot;settings&amp;quot;: [
    {
      &amp;quot;definition&amp;quot;: {
        &amp;quot;displayName&amp;quot;: &amp;quot;Connector class&amp;quot;,
        &amp;quot;group&amp;quot;: &amp;quot;core&amp;quot;,
        &amp;quot;orderInGroup&amp;quot;: 3,
        &amp;quot;key&amp;quot;: &amp;quot;connector.class&amp;quot;,
        &amp;quot;valueType&amp;quot;: &amp;quot;CLASS&amp;quot;,
        &amp;quot;necessary&amp;quot;: &amp;quot;REQUIRED&amp;quot;,
        &amp;quot;defaultValue&amp;quot;: null,
        &amp;quot;documentation&amp;quot;: &amp;quot;the class name of connector&amp;quot;,
        &amp;quot;reference&amp;quot;: &amp;quot;NONE&amp;quot;,
        &amp;quot;regex&amp;quot;: null,
        &amp;quot;internal&amp;quot;: false,
        &amp;quot;permission&amp;quot;: &amp;quot;EDITABLE&amp;quot;,
        &amp;quot;tableKeys&amp;quot;: [],
        &amp;quot;recommendedValues&amp;quot;: [],
        &amp;quot;blacklist&amp;quot;: []
      },
      &amp;quot;value&amp;quot;: {
        &amp;quot;key&amp;quot;: &amp;quot;connector.class&amp;quot;,
        &amp;quot;value&amp;quot;: &amp;quot;oharastream.ohara.connector.perf.PerfSource&amp;quot;,
        &amp;quot;errors&amp;quot;: []
      }
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above example only show a part of report. The element &lt;strong&gt;definition&lt;/strong&gt;
is equal to

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/workers/&#34;&gt;connector’s setting definition&lt;/a&gt;.
The definition is what connector must define. If you don&amp;rsquo;t
write any definitions for you connector, the validation will do nothing
for you. The element &lt;strong&gt;value&lt;/strong&gt; is what you request to validate.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;key (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the property key. It is equal to key in &lt;strong&gt;definition&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;value (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the value you request to validate&lt;/li&gt;
&lt;li&gt;errors (&lt;strong&gt;array(string)&lt;/strong&gt;) &amp;mdash; error message when the input value is
illegal to connector&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Validation</title>
      <link>https://oharastream.github.io/en/docs/master/rest-api/validate/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/master/rest-api/validate/</guid>
      <description>&lt;p&gt;Notwithstanding we have read a lot of document and guideline, there is a
chance to input incorrect request or settings when operating Ohara.
Hence, Ohara provides a serial APIs used to validate request/settings
before you do use them to start service. Noted that not all
request/settings are validated by Ohara configurator. If the
request/settings is used by other system (for example, kafka), Ohara
automatically bypass the validation request to target system and then
wrap the result to JSON representation.&lt;/p&gt;
&lt;h2 id=&#34;validate-the-connector-settings&#34;&gt;Validate the connector settings&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/validate/connector&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Before starting a connector, you can send the settings to test whether
all settings are available for the specific connector. Ohara is not in
charge of settings validation. Connector MUST define its setting via

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/setting_definition/&#34;&gt;setting definitions&lt;/a&gt;.
Ohara configurator only repackage the request to kafka
format and then collect the validation result from kafka.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;p&gt;The request format is same as 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/connectors/#create-settings&#34;&gt;connector request&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;p&gt;If target connector has defined the settings correctly, kafka is
doable to validate each setting of request. Ohara configurator
collect the result and then generate the following report.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;errorCount&amp;quot;: 0,
  &amp;quot;settings&amp;quot;: [
    {
      &amp;quot;definition&amp;quot;: {
        &amp;quot;displayName&amp;quot;: &amp;quot;Connector class&amp;quot;,
        &amp;quot;group&amp;quot;: &amp;quot;core&amp;quot;,
        &amp;quot;orderInGroup&amp;quot;: 3,
        &amp;quot;key&amp;quot;: &amp;quot;connector.class&amp;quot;,
        &amp;quot;valueType&amp;quot;: &amp;quot;CLASS&amp;quot;,
        &amp;quot;necessary&amp;quot;: &amp;quot;REQUIRED&amp;quot;,
        &amp;quot;defaultValue&amp;quot;: null,
        &amp;quot;documentation&amp;quot;: &amp;quot;the class name of connector&amp;quot;,
        &amp;quot;reference&amp;quot;: &amp;quot;NONE&amp;quot;,
        &amp;quot;regex&amp;quot;: null,
        &amp;quot;internal&amp;quot;: false,
        &amp;quot;permission&amp;quot;: &amp;quot;EDITABLE&amp;quot;,
        &amp;quot;tableKeys&amp;quot;: [],
        &amp;quot;recommendedValues&amp;quot;: [],
        &amp;quot;blacklist&amp;quot;: []
      },
      &amp;quot;value&amp;quot;: {
        &amp;quot;key&amp;quot;: &amp;quot;connector.class&amp;quot;,
        &amp;quot;value&amp;quot;: &amp;quot;oharastream.ohara.connector.perf.PerfSource&amp;quot;,
        &amp;quot;errors&amp;quot;: []
      }
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above example only show a part of report. The element &lt;strong&gt;definition&lt;/strong&gt;
is equal to

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/workers/&#34;&gt;connector’s setting definition&lt;/a&gt;.
The definition is what connector must define. If you don&amp;rsquo;t
write any definitions for you connector, the validation will do nothing
for you. The element &lt;strong&gt;value&lt;/strong&gt; is what you request to validate.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;key (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the property key. It is equal to key in &lt;strong&gt;definition&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;value (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the value you request to validate&lt;/li&gt;
&lt;li&gt;errors (&lt;strong&gt;array(string)&lt;/strong&gt;) &amp;mdash; error message when the input value is
illegal to connector&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Worker</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/rest-api/workers/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/rest-api/workers/</guid>
      <description>&lt;p&gt;
&lt;a href=&#34;https://kafka.apache.org/intro&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Worker&lt;/a&gt; is core of running connectors
for Ohara. It provides a simple but powerful system to distribute and
execute connectors on different nodes. The performance of connectors
depends on the scale of worker cluster. For example, you can assign the
number of task when creating connector. If there is only 3 nodes within
your worker cluster and you specify 6 tasks for your connector, the
tasks of you connectors still be deployed on 3 nodes. That is to say,
the connector can&amp;rsquo;t get more resources to execute.&lt;/p&gt;
&lt;p&gt;Worker is based on 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/brokers/&#34;&gt;Broker&lt;/a&gt;,
hence you have to create broker cluster first. Noted that a
broker cluster can be used by multi worker clusters. BTW, worker cluster
will pre-allocate a lot of topics on broker cluster, and the pre-created
topics CAN&amp;rsquo;T be reused by different worker clusters.&lt;/p&gt;
&lt;p&gt;The properties which can be set by user are shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; cluster name. The legal character is number,
lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; cluster group. The legal character is number,
lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;imageName (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; docker image&lt;/li&gt;
&lt;li&gt;brokerClusterKey (&lt;strong&gt;Object&lt;/strong&gt;) &amp;mdash; the broker cluster used to store
data generated by this worker cluster
&lt;ul&gt;
&lt;li&gt;brokerClusterKey.group (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the group of
cluster&lt;/li&gt;
&lt;li&gt;brokerClusterKey.name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the name of cluster&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    the following forms are legal as well: (1) &lt;code&gt;{&amp;quot;name&amp;quot;: &amp;quot;n&amp;quot;}&lt;/code&gt;, (2) &lt;code&gt;&amp;quot;n&amp;quot;&lt;/code&gt;.
Both forms are converted to &lt;code&gt;{&amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;n&amp;quot;}&lt;/code&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;
&lt;p&gt;clientPort (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; worker client port&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;jmxPort (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; worker jmx port&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;freePorts (&lt;strong&gt;Array(int)&lt;/strong&gt;) &amp;mdash; the ports you want to pre-bind for the connectors.&lt;/p&gt;
&lt;p&gt;If your connectors want to build a service on a port which is available
to external nodes, you have to define the free ports for your worker cluster
so as to make Configurator pre-bind the ports on your worker
cluster. Otherwise, your connectors is disable to build service
on the port of worker cluster and be connected by external node.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;group.id (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the id of worker stored in broker cluster&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;config.storage.topic (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; a internal topic used to store
connector configuration&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;config.storage.replication.factor (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; number of
replications for config topic&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;offset.storage.topic (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; a internal topic used to store
connector offset&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;offset.storage.partitions (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; number of partitions for
offset topic&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;offset.storage.replication.factor (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; number of
replications for offset topic&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;status.storage.topic (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; an internal topic used to store
connector status&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;status.storage.partitions (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; number of partitions for
status topic&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;status.storage.replication.factor (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; number of
replications for status topic&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;pluginKeys (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the &amp;ldquo;primary key&amp;rdquo; of jars which contain your connectors&lt;/p&gt;
&lt;p&gt;You can require worker cluster to load the jars stored in ohara
if you want to run custom connectors on the worker cluster. see

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/files/&#34;&gt;Files APIs&lt;/a&gt; for
uploading jars to ohara. The files which are deployed to worker
must be uber jars - it must include all dependencies exclude for
ohara stuff.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;sharedJarKeys (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; those jars is deployed on the root classpath so
all connectors are able to load them.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    &lt;ol&gt;
&lt;li&gt;
&lt;p&gt;When you implement the Ohara connector, you must use the
File API upload connector jar file to worker.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If your jdbc source connector need to use the third party
jar file (such oracle jdbc jar file), you must use the File
API upload jar file then setting sharedJarKeys to create the
worker API.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ol start=&#34;19&#34;&gt;
&lt;li&gt;
&lt;p&gt;nodeNames (&lt;strong&gt;array(string)&lt;/strong&gt;) &amp;mdash; the nodes running the worker
process&lt;/p&gt;
&lt;p&gt;The following information are updated by Ohara.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;aliveNodes (&lt;strong&gt;array(string)&lt;/strong&gt;) &amp;mdash; the nodes that host the running
containers of worker&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The group.id, config.storage.topic, offset.storage.topic and
status.storage.topic must be unique in broker cluster. Don&amp;rsquo;t reuse
them in same broker cluster. Dispatching above unique resources to
two worker cluster will pollute the data. Of course, Ohara do a
quick failure for this dumb case. However, it is not a quick
failure when you are using raw kafka rather than Ohara. Please
double check what you configure!
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;rest-workers-create&#34;&gt;create a worker properties&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;POST /v0/workers&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;wk&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [&amp;quot;node00&amp;quot;],
  &amp;quot;brokerClusterKey&amp;quot;: &amp;quot;bk&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;brokerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;bk00&amp;quot;
  },
  &amp;quot;name&amp;quot;: &amp;quot;wk00&amp;quot;,
  &amp;quot;offset.storage.partitions&amp;quot;: 1,
  &amp;quot;xms&amp;quot;: 2048,
  &amp;quot;routes&amp;quot;: {},
  &amp;quot;config.storage.topic&amp;quot;: &amp;quot;b8dadc3de21048fa927335b8f&amp;quot;,
  &amp;quot;sharedJarKeys&amp;quot;: [],
  &amp;quot;lastModified&amp;quot;: 1578982566359,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;xmx&amp;quot;: 2048,
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/connect-worker:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;offset.storage.topic&amp;quot;: &amp;quot;346b839ea3e74387ab1eea409&amp;quot;,
  &amp;quot;status.storage.replication.factor&amp;quot;: 1,
  &amp;quot;group.id&amp;quot;: &amp;quot;af4b4d49234a4848bb90fb452&amp;quot;,
  &amp;quot;offset.storage.replication.factor&amp;quot;: 1,
  &amp;quot;aliveNodes&amp;quot;: [],
  &amp;quot;pluginKeys&amp;quot;: [],
  &amp;quot;status.storage.partitions&amp;quot;: 1,
  &amp;quot;freePorts&amp;quot;: [],
  &amp;quot;jmxPort&amp;quot;: 33333,
  &amp;quot;config.storage.partitions&amp;quot;: 1,
  &amp;quot;clientPort&amp;quot;: 45127,
  &amp;quot;config.storage.replication.factor&amp;quot;: 1,
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ],
  &amp;quot;status.storage.topic&amp;quot;: &amp;quot;1cdca943f0b945bc892ebe9a7&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;rest-workers-list&#34;&gt;list all workers clusters&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/workers&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
  {
    &amp;quot;brokerClusterKey&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;bk00&amp;quot;
    },
    &amp;quot;name&amp;quot;: &amp;quot;wk00&amp;quot;,
    &amp;quot;offset.storage.partitions&amp;quot;: 1,
    &amp;quot;xms&amp;quot;: 2048,
    &amp;quot;routes&amp;quot;: {},
    &amp;quot;config.storage.topic&amp;quot;: &amp;quot;b8dadc3de21048fa927335b8f&amp;quot;,
    &amp;quot;sharedJarKeys&amp;quot;: [],
    &amp;quot;lastModified&amp;quot;: 1578982566359,
    &amp;quot;tags&amp;quot;: {},
    &amp;quot;xmx&amp;quot;: 2048,
    &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/connect-worker:0.11.0-SNAPSHOT&amp;quot;,
    &amp;quot;offset.storage.topic&amp;quot;: &amp;quot;346b839ea3e74387ab1eea409&amp;quot;,
    &amp;quot;status.storage.replication.factor&amp;quot;: 1,
    &amp;quot;group.id&amp;quot;: &amp;quot;af4b4d49234a4848bb90fb452&amp;quot;,
    &amp;quot;offset.storage.replication.factor&amp;quot;: 1,
    &amp;quot;aliveNodes&amp;quot;: [],
    &amp;quot;pluginKeys&amp;quot;: [],
    &amp;quot;status.storage.partitions&amp;quot;: 1,
    &amp;quot;freePorts&amp;quot;: [],
    &amp;quot;jmxPort&amp;quot;: 33333,
    &amp;quot;config.storage.partitions&amp;quot;: 1,
    &amp;quot;clientPort&amp;quot;: 45127,
    &amp;quot;config.storage.replication.factor&amp;quot;: 1,
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;nodeNames&amp;quot;: [
      &amp;quot;node00&amp;quot;
    ],
    &amp;quot;status.storage.topic&amp;quot;: &amp;quot;1cdca943f0b945bc892ebe9a7&amp;quot;
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;update-broker-cluster-properties&#34;&gt;update broker cluster properties&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/workers/$name?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    If the required worker (group, name) was not exists, we will try to use
this request as POST
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;jmxPort&amp;quot;: 7777
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;brokerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;bk00&amp;quot;
  },
  &amp;quot;name&amp;quot;: &amp;quot;wk00&amp;quot;,
  &amp;quot;offset.storage.partitions&amp;quot;: 1,
  &amp;quot;xms&amp;quot;: 2048,
  &amp;quot;routes&amp;quot;: {},
  &amp;quot;config.storage.topic&amp;quot;: &amp;quot;b8dadc3de21048fa927335b8f&amp;quot;,
  &amp;quot;sharedJarKeys&amp;quot;: [],
  &amp;quot;lastModified&amp;quot;: 1578982765738,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;xmx&amp;quot;: 2048,
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/connect-worker:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;offset.storage.topic&amp;quot;: &amp;quot;346b839ea3e74387ab1eea409&amp;quot;,
  &amp;quot;status.storage.replication.factor&amp;quot;: 1,
  &amp;quot;group.id&amp;quot;: &amp;quot;af4b4d49234a4848bb90fb452&amp;quot;,
  &amp;quot;offset.storage.replication.factor&amp;quot;: 1,
  &amp;quot;aliveNodes&amp;quot;: [],
  &amp;quot;pluginKeys&amp;quot;: [],
  &amp;quot;status.storage.partitions&amp;quot;: 1,
  &amp;quot;freePorts&amp;quot;: [],
  &amp;quot;jmxPort&amp;quot;: 7777,
  &amp;quot;config.storage.partitions&amp;quot;: 1,
  &amp;quot;clientPort&amp;quot;: 45127,
  &amp;quot;config.storage.replication.factor&amp;quot;: 1,
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ],
  &amp;quot;status.storage.topic&amp;quot;: &amp;quot;1cdca943f0b945bc892ebe9a7&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;delete-a-worker-properties&#34;&gt;delete a worker properties&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;DELETE /v0/workers/$name?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;You cannot delete properties of an non-stopped worker cluster. We will
use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you don&amp;rsquo;t
specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;204 NoContent
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    It is ok to delete an nonexistent worker cluster, and the response
is 204 NoContent.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;rest-workers-get&#34;&gt;get a worker cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/workers/$name?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;brokerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;bk00&amp;quot;
  },
  &amp;quot;name&amp;quot;: &amp;quot;wk00&amp;quot;,
  &amp;quot;offset.storage.partitions&amp;quot;: 1,
  &amp;quot;xms&amp;quot;: 2048,
  &amp;quot;routes&amp;quot;: {},
  &amp;quot;config.storage.topic&amp;quot;: &amp;quot;b8dadc3de21048fa927335b8f&amp;quot;,
  &amp;quot;sharedJarKeys&amp;quot;: [],
  &amp;quot;lastModified&amp;quot;: 1578982765738,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;xmx&amp;quot;: 2048,
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/connect-worker:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;offset.storage.topic&amp;quot;: &amp;quot;346b839ea3e74387ab1eea409&amp;quot;,
  &amp;quot;status.storage.replication.factor&amp;quot;: 1,
  &amp;quot;group.id&amp;quot;: &amp;quot;af4b4d49234a4848bb90fb452&amp;quot;,
  &amp;quot;offset.storage.replication.factor&amp;quot;: 1,
  &amp;quot;aliveNodes&amp;quot;: [],
  &amp;quot;pluginKeys&amp;quot;: [],
  &amp;quot;status.storage.partitions&amp;quot;: 1,
  &amp;quot;freePorts&amp;quot;: [],
  &amp;quot;jmxPort&amp;quot;: 7777,
  &amp;quot;config.storage.partitions&amp;quot;: 1,
  &amp;quot;clientPort&amp;quot;: 45127,
  &amp;quot;config.storage.replication.factor&amp;quot;: 1,
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ],
  &amp;quot;status.storage.topic&amp;quot;: &amp;quot;1cdca943f0b945bc892ebe9a7&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;start-a-worker-cluster&#34;&gt;start a worker cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/workers/$name/start?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#rest-workers-get&#34;&gt;Get worker cluster&lt;/a&gt; to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;stop-a-worker-cluster&#34;&gt;stop a worker cluster&lt;/h2&gt;
&lt;p&gt;Gracefully stopping a running worker cluster.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/workers/$name/stop?group=$group[&amp;amp;force=true]&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Query Parameters&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;force (&lt;strong&gt;boolean&lt;/strong&gt;) &amp;mdash; true if you don&amp;rsquo;t want to wait the
graceful shutdown (it can save your time but may damage your
data).&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#rest-workers-get&#34;&gt;Get worker cluster&lt;/a&gt; to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;add-a-new-node-to-a-running-worker-cluster&#34;&gt;add a new node to a running worker cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/workers/$name/$nodeName?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;p&gt;If you want to extend a running worker cluster, you can add a node to
share the heavy loading of a running worker cluster. However, the
balance is not triggered at once. By the way, moving a task to another
idle node needs to &lt;strong&gt;stop&lt;/strong&gt; task first. Don&amp;rsquo;t worry about the temporary
lower throughput when balancer is running.&lt;/p&gt;
&lt;h2 id=&#34;remove-a-node-from-a-running-worker-cluster&#34;&gt;remove a node from a running worker cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;DELETE /v0/workers/$name/$nodeName?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;p&gt;If your budget is limited, you can decrease the number of nodes running
worker cluster. BUT, removing a node from a running worker cluster
invoke a lot of task move, and it will decrease the throughput of your
connector.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;204 NoContent
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    It is ok to delete an nonexistent worker node, and the response is
204 NoContent.
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Worker</title>
      <link>https://oharastream.github.io/en/docs/master/rest-api/workers/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/master/rest-api/workers/</guid>
      <description>&lt;p&gt;
&lt;a href=&#34;https://kafka.apache.org/intro&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Worker&lt;/a&gt; is core of running connectors
for Ohara. It provides a simple but powerful system to distribute and
execute connectors on different nodes. The performance of connectors
depends on the scale of worker cluster. For example, you can assign the
number of task when creating connector. If there is only 3 nodes within
your worker cluster and you specify 6 tasks for your connector, the
tasks of you connectors still be deployed on 3 nodes. That is to say,
the connector can&amp;rsquo;t get more resources to execute.&lt;/p&gt;
&lt;p&gt;Worker is based on 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/brokers/&#34;&gt;Broker&lt;/a&gt;,
hence you have to create broker cluster first. Noted that a
broker cluster can be used by multi worker clusters. BTW, worker cluster
will pre-allocate a lot of topics on broker cluster, and the pre-created
topics CAN&amp;rsquo;T be reused by different worker clusters.&lt;/p&gt;
&lt;p&gt;The properties which can be set by user are shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; cluster name. The legal character is number,
lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; cluster group. The legal character is number,
lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;imageName (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; docker image&lt;/li&gt;
&lt;li&gt;brokerClusterKey (&lt;strong&gt;Object&lt;/strong&gt;) &amp;mdash; the broker cluster used to store
data generated by this worker cluster
&lt;ul&gt;
&lt;li&gt;brokerClusterKey.group (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the group of
cluster&lt;/li&gt;
&lt;li&gt;brokerClusterKey.name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the name of cluster&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    the following forms are legal as well: (1) &lt;code&gt;{&amp;quot;name&amp;quot;: &amp;quot;n&amp;quot;}&lt;/code&gt;, (2) &lt;code&gt;&amp;quot;n&amp;quot;&lt;/code&gt;.
Both forms are converted to &lt;code&gt;{&amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;n&amp;quot;}&lt;/code&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;
&lt;p&gt;clientPort (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; worker client port&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;jmxPort (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; worker jmx port&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;freePorts (&lt;strong&gt;Array(int)&lt;/strong&gt;) &amp;mdash; the ports you want to pre-bind for the connectors.&lt;/p&gt;
&lt;p&gt;If your connectors want to build a service on a port which is available
to external nodes, you have to define the free ports for your worker cluster
so as to make Configurator pre-bind the ports on your worker
cluster. Otherwise, your connectors is disable to build service
on the port of worker cluster and be connected by external node.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;group.id (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the id of worker stored in broker cluster&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;config.storage.topic (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; a internal topic used to store
connector configuration&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;config.storage.replication.factor (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; number of
replications for config topic&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;offset.storage.topic (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; a internal topic used to store
connector offset&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;offset.storage.partitions (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; number of partitions for
offset topic&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;offset.storage.replication.factor (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; number of
replications for offset topic&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;status.storage.topic (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; an internal topic used to store
connector status&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;status.storage.partitions (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; number of partitions for
status topic&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;status.storage.replication.factor (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; number of
replications for status topic&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;pluginKeys (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the &amp;ldquo;primary key&amp;rdquo; of jars which contain your connectors&lt;/p&gt;
&lt;p&gt;You can require worker cluster to load the jars stored in ohara
if you want to run custom connectors on the worker cluster. see

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/files/&#34;&gt;Files APIs&lt;/a&gt; for
uploading jars to ohara. The files which are deployed to worker
must be uber jars - it must include all dependencies exclude for
ohara stuff.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;sharedJarKeys (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; those jars is deployed on the root classpath so
all connectors are able to load them.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    &lt;ol&gt;
&lt;li&gt;
&lt;p&gt;When you implement the Ohara connector, you must use the
File API upload connector jar file to worker.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If your jdbc source connector need to use the third party
jar file (such oracle jdbc jar file), you must use the File
API upload jar file then setting sharedJarKeys to create the
worker API.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ol start=&#34;19&#34;&gt;
&lt;li&gt;
&lt;p&gt;nodeNames (&lt;strong&gt;array(string)&lt;/strong&gt;) &amp;mdash; the nodes running the worker
process&lt;/p&gt;
&lt;p&gt;The following information are updated by Ohara.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;aliveNodes (&lt;strong&gt;array(string)&lt;/strong&gt;) &amp;mdash; the nodes that host the running
containers of worker&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The group.id, config.storage.topic, offset.storage.topic and
status.storage.topic must be unique in broker cluster. Don&amp;rsquo;t reuse
them in same broker cluster. Dispatching above unique resources to
two worker cluster will pollute the data. Of course, Ohara do a
quick failure for this dumb case. However, it is not a quick
failure when you are using raw kafka rather than Ohara. Please
double check what you configure!
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;rest-workers-create&#34;&gt;create a worker properties&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;POST /v0/workers&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;wk&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [&amp;quot;node00&amp;quot;],
  &amp;quot;brokerClusterKey&amp;quot;: &amp;quot;bk&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;brokerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;bk00&amp;quot;
  },
  &amp;quot;name&amp;quot;: &amp;quot;wk00&amp;quot;,
  &amp;quot;offset.storage.partitions&amp;quot;: 1,
  &amp;quot;xms&amp;quot;: 2048,
  &amp;quot;routes&amp;quot;: {},
  &amp;quot;config.storage.topic&amp;quot;: &amp;quot;b8dadc3de21048fa927335b8f&amp;quot;,
  &amp;quot;sharedJarKeys&amp;quot;: [],
  &amp;quot;lastModified&amp;quot;: 1578982566359,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;xmx&amp;quot;: 2048,
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/connect-worker:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;offset.storage.topic&amp;quot;: &amp;quot;346b839ea3e74387ab1eea409&amp;quot;,
  &amp;quot;status.storage.replication.factor&amp;quot;: 1,
  &amp;quot;group.id&amp;quot;: &amp;quot;af4b4d49234a4848bb90fb452&amp;quot;,
  &amp;quot;offset.storage.replication.factor&amp;quot;: 1,
  &amp;quot;aliveNodes&amp;quot;: [],
  &amp;quot;pluginKeys&amp;quot;: [],
  &amp;quot;status.storage.partitions&amp;quot;: 1,
  &amp;quot;freePorts&amp;quot;: [],
  &amp;quot;jmxPort&amp;quot;: 33333,
  &amp;quot;config.storage.partitions&amp;quot;: 1,
  &amp;quot;clientPort&amp;quot;: 45127,
  &amp;quot;config.storage.replication.factor&amp;quot;: 1,
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ],
  &amp;quot;status.storage.topic&amp;quot;: &amp;quot;1cdca943f0b945bc892ebe9a7&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;rest-workers-list&#34;&gt;list all workers clusters&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/workers&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
  {
    &amp;quot;brokerClusterKey&amp;quot;: {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;bk00&amp;quot;
    },
    &amp;quot;name&amp;quot;: &amp;quot;wk00&amp;quot;,
    &amp;quot;offset.storage.partitions&amp;quot;: 1,
    &amp;quot;xms&amp;quot;: 2048,
    &amp;quot;routes&amp;quot;: {},
    &amp;quot;config.storage.topic&amp;quot;: &amp;quot;b8dadc3de21048fa927335b8f&amp;quot;,
    &amp;quot;sharedJarKeys&amp;quot;: [],
    &amp;quot;lastModified&amp;quot;: 1578982566359,
    &amp;quot;tags&amp;quot;: {},
    &amp;quot;xmx&amp;quot;: 2048,
    &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/connect-worker:0.11.0-SNAPSHOT&amp;quot;,
    &amp;quot;offset.storage.topic&amp;quot;: &amp;quot;346b839ea3e74387ab1eea409&amp;quot;,
    &amp;quot;status.storage.replication.factor&amp;quot;: 1,
    &amp;quot;group.id&amp;quot;: &amp;quot;af4b4d49234a4848bb90fb452&amp;quot;,
    &amp;quot;offset.storage.replication.factor&amp;quot;: 1,
    &amp;quot;aliveNodes&amp;quot;: [],
    &amp;quot;pluginKeys&amp;quot;: [],
    &amp;quot;status.storage.partitions&amp;quot;: 1,
    &amp;quot;freePorts&amp;quot;: [],
    &amp;quot;jmxPort&amp;quot;: 33333,
    &amp;quot;config.storage.partitions&amp;quot;: 1,
    &amp;quot;clientPort&amp;quot;: 45127,
    &amp;quot;config.storage.replication.factor&amp;quot;: 1,
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;nodeNames&amp;quot;: [
      &amp;quot;node00&amp;quot;
    ],
    &amp;quot;status.storage.topic&amp;quot;: &amp;quot;1cdca943f0b945bc892ebe9a7&amp;quot;
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;update-broker-cluster-properties&#34;&gt;update broker cluster properties&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/workers/$name?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    If the required worker (group, name) was not exists, we will try to use
this request as POST
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;jmxPort&amp;quot;: 7777
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;brokerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;bk00&amp;quot;
  },
  &amp;quot;name&amp;quot;: &amp;quot;wk00&amp;quot;,
  &amp;quot;offset.storage.partitions&amp;quot;: 1,
  &amp;quot;xms&amp;quot;: 2048,
  &amp;quot;routes&amp;quot;: {},
  &amp;quot;config.storage.topic&amp;quot;: &amp;quot;b8dadc3de21048fa927335b8f&amp;quot;,
  &amp;quot;sharedJarKeys&amp;quot;: [],
  &amp;quot;lastModified&amp;quot;: 1578982765738,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;xmx&amp;quot;: 2048,
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/connect-worker:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;offset.storage.topic&amp;quot;: &amp;quot;346b839ea3e74387ab1eea409&amp;quot;,
  &amp;quot;status.storage.replication.factor&amp;quot;: 1,
  &amp;quot;group.id&amp;quot;: &amp;quot;af4b4d49234a4848bb90fb452&amp;quot;,
  &amp;quot;offset.storage.replication.factor&amp;quot;: 1,
  &amp;quot;aliveNodes&amp;quot;: [],
  &amp;quot;pluginKeys&amp;quot;: [],
  &amp;quot;status.storage.partitions&amp;quot;: 1,
  &amp;quot;freePorts&amp;quot;: [],
  &amp;quot;jmxPort&amp;quot;: 7777,
  &amp;quot;config.storage.partitions&amp;quot;: 1,
  &amp;quot;clientPort&amp;quot;: 45127,
  &amp;quot;config.storage.replication.factor&amp;quot;: 1,
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ],
  &amp;quot;status.storage.topic&amp;quot;: &amp;quot;1cdca943f0b945bc892ebe9a7&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;delete-a-worker-properties&#34;&gt;delete a worker properties&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;DELETE /v0/workers/$name?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;You cannot delete properties of an non-stopped worker cluster. We will
use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you don&amp;rsquo;t
specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;204 NoContent
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    It is ok to delete an nonexistent worker cluster, and the response
is 204 NoContent.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;rest-workers-get&#34;&gt;get a worker cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/workers/$name?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;brokerClusterKey&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;bk00&amp;quot;
  },
  &amp;quot;name&amp;quot;: &amp;quot;wk00&amp;quot;,
  &amp;quot;offset.storage.partitions&amp;quot;: 1,
  &amp;quot;xms&amp;quot;: 2048,
  &amp;quot;routes&amp;quot;: {},
  &amp;quot;config.storage.topic&amp;quot;: &amp;quot;b8dadc3de21048fa927335b8f&amp;quot;,
  &amp;quot;sharedJarKeys&amp;quot;: [],
  &amp;quot;lastModified&amp;quot;: 1578982765738,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;xmx&amp;quot;: 2048,
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/connect-worker:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;offset.storage.topic&amp;quot;: &amp;quot;346b839ea3e74387ab1eea409&amp;quot;,
  &amp;quot;status.storage.replication.factor&amp;quot;: 1,
  &amp;quot;group.id&amp;quot;: &amp;quot;af4b4d49234a4848bb90fb452&amp;quot;,
  &amp;quot;offset.storage.replication.factor&amp;quot;: 1,
  &amp;quot;aliveNodes&amp;quot;: [],
  &amp;quot;pluginKeys&amp;quot;: [],
  &amp;quot;status.storage.partitions&amp;quot;: 1,
  &amp;quot;freePorts&amp;quot;: [],
  &amp;quot;jmxPort&amp;quot;: 7777,
  &amp;quot;config.storage.partitions&amp;quot;: 1,
  &amp;quot;clientPort&amp;quot;: 45127,
  &amp;quot;config.storage.replication.factor&amp;quot;: 1,
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ],
  &amp;quot;status.storage.topic&amp;quot;: &amp;quot;1cdca943f0b945bc892ebe9a7&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;start-a-worker-cluster&#34;&gt;start a worker cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/workers/$name/start?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#rest-workers-get&#34;&gt;Get worker cluster&lt;/a&gt; to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;stop-a-worker-cluster&#34;&gt;stop a worker cluster&lt;/h2&gt;
&lt;p&gt;Gracefully stopping a running worker cluster.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/workers/$name/stop?group=$group[&amp;amp;force=true]&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Query Parameters&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;force (&lt;strong&gt;boolean&lt;/strong&gt;) &amp;mdash; true if you don&amp;rsquo;t want to wait the
graceful shutdown (it can save your time but may damage your
data).&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#rest-workers-get&#34;&gt;Get worker cluster&lt;/a&gt; to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;add-a-new-node-to-a-running-worker-cluster&#34;&gt;add a new node to a running worker cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/workers/$name/$nodeName?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;p&gt;If you want to extend a running worker cluster, you can add a node to
share the heavy loading of a running worker cluster. However, the
balance is not triggered at once. By the way, moving a task to another
idle node needs to &lt;strong&gt;stop&lt;/strong&gt; task first. Don&amp;rsquo;t worry about the temporary
lower throughput when balancer is running.&lt;/p&gt;
&lt;h2 id=&#34;remove-a-node-from-a-running-worker-cluster&#34;&gt;remove a node from a running worker cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;DELETE /v0/workers/$name/$nodeName?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;p&gt;If your budget is limited, you can decrease the number of nodes running
worker cluster. BUT, removing a node from a running worker cluster
invoke a lot of task move, and it will decrease the throughput of your
connector.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;204 NoContent
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    It is ok to delete an nonexistent worker node, and the response is
204 NoContent.
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Zookeeper</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/rest-api/zookeepers/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/rest-api/zookeepers/</guid>
      <description>&lt;p&gt;
&lt;a href=&#34;https://zookeeper.apache.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Zookeeper&lt;/a&gt; service is the base of all
other services. It is also the fist service you should set up. At the
beginning, you can deploy zookeeper cluster in single node. However, it
may be unstable since single node can&amp;rsquo;t guarantee the data durability
when node crash. In production you should set up zookeeper cluster on 3
nodes at least.&lt;/p&gt;
&lt;p&gt;Zookeeper service has many configs which make you spend a lot of time to
read and set. Ohara provides default values to all configs but open a
room to enable you to overwrite somethings you do care.&lt;/p&gt;
&lt;p&gt;The properties which can be set by user are shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; cluster name. The legal character is number,
lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; cluster group. The legal character is number,
lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;imageName (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; docker image&lt;/li&gt;
&lt;li&gt;jmxPort (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; zookeeper jmx port&lt;/li&gt;
&lt;li&gt;clientPort (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; zookeeper client port&lt;/li&gt;
&lt;li&gt;electionPort (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; used to select the zk node leader&lt;/li&gt;
&lt;li&gt;peerPort (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; port used by internal communication&lt;/li&gt;
&lt;li&gt;nodeNames (&lt;strong&gt;array(string)&lt;/strong&gt;) &amp;mdash; the nodes running the zookeeper
process&lt;/li&gt;
&lt;li&gt;tags (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the user defined parameters&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The following information are updated by Ohara.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;aliveNodes (&lt;strong&gt;array(string)&lt;/strong&gt;) &amp;mdash; the nodes that host the running
containers of zookeeper&lt;/li&gt;
&lt;li&gt;state (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; only started/failed zookeeper has
state (RUNNING or DEAD)&lt;/li&gt;
&lt;li&gt;error (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the error message from a failed
zookeeper. If zookeeper is fine or un-started, you won&amp;rsquo;t get this
field.&lt;/li&gt;
&lt;li&gt;lastModified (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; last modified this jar time&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;create-properties&#34;&gt;create a zookeeper properties&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;POST /v0/zookeepers&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;zk&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;syncLimit&amp;quot;: 5,
  &amp;quot;name&amp;quot;: &amp;quot;zk00&amp;quot;,
  &amp;quot;xms&amp;quot;: 1024,
  &amp;quot;routes&amp;quot;: {},
  &amp;quot;lastModified&amp;quot;: 1578642569693,
  &amp;quot;dataDir&amp;quot;: &amp;quot;/home/ohara/default/data&amp;quot;,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;electionPort&amp;quot;: 44371,
  &amp;quot;xmx&amp;quot;: 1024,
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/zookeeper:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;aliveNodes&amp;quot;: [],
  &amp;quot;initLimit&amp;quot;: 10,
  &amp;quot;jmxPort&amp;quot;: 33915,
  &amp;quot;clientPort&amp;quot;: 42006,
  &amp;quot;peerPort&amp;quot;: 46559,
  &amp;quot;tickTime&amp;quot;: 2000,
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    All ports have default value so you can ignore them when creating
zookeeper cluster. However, the port conflict detect does not allow
you to reuse port on different purpose (a dangerous behavior, right?).
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;list-all-zookeeper-clusters&#34;&gt;list all zookeeper clusters&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/zookeepers&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;the accepted query keys are listed below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;group&lt;/li&gt;
&lt;li&gt;name&lt;/li&gt;
&lt;li&gt;lastModified&lt;/li&gt;
&lt;li&gt;tags&lt;/li&gt;
&lt;li&gt;tag - this field is similar to tags but it addresses the &amp;ldquo;contain&amp;rdquo;
behavior.&lt;/li&gt;
&lt;li&gt;state&lt;/li&gt;
&lt;li&gt;aliveNodes&lt;/li&gt;
&lt;li&gt;key&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
  {
    &amp;quot;syncLimit&amp;quot;: 5,
    &amp;quot;name&amp;quot;: &amp;quot;zk00&amp;quot;,
    &amp;quot;xms&amp;quot;: 1024,
    &amp;quot;routes&amp;quot;: {},
    &amp;quot;lastModified&amp;quot;: 1578642569693,
    &amp;quot;dataDir&amp;quot;: &amp;quot;/home/ohara/default/data&amp;quot;,
    &amp;quot;tags&amp;quot;: {},
    &amp;quot;electionPort&amp;quot;: 44371,
    &amp;quot;xmx&amp;quot;: 1024,
    &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/zookeeper:0.11.0-SNAPSHOT&amp;quot;,
    &amp;quot;aliveNodes&amp;quot;: [],
    &amp;quot;initLimit&amp;quot;: 10,
    &amp;quot;jmxPort&amp;quot;: 33915,
    &amp;quot;clientPort&amp;quot;: 42006,
    &amp;quot;peerPort&amp;quot;: 46559,
    &amp;quot;tickTime&amp;quot;: 2000,
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;nodeNames&amp;quot;: [
      &amp;quot;node00&amp;quot;
    ]
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;update-zookeeper-cluster-properties&#34;&gt;update zookeeper cluster properties&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/zookeepers/$name?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    If the required zookeeper (group, name) was not exists, we will try to
use this request as POST
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;jmxPort&amp;quot;: 12345
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;syncLimit&amp;quot;: 5,
  &amp;quot;name&amp;quot;: &amp;quot;zk00&amp;quot;,
  &amp;quot;xms&amp;quot;: 1024,
  &amp;quot;routes&amp;quot;: {},
  &amp;quot;lastModified&amp;quot;: 1578642751122,
  &amp;quot;dataDir&amp;quot;: &amp;quot;/home/ohara/default/data&amp;quot;,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;electionPort&amp;quot;: 44371,
  &amp;quot;xmx&amp;quot;: 1024,
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/zookeeper:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;aliveNodes&amp;quot;: [],
  &amp;quot;initLimit&amp;quot;: 10,
  &amp;quot;jmxPort&amp;quot;: 12345,
  &amp;quot;clientPort&amp;quot;: 42006,
  &amp;quot;peerPort&amp;quot;: 46559,
  &amp;quot;tickTime&amp;quot;: 2000,
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;delete-a-zookeeper-properties&#34;&gt;delete a zookeeper properties&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;DELETE /v0/zookeepers/$name?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;You cannot delete properties of an non-stopped zookeeper cluster. We
will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;204 NoContent
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    It is ok to delete an nonexistent zookeeper cluster, and the
response is 204 NoContent.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;get&#34;&gt;get a zookeeper cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/zookeepers/$name?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Get zookeeper information by name and group. This API could fetch all
information of a zookeeper (include state). We will use the default
value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;syncLimit&amp;quot;: 5,
  &amp;quot;name&amp;quot;: &amp;quot;zk00&amp;quot;,
  &amp;quot;xms&amp;quot;: 1024,
  &amp;quot;routes&amp;quot;: {},
  &amp;quot;lastModified&amp;quot;: 1578642569693,
  &amp;quot;dataDir&amp;quot;: &amp;quot;/home/ohara/default/data&amp;quot;,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;electionPort&amp;quot;: 44371,
  &amp;quot;xmx&amp;quot;: 1024,
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/zookeeper:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;aliveNodes&amp;quot;: [],
  &amp;quot;initLimit&amp;quot;: 10,
  &amp;quot;jmxPort&amp;quot;: 33915,
  &amp;quot;clientPort&amp;quot;: 42006,
  &amp;quot;peerPort&amp;quot;: 46559,
  &amp;quot;tickTime&amp;quot;: 2000,
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;start-a-zookeeper-cluster&#34;&gt;start a zookeeper cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/zookeepers/$name/start?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#get&#34;&gt;Get zookeeper cluster&lt;/a&gt; to fetch
up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;stop-a-zookeeper-cluster&#34;&gt;stop a zookeeper cluster&lt;/h2&gt;
&lt;p&gt;Gracefully stopping a running zookeeper cluster. It is disallowed to
stop a zookeeper cluster used by a running

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/brokers/&#34;&gt;broker cluster&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/zookeepers/$name/stop?group=$group[&amp;amp;force=true]&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Query Parameters&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;force (&lt;strong&gt;boolean&lt;/strong&gt;) - true if you don&amp;rsquo;t want to wait the
graceful shutdown (it can save your time but may damage your
data).&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#get&#34;&gt;Get zookeeper cluster&lt;/a&gt;
to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;delete-a-node-from-a-running-zookeeper-cluster&#34;&gt;delete a node from a running zookeeper cluster&lt;/h2&gt;
&lt;p&gt;Unfortunately, it is a litter dangerous to remove a node from a running
zookeeper cluster so we don&amp;rsquo;t support it yet.&lt;/p&gt;
&lt;h2 id=&#34;add-a-node-to-a-running-zookeeper-cluster&#34;&gt;add a node to a running zookeeper cluster&lt;/h2&gt;
&lt;p&gt;Unfortunately, it is a litter hard to add a node to a running zookeeper
cluster so we don&amp;rsquo;t support it yet.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Zookeeper</title>
      <link>https://oharastream.github.io/en/docs/master/rest-api/zookeepers/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/master/rest-api/zookeepers/</guid>
      <description>&lt;p&gt;
&lt;a href=&#34;https://zookeeper.apache.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Zookeeper&lt;/a&gt; service is the base of all
other services. It is also the fist service you should set up. At the
beginning, you can deploy zookeeper cluster in single node. However, it
may be unstable since single node can&amp;rsquo;t guarantee the data durability
when node crash. In production you should set up zookeeper cluster on 3
nodes at least.&lt;/p&gt;
&lt;p&gt;Zookeeper service has many configs which make you spend a lot of time to
read and set. Ohara provides default values to all configs but open a
room to enable you to overwrite somethings you do care.&lt;/p&gt;
&lt;p&gt;The properties which can be set by user are shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;name (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; cluster name. The legal character is number,
lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; cluster group. The legal character is number,
lowercase alphanumeric characters, or &amp;lsquo;.&amp;rsquo;&lt;/li&gt;
&lt;li&gt;imageName (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; docker image&lt;/li&gt;
&lt;li&gt;jmxPort (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; zookeeper jmx port&lt;/li&gt;
&lt;li&gt;clientPort (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; zookeeper client port&lt;/li&gt;
&lt;li&gt;electionPort (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; used to select the zk node leader&lt;/li&gt;
&lt;li&gt;peerPort (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; port used by internal communication&lt;/li&gt;
&lt;li&gt;nodeNames (&lt;strong&gt;array(string)&lt;/strong&gt;) &amp;mdash; the nodes running the zookeeper
process&lt;/li&gt;
&lt;li&gt;tags (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the user defined parameters&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The following information are updated by Ohara.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;aliveNodes (&lt;strong&gt;array(string)&lt;/strong&gt;) &amp;mdash; the nodes that host the running
containers of zookeeper&lt;/li&gt;
&lt;li&gt;state (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; only started/failed zookeeper has
state (RUNNING or DEAD)&lt;/li&gt;
&lt;li&gt;error (&lt;strong&gt;option(string)&lt;/strong&gt;) &amp;mdash; the error message from a failed
zookeeper. If zookeeper is fine or un-started, you won&amp;rsquo;t get this
field.&lt;/li&gt;
&lt;li&gt;lastModified (&lt;strong&gt;long&lt;/strong&gt;) &amp;mdash; last modified this jar time&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;create-properties&#34;&gt;create a zookeeper properties&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;POST /v0/zookeepers&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;zk&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;syncLimit&amp;quot;: 5,
  &amp;quot;name&amp;quot;: &amp;quot;zk00&amp;quot;,
  &amp;quot;xms&amp;quot;: 1024,
  &amp;quot;routes&amp;quot;: {},
  &amp;quot;lastModified&amp;quot;: 1578642569693,
  &amp;quot;dataDir&amp;quot;: &amp;quot;/home/ohara/default/data&amp;quot;,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;electionPort&amp;quot;: 44371,
  &amp;quot;xmx&amp;quot;: 1024,
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/zookeeper:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;aliveNodes&amp;quot;: [],
  &amp;quot;initLimit&amp;quot;: 10,
  &amp;quot;jmxPort&amp;quot;: 33915,
  &amp;quot;clientPort&amp;quot;: 42006,
  &amp;quot;peerPort&amp;quot;: 46559,
  &amp;quot;tickTime&amp;quot;: 2000,
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    All ports have default value so you can ignore them when creating
zookeeper cluster. However, the port conflict detect does not allow
you to reuse port on different purpose (a dangerous behavior, right?).
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;list-all-zookeeper-clusters&#34;&gt;list all zookeeper clusters&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/zookeepers&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;the accepted query keys are listed below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;group&lt;/li&gt;
&lt;li&gt;name&lt;/li&gt;
&lt;li&gt;lastModified&lt;/li&gt;
&lt;li&gt;tags&lt;/li&gt;
&lt;li&gt;tag - this field is similar to tags but it addresses the &amp;ldquo;contain&amp;rdquo;
behavior.&lt;/li&gt;
&lt;li&gt;state&lt;/li&gt;
&lt;li&gt;aliveNodes&lt;/li&gt;
&lt;li&gt;key&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;[
  {
    &amp;quot;syncLimit&amp;quot;: 5,
    &amp;quot;name&amp;quot;: &amp;quot;zk00&amp;quot;,
    &amp;quot;xms&amp;quot;: 1024,
    &amp;quot;routes&amp;quot;: {},
    &amp;quot;lastModified&amp;quot;: 1578642569693,
    &amp;quot;dataDir&amp;quot;: &amp;quot;/home/ohara/default/data&amp;quot;,
    &amp;quot;tags&amp;quot;: {},
    &amp;quot;electionPort&amp;quot;: 44371,
    &amp;quot;xmx&amp;quot;: 1024,
    &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/zookeeper:0.11.0-SNAPSHOT&amp;quot;,
    &amp;quot;aliveNodes&amp;quot;: [],
    &amp;quot;initLimit&amp;quot;: 10,
    &amp;quot;jmxPort&amp;quot;: 33915,
    &amp;quot;clientPort&amp;quot;: 42006,
    &amp;quot;peerPort&amp;quot;: 46559,
    &amp;quot;tickTime&amp;quot;: 2000,
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;nodeNames&amp;quot;: [
      &amp;quot;node00&amp;quot;
    ]
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;update-zookeeper-cluster-properties&#34;&gt;update zookeeper cluster properties&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/zookeepers/$name?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    If the required zookeeper (group, name) was not exists, we will try to
use this request as POST
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;jmxPort&amp;quot;: 12345
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;syncLimit&amp;quot;: 5,
  &amp;quot;name&amp;quot;: &amp;quot;zk00&amp;quot;,
  &amp;quot;xms&amp;quot;: 1024,
  &amp;quot;routes&amp;quot;: {},
  &amp;quot;lastModified&amp;quot;: 1578642751122,
  &amp;quot;dataDir&amp;quot;: &amp;quot;/home/ohara/default/data&amp;quot;,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;electionPort&amp;quot;: 44371,
  &amp;quot;xmx&amp;quot;: 1024,
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/zookeeper:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;aliveNodes&amp;quot;: [],
  &amp;quot;initLimit&amp;quot;: 10,
  &amp;quot;jmxPort&amp;quot;: 12345,
  &amp;quot;clientPort&amp;quot;: 42006,
  &amp;quot;peerPort&amp;quot;: 46559,
  &amp;quot;tickTime&amp;quot;: 2000,
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;delete-a-zookeeper-properties&#34;&gt;delete a zookeeper properties&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;DELETE /v0/zookeepers/$name?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;You cannot delete properties of an non-stopped zookeeper cluster. We
will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;204 NoContent
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    It is ok to delete an nonexistent zookeeper cluster, and the
response is 204 NoContent.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;get&#34;&gt;get a zookeeper cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/zookeepers/$name?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Get zookeeper information by name and group. This API could fetch all
information of a zookeeper (include state). We will use the default
value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;syncLimit&amp;quot;: 5,
  &amp;quot;name&amp;quot;: &amp;quot;zk00&amp;quot;,
  &amp;quot;xms&amp;quot;: 1024,
  &amp;quot;routes&amp;quot;: {},
  &amp;quot;lastModified&amp;quot;: 1578642569693,
  &amp;quot;dataDir&amp;quot;: &amp;quot;/home/ohara/default/data&amp;quot;,
  &amp;quot;tags&amp;quot;: {},
  &amp;quot;electionPort&amp;quot;: 44371,
  &amp;quot;xmx&amp;quot;: 1024,
  &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/zookeeper:0.11.0-SNAPSHOT&amp;quot;,
  &amp;quot;aliveNodes&amp;quot;: [],
  &amp;quot;initLimit&amp;quot;: 10,
  &amp;quot;jmxPort&amp;quot;: 33915,
  &amp;quot;clientPort&amp;quot;: 42006,
  &amp;quot;peerPort&amp;quot;: 46559,
  &amp;quot;tickTime&amp;quot;: 2000,
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;start-a-zookeeper-cluster&#34;&gt;start a zookeeper cluster&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/zookeepers/$name/start?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#get&#34;&gt;Get zookeeper cluster&lt;/a&gt; to fetch
up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;stop-a-zookeeper-cluster&#34;&gt;stop a zookeeper cluster&lt;/h2&gt;
&lt;p&gt;Gracefully stopping a running zookeeper cluster. It is disallowed to
stop a zookeeper cluster used by a running

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/brokers/&#34;&gt;broker cluster&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/zookeepers/$name/stop?group=$group[&amp;amp;force=true]&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you
don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Query Parameters&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;force (&lt;strong&gt;boolean&lt;/strong&gt;) - true if you don&amp;rsquo;t want to wait the
graceful shutdown (it can save your time but may damage your
data).&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You should use &lt;a href=&#34;#get&#34;&gt;Get zookeeper cluster&lt;/a&gt;
to fetch up-to-date status
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;delete-a-node-from-a-running-zookeeper-cluster&#34;&gt;delete a node from a running zookeeper cluster&lt;/h2&gt;
&lt;p&gt;Unfortunately, it is a litter dangerous to remove a node from a running
zookeeper cluster so we don&amp;rsquo;t support it yet.&lt;/p&gt;
&lt;h2 id=&#34;add-a-node-to-a-running-zookeeper-cluster&#34;&gt;add a node to a running zookeeper cluster&lt;/h2&gt;
&lt;p&gt;Unfortunately, it is a litter hard to add a node to a running zookeeper
cluster so we don&amp;rsquo;t support it yet.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Setting Definition Guide</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/setting_definition/</link>
      <pubDate>Wed, 17 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/setting_definition/</guid>
      <description>&lt;p&gt;A powerful application always has a complicated configuration. In order
to be a best friend of Ohara users, Ohara provides a method which can
return the details of setting definitions, and ohara suggests that all
developers ought to implement the method so as to guide users through
the complicated settings of your applications.&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    If you have no interest in settings or your application is too simple to
have any settings, you can just skip this section.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;SettingDef is a class used to describe the details of &lt;strong&gt;a&lt;/strong&gt; setting. It
consists of following arguments.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;a href=&#34;#setting-reference&#34;&gt;reference&lt;/a&gt;(&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; works for ohara manager.
It represents the reference of value.&lt;/li&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the group of this setting (all core setting are in core group)&lt;/li&gt;
&lt;li&gt;orderInGroup (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; the order in group&lt;/li&gt;
&lt;li&gt;displayName (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the readable name of this setting&lt;/li&gt;
&lt;li&gt;permission (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the way to &amp;ldquo;touch&amp;rdquo; value. It consists of
&lt;ul&gt;
&lt;li&gt;READ_ONLY &amp;mdash; you can&amp;rsquo;t define an new value for it&lt;/li&gt;
&lt;li&gt;CREATE_ONLY &amp;mdash; you can&amp;rsquo;t update the value to an new one&lt;/li&gt;
&lt;li&gt;EDITABLE &amp;mdash; feel free to modify the value as you wish :)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;key (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the key of configuration&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#value-type&#34;&gt;valueType&lt;/a&gt;(&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the type of value&lt;/li&gt;
&lt;li&gt;necessary (&lt;strong&gt;string&lt;/strong&gt;)
&lt;ul&gt;
&lt;li&gt;REQUIRED &amp;mdash; this field has no default and user MUST define something for it.&lt;/li&gt;
&lt;li&gt;OPTIONAL &amp;mdash; this field has no default and user does NOT need to define something for it.&lt;/li&gt;
&lt;li&gt;RANDOM_DEFAULT &amp;mdash; this field has a &amp;ldquo;random&amp;rdquo; default value&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;defaultValue (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the default value. the type is equal to what valueType
defines but we only allow string, number and boolean type to have default value currently.&lt;/li&gt;
&lt;li&gt;documentation (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the explanation of this definition&lt;/li&gt;
&lt;li&gt;internal (&lt;strong&gt;boolean&lt;/strong&gt;) &amp;mdash; true if this setting is assigned by system automatically.&lt;/li&gt;
&lt;li&gt;tableKeys (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the description to Type.TABLE
&lt;ul&gt;
&lt;li&gt;tableKeys[i].name &amp;mdash; the column name&lt;/li&gt;
&lt;li&gt;tableKeys[i].type &amp;mdash; acceptable type (string, number and boolean)&lt;/li&gt;
&lt;li&gt;tableKeys[i].recommendedValues &amp;mdash; recommended values
(it is legal to enter other values you prefer)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You can call &lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/workers/&#34;&gt;Worker APIs&lt;/a&gt;
to get all connectors&amp;rsquo; setting definitions, and use &lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/streams/&#34;&gt;Stream APIs&lt;/a&gt;
to get all stream setting definitions.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Although a SettingDef can include many elements, you can simply build a
SettingDef with only what you need. An extreme example is that you can
create a SettingDef with only key.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notwithstanding it is flexible to build a SettingDef, we encourage
developers to create a description-rich SettingDef. More description to
your setting produces more &lt;strong&gt;document&lt;/strong&gt; in calling ohara rest APIs. We
all hate write documentation, so it would be better to make your code
readable.&lt;/p&gt;
&lt;h2 id=&#34;reference-internal-and-tablekeys-are-not-public&#34;&gt;Reference, Internal and TableKeys Are NOT Public&lt;/h2&gt;
&lt;p&gt;Ohara offers a great UI, which is located at ohara-manager. The UI
requires some &lt;strong&gt;private&lt;/strong&gt; information to generate forms for custom
applications. The such private information is specific-purpose and is
meaningless to non-ohara developers. Hence, all of them are declared as
package-private and ohara does not encourage developers to stop at
nothing to use them.&lt;/p&gt;
&lt;h2 id=&#34;optional-required-and-default-value&#34;&gt;Optional, Required And Default Value&lt;/h2&gt;
&lt;p&gt;We know a great application must have countless settings and only The
Chosen One can control it. In order to shorten the gap between your
application and human begin, ohara encourage developers to offer the
default values to most of settings as much as possible. Assigning a
default value to a SettingDef is a piece of cake.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .optional(defaultValue)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    the default value is declared as &lt;strong&gt;string&lt;/strong&gt; type as it must be &lt;strong&gt;readable&lt;/strong&gt; in Restful APIs.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;After calling the &lt;strong&gt;optional(String)&lt;/strong&gt; method, the response, created by

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/workers/&#34;&gt;Worker APIs&lt;/a&gt; for example,
will display the following information.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;necessary&amp;quot;: &amp;quot;OPTIONAL_WITH_DEFAULT&amp;quot;,
  &amp;quot;defaultValue&amp;quot;: &amp;quot;ur_default_value&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The default value will be added to
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/custom_connector/#source-start&#34;&gt;TaskSetting&lt;/a&gt;
automatically if the specified key is not already associated with a value.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;a-readonly-setting-definition&#34;&gt;A Readonly Setting Definition&lt;/h2&gt;
&lt;p&gt;You can declare a &lt;strong&gt;readonly&lt;/strong&gt; setting that not only exposes something
of your application to user but also remind user the setting can&amp;rsquo;t be
changed at runtime. For instance, the information of

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/custom_connector/#version&#34;&gt;version&lt;/a&gt; is fixed
after you have completed your connector so it is not an &lt;strong&gt;editable&lt;/strong&gt;
setting. Hence, ohara define a setting for &lt;strong&gt;version&lt;/strong&gt; with a readonly
label. By the way, you should assign a default value to a readonly
setting since a readonly setting without default value is really weird.
There is an example of creating a readonly setting.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .optional(defaultValue)
    .permission(SettingDef.Permission.READ_ONLY)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The input value will be removed automatically if the associated setting
is declared readonly.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;setting-reference&#34;&gt;Setting Reference&lt;/h2&gt;
&lt;p&gt;This element is a specific purpose. It is used by Ohara manager (UI) only.
If you don&amp;rsquo;t have interest in UI, you can just ignore this element.
However, we still list the available values here.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NODE&lt;/li&gt;
&lt;li&gt;TOPIC&lt;/li&gt;
&lt;li&gt;ZOOKEEPER&lt;/li&gt;
&lt;li&gt;BROKER&lt;/li&gt;
&lt;li&gt;WORKER&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    For each reference value, it may have different type and will produce
different behavior.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Topic String&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder().key(&amp;quot;topic&amp;quot;).reference(Reference.TOPIC).required(Type.STRING).build();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which means the request should &amp;ldquo;accept one topic of string type&amp;rdquo;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;topic&amp;quot;: &amp;quot;t1&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;TopicKey List&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(&amp;quot;topicKeys&amp;quot;)
    .reference(Reference.TOPIC)
    .required(Type.OBJECT_KEYS)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which means the request should &amp;ldquo;accept topic list of &lt;strong&gt;TopicKey&lt;/strong&gt; type&amp;rdquo;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;topicKeys&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;t1&amp;quot;
    },
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;t2&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;Topic String List&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(&amp;quot;topics&amp;quot;)
    .reference(Reference.TOPIC)
    .required(Type.ARRAY)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which means the request should &amp;ldquo;accept topic list of string type&amp;rdquo;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;topics&amp;quot;: [&amp;quot;t1&amp;quot;, &amp;quot;t2&amp;quot;, &amp;quot;t3&amp;quot;]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;value-type&#34;&gt;Value Type&lt;/h2&gt;
&lt;p&gt;In a custom application, the settings could have various data type. In
order to display correct data type in ohara manager and leverage the
benefit of 
&lt;a href=&#34;#checker&#34;&gt;type checker&lt;/a&gt;, we
strongly suggest you to define the correct data type for each setting.&lt;/p&gt;
&lt;p&gt;The following data types are supported currently.&lt;/p&gt;
&lt;h4 id=&#34;typeboolean&#34;&gt;Type.BOOLEAN&lt;/h4&gt;
&lt;p&gt;Boolean type represents that the data should have only two possible
value: &lt;strong&gt;true&lt;/strong&gt; or &lt;strong&gt;false&lt;/strong&gt;. The value must be able cast to
&lt;strong&gt;java.lang.Boolean&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;typestring&#34;&gt;Type.STRING&lt;/h4&gt;
&lt;p&gt;String type represents that the data should be a string. The value must
be able cast to &lt;strong&gt;java.lang.String&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.STRING)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typepositive_short&#34;&gt;Type.POSITIVE_SHORT&lt;/h4&gt;
&lt;p&gt;Short type represents that the data should be a 2-bytes integer. The
value must be able cast to &lt;strong&gt;java.lang.Short&lt;/strong&gt;. Noted: only positive
number is acceptable&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.POSITIVE_SHORT)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typeshort&#34;&gt;Type.SHORT&lt;/h4&gt;
&lt;p&gt;Short type represents that the data should be a 2-bytes integer. The
value must be able cast to &lt;strong&gt;java.lang.Short&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.SHORT)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typepositive_int&#34;&gt;Type.POSITIVE_INT&lt;/h4&gt;
&lt;p&gt;Int type represents that the data should be a 4-bytes integer. The value
must be able cast to &lt;strong&gt;java.lang.Integer&lt;/strong&gt;. Noted: only positive number
is acceptable&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.POSITIVE_INT)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typeint&#34;&gt;Type.INT&lt;/h4&gt;
&lt;p&gt;Int type represents that the data should be a 4-bytes integer. The value
must be able cast to &lt;strong&gt;java.lang.Integer&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.INT)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typepositive_long&#34;&gt;Type.POSITIVE_LONG&lt;/h4&gt;
&lt;p&gt;Long type represents that the data should be a 8-bytes integer. The
value must be able cast to &lt;strong&gt;java.lang.Long&lt;/strong&gt;. Noted: only positive
number is acceptable&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.POSITIVE_LONG)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typelong&#34;&gt;Type.LONG&lt;/h4&gt;
&lt;p&gt;Long type represents that the data should be a 8-bytes integer. The
value must be able cast to &lt;strong&gt;java.lang.Long&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.LONG)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typepositive_double&#34;&gt;Type.POSITIVE_DOUBLE&lt;/h4&gt;
&lt;p&gt;Double type represents that the data should be a 8-bytes floating-point.
The value must be able cast to &lt;strong&gt;java.lang.Double&lt;/strong&gt;. Noted: only
positive number is acceptable&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.POSITIVE_DOUBLE)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typedouble&#34;&gt;Type.DOUBLE&lt;/h4&gt;
&lt;p&gt;Double type represents that the data should be a 8-bytes floating point.
The value must be able cast to &lt;strong&gt;java.lang.Double&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.DOUBLE)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typearray&#34;&gt;Type.ARRAY&lt;/h4&gt;
&lt;p&gt;Array type represents that the data should be a collection of data. We
don&amp;rsquo;t check the element data type in the collection, that is, the
following request is legal in SettingDef but will produce a weird
behavior in ohara manager. We suggest you use the same data type of
element in an array.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;key&amp;quot;: [&amp;quot;abc&amp;quot;, 123, 2.0]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.ARRAY)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;An empty array is ok and will pass the checker:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;key&amp;quot;: []
}
&lt;/code&gt;&lt;/pre&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    the default value to array value is empty
  &lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;typeclass&#34;&gt;Type.CLASS&lt;/h4&gt;
&lt;p&gt;Class type represents that the data is a class. This data type is used
to display a value that is a class. The value must be able cast to
&lt;strong&gt;java.lang.String&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.CLASS)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typepassword&#34;&gt;Type.PASSWORD&lt;/h4&gt;
&lt;p&gt;Password type represents that the data is a password. We will replace
the value by &lt;strong&gt;hidden&lt;/strong&gt; symbol in APIs. if the data type is used as
password. The value must be able cast to &lt;strong&gt;java.lang.String&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.PASSWORD)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typejdbc_table&#34;&gt;Type.JDBC_TABLE&lt;/h4&gt;
&lt;p&gt;JDBC_TABLE is a specific string type used to reminder Ohara Manager
that this field requires a &lt;strong&gt;magic&lt;/strong&gt; button to show available tables of
remote database via Query APIs. Except for the &lt;strong&gt;magic&lt;/strong&gt; in UI, there is
no other stuff for this JDBC_TYPE since kafka can&amp;rsquo;t verify the input
arguments according to other arguments. It means we can&amp;rsquo;t connect to
remote database to check the existence of input table.&lt;/p&gt;
&lt;p&gt;It is ok to replace this field by Type.STRING if you don&amp;rsquo;t use Ohara
Manager. Nevertheless, we still encourage the developer to choose the
&lt;strong&gt;fitting&lt;/strong&gt; type for your setting if you demand your user to input a
database table.&lt;/p&gt;
&lt;h4 id=&#34;typetable&#34;&gt;Type.TABLE&lt;/h4&gt;
&lt;p&gt;Table type enable you to define a setting having table structure value.
Apart from assigning Type.Table to your setting definition, you also
have to define which keys are in your table. The following example show
a case that declares a table having two columns called &lt;strong&gt;c0&lt;/strong&gt; and
&lt;strong&gt;c1&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .tableKeys(Arrays.asList(&amp;quot;c0&amp;quot;, &amp;quot;c1&amp;quot;))
    .required(Type.TABLE)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The legal value for above setting definition is shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;key&amp;quot;: [
    {
      &amp;quot;c0&amp;quot;: &amp;quot;v0&amp;quot;,
      &amp;quot;c1&amp;quot;: &amp;quot;v1&amp;quot;
    },
    {
      &amp;quot;c0&amp;quot;: &amp;quot;v2&amp;quot;,
      &amp;quot;c1&amp;quot;: &amp;quot;v3&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above example implies there is a table having two columns called
&lt;strong&gt;c0&lt;/strong&gt; and &lt;strong&gt;c1&lt;/strong&gt;. Also, you assign two values to &lt;strong&gt;c0&lt;/strong&gt; that first is
&lt;strong&gt;v0&lt;/strong&gt; and another is &lt;strong&gt;v2&lt;/strong&gt;. Ohara offers a check for Type.Table that
the input value &lt;strong&gt;must&lt;/strong&gt; match all keys in.&lt;/p&gt;
&lt;p&gt;How to get the description of above &lt;strong&gt;keys&lt;/strong&gt; ? If the setting type is
&lt;strong&gt;table&lt;/strong&gt;, the setting must have &lt;strong&gt;tableKeys&lt;/strong&gt;. It is an array of string
which shows the keys used in the table type. For instance, a setting
having table type is shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;reference&amp;quot;: &amp;quot;NONE&amp;quot;,
  &amp;quot;displayName&amp;quot;: &amp;quot;columns&amp;quot;,
  &amp;quot;internal&amp;quot;: false,
  &amp;quot;documentation&amp;quot;: &amp;quot;output schema&amp;quot;,
  &amp;quot;valueType&amp;quot;: &amp;quot;TABLE&amp;quot;,
  &amp;quot;tableKeys&amp;quot;: [
    &amp;quot;order&amp;quot;,
    &amp;quot;dataType&amp;quot;,
    &amp;quot;name&amp;quot;,
    &amp;quot;newName&amp;quot;
  ],
  &amp;quot;orderInGroup&amp;quot;: 6,
  &amp;quot;key&amp;quot;: &amp;quot;columns&amp;quot;,
  &amp;quot;necessary&amp;quot;: &amp;quot;REQUIRED&amp;quot;,
  &amp;quot;defaultValue&amp;quot;: null,
  &amp;quot;group&amp;quot;: &amp;quot;core&amp;quot;,
  &amp;quot;permission&amp;quot;: &amp;quot;EDITABLE&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    If you ignore the table keys for Type.Table, the check to your input
value is also ignored. By contrast, the table keys are useless for other
types.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    the default value to table value is empty
  &lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;typeduration&#34;&gt;Type.DURATION&lt;/h4&gt;
&lt;p&gt;The time-based amount of time is a common setting in our world. However,
it is also hard to reach the consensus about the &lt;strong&gt;string representation&lt;/strong&gt;
for a duration. For instance, the &lt;code&gt;java.time.Duration&lt;/code&gt;
prefers ISO-8601, such as PT10S. The scala.concurrent.duration.Duration
prefers simple format, such as 10 seconds. Ohara offers a official
support to Duration type so as to ease the pain of using string in
connector. When you declare a setting with duration type, ohara provides
the default check which casts input value to java Duration and scala
Duration. Also, your connector can get the &lt;strong&gt;Duration&lt;/strong&gt; from

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/custom_connector/#source-start&#34;&gt;TaskSetting&lt;/a&gt;
easily without worrying about the conversion between java and scala.
Furthermore, connector users can input both java.Duration and
scala.Duration when starting connector.&lt;/p&gt;
&lt;p&gt;The value must be castable to &lt;strong&gt;java.time.Duration&lt;/strong&gt; and it is based on
the ISO-860 duration format PnDTnHnMn.nS&lt;/p&gt;
&lt;h4 id=&#34;typeremote_port&#34;&gt;Type.REMOTE_PORT&lt;/h4&gt;
&lt;p&gt;Remote port is a common property to connector. For example, the ftp
connector needs port used to connect to source/target ftp server in
remote . Inputting an illegal port can destroy connector easily.
Declaring your type of value to Port involve a check that only the port
which is smaller than 65536 and bigger than zero can be accepted. Other
port value will be rejected in starting connector.&lt;/p&gt;
&lt;h4 id=&#34;typebinding_port&#34;&gt;Type.BINDING_PORT&lt;/h4&gt;
&lt;p&gt;This type is similar to Type.PORT except that the value mapped to
BINDING_PORT has an extra check to the availability on the target nodes.
For example, you define value 5555 as a BINDING_PORT, and you will get
a exception when you try to deploy your code on the node which is using
port 5555 as well. The legal value of binding port is between [0, 65535].&lt;/p&gt;
&lt;h4 id=&#34;typeobject_key&#34;&gt;Type.OBJECT_KEY&lt;/h4&gt;
&lt;p&gt;object key represents a format of
&lt;strong&gt;oharastream.ohara.common.setting.ObjectKey&lt;/strong&gt; for a specific object. It
consists &amp;ldquo;group&amp;rdquo; and &amp;ldquo;name&amp;rdquo; fields. In a custom application, you
should check the request contains both fields.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;key&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;abc&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typeobject_keys&#34;&gt;Type.OBJECT_KEYS&lt;/h4&gt;
&lt;p&gt;OBJECT_KEYS represents a list of
&lt;strong&gt;oharastream.ohara.common.setting.Obj&lt;/strong&gt;. Note the type of the plural
char &amp;ldquo;s&amp;rdquo;. It means the request value should pass an array.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;objectKeys&amp;quot;: [{
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;t1&amp;quot;
  }]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    the default value to table value is empty
  &lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;typetags&#34;&gt;Type.TAGS&lt;/h4&gt;
&lt;p&gt;Tags is a flexible type that accept a json object. It could use in some
circumstances that user needs to define additional values which type is
not list above.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;tags&amp;quot;: {
    &amp;quot;name&amp;quot;: &amp;quot;hello&amp;quot;,
    &amp;quot;anArray&amp;quot;: [&amp;quot;bar&amp;quot;, &amp;quot;foo&amp;quot;],
    &amp;quot;count&amp;quot;: 10,
    &amp;quot;params&amp;quot;: {
      &amp;quot;k&amp;quot;: &amp;quot;v&amp;quot;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    the default value to table value is empty
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;necessary&#34;&gt;Necessary&lt;/h2&gt;
&lt;p&gt;In Ohara world, most components have a lot of configs to offers various
usage in production. In order to simplify the settings, most configs
have default value and you can trace Necessary field to know that.&lt;/p&gt;
&lt;p&gt;Necessary field has three values.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;REQUIRED&lt;/strong&gt; &amp;mdash; this value has no default value, and it must be defined.
You may get error if you don&amp;rsquo;t give any value to it.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OPTIONAL&lt;/strong&gt; &amp;mdash; this value has no default value, but it is ok to leave nothing.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RANDOM_DEFAULT&lt;/strong&gt; &amp;mdash; the default value assigned to this value is random.
For example, all objects&amp;rsquo; name has a random string by default; The binding
port field has a random free port by default.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;checker&#34;&gt;Checker&lt;/h2&gt;
&lt;p&gt;We all love quick failure, right? A quick failure can save our resource
and time. Ohara offers many checks for your setting according to the
&lt;strong&gt;expected&lt;/strong&gt; type. For example, a setting declared &lt;strong&gt;Duration&lt;/strong&gt; type has
a checker which validate whether the input value is able to be cast to
either java.time.Duration or scala.duration.Duration. However, you are
going to design a complicated connector which has specific limit for
input value.&lt;/p&gt;
&lt;h2 id=&#34;denylist&#34;&gt;DenyList&lt;/h2&gt;
&lt;p&gt;The denyList is useful information that it offers following checks.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The restful APIs will reject the values in the denyList&lt;/li&gt;
&lt;li&gt;Ohara UI disable user to input the illegal words&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Currently, denyList is used by Array type only.&lt;/p&gt;
&lt;h2 id=&#34;recommended-values&#34;&gt;Recommended values&lt;/h2&gt;
&lt;p&gt;Recommended values is used by Ohara UI that it able to pop a list to
users when they are using UI.&lt;/p&gt;
&lt;p&gt;Currently, recommended values is used by String type only.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Setting Definition Guide</title>
      <link>https://oharastream.github.io/en/docs/master/setting_definition/</link>
      <pubDate>Wed, 17 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/master/setting_definition/</guid>
      <description>&lt;p&gt;A powerful application always has a complicated configuration. In order
to be a best friend of Ohara users, Ohara provides a method which can
return the details of setting definitions, and ohara suggests that all
developers ought to implement the method so as to guide users through
the complicated settings of your applications.&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    If you have no interest in settings or your application is too simple to
have any settings, you can just skip this section.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;SettingDef is a class used to describe the details of &lt;strong&gt;a&lt;/strong&gt; setting. It
consists of following arguments.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;a href=&#34;#setting-reference&#34;&gt;reference&lt;/a&gt;(&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; works for ohara manager.
It represents the reference of value.&lt;/li&gt;
&lt;li&gt;group (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the group of this setting (all core setting are in core group)&lt;/li&gt;
&lt;li&gt;orderInGroup (&lt;strong&gt;int&lt;/strong&gt;) &amp;mdash; the order in group&lt;/li&gt;
&lt;li&gt;displayName (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the readable name of this setting&lt;/li&gt;
&lt;li&gt;permission (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the way to &amp;ldquo;touch&amp;rdquo; value. It consists of
&lt;ul&gt;
&lt;li&gt;READ_ONLY &amp;mdash; you can&amp;rsquo;t define an new value for it&lt;/li&gt;
&lt;li&gt;CREATE_ONLY &amp;mdash; you can&amp;rsquo;t update the value to an new one&lt;/li&gt;
&lt;li&gt;EDITABLE &amp;mdash; feel free to modify the value as you wish :)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;key (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the key of configuration&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#value-type&#34;&gt;valueType&lt;/a&gt;(&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the type of value&lt;/li&gt;
&lt;li&gt;necessary (&lt;strong&gt;string&lt;/strong&gt;)
&lt;ul&gt;
&lt;li&gt;REQUIRED &amp;mdash; this field has no default and user MUST define something for it.&lt;/li&gt;
&lt;li&gt;OPTIONAL &amp;mdash; this field has no default and user does NOT need to define something for it.&lt;/li&gt;
&lt;li&gt;RANDOM_DEFAULT &amp;mdash; this field has a &amp;ldquo;random&amp;rdquo; default value&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;defaultValue (&lt;strong&gt;object&lt;/strong&gt;) &amp;mdash; the default value. the type is equal to what valueType
defines but we only allow string, number and boolean type to have default value currently.&lt;/li&gt;
&lt;li&gt;documentation (&lt;strong&gt;string&lt;/strong&gt;) &amp;mdash; the explanation of this definition&lt;/li&gt;
&lt;li&gt;internal (&lt;strong&gt;boolean&lt;/strong&gt;) &amp;mdash; true if this setting is assigned by system automatically.&lt;/li&gt;
&lt;li&gt;tableKeys (&lt;strong&gt;array(object)&lt;/strong&gt;) &amp;mdash; the description to Type.TABLE
&lt;ul&gt;
&lt;li&gt;tableKeys[i].name &amp;mdash; the column name&lt;/li&gt;
&lt;li&gt;tableKeys[i].type &amp;mdash; acceptable type (string, number and boolean)&lt;/li&gt;
&lt;li&gt;tableKeys[i].recommendedValues &amp;mdash; recommended values
(it is legal to enter other values you prefer)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You can call &lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/workers/&#34;&gt;Worker APIs&lt;/a&gt;
to get all connectors&amp;rsquo; setting definitions, and use &lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/streams/&#34;&gt;Stream APIs&lt;/a&gt;
to get all stream setting definitions.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Although a SettingDef can include many elements, you can simply build a
SettingDef with only what you need. An extreme example is that you can
create a SettingDef with only key.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notwithstanding it is flexible to build a SettingDef, we encourage
developers to create a description-rich SettingDef. More description to
your setting produces more &lt;strong&gt;document&lt;/strong&gt; in calling ohara rest APIs. We
all hate write documentation, so it would be better to make your code
readable.&lt;/p&gt;
&lt;h2 id=&#34;reference-internal-and-tablekeys-are-not-public&#34;&gt;Reference, Internal and TableKeys Are NOT Public&lt;/h2&gt;
&lt;p&gt;Ohara offers a great UI, which is located at ohara-manager. The UI
requires some &lt;strong&gt;private&lt;/strong&gt; information to generate forms for custom
applications. The such private information is specific-purpose and is
meaningless to non-ohara developers. Hence, all of them are declared as
package-private and ohara does not encourage developers to stop at
nothing to use them.&lt;/p&gt;
&lt;h2 id=&#34;optional-required-and-default-value&#34;&gt;Optional, Required And Default Value&lt;/h2&gt;
&lt;p&gt;We know a great application must have countless settings and only The
Chosen One can control it. In order to shorten the gap between your
application and human begin, ohara encourage developers to offer the
default values to most of settings as much as possible. Assigning a
default value to a SettingDef is a piece of cake.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .optional(defaultValue)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    the default value is declared as &lt;strong&gt;string&lt;/strong&gt; type as it must be &lt;strong&gt;readable&lt;/strong&gt; in Restful APIs.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;After calling the &lt;strong&gt;optional(String)&lt;/strong&gt; method, the response, created by

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/workers/&#34;&gt;Worker APIs&lt;/a&gt; for example,
will display the following information.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;necessary&amp;quot;: &amp;quot;OPTIONAL_WITH_DEFAULT&amp;quot;,
  &amp;quot;defaultValue&amp;quot;: &amp;quot;ur_default_value&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The default value will be added to
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/custom_connector/#source-start&#34;&gt;TaskSetting&lt;/a&gt;
automatically if the specified key is not already associated with a value.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;a-readonly-setting-definition&#34;&gt;A Readonly Setting Definition&lt;/h2&gt;
&lt;p&gt;You can declare a &lt;strong&gt;readonly&lt;/strong&gt; setting that not only exposes something
of your application to user but also remind user the setting can&amp;rsquo;t be
changed at runtime. For instance, the information of

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/custom_connector/#version&#34;&gt;version&lt;/a&gt; is fixed
after you have completed your connector so it is not an &lt;strong&gt;editable&lt;/strong&gt;
setting. Hence, ohara define a setting for &lt;strong&gt;version&lt;/strong&gt; with a readonly
label. By the way, you should assign a default value to a readonly
setting since a readonly setting without default value is really weird.
There is an example of creating a readonly setting.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .optional(defaultValue)
    .permission(SettingDef.Permission.READ_ONLY)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    The input value will be removed automatically if the associated setting
is declared readonly.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;setting-reference&#34;&gt;Setting Reference&lt;/h2&gt;
&lt;p&gt;This element is a specific purpose. It is used by Ohara manager (UI) only.
If you don&amp;rsquo;t have interest in UI, you can just ignore this element.
However, we still list the available values here.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NODE&lt;/li&gt;
&lt;li&gt;TOPIC&lt;/li&gt;
&lt;li&gt;ZOOKEEPER&lt;/li&gt;
&lt;li&gt;BROKER&lt;/li&gt;
&lt;li&gt;WORKER&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    For each reference value, it may have different type and will produce
different behavior.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Topic String&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder().key(&amp;quot;topic&amp;quot;).reference(Reference.TOPIC).required(Type.STRING).build();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which means the request should &amp;ldquo;accept one topic of string type&amp;rdquo;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;topic&amp;quot;: &amp;quot;t1&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;TopicKey List&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(&amp;quot;topicKeys&amp;quot;)
    .reference(Reference.TOPIC)
    .required(Type.OBJECT_KEYS)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which means the request should &amp;ldquo;accept topic list of &lt;strong&gt;TopicKey&lt;/strong&gt; type&amp;rdquo;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;topicKeys&amp;quot;: [
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;t1&amp;quot;
    },
    {
      &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
      &amp;quot;name&amp;quot;: &amp;quot;t2&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;p&gt;Topic String List&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(&amp;quot;topics&amp;quot;)
    .reference(Reference.TOPIC)
    .required(Type.ARRAY)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which means the request should &amp;ldquo;accept topic list of string type&amp;rdquo;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;topics&amp;quot;: [&amp;quot;t1&amp;quot;, &amp;quot;t2&amp;quot;, &amp;quot;t3&amp;quot;]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;value-type&#34;&gt;Value Type&lt;/h2&gt;
&lt;p&gt;In a custom application, the settings could have various data type. In
order to display correct data type in ohara manager and leverage the
benefit of 
&lt;a href=&#34;#checker&#34;&gt;type checker&lt;/a&gt;, we
strongly suggest you to define the correct data type for each setting.&lt;/p&gt;
&lt;p&gt;The following data types are supported currently.&lt;/p&gt;
&lt;h4 id=&#34;typeboolean&#34;&gt;Type.BOOLEAN&lt;/h4&gt;
&lt;p&gt;Boolean type represents that the data should have only two possible
value: &lt;strong&gt;true&lt;/strong&gt; or &lt;strong&gt;false&lt;/strong&gt;. The value must be able cast to
&lt;strong&gt;java.lang.Boolean&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;typestring&#34;&gt;Type.STRING&lt;/h4&gt;
&lt;p&gt;String type represents that the data should be a string. The value must
be able cast to &lt;strong&gt;java.lang.String&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.STRING)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typepositive_short&#34;&gt;Type.POSITIVE_SHORT&lt;/h4&gt;
&lt;p&gt;Short type represents that the data should be a 2-bytes integer. The
value must be able cast to &lt;strong&gt;java.lang.Short&lt;/strong&gt;. Noted: only positive
number is acceptable&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.POSITIVE_SHORT)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typeshort&#34;&gt;Type.SHORT&lt;/h4&gt;
&lt;p&gt;Short type represents that the data should be a 2-bytes integer. The
value must be able cast to &lt;strong&gt;java.lang.Short&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.SHORT)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typepositive_int&#34;&gt;Type.POSITIVE_INT&lt;/h4&gt;
&lt;p&gt;Int type represents that the data should be a 4-bytes integer. The value
must be able cast to &lt;strong&gt;java.lang.Integer&lt;/strong&gt;. Noted: only positive number
is acceptable&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.POSITIVE_INT)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typeint&#34;&gt;Type.INT&lt;/h4&gt;
&lt;p&gt;Int type represents that the data should be a 4-bytes integer. The value
must be able cast to &lt;strong&gt;java.lang.Integer&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.INT)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typepositive_long&#34;&gt;Type.POSITIVE_LONG&lt;/h4&gt;
&lt;p&gt;Long type represents that the data should be a 8-bytes integer. The
value must be able cast to &lt;strong&gt;java.lang.Long&lt;/strong&gt;. Noted: only positive
number is acceptable&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.POSITIVE_LONG)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typelong&#34;&gt;Type.LONG&lt;/h4&gt;
&lt;p&gt;Long type represents that the data should be a 8-bytes integer. The
value must be able cast to &lt;strong&gt;java.lang.Long&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.LONG)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typepositive_double&#34;&gt;Type.POSITIVE_DOUBLE&lt;/h4&gt;
&lt;p&gt;Double type represents that the data should be a 8-bytes floating-point.
The value must be able cast to &lt;strong&gt;java.lang.Double&lt;/strong&gt;. Noted: only
positive number is acceptable&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.POSITIVE_DOUBLE)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typedouble&#34;&gt;Type.DOUBLE&lt;/h4&gt;
&lt;p&gt;Double type represents that the data should be a 8-bytes floating point.
The value must be able cast to &lt;strong&gt;java.lang.Double&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.DOUBLE)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typearray&#34;&gt;Type.ARRAY&lt;/h4&gt;
&lt;p&gt;Array type represents that the data should be a collection of data. We
don&amp;rsquo;t check the element data type in the collection, that is, the
following request is legal in SettingDef but will produce a weird
behavior in ohara manager. We suggest you use the same data type of
element in an array.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;key&amp;quot;: [&amp;quot;abc&amp;quot;, 123, 2.0]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.ARRAY)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;An empty array is ok and will pass the checker:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;key&amp;quot;: []
}
&lt;/code&gt;&lt;/pre&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    the default value to array value is empty
  &lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;typeclass&#34;&gt;Type.CLASS&lt;/h4&gt;
&lt;p&gt;Class type represents that the data is a class. This data type is used
to display a value that is a class. The value must be able cast to
&lt;strong&gt;java.lang.String&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.CLASS)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typepassword&#34;&gt;Type.PASSWORD&lt;/h4&gt;
&lt;p&gt;Password type represents that the data is a password. We will replace
the value by &lt;strong&gt;hidden&lt;/strong&gt; symbol in APIs. if the data type is used as
password. The value must be able cast to &lt;strong&gt;java.lang.String&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .required(Type.PASSWORD)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typejdbc_table&#34;&gt;Type.JDBC_TABLE&lt;/h4&gt;
&lt;p&gt;JDBC_TABLE is a specific string type used to reminder Ohara Manager
that this field requires a &lt;strong&gt;magic&lt;/strong&gt; button to show available tables of
remote database via Query APIs. Except for the &lt;strong&gt;magic&lt;/strong&gt; in UI, there is
no other stuff for this JDBC_TYPE since kafka can&amp;rsquo;t verify the input
arguments according to other arguments. It means we can&amp;rsquo;t connect to
remote database to check the existence of input table.&lt;/p&gt;
&lt;p&gt;It is ok to replace this field by Type.STRING if you don&amp;rsquo;t use Ohara
Manager. Nevertheless, we still encourage the developer to choose the
&lt;strong&gt;fitting&lt;/strong&gt; type for your setting if you demand your user to input a
database table.&lt;/p&gt;
&lt;h4 id=&#34;typetable&#34;&gt;Type.TABLE&lt;/h4&gt;
&lt;p&gt;Table type enable you to define a setting having table structure value.
Apart from assigning Type.Table to your setting definition, you also
have to define which keys are in your table. The following example show
a case that declares a table having two columns called &lt;strong&gt;c0&lt;/strong&gt; and
&lt;strong&gt;c1&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;SettingDef.builder()
    .key(key)
    .tableKeys(Arrays.asList(&amp;quot;c0&amp;quot;, &amp;quot;c1&amp;quot;))
    .required(Type.TABLE)
    .build();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The legal value for above setting definition is shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;key&amp;quot;: [
    {
      &amp;quot;c0&amp;quot;: &amp;quot;v0&amp;quot;,
      &amp;quot;c1&amp;quot;: &amp;quot;v1&amp;quot;
    },
    {
      &amp;quot;c0&amp;quot;: &amp;quot;v2&amp;quot;,
      &amp;quot;c1&amp;quot;: &amp;quot;v3&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above example implies there is a table having two columns called
&lt;strong&gt;c0&lt;/strong&gt; and &lt;strong&gt;c1&lt;/strong&gt;. Also, you assign two values to &lt;strong&gt;c0&lt;/strong&gt; that first is
&lt;strong&gt;v0&lt;/strong&gt; and another is &lt;strong&gt;v2&lt;/strong&gt;. Ohara offers a check for Type.Table that
the input value &lt;strong&gt;must&lt;/strong&gt; match all keys in.&lt;/p&gt;
&lt;p&gt;How to get the description of above &lt;strong&gt;keys&lt;/strong&gt; ? If the setting type is
&lt;strong&gt;table&lt;/strong&gt;, the setting must have &lt;strong&gt;tableKeys&lt;/strong&gt;. It is an array of string
which shows the keys used in the table type. For instance, a setting
having table type is shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;reference&amp;quot;: &amp;quot;NONE&amp;quot;,
  &amp;quot;displayName&amp;quot;: &amp;quot;columns&amp;quot;,
  &amp;quot;internal&amp;quot;: false,
  &amp;quot;documentation&amp;quot;: &amp;quot;output schema&amp;quot;,
  &amp;quot;valueType&amp;quot;: &amp;quot;TABLE&amp;quot;,
  &amp;quot;tableKeys&amp;quot;: [
    &amp;quot;order&amp;quot;,
    &amp;quot;dataType&amp;quot;,
    &amp;quot;name&amp;quot;,
    &amp;quot;newName&amp;quot;
  ],
  &amp;quot;orderInGroup&amp;quot;: 6,
  &amp;quot;key&amp;quot;: &amp;quot;columns&amp;quot;,
  &amp;quot;necessary&amp;quot;: &amp;quot;REQUIRED&amp;quot;,
  &amp;quot;defaultValue&amp;quot;: null,
  &amp;quot;group&amp;quot;: &amp;quot;core&amp;quot;,
  &amp;quot;permission&amp;quot;: &amp;quot;EDITABLE&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    If you ignore the table keys for Type.Table, the check to your input
value is also ignored. By contrast, the table keys are useless for other
types.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    the default value to table value is empty
  &lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;typeduration&#34;&gt;Type.DURATION&lt;/h4&gt;
&lt;p&gt;The time-based amount of time is a common setting in our world. However,
it is also hard to reach the consensus about the &lt;strong&gt;string representation&lt;/strong&gt;
for a duration. For instance, the &lt;code&gt;java.time.Duration&lt;/code&gt;
prefers ISO-8601, such as PT10S. The scala.concurrent.duration.Duration
prefers simple format, such as 10 seconds. Ohara offers a official
support to Duration type so as to ease the pain of using string in
connector. When you declare a setting with duration type, ohara provides
the default check which casts input value to java Duration and scala
Duration. Also, your connector can get the &lt;strong&gt;Duration&lt;/strong&gt; from

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/custom_connector/#source-start&#34;&gt;TaskSetting&lt;/a&gt;
easily without worrying about the conversion between java and scala.
Furthermore, connector users can input both java.Duration and
scala.Duration when starting connector.&lt;/p&gt;
&lt;p&gt;The value must be castable to &lt;strong&gt;java.time.Duration&lt;/strong&gt; and it is based on
the ISO-860 duration format PnDTnHnMn.nS&lt;/p&gt;
&lt;h4 id=&#34;typeremote_port&#34;&gt;Type.REMOTE_PORT&lt;/h4&gt;
&lt;p&gt;Remote port is a common property to connector. For example, the ftp
connector needs port used to connect to source/target ftp server in
remote . Inputting an illegal port can destroy connector easily.
Declaring your type of value to Port involve a check that only the port
which is smaller than 65536 and bigger than zero can be accepted. Other
port value will be rejected in starting connector.&lt;/p&gt;
&lt;h4 id=&#34;typebinding_port&#34;&gt;Type.BINDING_PORT&lt;/h4&gt;
&lt;p&gt;This type is similar to Type.PORT except that the value mapped to
BINDING_PORT has an extra check to the availability on the target nodes.
For example, you define value 5555 as a BINDING_PORT, and you will get
a exception when you try to deploy your code on the node which is using
port 5555 as well. The legal value of binding port is between [0, 65535].&lt;/p&gt;
&lt;h4 id=&#34;typeobject_key&#34;&gt;Type.OBJECT_KEY&lt;/h4&gt;
&lt;p&gt;object key represents a format of
&lt;strong&gt;oharastream.ohara.common.setting.ObjectKey&lt;/strong&gt; for a specific object. It
consists &amp;ldquo;group&amp;rdquo; and &amp;ldquo;name&amp;rdquo; fields. In a custom application, you
should check the request contains both fields.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;key&amp;quot;: {
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;abc&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;typeobject_keys&#34;&gt;Type.OBJECT_KEYS&lt;/h4&gt;
&lt;p&gt;OBJECT_KEYS represents a list of
&lt;strong&gt;oharastream.ohara.common.setting.Obj&lt;/strong&gt;. Note the type of the plural
char &amp;ldquo;s&amp;rdquo;. It means the request value should pass an array.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;objectKeys&amp;quot;: [{
    &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;name&amp;quot;: &amp;quot;t1&amp;quot;
  }]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    the default value to table value is empty
  &lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;typetags&#34;&gt;Type.TAGS&lt;/h4&gt;
&lt;p&gt;Tags is a flexible type that accept a json object. It could use in some
circumstances that user needs to define additional values which type is
not list above.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;tags&amp;quot;: {
    &amp;quot;name&amp;quot;: &amp;quot;hello&amp;quot;,
    &amp;quot;anArray&amp;quot;: [&amp;quot;bar&amp;quot;, &amp;quot;foo&amp;quot;],
    &amp;quot;count&amp;quot;: 10,
    &amp;quot;params&amp;quot;: {
      &amp;quot;k&amp;quot;: &amp;quot;v&amp;quot;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    the default value to table value is empty
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;necessary&#34;&gt;Necessary&lt;/h2&gt;
&lt;p&gt;In Ohara world, most components have a lot of configs to offers various
usage in production. In order to simplify the settings, most configs
have default value and you can trace Necessary field to know that.&lt;/p&gt;
&lt;p&gt;Necessary field has three values.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;REQUIRED&lt;/strong&gt; &amp;mdash; this value has no default value, and it must be defined.
You may get error if you don&amp;rsquo;t give any value to it.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OPTIONAL&lt;/strong&gt; &amp;mdash; this value has no default value, but it is ok to leave nothing.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RANDOM_DEFAULT&lt;/strong&gt; &amp;mdash; the default value assigned to this value is random.
For example, all objects&amp;rsquo; name has a random string by default; The binding
port field has a random free port by default.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;checker&#34;&gt;Checker&lt;/h2&gt;
&lt;p&gt;We all love quick failure, right? A quick failure can save our resource
and time. Ohara offers many checks for your setting according to the
&lt;strong&gt;expected&lt;/strong&gt; type. For example, a setting declared &lt;strong&gt;Duration&lt;/strong&gt; type has
a checker which validate whether the input value is able to be cast to
either java.time.Duration or scala.duration.Duration. However, you are
going to design a complicated connector which has specific limit for
input value.&lt;/p&gt;
&lt;h2 id=&#34;denylist&#34;&gt;DenyList&lt;/h2&gt;
&lt;p&gt;The denyList is useful information that it offers following checks.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The restful APIs will reject the values in the denyList&lt;/li&gt;
&lt;li&gt;Ohara UI disable user to input the illegal words&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Currently, denyList is used by Array type only.&lt;/p&gt;
&lt;h2 id=&#34;recommended-values&#34;&gt;Recommended values&lt;/h2&gt;
&lt;p&gt;Recommended values is used by Ohara UI that it able to pop a list to
users when they are using UI.&lt;/p&gt;
&lt;p&gt;Currently, recommended values is used by String type only.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>User Guide</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/user_guide/</link>
      <pubDate>Wed, 17 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/user_guide/</guid>
      <description>&lt;p&gt;This documentation is for Ohara users who try to exercise or test Ohara
without writing any code. Ohara team design and implement Ohara to
provide a unparalleled platform which enable everyone to build streaming
easily and quickly. For normal users, you can manipulate Ohara through
UI interface even if you have no idea about the magic infra of Ohara.
For advanced users trying to build custom streaming, they are encouraged
to design and write application based on Ohara&amp;rsquo;s various and powerful
APIs (see 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/custom_connector/&#34;&gt;Custom Connector&lt;/a&gt;
and 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/custom_stream/&#34;&gt;Custom Stream&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Ohara consists of many services, such as&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;a href=&#34;#configurator&#34;&gt;Ohara Configurator&lt;/a&gt; &amp;mdash; the controller of Ohara.
It cooperates other services and provides the 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/&#34;&gt;Restful APIs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#manager&#34;&gt;Ohara Manager&lt;/a&gt; &amp;mdash; the UI service of Ohara. It offers a
streaming flow called &lt;strong&gt;pipeline&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#zookeeper&#34;&gt;Zookeeper&lt;/a&gt; &amp;mdash; works for Broker. It has charge of managing
the configuration of topics and health of node&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#broker&#34;&gt;Broker&lt;/a&gt; &amp;mdash; It provides the access of topics, topics&amp;rsquo; data
durability and balance.&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#worker&#34;&gt;Worker&lt;/a&gt; &amp;mdash;
It hosts and execute 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/custom_connector/&#34;&gt;Custom Connector&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#docker&#34;&gt;Docker&lt;/a&gt; &amp;mdash; It packages the configs, dependencies and binary
required by services and execute them in a isolated environments&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#k8s&#34;&gt;Kubernetes&lt;/a&gt; &amp;mdash; a management tool of docker instances&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Ohara has a complicated software stack, but most services are almost
transparent to you. For example, before creating a topic on Ohara, you
ought to set up a zookeeper cluster and a broker cluster. There are ,
unfortunately, a bunch of configs which you have to design and write for
both cluster. Ohara auto-generates most configs for you as best as it
can, and Ohara offers the the readable

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/&#34;&gt;Restful APIs&lt;/a&gt; and friendly UI to
you. All complicated configs are replaced by some simple steps showed on
UI. The 
&lt;a href=&#34;#quickstart&#34;&gt;Quick Start&lt;/a&gt; section teach you to exercise Ohara easily and quickly.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;quickstart&#34;&gt;Quick Start&lt;/h2&gt;
&lt;p&gt;The core component of Ohara is 
&lt;a href=&#34;#configurator&#34;&gt;Configurator&lt;/a&gt;. After installing

&lt;a href=&#34;#installation&#34;&gt;related tools&lt;/a&gt;, you can set up a Configurator via following docker command.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ docker run --rm -p 12345:12345 oharastream/configurator:0.11.0-SNAPSHOT --port 12345 --hostname ${host}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    click &lt;a href=&#34;#execute-configurator&#34;&gt;here&lt;/a&gt; to see more options for configurator
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;And then you can also create a manager to provide a beautiful UI based on above Ohara Configurator.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ docker run --rm -p 5050:5050 oharastream/manager:0.11.0-SNAPSHOT --port 5050 --configurator http://$ip:12345/v0
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Please replace the &lt;strong&gt;ip&lt;/strong&gt; by your host&amp;rsquo;s address
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Open your browser (we recommend 
&lt;a href=&#34;https://www.google.com/intl/zh-TW/chrome/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google Chrome&lt;/a&gt;)
and link to 
&lt;a href=&#34;http://localhost:5050/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://localhost:5050/&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;
&lt;p&gt;We all love docker, right? All Ohara services are executed by docker
container. However, it is ok to run Ohara services through

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/build/build-ohara/#build-binary&#34;&gt;assembly file&lt;/a&gt; if you
really really really hate docker.&lt;/p&gt;
&lt;h3 id=&#34;network-configurations&#34;&gt;Network Configurations&lt;/h3&gt;
&lt;p&gt;We are trying to do everything for you. However, your network your
problem (reference to Hadoop&amp;rsquo;s

&lt;a href=&#34;https://cwiki.apache.org/confluence/display/HADOOP2/YourNetworkYourProblem&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;motto&lt;/a&gt;.
A bad network configurations can bring any kind of exception in any
time, and it is hard to diagnose your network problems. In order to make
each container be able to find each other, please ensure following
common problems (reference to

&lt;a href=&#34;https://cwiki.apache.org/confluence/display/HADOOP2/YourNetworkYourProblem&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hadoop&lt;/a&gt;
again) don&amp;rsquo;t happen on your nodes.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;DNS and reverse DNS broken/non-existent.&lt;/li&gt;
&lt;li&gt;Host tables in the machines invalid.&lt;/li&gt;
&lt;li&gt;Firewalls in the hosts blocking connections.&lt;/li&gt;
&lt;li&gt;Routers blocking traffic.&lt;/li&gt;
&lt;li&gt;Hosts with multiple network cards listening/talking on the wrong NIC.&lt;/li&gt;
&lt;li&gt;Difference between the hadoop configuration files&amp;rsquo; definition of the
cluster (especially hostnames and ports) from that of the actual
cluster setup.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;After validating your network configurations layer by layer, you could
try filing issue on github if you still can&amp;rsquo;t get Ohara to work.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;We often encounter problems with network problems&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;After install Docker-ce package in CentOS,the network default policy is
block docker&amp;rsquo;s bridge to host network, You &lt;strong&gt;must&lt;/strong&gt; add a rule on the
firewall:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ sudo firewall-cmd --zone=trusted --permanent --add-interface=docker0
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;install-docker-ce-on-centos&#34;&gt;Install Docker-ce on CentOS&lt;/h3&gt;
&lt;p&gt;Docker has provided a great docs about installing docker-ce. Please
click this 
&lt;a href=&#34;https://docs.docker.com/install/linux/docker-ce/centos/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;download-images&#34;&gt;Download Ohara Images&lt;/h3&gt;
&lt;p&gt;Ohara deploys docker images on 
&lt;a href=&#34;https://hub.docker.com/u/oharastream&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;docker hub&lt;/a&gt;.
You can download images via &lt;code&gt;docker pull&lt;/code&gt; command. All images are list below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;oharastream/broker:0.11.0-SNAPSHOT&lt;/li&gt;
&lt;li&gt;oharastream/zookeeper:0.11.0-SNAPSHOT&lt;/li&gt;
&lt;li&gt;oharastream/connect-worker:0.11.0-SNAPSHOT&lt;/li&gt;
&lt;li&gt;oharastream/configurator:0.11.0-SNAPSHOT&lt;/li&gt;
&lt;li&gt;oharastream/manager:0.11.0-SNAPSHOT&lt;/li&gt;
&lt;li&gt;oharastream/stream:0.11.0-SNAPSHOT&lt;/li&gt;
&lt;li&gt;oharastream/shabondi:0.11.0-SNAPSHOT&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;execute-configurator&#34;&gt;Execute Configurator&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ docker run --rm -p ${port}:${port} --add-host ${nodeHostName}:${nodeHostIP} oharastream/configurator:0.11.0-SNAPSHOT --port ${port} --hostname ${host}
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--folder&lt;/code&gt;: the folder used to store data (default is random). Mount
the volume if you want to keep your data after restarting Configurator&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--port&lt;/code&gt;: bound by Configurator (default is random)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--add-host&lt;/code&gt;: add a host mapping to /etc/hosts in Ohara Configurator
(nodeHostName:nodeHostIP). If you have DNS server, you can just
ignore parameter of add-host.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--hostname&lt;/code&gt;: hostname to run Ohara Configurator (defaults to 0.0.0.0)&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;You can enable the jmx reporter via inputting two env variables -
&amp;ldquo;JMX_HOSTNAME&amp;rdquo; and &amp;ldquo;JMX_PORT&amp;rdquo;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;JMX_HOSTNAME&amp;rdquo; should be same as the host running Ohara
Configurator container so as to access the jmx service in docker
from outside.&lt;/li&gt;
&lt;li&gt;&amp;ldquo;JMX_PORT&amp;rdquo; should be opened by docker (for example, add &amp;ldquo;-p $JMX_PORT:$JMX_PORT&amp;rdquo;)&lt;/li&gt;
&lt;/ul&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;All services host by Ohara Configurator are based on docker technique.
By default Ohara Configurator use ssh to control the docker containers
from remote nodes (see 
&lt;a href=&#34;#docker&#34;&gt;Docker&lt;/a&gt; section).
In this mode, please make sure the ssh account
added by 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/nodes/&#34;&gt;Node APIs&lt;/a&gt; should
have sudo permission to run docker command (see

&lt;a href=&#34;https://docs.docker.com/install/linux/linux-postinstall/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt; for
related steps).&lt;/p&gt;
&lt;h3 id=&#34;configurator-data&#34;&gt;Keep the data of Configurator&lt;/h3&gt;
&lt;p&gt;Ohara Configurator demand a folder to store &lt;code&gt;data&lt;/code&gt; and

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/files/&#34;&gt;jars&lt;/a&gt;. As Ohara Configurator
is running in docker container, you have to mount the volume, which is
located on container host, on the home folder of Ohara Configurator if
you want to keep all data of Ohara Configurator. The following example
is to mount a local folder (/tmp/configurator) on
&lt;strong&gt;/home/ohara/configurator&lt;/strong&gt; of Ohara Configurator&amp;rsquo;s container.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ mkdir /tmp/configurator
$ docker run -v /tmp/configurator:/home/ohara/configurator \
         -p 12345:12345 \
         oharastream/configurator:0.11.0-SNAPSHOT \
         --port 12345 \
         --hostname ${host} \
         --folder /home/ohara/configurator
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The user account in docker container is &lt;strong&gt;ohara&lt;/strong&gt;, and hence it would be
better to set the folder under the &lt;strong&gt;/home/ohara&lt;/strong&gt;. Otherwise, you will
encounter the permission error. Noted that you have tell Ohara
Configurator to save data in the folder referencing to the outside
folder. Otherwise, Ohara Configurator flush all data to a random folder.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How to solve the start configurator container permission denied issue?&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;You must confirm your host username is the ohara and UID is 1000.
Please refer to issue 
&lt;a href=&#34;https://github.com/oharastream/ohara/issues/2573

&#34;&gt;#2573&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Please confirm the &lt;strong&gt;/tmp/configurator&lt;/strong&gt; host path owner is ohara user
and have to write permission.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;execute-manager&#34;&gt;Execute Manager&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ docker run --rm -p 5050:5050 oharastream/manager:0.11.0-SNAPSHOT --port 5050 --configurator http://localhost:12345/v0
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--port&lt;/code&gt;: bound by manager (default is 5050)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--configurator&lt;/code&gt;: basic form of restful API of Ohara Configurator&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;execute-postgresql-instance&#34;&gt;Execute PostgreSQL Instance&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ docker run -d --rm --name postgresql -p 5432:5432 --env POSTGRES_DB=${DB_NAME} --env POSTGRES_USER=${USER_NAME} --env POSTGRES_PASSWORD=${PASSWORD} -it islandsystems/postgresql:9.2.24
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;POSTGRES_DB: PostgreSQL DataBase name&lt;/li&gt;
&lt;li&gt;POSTGRES_USER: PostgreSQL login user name.&lt;/li&gt;
&lt;li&gt;POSTGRES_PASSWORD: PostgreSQL login password.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    POSTGRES_USER=&amp;quot;user&amp;rdquo; is illegal to postgresql
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;execute-ftp-instance&#34;&gt;Execute FTP Instance&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ docker run --rm -p 10000-10011:10000-10011 oharastream/backend:0.11.0-SNAPSHOT oharastream.ohara.testing.service.FtpServer --controlPort 10000 --dataPorts 10001-10011 --user ${UserName} --password ${Password} --hostname ${hostIP or hostName}
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;controlPort: bound by FTP Server&lt;/li&gt;
&lt;li&gt;dataPorts: bound by data transportation in FTP Server&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;configurator&#34;&gt;Ohara Configurator&lt;/h2&gt;
&lt;p&gt;Ohara consists of many services, and Ohara Configurator plays the most
important rule which coordinates all services and offers a bunch of
restful APIs to user to get all under control. The brief architecture of
Ohara Configurator is shown below.&lt;/p&gt;















&lt;figure id=&#34;figure-configurator-architecture&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/configurator_arch.jpg&#34; data-caption=&#34;Configurator architecture&#34;&gt;


  &lt;img src=&#34;../img/configurator_arch.jpg&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Configurator architecture
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;The introduction of each components are shown below. Feel free to trace
the component in which you have interest.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#configurator-route&#34;&gt;Route of Ohara Configurator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#configurator-store&#34;&gt;Store of Ohara Configurator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#configurator-cache&#34;&gt;Cache of Ohara Configurator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#configurator-collie&#34;&gt;Collie of Ohara Configurator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#configurator-client&#34;&gt;Client of Ohara Configurator&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;configurator-route&#34;&gt;Route of Configurator&lt;/h3&gt;
&lt;p&gt;Ohara Configurator leverages the akka-http to implements the rest server
and handle the conversion of json objects. You can click our

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/&#34;&gt;RESTful API docs&lt;/a&gt; to see all
public APIs and introduction.&lt;/p&gt;
&lt;p&gt;The APIs supported by Ohara Configurator is only the Restful APIs. Of
course, you can raise a question to us - why we choose the Restful APIs
rather than pure Java APIs? The answer is - We all hate the other
programming language except for the one we are using. However, we always
need to work with other people who are typing terrible and weird code,
and all they want to do is to call your APIs. In order to save our time
from co-working with them, providing the Restful APIs is always to be
our solution. For another reason, Ohara Configurator is not in charge of
I/O flow. Coordinating all services requires small bandwidth only. We
don&amp;rsquo;t need to care for the performance issue about Restful APIs.&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You can use our internal scala APIs to control Configurator. The
library is called ohara-client and it covers all Restful APIs of
Configurator. However, we don&amp;rsquo;t guarantee any compatibility for
ohara-client.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;configurator-store&#34;&gt;Store of Configurator&lt;/h3&gt;
&lt;p&gt;All settings you request to Ohara Configurator are saved in Store, such
as connector settings, cluster information and pipeline description. The
default implementation of Store is 
&lt;a href=&#34;https://rocksdb.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RocksDB&lt;/a&gt; which
offers fast in-memory access and persists all data on disk. Please read
this 
&lt;a href=&#34;#configurator-data&#34;&gt;section&lt;/a&gt; about mounting host&amp;rsquo;s
folder on docker container.&lt;/p&gt;
&lt;h3 id=&#34;configurator-cache&#34;&gt;Cache of Configurator&lt;/h3&gt;
&lt;p&gt;The cost of coordinating countless services is the big &lt;strong&gt;latency&lt;/strong&gt;. For
example, 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/topics/&#34;&gt;Topic APIs&lt;/a&gt; allows
you to fetch metrics from different

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/brokers/&#34;&gt;broker clusters&lt;/a&gt;. Ohara
Configurator has to file a bunch of connections to different clusters to
retrieve all requisite information, and, of course, the &lt;strong&gt;connections&lt;/strong&gt;
bring the large latency to the GET request. Hence, Ohara Configurator
sets up a inner cache which stores the data from remote clusters. It
reduces the latency from seconds to milliseconds and allay your anger.
In order to make all data up-to-date as much as possible, the cache
auto-refreshes timeout data in the background. It brings some extra cost
of building connections to remote clusters.&lt;/p&gt;
&lt;h3 id=&#34;configurator-collie&#34;&gt;Collie of Configurator&lt;/h3&gt;
&lt;p&gt;Apart from the data flow, Ohara Configurator is also doable to manage
clusters for you. For instance, you can&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;add 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/nodes/&#34;&gt;node&lt;/a&gt; to Ohara Configurator&lt;/li&gt;
&lt;li&gt;deploy a 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/zookeepers/&#34;&gt;zookeeper cluster&lt;/a&gt; on the node&lt;/li&gt;
&lt;li&gt;deploy a 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/brokers/&#34;&gt;broker cluster&lt;/a&gt; on the node as well&lt;/li&gt;
&lt;li&gt;deploy a 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/workers/&#34;&gt;worker cluster&lt;/a&gt; on the node&lt;/li&gt;
&lt;li&gt;finally, you can run a connector to stream your data and all
services you have created are hosted by Ohara Configurator&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In order to host your services safely and quickly, Ohara Configurator
leverages the Docker technique that all services are packaged to a
container and executed on the node(s) specified by you. As a good
software stack, Ohara Configurator creates a container manager, which is
called &lt;strong&gt;collie&lt;/strong&gt;, to wrap Restful APIs of 
&lt;a href=&#34;#k8s&#34;&gt;k8s&lt;/a&gt;
and ssh command to Scala APIs.&lt;/p&gt;
&lt;h3 id=&#34;configurator-client&#34;&gt;Client of Configurator&lt;/h3&gt;
&lt;p&gt;As a good programmer, we all love to reuse the code. However, it is hard
to trust all third-party libraries guarantee the suitable compatibility
policy. The Client code in Ohara is a collection of wrap for all client
codes to services, such as broker and worker, so as not to be badly hurt
by the update of services.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;manager&#34;&gt;Ohara Manager&lt;/h2&gt;
&lt;p&gt;Ohara Manager is the user interface (UI) of Ohara. It&amp;rsquo;s built with the
standard web technologies and so can be run in almost all the modern
browsers (We recommend you to use Google chrome though). Ohara Manager
talks to Ohara Configurator via its RESTful APIs under the hook which
then connects with the rest of Ohara services.&lt;/p&gt;
&lt;p&gt;Ohara Manager was built and designed with the user&amp;rsquo;s needs in mind. We
aimed to reduce the pain of complex operations that often required in a
big data system. With Ohara Manager, you can create your own services,
pipelines and working with data streaming without touching a single line
of code.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Following is a quick walk through of Ohara Manager&amp;rsquo;s user interface:&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;pipelines&#34;&gt;Pipelines&lt;/h3&gt;
&lt;p&gt;Pipeline list page is where you can view, create, edit and delete
pipelines.&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/pipelines.png&#34; &gt;


  &lt;img src=&#34;../img/pipelines.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;Inside the new/edit pipeline page, you can create and play around with
your pipelines here. This is also where you can run and stop your
pipelines. The pipeline graph helps you to easily visualize the pipeline
that you&amp;rsquo;re working on. Also, you can edit and tweak a connector&amp;rsquo;s
configuration by clicking on the graph and edit the configuration form
which will be displayed in the sidebar. We know it&amp;rsquo;s sometimes tedious
and time consuming to edit the configuration and it&amp;rsquo;s also frustrating
when you lose all of your configuration without saving them! That&amp;rsquo;s why
we made these configuration forms automatically save changes for you.
Whenever you type in a text field, choose a new topic form a dropdown,
the changes will be saved immediately.&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/pipelines_new.png&#34; &gt;


  &lt;img src=&#34;../img/pipelines_new.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;Please note that a pipeline can only be added to a workspace, so
before creating pipelines, you will need to 
&lt;a href=&#34;#workspaces&#34;&gt;create a workspace first&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;nodes&#34;&gt;Nodes&lt;/h3&gt;
&lt;p&gt;This is where you create and edit Ohara Nodes. These nodes are usually
your VMs. When you&amp;rsquo;re starting a new Ohara Configurator. You can
optionally supply some node information with the CLI command. The node
you supplied to the CLI will then be listed in this page.&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/nodes.png&#34; &gt;


  &lt;img src=&#34;../img/nodes.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h3 id=&#34;workspaces&#34;&gt;Workspaces&lt;/h3&gt;
&lt;p&gt;A workspace contains multiple Ohara services including: Zookeepers,
Brokers and Workers. You can create a workspace and add new node, topic
and stream application in these pages.&lt;/p&gt;















&lt;figure id=&#34;figure-ohara-manager-workspaces-page&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/workspaces.png&#34; data-caption=&#34;Ohara Manager Workspaces page&#34;&gt;


  &lt;img src=&#34;../img/workspaces.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Ohara Manager Workspaces page
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Overview&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;Overview page is like a dashboard of the workspace. You can view the
services, connectors, topics and stream jars that are using in this
workspace&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/workspaces_overview.png&#34; &gt;


  &lt;img src=&#34;../img/workspaces_overview.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Nodes&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;When creating a workspace, you can choose which node to deploy your
services. But you tweak the node settings here.&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/workspaces_nodes.png&#34; &gt;


  &lt;img src=&#34;../img/workspaces_nodes.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Topics&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;You can add new topics to your workspace as well as deleting them
here.&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/workspaces_topics.png&#34; &gt;


  &lt;img src=&#34;../img/workspaces_topics.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Stream jars&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;Same like the topics page, you can add and delete stream jars in
this page&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/workspaces_stream_jars.png&#34; &gt;


  &lt;img src=&#34;../img/workspaces_stream_jars.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you&amp;rsquo;d like to learn more about the development setup or have issue
starting/working with it. Please see

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/manager_dev_guide/&#34;&gt;Ohara Manager Development Guideline&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;zookeeper&#34;&gt;Zookeeper&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://zookeeper.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Zookeeper&lt;/a&gt; plays an important role in
Ohara that it persists metadata for kafka and monitors the running nodes
of kafka. Setting up a zookeeper cluster is always the first phase
before you start to use Ohara to host your clusters. It may be weird,
however, to you since this cryptic service is almost transparent to you.
Currently, zookeeper cluster exists only for kafka. At any rate, you are
still doable to access zookeeper via any zk client if you have to.&lt;/p&gt;
&lt;p&gt;As a result of algorithm used by zookeeper, we recommend your zookeeper
cluster should have 2n + 1 nodes which can address the best reliability
and availability
(
&lt;a href=&#34;https://stackoverflow.com/questions/4228227/what-does-2n-1-quorum-mean&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;related discussion&lt;/a&gt;).
In most cases, running a zookeeper cluster with 3 servers is enough to
your production because we don&amp;rsquo;t put our data flow on zookeeper cluster.
However, you should consider higher number of nodes if your production
does care for the recovery time of node crash. More nodes in zookeeper
cluster brings more time to you for fixing your broken zookeeper
cluster.&lt;/p&gt;
&lt;p&gt;Ohara is responsible for creating your zookeeper cluster, and hence
Ohara also auto-generate most configs used by a zookeeper cluster. A
basic auto-generated configs file to zookeeper cluster is shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tickTime=2000
initLimit=10
syncLimit=5
maxClientCnxns=60
clientPort=2181
dataDir=/tmp/zookeeper/data
server.0=node00:2888:3888
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Most options are auto-generated by Ohara Configurator, and

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/zookeepers/#create-properties&#34;&gt;Zookeeper APIs&lt;/a&gt;
displays the configurable settings to user.
Feel free to file an issue to Ohara community if you have better configs for zookeeper.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;broker&#34;&gt;Broker&lt;/h2&gt;
&lt;p&gt;After setting up a 
&lt;a href=&#34;#zookeeepr&#34;&gt;Zookeeper cluster&lt;/a&gt;,
you have to build a broker cluster before going on your streaming trip.

&lt;a href=&#34;https://kafka.apache.org/intro&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Broker&lt;/a&gt; is the streaming center of
Ohara that all applications on Ohara goes through brokers to switch
data. There are many stories about Ohara leverages the broker to
complete countless significant works. But the most important usage of
Brokers for Ohara is the 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/topics/&#34;&gt;Topic&lt;/a&gt;.
Each endpoint in

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/pipelines/&#34;&gt;Pipeline&lt;/a&gt; must connect
to/from a topic, and each topic in Ohara is mapped to a topic in broker.
It means all data sent/received to/from topic is implemented by a true
connection to a broker.&lt;/p&gt;
&lt;p&gt;As a result of addressing scalability, a topic is split to many
&lt;strong&gt;partitions&lt;/strong&gt; distributed on different brokers. It implies the number
of brokers directly impact the performance of Ohara

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/pipelines/&#34;&gt;Pipeline&lt;/a&gt;. If you are
streaming a bunch of data and there is only a broker in your broker
cluster, you will get a slow streaming since all data in the streaming
are processed by the single broker. Hence, please be careful on
deploying your broker cluster. But you don&amp;rsquo;t worry about the incorrect
settings to cluster. Ohara provides many flexible

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/brokers/&#34;&gt;Broker APIs&lt;/a&gt; to
increase/decrease nodes of a running broker cluster. You are able to
scale your cluster up/down arbitrarily via Ohara APIs.&lt;/p&gt;
&lt;p&gt;In order to simplify your life, Ohara auto-generate most configs for
your broker cluster.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
num.partitions=1
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
log.retention.hours=168
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000
zookeeper.connection.timeout.ms=6000
group.initial.rebalance.delay.ms=0
broker.id=0
listeners=PLAINTEXT://:9092
log.dirs=/tmp/broker/data
zookeeper.connect=node00:2181
advertised.listeners=PLAINTEXT://node00:9092
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Most options are auto-generated by Ohara Configurator, and

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/brokers/&#34;&gt;Broker APIs&lt;/a&gt;
displays the configurable settings to user. Ohara community always
welcomes user to raise issue about &lt;strong&gt;we should give a better default
configs&lt;/strong&gt; or &lt;strong&gt;we should enable user to change xxx config&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;worker&#34;&gt;Worker&lt;/h2&gt;
&lt;p&gt;In contrast with 
&lt;a href=&#34;#broker&#34;&gt;Broker&lt;/a&gt;,
Worker takes charge of hosting and distributing your
applications. Via Ohara Configurator you can deploy applications on a
worker cluster. Worker executes your application on a single thread and
handle following issues for you.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;tolerance - worker cluster auto-migrate your application from a dead
node to another live one.&lt;/li&gt;
&lt;li&gt;distribution - you can decide the number of threads invoked by
worker cluster to run your applications. Of course, the threads are
distributed across whole cluster.&lt;/li&gt;
&lt;li&gt;Data - Worker is in charge of fetching/pushing data from/to topics
specified by your application. All you have to do is to process the
data.&lt;/li&gt;
&lt;li&gt;consistency - The offset of data in/from topics are auto-record by
worker. Also, for advanced user, there are a lot of offset-related
APIs, which is exposed to your application, that you can control the
offsets of data. 1.balance - worker cluster keeps tracing the
loading for each worker node and auto-balance the loading for heavy
one. Via 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/workers/&#34;&gt;Ohara APIs&lt;/a&gt;,
you can increase the node of a running worker cluster easily if you
do want to scala the throughput up.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Setting up a worker cluster also requires many configurations. Ohara
Configurator auto-fill the following settings for you when you request
to create a worker cluster.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;key.converter=org.apache.kafka.connect.json.JsonConverter
value.converter=org.apache.kafka.connect.json.JsonConverter
key.converter.schemas.enable=true
value.converter.schemas.enable=true
offset.flush.interval.ms=10000
internal.key.converter=org.apache.kafka.connect.json.JsonConverter
internal.value.converter=org.apache.kafka.connect.json.JsonConverter
internal.key.converter.schemas.enable=false
internal.value.converter.schemas.enable=false
group.id=339f4352b3
offset.storage.topic=offset-8e5c68825d
offset.storage.replication.factor=1
offset.storage.partitions=1
config.storage.topic=setting-2b86167398
config.storage.replication.factor=1
status.storage.topic=status-4841be564b
status.storage.replication.factor=1
status.storage.partitions=1
plugin.path=/tmp/plugins
bootstrap.servers=node00:9092
rest.port=8083
rest.advertised.host.name=node00
rest.advertised.port=8083
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Most options are auto-generated by Ohara Configurator, and

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/workers/#rest-workers-create&#34;&gt;Worker APIs&lt;/a&gt;
displays the configurable settings to user. Welcome you to file an issue
to request more control right of worker cluster.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;docker&#34;&gt;Docker&lt;/h2&gt;
&lt;p&gt;All services host by Ohara are based on docker containers, such as

&lt;a href=&#34;#configurator&#34;&gt;Configurator&lt;/a&gt;, 
&lt;a href=&#34;#manager&#34;&gt;Manager&lt;/a&gt;,

&lt;a href=&#34;#zookeeper&#34;&gt;Zookeeper&lt;/a&gt;,

&lt;a href=&#34;#broker&#34;&gt;Broker&lt;/a&gt; and 
&lt;a href=&#34;#worker&#34;&gt;Worker&lt;/a&gt;.
You should install suggested version of Docker before enjoying Ohara service
(see 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/build/build-ohara/&#34;&gt;how to build&lt;/a&gt; for prerequisite).&lt;/p&gt;
&lt;p&gt;The post-installation for all docker nodes are listed below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/build/build-ohara/#prerequisites&#34;&gt;Install the supported version of docker&lt;/a&gt; -
Ohara community does not support the legacy docker.&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#download-images&#34;&gt;download all ohara images&lt;/a&gt; -
Ohara Configurator expect all images are available from local disk rather than network.&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://docs.docker.com/install/linux/linux-postinstall/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;create a user account which can access docker without sudo&lt;/a&gt; -
Ohara Configurator may use ssh to control docker of remote node.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    all containers created by Ohara, which is on docker mode, have a
specific label - createdByOhara - this label enables Ohara to ignore the
unrelated containers. For examples, You request Ohara Configurator (of
course, it is on docker mode) to create a zookeeper service. The
container of zookeeper service will have label - createdByOhara=docker.
  &lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 id=&#34;k8s&#34;&gt;Kubernetes&lt;/h2&gt;
&lt;p&gt;Kubernetes is a managed container platform. It can across different
container communication of a node. solve more deploy multiple a node
container problems, below is Kubernetes advantage:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Automatically deploy Docker container&lt;/li&gt;
&lt;li&gt;Docker container resource manage and scaling&lt;/li&gt;
&lt;li&gt;Orcherstrate docker container on multiple hosts&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;About details please refer:
&lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/&#34;&gt;https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ohara builds multiple docker images. This includes zookeeper, broker,
and connect-worker. These services can be run and controlled through
Kubernetes and making container management a lot easier. Before running
any Ohara containers, you need to install Kubernetes first. We&amp;rsquo;ll walk
you through this process with a few k8s commands:&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    all containers created by Ohara, which is on k8s mode, have a specific
label - createdByOhara - this label enables Ohara to ignore the
unrelated containers. For examples, You request Ohara Configurator (of
course, it is on k8s mode) to create a zookeeper service. The container
of zookeeper service will have label - createdByOhara=k8s.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;install-distribution-mode-for-kubernetes&#34;&gt;Install distribution mode for Kubernetes&lt;/h3&gt;
&lt;h4 id=&#34;hardware-requirement&#34;&gt;Hardware requirement&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;2 CPUs or more&lt;/li&gt;
&lt;li&gt;2 GB or more of RAM per machine&lt;/li&gt;
&lt;li&gt;Full network connectivity between all machines in the cluster&lt;/li&gt;
&lt;li&gt;Swap disabled&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    &lt;ul&gt;
&lt;li&gt;Ohara support install Kubernetes shell script OS only CentOS7&lt;/li&gt;
&lt;li&gt;More details is
&lt;a href=&#34;https://kubernetes.io/docs/setup/independent/install-kubeadm/#before-you-begin&#34;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;step-1-install-kubernetes-master-node&#34;&gt;Step 1. Install Kubernetes master node&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Switch to root user
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ su root
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    &lt;strong&gt;Why change to root user?&lt;/strong&gt;
Use the root user to install Kubernetes is simple and convenient. Avoid
changing not an admin user. Of course, you can use the admin user and
add the &amp;ldquo;sudo&amp;rdquo; keyword to execute install the Kubernetes shell script.
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Change directory to &lt;code&gt;kubernetes/distribute&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# cd $OHARA_HOME/kubernetes/distribute
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run &lt;code&gt;bash k8s-master-install.sh ${Your_K8S_Master_Host_IP}&lt;/code&gt; to
install Kubernetes master&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# bash k8s-master-install.sh ${Your_K8S_Master_Host_IP}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Token and hash will be used in worker installation later on&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# cat /tmp/k8s-install-info.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The token and hash should look like the following:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# kubeadm join 10.100.0.178:6443 --token 14aoza.xpgpa26br32sxwl8 --discovery-token-ca-cert-hash sha256:f5614e6b6376f7559910e66bc014df63398feb7411fe6d0e7057531d7143d47b
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;step-2-install-kubernetes-worker-node&#34;&gt;Step 2. Install Kubernetes worker node&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Switch to root&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ su root
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Goto &lt;code&gt;kubernetes/distribute&lt;/code&gt; directory&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# cd $OHARA_HOME/kubernetes/distribute 
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run following command in your terminal:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# bash k8s-worker-install.sh ${Your_K8S_Master_Host_IP} ${TOKEN} ${HASH_CODE}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;&lt;strong&gt;TOKEN&lt;/strong&gt; and &lt;strong&gt;HASH_CODE&lt;/strong&gt; can be found in the
/tmp/k8s-install-info.txt file of Kubernetes master, the one we
mention in the previous steps&lt;/p&gt;
&lt;p&gt;For example:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# bash k8s-worker-install.sh 10.100.0.178 14aoza.xpgpa26br32sxwl8 sha256:f5614e6b6376f7559910e66bc014df63398feb7411fe6d0e7057531d7143d47b
&lt;/code&gt;&lt;/pre&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;step-3-ensure-the-k8s-api-server-is-running-properly&#34;&gt;Step 3. Ensure the K8S API server is running properly&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Log into Kubernetes master and use the following command to see if these
Kubernetes nodes are running properly:
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# kubectl get nodes
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;You can check Kubernetes node status like the following:
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# curl -X GET http://${Your_K8S_Master_Host_IP}:8080/api/v1/nodes
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;troubleshooting&#34;&gt;Troubleshooting&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;How to autostart the Kubernetes API proxy server after reboot server?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Copy &amp;ldquo;ohara/kubernetes/k8sproxyserver.service&amp;rdquo; file to your
Kubernetes master server &amp;ldquo;/etc/systemd/system&amp;rdquo; path&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Below is setting autostart the command to run the Kubernetes API
proxy server &lt;code&gt;(default port is 8080)&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# systemctl enable k8sproxyserver.service
# systemctl start k8sproxyserver.service
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;how-to-use-kubernetes-in-ohara&#34;&gt;How to use Kubernetes in Ohara?&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;You must create the service to Kubernetes for DNS use in kubernetes
master host, Below is the command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# cd $OHARA_HOME/kubernetes
# kubectl create -f dns-service.yaml
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Below is an example command to run Ohara configurator service for K8S mode:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# docker run --rm \
             -p 5000:5000 \
             --add-host ${K8S_WORKER01_HOSTNAME}:${K8S_WORKER01_IP} \
             --add-host ${K8S_WORKER02_HOSTNAME}:${K8S_WORKER02_IP} \
             oharastream/configurator:$|version| \
             --port 5000 \
             --hostname ${Start Configurator Host Name} \
             --k8s http://${Your_K8S_Master_Host_IP}:8080/api/v1
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--add-host&lt;/code&gt;: Add all k8s worker hostname and ip information to
configurator container /etc/hosts file. If you have DNS server, you
can just ignore parameter of &lt;code&gt;--add-host&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--k8s-namespace&lt;/code&gt;: If you don&amp;rsquo;t use the Kubernetes default namespace,
you can assign the &amp;ndash;k8s-namespace argument to set other the Kubernetes namespace.
Kubernetes namespace default value is &amp;ldquo;default&amp;rdquo; string&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--k8s-metrics-server&lt;/code&gt;: If you have installed the Kubernetes metrics
server, you can set metrics server URL to monitor your Kubernetes node
resource. Example: &lt;code&gt;--k8s-metrics-server http://ohara-kubernetes:8080/apis&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--k8s&lt;/code&gt;: Assignment your K8S API server HTTP URL&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use Ohara configurator to create a zookeeper and broker in
Kubernetes pod for the test:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# Add Ohara Node example
$ curl -H &amp;quot;Content-Type: application/json&amp;quot; \
       -X POST \
       -d &#39;{&amp;quot;hostname&amp;quot;: &amp;quot;${K8S_WORKER01_HOSTNAME}&amp;quot;, \
            &amp;quot;port&amp;quot;: 22, \
            &amp;quot;user&amp;quot;: &amp;quot;${USERNAME}&amp;quot;, \
            &amp;quot;password&amp;quot;: &amp;quot;${PASSWORD}&amp;quot;}&#39; \
       http://${CONFIGURATOR_HOSTNAME_OR_IP}:5000/v0/nodes
  
$ curl -H &amp;quot;Content-Type: application/json&amp;quot; \
       -X POST \
       -d &#39;{&amp;quot;hostname&amp;quot;: &amp;quot;${K8S_WORKER02_HOSTNAME}&amp;quot;, \
            &amp;quot;port&amp;quot;: 22, \
            &amp;quot;user&amp;quot;: &amp;quot;${USERNAME}&amp;quot;, \
            &amp;quot;password&amp;quot;: &amp;quot;${PASSWORD}&amp;quot;}&#39; \
       http://${CONFIGURATOR_HOSTNAME_OR_IP}:5000/v0/nodes
  
# You must pre pull docker image in the ${K8S_WORKER01_HOSTNAME} and ${K8S_WORKER02_HOSTNAME} host, Below is command:
docker pull oharastream/zookeeper:0.11.0-SNAPSHOT
docker pull oharastream/broker:0.11.0-SNAPSHOT
  
# Create Zookeeper cluster service
$ curl -H &amp;quot;Content-Type: application/json&amp;quot; \
       -X POST \
       -d &#39;{&amp;quot;name&amp;quot;: &amp;quot;zk&amp;quot;, \
            &amp;quot;clientPort&amp;quot;: 2181, \
            &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/zookeeper:$|version|&amp;quot;, \
            &amp;quot;peerPort&amp;quot;: 2000, \
            &amp;quot;electionPort&amp;quot;: 2001, \
            &amp;quot;nodeNames&amp;quot;: [&amp;quot;${K8S_WORKER01_HOSTNAME}&amp;quot;]}&#39; \
       http://${CONFIGURATOR_HOSTNAME_OR_IP}:5000/v0/zookeepers
  
# Start Zookeeper cluster service
$ curl -H &amp;quot;Content-Type: application/json&amp;quot; -X PUT http://${CONFIGURATOR_HOSTNAME_OR_IP}:5000/v0/zookeepers/zk/start
  
# Create Broker service example
$ curl -H &amp;quot;Content-Type: application/json&amp;quot; \
       -X POST \
       -d &#39;{&amp;quot;name&amp;quot;: &amp;quot;bk&amp;quot;, \
            &amp;quot;clientPort&amp;quot;: 9092, \
            &amp;quot;zookeeperClusterName&amp;quot;: &amp;quot;zk&amp;quot;, \
            &amp;quot;nodeNames&amp;quot;: [&amp;quot;${K8S_WORKER02_HOSTNAME}&amp;quot;]}&#39; \
       http://${CONFIGURATOR_HOSTNAME_OR_IP}:5000/v0/brokers
  
# Start Broker cluster service
$ curl -H &amp;quot;Content-Type: application/json&amp;quot; -X PUT http://${CONFIGURATOR_HOSTNAME_OR_IP}:5000/v0/brokers/bk/start
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You can use the &lt;strong&gt;kubectl&lt;/strong&gt; command to get zookeeper and broker pod
status with the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# kubectl get pods
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;how-to-install-k8s-metrics-server&#34;&gt;How to install K8S metrics server?&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;You must install the git command to pull the Kubernetes metrics
server source code from the repository to deploy metrics server,
below is sample command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# yum install -y git
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;After complete install git, you can pull the K8S metrics server
source code, below is sample command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# git clone https://github.com/kubernetes-sigs/metrics-server.git
# git checkout tags/v0.3.7 -b v0.3.7
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There should encounter an issue that kubelet and apiserver unable to
communicate with metric-server with default setting. Please use
following YAML setting to override the content of
&lt;strong&gt;deploy/1.8+/metrics-server-deployment.yaml&lt;/strong&gt; file.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: metrics-server
  namespace: kube-system
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: metrics-server
  namespace: kube-system
  labels:
    k8s-app: metrics-server
spec:
  selector:
    matchLabels:
      k8s-app: metrics-server
  template:
    metadata:
      name: metrics-server
      labels:
        k8s-app: metrics-server
    spec:
      serviceAccountName: metrics-server
      volumes:
      # mount in tmp so we can safely use from-scratch images and/or read-only containers
      - name: tmp-dir
        emptyDir: {}
      containers:
      - name: metrics-server
        command:
        - /metrics-server
        - --kubelet-preferred-address-types=InternalIP
        - --kubelet-insecure-tls
        image: k8s.gcr.io/metrics-server-amd64:v0.3.6
        args:
          - --cert-dir=/tmp
          - --secure-port=4443
        ports:
        - name: main-port
          containerPort: 4443
          protocol: TCP
        imagePullPolicy: Always
        volumeMounts:
        - name: tmp-dir
          mountPath: /tmp
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    For more details please refer to &lt;a href=&#34;https://github.com/kubernetes-sigs/metrics-server/issues/131&#34;&gt;here&lt;/a&gt;.
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Deploy the Kubernetes metrics server, below is the command:
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# kubectl apply -f deploy/1.8+
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;Confirm the Kubernetes metrics service is installed complete, you
can input the URL to the browser, below is the example:
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;http://${Your_Kubernetes_Master_HostName_OR_IP}:8080/apis/metrics.k8s.io/v1beta1/nodes
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You maybe wait seconds time to receive the Kubernetes node metrics data.&lt;/p&gt;
&lt;h4 id=&#34;how-to-revert-k8s-environment-setting&#34;&gt;How to revert K8S environment setting?&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;You must stop the K8S API server with this command: &lt;code&gt;kubeadm reset&lt;/code&gt; command.&lt;/li&gt;
&lt;li&gt;More details is 
&lt;a href=&#34;https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-reset&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;how-to-get-the-log-info-in-container-for-debug&#34;&gt;How to get the log info in container for debug?&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;First, log into Kubernetes&amp;rsquo; master server&lt;/li&gt;
&lt;li&gt;List all Kubernetes pod name to query
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# kubectl get pods
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;Get log info in container
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# kubectl logs ${Your_K8S_Pod_Name}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;other&#34;&gt;Other&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Ohara K8SClient ImagePullPolicy default is IfNotPresent.&lt;/li&gt;
&lt;li&gt;Please remember to start K8S API server after you reboot the K8S master server:
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# nohup kubectl proxy --accept-hosts=^*$ --address=$Your_master_host_IP --port=8080 &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>User Guide</title>
      <link>https://oharastream.github.io/en/docs/master/user_guide/</link>
      <pubDate>Wed, 17 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/master/user_guide/</guid>
      <description>&lt;p&gt;This documentation is for Ohara users who try to exercise or test Ohara
without writing any code. Ohara team design and implement Ohara to
provide a unparalleled platform which enable everyone to build streaming
easily and quickly. For normal users, you can manipulate Ohara through
UI interface even if you have no idea about the magic infra of Ohara.
For advanced users trying to build custom streaming, they are encouraged
to design and write application based on Ohara&amp;rsquo;s various and powerful
APIs (see 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/custom_connector/&#34;&gt;Custom Connector&lt;/a&gt;
and 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/custom_stream/&#34;&gt;Custom Stream&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Ohara consists of many services, such as&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;a href=&#34;#configurator&#34;&gt;Ohara Configurator&lt;/a&gt; &amp;mdash; the controller of Ohara.
It cooperates other services and provides the 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/&#34;&gt;Restful APIs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#manager&#34;&gt;Ohara Manager&lt;/a&gt; &amp;mdash; the UI service of Ohara. It offers a
streaming flow called &lt;strong&gt;pipeline&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#zookeeper&#34;&gt;Zookeeper&lt;/a&gt; &amp;mdash; works for Broker. It has charge of managing
the configuration of topics and health of node&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#broker&#34;&gt;Broker&lt;/a&gt; &amp;mdash; It provides the access of topics, topics&amp;rsquo; data
durability and balance.&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#worker&#34;&gt;Worker&lt;/a&gt; &amp;mdash;
It hosts and execute 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/custom_connector/&#34;&gt;Custom Connector&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#volume&#34;&gt;Volumes&lt;/a&gt; &amp;mdash; Support the persistent data.&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#docker&#34;&gt;Docker&lt;/a&gt; &amp;mdash; It packages the configs, dependencies and binary
required by services and execute them in a isolated environments&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#k8s&#34;&gt;Kubernetes&lt;/a&gt; &amp;mdash; a management tool of docker instances&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Ohara has a complicated software stack, but most services are almost
transparent to you. For example, before creating a topic on Ohara, you
ought to set up a zookeeper cluster and a broker cluster. There are ,
unfortunately, a bunch of configs which you have to design and write for
both cluster. Ohara auto-generates most configs for you as best as it
can, and Ohara offers the the readable

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/&#34;&gt;Restful APIs&lt;/a&gt; and friendly UI to
you. All complicated configs are replaced by some simple steps showed on
UI. The 
&lt;a href=&#34;#quickstart&#34;&gt;Quick Start&lt;/a&gt; section teach you to exercise Ohara easily and quickly.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;quickstart&#34;&gt;Quick Start&lt;/h2&gt;
&lt;p&gt;The core component of Ohara is 
&lt;a href=&#34;#configurator&#34;&gt;Configurator&lt;/a&gt;. After installing

&lt;a href=&#34;#installation&#34;&gt;related tools&lt;/a&gt;, you can set up a Configurator via following docker command.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ docker run --rm -p 12345:12345 oharastream/configurator:0.11.0-SNAPSHOT --port 12345 --hostname ${host}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    click &lt;a href=&#34;#execute-configurator&#34;&gt;here&lt;/a&gt; to see more options for configurator
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;And then you can also create a manager to provide a beautiful UI based on above Ohara Configurator.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ docker run --rm -p 5050:5050 oharastream/manager:0.11.0-SNAPSHOT --port 5050 --configurator http://$ip:12345/v0
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Please replace the &lt;strong&gt;ip&lt;/strong&gt; by your host&amp;rsquo;s address
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Open your browser (we recommend 
&lt;a href=&#34;https://www.google.com/intl/zh-TW/chrome/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google Chrome&lt;/a&gt;)
and link to 
&lt;a href=&#34;http://localhost:5050/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://localhost:5050/&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;
&lt;p&gt;We all love docker, right? All Ohara services are executed by docker
container. However, it is ok to run Ohara services through

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/build/build-ohara/#build-binary&#34;&gt;assembly file&lt;/a&gt; if you
really really really hate docker.&lt;/p&gt;
&lt;h3 id=&#34;network-configurations&#34;&gt;Network Configurations&lt;/h3&gt;
&lt;p&gt;We are trying to do everything for you. However, your network your
problem (reference to Hadoop&amp;rsquo;s

&lt;a href=&#34;https://cwiki.apache.org/confluence/display/HADOOP2/YourNetworkYourProblem&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;motto&lt;/a&gt;.
A bad network configurations can bring any kind of exception in any
time, and it is hard to diagnose your network problems. In order to make
each container be able to find each other, please ensure following
common problems (reference to

&lt;a href=&#34;https://cwiki.apache.org/confluence/display/HADOOP2/YourNetworkYourProblem&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hadoop&lt;/a&gt;
again) don&amp;rsquo;t happen on your nodes.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;DNS and reverse DNS broken/non-existent.&lt;/li&gt;
&lt;li&gt;Host tables in the machines invalid.&lt;/li&gt;
&lt;li&gt;Firewalls in the hosts blocking connections.&lt;/li&gt;
&lt;li&gt;Routers blocking traffic.&lt;/li&gt;
&lt;li&gt;Hosts with multiple network cards listening/talking on the wrong NIC.&lt;/li&gt;
&lt;li&gt;Difference between the hadoop configuration files&amp;rsquo; definition of the
cluster (especially hostnames and ports) from that of the actual
cluster setup.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;After validating your network configurations layer by layer, you could
try filing issue on github if you still can&amp;rsquo;t get Ohara to work.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;We often encounter problems with network problems&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;After install Docker-ce package in CentOS,the network default policy is
block docker&amp;rsquo;s bridge to host network, You &lt;strong&gt;must&lt;/strong&gt; add a rule on the
firewall:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ sudo firewall-cmd --zone=trusted --permanent --add-interface=docker0
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;install-docker-ce-on-centos&#34;&gt;Install Docker-ce on CentOS&lt;/h3&gt;
&lt;p&gt;Docker has provided a great docs about installing docker-ce. Please
click this 
&lt;a href=&#34;https://docs.docker.com/install/linux/docker-ce/centos/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;download-images&#34;&gt;Download Ohara Images&lt;/h3&gt;
&lt;p&gt;Ohara deploys docker images on 
&lt;a href=&#34;https://hub.docker.com/u/oharastream&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;docker hub&lt;/a&gt;.
You can download images via &lt;code&gt;docker pull&lt;/code&gt; command. All images are list below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;oharastream/broker:0.11.0-SNAPSHOT&lt;/li&gt;
&lt;li&gt;oharastream/zookeeper:0.11.0-SNAPSHOT&lt;/li&gt;
&lt;li&gt;oharastream/connect-worker:0.11.0-SNAPSHOT&lt;/li&gt;
&lt;li&gt;oharastream/configurator:0.11.0-SNAPSHOT&lt;/li&gt;
&lt;li&gt;oharastream/manager:0.11.0-SNAPSHOT&lt;/li&gt;
&lt;li&gt;oharastream/stream:0.11.0-SNAPSHOT&lt;/li&gt;
&lt;li&gt;oharastream/shabondi:0.11.0-SNAPSHOT&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;execute-configurator&#34;&gt;Execute Configurator&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ docker run --rm -p ${port}:${port} --add-host ${nodeHostName}:${nodeHostIP} oharastream/configurator:0.11.0-SNAPSHOT --port ${port} --hostname ${host}
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--folder&lt;/code&gt;: the folder used to store data (default is random). Mount
the volume if you want to keep your data after restarting Configurator&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--port&lt;/code&gt;: bound by Configurator (default is random)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--add-host&lt;/code&gt;: add a host mapping to /etc/hosts in Ohara Configurator
(nodeHostName:nodeHostIP). If you have DNS server, you can just
ignore parameter of add-host.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--hostname&lt;/code&gt;: hostname to run Ohara Configurator (defaults to 0.0.0.0)&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;You can enable the jmx reporter via inputting two env variables -
&amp;ldquo;JMX_HOSTNAME&amp;rdquo; and &amp;ldquo;JMX_PORT&amp;rdquo;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;JMX_HOSTNAME&amp;rdquo; should be same as the host running Ohara
Configurator container so as to access the jmx service in docker
from outside.&lt;/li&gt;
&lt;li&gt;&amp;ldquo;JMX_PORT&amp;rdquo; should be opened by docker (for example, add &amp;ldquo;-p $JMX_PORT:$JMX_PORT&amp;rdquo;)&lt;/li&gt;
&lt;/ul&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;All services host by Ohara Configurator are based on docker technique.
By default Ohara Configurator use ssh to control the docker containers
from remote nodes (see 
&lt;a href=&#34;#docker&#34;&gt;Docker&lt;/a&gt; section).
In this mode, please make sure the ssh account
added by 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/nodes/&#34;&gt;Node APIs&lt;/a&gt; should
have sudo permission to run docker command (see

&lt;a href=&#34;https://docs.docker.com/install/linux/linux-postinstall/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt; for
related steps).&lt;/p&gt;
&lt;h3 id=&#34;configurator-data&#34;&gt;Keep the data of Configurator&lt;/h3&gt;
&lt;p&gt;Ohara Configurator demand a folder to store &lt;code&gt;data&lt;/code&gt; and

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/files/&#34;&gt;jars&lt;/a&gt;. As Ohara Configurator
is running in docker container, you have to mount the volume, which is
located on container host, on the home folder of Ohara Configurator if
you want to keep all data of Ohara Configurator. The following example
is to mount a local folder (/tmp/configurator) on
&lt;strong&gt;/home/ohara/configurator&lt;/strong&gt; of Ohara Configurator&amp;rsquo;s container.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ mkdir /tmp/configurator
$ docker run -v /tmp/configurator:/home/ohara/configurator \
         -p 12345:12345 \
         oharastream/configurator:0.11.0-SNAPSHOT \
         --port 12345 \
         --hostname ${host} \
         --folder /home/ohara/configurator
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The user account in docker container is &lt;strong&gt;ohara&lt;/strong&gt;, and hence it would be
better to set the folder under the &lt;strong&gt;/home/ohara&lt;/strong&gt;. Otherwise, you will
encounter the permission error. Noted that you have tell Ohara
Configurator to save data in the folder referencing to the outside
folder. Otherwise, Ohara Configurator flush all data to a random folder.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How to solve the start configurator container permission denied issue?&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;You must confirm your host username is the ohara and UID is 1000.
Please refer to issue 
&lt;a href=&#34;https://github.com/oharastream/ohara/issues/2573

&#34;&gt;#2573&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Please confirm the &lt;strong&gt;/tmp/configurator&lt;/strong&gt; host path owner is ohara user
and have to write permission.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;execute-manager&#34;&gt;Execute Manager&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ docker run --rm -p 5050:5050 oharastream/manager:0.11.0-SNAPSHOT --port 5050 --configurator http://localhost:12345/v0
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--port&lt;/code&gt;: bound by manager (default is 5050)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--configurator&lt;/code&gt;: basic form of restful API of Ohara Configurator&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;execute-postgresql-instance&#34;&gt;Execute PostgreSQL Instance&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ docker run -d --rm --name postgresql -p 5432:5432 --env POSTGRES_DB=${DB_NAME} --env POSTGRES_USER=${USER_NAME} --env POSTGRES_PASSWORD=${PASSWORD} -it islandsystems/postgresql:9.2.24
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;POSTGRES_DB: PostgreSQL DataBase name&lt;/li&gt;
&lt;li&gt;POSTGRES_USER: PostgreSQL login user name.&lt;/li&gt;
&lt;li&gt;POSTGRES_PASSWORD: PostgreSQL login password.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    POSTGRES_USER=&amp;quot;user&amp;rdquo; is illegal to postgresql
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;execute-ftp-instance&#34;&gt;Execute FTP Instance&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ docker run --rm -p 10000-10011:10000-10011 oharastream/backend:0.11.0-SNAPSHOT oharastream.ohara.testing.service.FtpServer --controlPort 10000 --dataPorts 10001-10011 --user ${UserName} --password ${Password} --hostname ${hostIP or hostName}
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;controlPort: bound by FTP Server&lt;/li&gt;
&lt;li&gt;dataPorts: bound by data transportation in FTP Server&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;configurator&#34;&gt;Ohara Configurator&lt;/h2&gt;
&lt;p&gt;Ohara consists of many services, and Ohara Configurator plays the most
important rule which coordinates all services and offers a bunch of
restful APIs to user to get all under control. The brief architecture of
Ohara Configurator is shown below.&lt;/p&gt;















&lt;figure id=&#34;figure-configurator-architecture&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/configurator_arch.jpg&#34; data-caption=&#34;Configurator architecture&#34;&gt;


  &lt;img src=&#34;../img/configurator_arch.jpg&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Configurator architecture
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;The introduction of each components are shown below. Feel free to trace
the component in which you have interest.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#configurator-route&#34;&gt;Route of Ohara Configurator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#configurator-store&#34;&gt;Store of Ohara Configurator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#configurator-cache&#34;&gt;Cache of Ohara Configurator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#configurator-collie&#34;&gt;Collie of Ohara Configurator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#configurator-client&#34;&gt;Client of Ohara Configurator&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;configurator-route&#34;&gt;Route of Configurator&lt;/h3&gt;
&lt;p&gt;Ohara Configurator leverages the akka-http to implements the rest server
and handle the conversion of json objects. You can click our

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/&#34;&gt;RESTful API docs&lt;/a&gt; to see all
public APIs and introduction.&lt;/p&gt;
&lt;p&gt;The APIs supported by Ohara Configurator is only the Restful APIs. Of
course, you can raise a question to us - why we choose the Restful APIs
rather than pure Java APIs? The answer is - We all hate the other
programming language except for the one we are using. However, we always
need to work with other people who are typing terrible and weird code,
and all they want to do is to call your APIs. In order to save our time
from co-working with them, providing the Restful APIs is always to be
our solution. For another reason, Ohara Configurator is not in charge of
I/O flow. Coordinating all services requires small bandwidth only. We
don&amp;rsquo;t need to care for the performance issue about Restful APIs.&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    You can use our internal scala APIs to control Configurator. The
library is called ohara-client and it covers all Restful APIs of
Configurator. However, we don&amp;rsquo;t guarantee any compatibility for
ohara-client.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;configurator-store&#34;&gt;Store of Configurator&lt;/h3&gt;
&lt;p&gt;All settings you request to Ohara Configurator are saved in Store, such
as connector settings, cluster information and pipeline description. The
default implementation of Store is 
&lt;a href=&#34;https://rocksdb.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RocksDB&lt;/a&gt; which
offers fast in-memory access and persists all data on disk. Please read
this 
&lt;a href=&#34;#configurator-data&#34;&gt;section&lt;/a&gt; about mounting host&amp;rsquo;s
folder on docker container.&lt;/p&gt;
&lt;h3 id=&#34;configurator-cache&#34;&gt;Cache of Configurator&lt;/h3&gt;
&lt;p&gt;The cost of coordinating countless services is the big &lt;strong&gt;latency&lt;/strong&gt;. For
example, 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/topics/&#34;&gt;Topic APIs&lt;/a&gt; allows
you to fetch metrics from different

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/brokers/&#34;&gt;broker clusters&lt;/a&gt;. Ohara
Configurator has to file a bunch of connections to different clusters to
retrieve all requisite information, and, of course, the &lt;strong&gt;connections&lt;/strong&gt;
bring the large latency to the GET request. Hence, Ohara Configurator
sets up a inner cache which stores the data from remote clusters. It
reduces the latency from seconds to milliseconds and allay your anger.
In order to make all data up-to-date as much as possible, the cache
auto-refreshes timeout data in the background. It brings some extra cost
of building connections to remote clusters.&lt;/p&gt;
&lt;h3 id=&#34;configurator-collie&#34;&gt;Collie of Configurator&lt;/h3&gt;
&lt;p&gt;Apart from the data flow, Ohara Configurator is also doable to manage
clusters for you. For instance, you can&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;add 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/nodes/&#34;&gt;node&lt;/a&gt; to Ohara Configurator&lt;/li&gt;
&lt;li&gt;deploy a 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/zookeepers/&#34;&gt;zookeeper cluster&lt;/a&gt; on the node&lt;/li&gt;
&lt;li&gt;deploy a 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/brokers/&#34;&gt;broker cluster&lt;/a&gt; on the node as well&lt;/li&gt;
&lt;li&gt;deploy a 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/workers/&#34;&gt;worker cluster&lt;/a&gt; on the node&lt;/li&gt;
&lt;li&gt;finally, you can run a connector to stream your data and all
services you have created are hosted by Ohara Configurator&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In order to host your services safely and quickly, Ohara Configurator
leverages the Docker technique that all services are packaged to a
container and executed on the node(s) specified by you. As a good
software stack, Ohara Configurator creates a container manager, which is
called &lt;strong&gt;collie&lt;/strong&gt;, to wrap Restful APIs of 
&lt;a href=&#34;#k8s&#34;&gt;k8s&lt;/a&gt;
and ssh command to Scala APIs.&lt;/p&gt;
&lt;h3 id=&#34;configurator-client&#34;&gt;Client of Configurator&lt;/h3&gt;
&lt;p&gt;As a good programmer, we all love to reuse the code. However, it is hard
to trust all third-party libraries guarantee the suitable compatibility
policy. The Client code in Ohara is a collection of wrap for all client
codes to services, such as broker and worker, so as not to be badly hurt
by the update of services.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;manager&#34;&gt;Ohara Manager&lt;/h2&gt;
&lt;p&gt;Ohara Manager is the user interface (UI) of Ohara. It&amp;rsquo;s built with the
standard web technologies and so can be run in almost all the modern
browsers (We recommend you to use Google chrome though). Ohara Manager
talks to Ohara Configurator via its RESTful APIs under the hook which
then connects with the rest of Ohara services.&lt;/p&gt;
&lt;p&gt;Ohara Manager was built and designed with the user&amp;rsquo;s needs in mind. We
aimed to reduce the pain of complex operations that often required in a
big data system. With Ohara Manager, you can create your own services,
pipelines and working with data streaming without touching a single line
of code.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Following is a quick walk through of Ohara Manager&amp;rsquo;s user interface:&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;pipelines&#34;&gt;Pipelines&lt;/h3&gt;
&lt;p&gt;Pipeline list page is where you can view, create, edit and delete
pipelines.&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/pipelines.png&#34; &gt;


  &lt;img src=&#34;../img/pipelines.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;Inside the new/edit pipeline page, you can create and play around with
your pipelines here. This is also where you can run and stop your
pipelines. The pipeline graph helps you to easily visualize the pipeline
that you&amp;rsquo;re working on. Also, you can edit and tweak a connector&amp;rsquo;s
configuration by clicking on the graph and edit the configuration form
which will be displayed in the sidebar. We know it&amp;rsquo;s sometimes tedious
and time consuming to edit the configuration and it&amp;rsquo;s also frustrating
when you lose all of your configuration without saving them! That&amp;rsquo;s why
we made these configuration forms automatically save changes for you.
Whenever you type in a text field, choose a new topic form a dropdown,
the changes will be saved immediately.&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/pipelines_new.png&#34; &gt;


  &lt;img src=&#34;../img/pipelines_new.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;Please note that a pipeline can only be added to a workspace, so
before creating pipelines, you will need to 
&lt;a href=&#34;#workspaces&#34;&gt;create a workspace first&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;nodes&#34;&gt;Nodes&lt;/h3&gt;
&lt;p&gt;This is where you create and edit Ohara Nodes. These nodes are usually
your VMs. When you&amp;rsquo;re starting a new Ohara Configurator. You can
optionally supply some node information with the CLI command. The node
you supplied to the CLI will then be listed in this page.&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/nodes.png&#34; &gt;


  &lt;img src=&#34;../img/nodes.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h3 id=&#34;workspaces&#34;&gt;Workspaces&lt;/h3&gt;
&lt;p&gt;A workspace contains multiple Ohara services including: Zookeepers,
Brokers and Workers. You can create a workspace and add new node, topic
and stream application in these pages.&lt;/p&gt;















&lt;figure id=&#34;figure-ohara-manager-workspaces-page&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/workspaces.png&#34; data-caption=&#34;Ohara Manager Workspaces page&#34;&gt;


  &lt;img src=&#34;../img/workspaces.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Ohara Manager Workspaces page
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Overview&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;Overview page is like a dashboard of the workspace. You can view the
services, connectors, topics and stream jars that are using in this
workspace&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/workspaces_overview.png&#34; &gt;


  &lt;img src=&#34;../img/workspaces_overview.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Nodes&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;When creating a workspace, you can choose which node to deploy your
services. But you tweak the node settings here.&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/workspaces_nodes.png&#34; &gt;


  &lt;img src=&#34;../img/workspaces_nodes.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Topics&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;You can add new topics to your workspace as well as deleting them
here.&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/workspaces_topics.png&#34; &gt;


  &lt;img src=&#34;../img/workspaces_topics.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Stream jars&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;Same like the topics page, you can add and delete stream jars in
this page&lt;/p&gt;















&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/workspaces_stream_jars.png&#34; &gt;


  &lt;img src=&#34;../img/workspaces_stream_jars.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you&amp;rsquo;d like to learn more about the development setup or have issue
starting/working with it. Please see

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/manager_dev_guide/&#34;&gt;Ohara Manager Development Guideline&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;zookeeper&#34;&gt;Zookeeper&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://zookeeper.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Zookeeper&lt;/a&gt; plays an important role in
Ohara that it persists metadata for kafka and monitors the running nodes
of kafka. Setting up a zookeeper cluster is always the first phase
before you start to use Ohara to host your clusters. It may be weird,
however, to you since this cryptic service is almost transparent to you.
Currently, zookeeper cluster exists only for kafka. At any rate, you are
still doable to access zookeeper via any zk client if you have to.&lt;/p&gt;
&lt;p&gt;As a result of algorithm used by zookeeper, we recommend your zookeeper
cluster should have 2n + 1 nodes which can address the best reliability
and availability
(
&lt;a href=&#34;https://stackoverflow.com/questions/4228227/what-does-2n-1-quorum-mean&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;related discussion&lt;/a&gt;).
In most cases, running a zookeeper cluster with 3 servers is enough to
your production because we don&amp;rsquo;t put our data flow on zookeeper cluster.
However, you should consider higher number of nodes if your production
does care for the recovery time of node crash. More nodes in zookeeper
cluster brings more time to you for fixing your broken zookeeper
cluster.&lt;/p&gt;
&lt;p&gt;Ohara is responsible for creating your zookeeper cluster, and hence
Ohara also auto-generate most configs used by a zookeeper cluster. A
basic auto-generated configs file to zookeeper cluster is shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tickTime=2000
initLimit=10
syncLimit=5
maxClientCnxns=60
clientPort=2181
dataDir=/tmp/zookeeper/data
server.0=node00:2888:3888
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Most options are auto-generated by Ohara Configurator, and

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/zookeepers/#create-properties&#34;&gt;Zookeeper APIs&lt;/a&gt;
displays the configurable settings to user.
Feel free to file an issue to Ohara community if you have better configs for zookeeper.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;broker&#34;&gt;Broker&lt;/h2&gt;
&lt;p&gt;After setting up a 
&lt;a href=&#34;#zookeeepr&#34;&gt;Zookeeper cluster&lt;/a&gt;,
you have to build a broker cluster before going on your streaming trip.

&lt;a href=&#34;https://kafka.apache.org/intro&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Broker&lt;/a&gt; is the streaming center of
Ohara that all applications on Ohara goes through brokers to switch
data. There are many stories about Ohara leverages the broker to
complete countless significant works. But the most important usage of
Brokers for Ohara is the 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/topics/&#34;&gt;Topic&lt;/a&gt;.
Each endpoint in

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/pipelines/&#34;&gt;Pipeline&lt;/a&gt; must connect
to/from a topic, and each topic in Ohara is mapped to a topic in broker.
It means all data sent/received to/from topic is implemented by a true
connection to a broker.&lt;/p&gt;
&lt;p&gt;As a result of addressing scalability, a topic is split to many
&lt;strong&gt;partitions&lt;/strong&gt; distributed on different brokers. It implies the number
of brokers directly impact the performance of Ohara

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/pipelines/&#34;&gt;Pipeline&lt;/a&gt;. If you are
streaming a bunch of data and there is only a broker in your broker
cluster, you will get a slow streaming since all data in the streaming
are processed by the single broker. Hence, please be careful on
deploying your broker cluster. But you don&amp;rsquo;t worry about the incorrect
settings to cluster. Ohara provides many flexible

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/brokers/&#34;&gt;Broker APIs&lt;/a&gt; to
increase/decrease nodes of a running broker cluster. You are able to
scale your cluster up/down arbitrarily via Ohara APIs.&lt;/p&gt;
&lt;p&gt;In order to simplify your life, Ohara auto-generate most configs for
your broker cluster.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
num.partitions=1
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
log.retention.hours=168
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000
zookeeper.connection.timeout.ms=6000
group.initial.rebalance.delay.ms=0
broker.id=0
listeners=PLAINTEXT://:9092
log.dirs=/tmp/broker/data
zookeeper.connect=node00:2181
advertised.listeners=PLAINTEXT://node00:9092
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Most options are auto-generated by Ohara Configurator, and

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/brokers/&#34;&gt;Broker APIs&lt;/a&gt;
displays the configurable settings to user. Ohara community always
welcomes user to raise issue about &lt;strong&gt;we should give a better default
configs&lt;/strong&gt; or &lt;strong&gt;we should enable user to change xxx config&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;worker&#34;&gt;Worker&lt;/h2&gt;
&lt;p&gt;In contrast with 
&lt;a href=&#34;#broker&#34;&gt;Broker&lt;/a&gt;,
Worker takes charge of hosting and distributing your
applications. Via Ohara Configurator you can deploy applications on a
worker cluster. Worker executes your application on a single thread and
handle following issues for you.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;tolerance - worker cluster auto-migrate your application from a dead
node to another live one.&lt;/li&gt;
&lt;li&gt;distribution - you can decide the number of threads invoked by
worker cluster to run your applications. Of course, the threads are
distributed across whole cluster.&lt;/li&gt;
&lt;li&gt;Data - Worker is in charge of fetching/pushing data from/to topics
specified by your application. All you have to do is to process the
data.&lt;/li&gt;
&lt;li&gt;consistency - The offset of data in/from topics are auto-record by
worker. Also, for advanced user, there are a lot of offset-related
APIs, which is exposed to your application, that you can control the
offsets of data. 1.balance - worker cluster keeps tracing the
loading for each worker node and auto-balance the loading for heavy
one. Via 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/workers/&#34;&gt;Ohara APIs&lt;/a&gt;,
you can increase the node of a running worker cluster easily if you
do want to scala the throughput up.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Setting up a worker cluster also requires many configurations. Ohara
Configurator auto-fill the following settings for you when you request
to create a worker cluster.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;key.converter=org.apache.kafka.connect.json.JsonConverter
value.converter=org.apache.kafka.connect.json.JsonConverter
key.converter.schemas.enable=true
value.converter.schemas.enable=true
offset.flush.interval.ms=10000
internal.key.converter=org.apache.kafka.connect.json.JsonConverter
internal.value.converter=org.apache.kafka.connect.json.JsonConverter
internal.key.converter.schemas.enable=false
internal.value.converter.schemas.enable=false
group.id=339f4352b3
offset.storage.topic=offset-8e5c68825d
offset.storage.replication.factor=1
offset.storage.partitions=1
config.storage.topic=setting-2b86167398
config.storage.replication.factor=1
status.storage.topic=status-4841be564b
status.storage.replication.factor=1
status.storage.partitions=1
plugin.path=/tmp/plugins
bootstrap.servers=node00:9092
rest.port=8083
rest.advertised.host.name=node00
rest.advertised.port=8083
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Most options are auto-generated by Ohara Configurator, and

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/workers/#rest-workers-create&#34;&gt;Worker APIs&lt;/a&gt;
displays the configurable settings to user. Welcome you to file an issue
to request more control right of worker cluster.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;docker&#34;&gt;Docker&lt;/h2&gt;
&lt;p&gt;All services host by Ohara are based on docker containers, such as

&lt;a href=&#34;#configurator&#34;&gt;Configurator&lt;/a&gt;, 
&lt;a href=&#34;#manager&#34;&gt;Manager&lt;/a&gt;,

&lt;a href=&#34;#zookeeper&#34;&gt;Zookeeper&lt;/a&gt;,

&lt;a href=&#34;#broker&#34;&gt;Broker&lt;/a&gt; and 
&lt;a href=&#34;#worker&#34;&gt;Worker&lt;/a&gt;.
You should install suggested version of Docker before enjoying Ohara service
(see 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/build/build-ohara/&#34;&gt;how to build&lt;/a&gt; for prerequisite).&lt;/p&gt;
&lt;p&gt;The post-installation for all docker nodes are listed below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/build/build-ohara/#prerequisites&#34;&gt;Install the supported version of docker&lt;/a&gt; -
Ohara community does not support the legacy docker.&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#download-images&#34;&gt;download all ohara images&lt;/a&gt; -
Ohara Configurator expect all images are available from local disk rather than network.&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://docs.docker.com/install/linux/linux-postinstall/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;create a user account which can access docker without sudo&lt;/a&gt; -
Ohara Configurator may use ssh to control docker of remote node.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    all containers created by Ohara, which is on docker mode, have a
specific label - createdByOhara - this label enables Ohara to ignore the
unrelated containers. For examples, You request Ohara Configurator (of
course, it is on docker mode) to create a zookeeper service. The
container of zookeeper service will have label - createdByOhara=docker.
  &lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 id=&#34;k8s&#34;&gt;Kubernetes&lt;/h2&gt;
&lt;p&gt;Kubernetes is a managed container platform. It can across different
container communication of a node. solve more deploy multiple a node
container problems, below is Kubernetes advantage:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Automatically deploy Docker container&lt;/li&gt;
&lt;li&gt;Docker container resource manage and scaling&lt;/li&gt;
&lt;li&gt;Orcherstrate docker container on multiple hosts&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;About details please refer:
&lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/&#34;&gt;https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ohara builds multiple docker images. This includes zookeeper, broker,
and connect-worker. These services can be run and controlled through
Kubernetes and making container management a lot easier. Before running
any Ohara containers, you need to install Kubernetes first. We&amp;rsquo;ll walk
you through this process with a few k8s commands:&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    all containers created by Ohara, which is on k8s mode, have a specific
label - createdByOhara - this label enables Ohara to ignore the
unrelated containers. For examples, You request Ohara Configurator (of
course, it is on k8s mode) to create a zookeeper service. The container
of zookeeper service will have label - createdByOhara=k8s.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;install-distribution-mode-for-kubernetes&#34;&gt;Install distribution mode for Kubernetes&lt;/h3&gt;
&lt;h4 id=&#34;hardware-requirement&#34;&gt;Hardware requirement&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;2 CPUs or more&lt;/li&gt;
&lt;li&gt;2 GB or more of RAM per machine&lt;/li&gt;
&lt;li&gt;Full network connectivity between all machines in the cluster&lt;/li&gt;
&lt;li&gt;Swap disabled&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    &lt;ul&gt;
&lt;li&gt;Ohara support install Kubernetes shell script OS only CentOS7&lt;/li&gt;
&lt;li&gt;More details is
&lt;a href=&#34;https://kubernetes.io/docs/setup/independent/install-kubeadm/#before-you-begin&#34;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;step-1-install-kubernetes-master-node&#34;&gt;Step 1. Install Kubernetes master node&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Switch to root user
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ su root
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    &lt;strong&gt;Why change to root user?&lt;/strong&gt;
Use the root user to install Kubernetes is simple and convenient. Avoid
changing not an admin user. Of course, you can use the admin user and
add the &amp;ldquo;sudo&amp;rdquo; keyword to execute install the Kubernetes shell script.
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Change directory to &lt;code&gt;kubernetes/distribute&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# cd $OHARA_HOME/kubernetes/distribute
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run &lt;code&gt;bash k8s-master-install.sh ${Your_K8S_Master_Host_IP}&lt;/code&gt; to
install Kubernetes master&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# bash k8s-master-install.sh ${Your_K8S_Master_Host_IP}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Token and hash will be used in worker installation later on&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# cat /tmp/k8s-install-info.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The token and hash should look like the following:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# kubeadm join 10.100.0.178:6443 --token 14aoza.xpgpa26br32sxwl8 --discovery-token-ca-cert-hash sha256:f5614e6b6376f7559910e66bc014df63398feb7411fe6d0e7057531d7143d47b
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;step-2-install-kubernetes-worker-node&#34;&gt;Step 2. Install Kubernetes worker node&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Switch to root&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ su root
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Goto &lt;code&gt;kubernetes/distribute&lt;/code&gt; directory&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# cd $OHARA_HOME/kubernetes/distribute 
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run following command in your terminal:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# bash k8s-worker-install.sh ${Your_K8S_Master_Host_IP} ${TOKEN} ${HASH_CODE}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;&lt;strong&gt;TOKEN&lt;/strong&gt; and &lt;strong&gt;HASH_CODE&lt;/strong&gt; can be found in the
/tmp/k8s-install-info.txt file of Kubernetes master, the one we
mention in the previous steps&lt;/p&gt;
&lt;p&gt;For example:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# bash k8s-worker-install.sh 10.100.0.178 14aoza.xpgpa26br32sxwl8 sha256:f5614e6b6376f7559910e66bc014df63398feb7411fe6d0e7057531d7143d47b
&lt;/code&gt;&lt;/pre&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;step-3-ensure-the-k8s-api-server-is-running-properly&#34;&gt;Step 3. Ensure the K8S API server is running properly&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Log into Kubernetes master and use the following command to see if these
Kubernetes nodes are running properly:
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# kubectl get nodes
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;You can check Kubernetes node status like the following:
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# curl -X GET http://${Your_K8S_Master_Host_IP}:8080/api/v1/nodes
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;troubleshooting&#34;&gt;Troubleshooting&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;How to autostart the Kubernetes API proxy server after reboot server?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Copy &amp;ldquo;ohara/kubernetes/k8sproxyserver.service&amp;rdquo; file to your
Kubernetes master server &amp;ldquo;/etc/systemd/system&amp;rdquo; path&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Below is setting autostart the command to run the Kubernetes API
proxy server &lt;code&gt;(default port is 8080)&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# systemctl enable k8sproxyserver.service
# systemctl start k8sproxyserver.service
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;how-to-use-kubernetes-in-ohara&#34;&gt;How to use Kubernetes in Ohara?&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;You must create the service to Kubernetes for DNS use in kubernetes
master host, Below is the command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# cd $OHARA_HOME/kubernetes
# kubectl create -f dns-service.yaml
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Below is an example command to run Ohara configurator service for K8S mode:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# docker run --rm \
             -p 5000:5000 \
             --add-host ${K8S_WORKER01_HOSTNAME}:${K8S_WORKER01_IP} \
             --add-host ${K8S_WORKER02_HOSTNAME}:${K8S_WORKER02_IP} \
             oharastream/configurator:$|version| \
             --port 5000 \
             --hostname ${Start Configurator Host Name} \
             --k8s http://${Your_K8S_Master_Host_IP}:8080/api/v1
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--add-host&lt;/code&gt;: Add all k8s worker hostname and ip information to
configurator container /etc/hosts file. If you have DNS server, you
can just ignore parameter of &lt;code&gt;--add-host&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--k8s-namespace&lt;/code&gt;: If you don&amp;rsquo;t use the Kubernetes default namespace,
you can assign the &amp;ndash;k8s-namespace argument to set other the Kubernetes namespace.
Kubernetes namespace default value is &amp;ldquo;default&amp;rdquo; string&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--k8s-metrics-server&lt;/code&gt;: If you have installed the Kubernetes metrics
server, you can set metrics server URL to monitor your Kubernetes node
resource. Example: &lt;code&gt;--k8s-metrics-server http://ohara-kubernetes:8080/apis&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--k8s&lt;/code&gt;: Assignment your K8S API server HTTP URL&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use Ohara configurator to create a zookeeper and broker in
Kubernetes pod for the test:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# Add Ohara Node example
$ curl -H &amp;quot;Content-Type: application/json&amp;quot; \
       -X POST \
       -d &#39;{&amp;quot;hostname&amp;quot;: &amp;quot;${K8S_WORKER01_HOSTNAME}&amp;quot;, \
            &amp;quot;port&amp;quot;: 22, \
            &amp;quot;user&amp;quot;: &amp;quot;${USERNAME}&amp;quot;, \
            &amp;quot;password&amp;quot;: &amp;quot;${PASSWORD}&amp;quot;}&#39; \
       http://${CONFIGURATOR_HOSTNAME_OR_IP}:5000/v0/nodes
  
$ curl -H &amp;quot;Content-Type: application/json&amp;quot; \
       -X POST \
       -d &#39;{&amp;quot;hostname&amp;quot;: &amp;quot;${K8S_WORKER02_HOSTNAME}&amp;quot;, \
            &amp;quot;port&amp;quot;: 22, \
            &amp;quot;user&amp;quot;: &amp;quot;${USERNAME}&amp;quot;, \
            &amp;quot;password&amp;quot;: &amp;quot;${PASSWORD}&amp;quot;}&#39; \
       http://${CONFIGURATOR_HOSTNAME_OR_IP}:5000/v0/nodes
  
# You must pre pull docker image in the ${K8S_WORKER01_HOSTNAME} and ${K8S_WORKER02_HOSTNAME} host, Below is command:
docker pull oharastream/zookeeper:0.11.0-SNAPSHOT
docker pull oharastream/broker:0.11.0-SNAPSHOT
  
# Create Zookeeper cluster service
$ curl -H &amp;quot;Content-Type: application/json&amp;quot; \
       -X POST \
       -d &#39;{&amp;quot;name&amp;quot;: &amp;quot;zk&amp;quot;, \
            &amp;quot;clientPort&amp;quot;: 2181, \
            &amp;quot;imageName&amp;quot;: &amp;quot;oharastream/zookeeper:$|version|&amp;quot;, \
            &amp;quot;peerPort&amp;quot;: 2000, \
            &amp;quot;electionPort&amp;quot;: 2001, \
            &amp;quot;nodeNames&amp;quot;: [&amp;quot;${K8S_WORKER01_HOSTNAME}&amp;quot;]}&#39; \
       http://${CONFIGURATOR_HOSTNAME_OR_IP}:5000/v0/zookeepers
  
# Start Zookeeper cluster service
$ curl -H &amp;quot;Content-Type: application/json&amp;quot; -X PUT http://${CONFIGURATOR_HOSTNAME_OR_IP}:5000/v0/zookeepers/zk/start
  
# Create Broker service example
$ curl -H &amp;quot;Content-Type: application/json&amp;quot; \
       -X POST \
       -d &#39;{&amp;quot;name&amp;quot;: &amp;quot;bk&amp;quot;, \
            &amp;quot;clientPort&amp;quot;: 9092, \
            &amp;quot;zookeeperClusterName&amp;quot;: &amp;quot;zk&amp;quot;, \
            &amp;quot;nodeNames&amp;quot;: [&amp;quot;${K8S_WORKER02_HOSTNAME}&amp;quot;]}&#39; \
       http://${CONFIGURATOR_HOSTNAME_OR_IP}:5000/v0/brokers
  
# Start Broker cluster service
$ curl -H &amp;quot;Content-Type: application/json&amp;quot; -X PUT http://${CONFIGURATOR_HOSTNAME_OR_IP}:5000/v0/brokers/bk/start
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You can use the &lt;strong&gt;kubectl&lt;/strong&gt; command to get zookeeper and broker pod
status with the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# kubectl get pods
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;how-to-install-k8s-metrics-server&#34;&gt;How to install K8S metrics server?&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;You must install the git command to pull the Kubernetes metrics
server source code from the repository to deploy metrics server,
below is sample command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# yum install -y git
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;After complete install git, you can pull the K8S metrics server
source code, below is sample command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# git clone https://github.com/kubernetes-sigs/metrics-server.git
# git checkout tags/v0.3.7 -b v0.3.7
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There should encounter an issue that kubelet and apiserver unable to
communicate with metric-server with default setting. Please use
following YAML setting to override the content of
&lt;strong&gt;deploy/1.8+/metrics-server-deployment.yaml&lt;/strong&gt; file.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: metrics-server
  namespace: kube-system
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: metrics-server
  namespace: kube-system
  labels:
    k8s-app: metrics-server
spec:
  selector:
    matchLabels:
      k8s-app: metrics-server
  template:
    metadata:
      name: metrics-server
      labels:
        k8s-app: metrics-server
    spec:
      serviceAccountName: metrics-server
      volumes:
      # mount in tmp so we can safely use from-scratch images and/or read-only containers
      - name: tmp-dir
        emptyDir: {}
      containers:
      - name: metrics-server
        command:
        - /metrics-server
        - --kubelet-preferred-address-types=InternalIP
        - --kubelet-insecure-tls
        image: k8s.gcr.io/metrics-server-amd64:v0.3.6
        args:
          - --cert-dir=/tmp
          - --secure-port=4443
        ports:
        - name: main-port
          containerPort: 4443
          protocol: TCP
        imagePullPolicy: Always
        volumeMounts:
        - name: tmp-dir
          mountPath: /tmp
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    For more details please refer to &lt;a href=&#34;https://github.com/kubernetes-sigs/metrics-server/issues/131&#34;&gt;here&lt;/a&gt;.
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Deploy the Kubernetes metrics server, below is the command:
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# kubectl apply -f deploy/1.8+
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;Confirm the Kubernetes metrics service is installed complete, you
can input the URL to the browser, below is the example:
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;http://${Your_Kubernetes_Master_HostName_OR_IP}:8080/apis/metrics.k8s.io/v1beta1/nodes
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You maybe wait seconds time to receive the Kubernetes node metrics data.&lt;/p&gt;
&lt;h4 id=&#34;how-to-revert-k8s-environment-setting&#34;&gt;How to revert K8S environment setting?&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;You must stop the K8S API server with this command: &lt;code&gt;kubeadm reset&lt;/code&gt; command.&lt;/li&gt;
&lt;li&gt;More details is 
&lt;a href=&#34;https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-reset&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;how-to-get-the-log-info-in-container-for-debug&#34;&gt;How to get the log info in container for debug?&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;First, log into Kubernetes&amp;rsquo; master server&lt;/li&gt;
&lt;li&gt;List all Kubernetes pod name to query
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# kubectl get pods
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;Get log info in container
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# kubectl logs ${Your_K8S_Pod_Name}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;other&#34;&gt;Other&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Ohara K8SClient ImagePullPolicy default is IfNotPresent.&lt;/li&gt;
&lt;li&gt;Please remember to start K8S API server after you reboot the K8S master server:
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# nohup kubectl proxy --accept-hosts=^*$ --address=$Your_master_host_IP --port=8080 &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Docker and Docker-compose</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/docker/</link>
      <pubDate>Tue, 16 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/docker/</guid>
      <description>&lt;h2 id=&#34;why-we-need-docker-compose&#34;&gt;Why we need docker-compose&lt;/h2&gt;
&lt;p&gt;Ohara is good at connecting to various systems to collect, transform, aggregate
(and other operations you can imagine) data. In order to test Ohara, we need a
way to run a bunch of systems simultaneously. We can build a heavy infra to iron
out this problem. Or we can leverage docker-compose to host various systems &amp;ldquo;locally&amp;rdquo;
(yes, you need a powerful machine to use Ohara&amp;rsquo;s docker-compose file).&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Centos 7.6+ (supported by official community. However, other
GNU/Linux should work well also)&lt;/li&gt;
&lt;li&gt;Docker 18.09+&lt;/li&gt;
&lt;li&gt;Docker-compose 1.23.2+&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;how-to-install&#34;&gt;How to install&lt;/h2&gt;
&lt;h3 id=&#34;install-docker&#34;&gt;Install docker&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;This section is a clone of &lt;a href=&#34;https://docs.docker.com/install/linux/docker-ce/centos/&#34;&gt;https://docs.docker.com/install/linux/docker-ce/centos/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Uninstall old versions&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ sudo yum remove docker \
                  docker-client \
                  docker-client-latest \
                  docker-common \
                  docker-latest \
                  docker-latest-logrotate \
                  docker-logrotate \
                  docker-engine
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Install required packages&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ sudo yum install -y yum-utils \
    device-mapper-persistent-data \
    lvm2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Install using the repository&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ sudo yum-config-manager \
    --add-repo \
    https://download.docker.com/linux/centos/docker-ce.repo
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Install docker-ce&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ sudo yum install docker-ce
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;install-docker-compose&#34;&gt;Install Docker-compose&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ wget https://github.com/docker/compose/releases/download/1.23.2/docker-compose-Linux-x86_64 -O docker-compose
$ sudo chmod +x ./docker-compose
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    see &lt;a href=&#34;https://github.com/docker/compose/releases&#34;&gt;https://github.com/docker/compose/releases&lt;/a&gt; for more details
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;how-to-&#34;&gt;How to &amp;hellip;&lt;/h2&gt;
&lt;h3 id=&#34;start-services-by-docker-compose-file&#34;&gt;Start services by docker-compose file&lt;/h3&gt;
&lt;p&gt;Before start services, you must set postgresql connection info for
environment variable, example:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export POSTGRES_DB=postgres
export POSTGRES_USER=username
export POSTGRES_PASSWORD=password
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start services command&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ./docker-compose -f {docker-compose file} up
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;stop-services&#34;&gt;Stop services&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ctrl+c
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We are talking about tests, right? We don&amp;rsquo;t care about how to shut down services gracefully&lt;/p&gt;
&lt;h3 id=&#34;clean-up-all-containers&#34;&gt;Clean up all containers&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ docker rm -f $(docker ps -q -a)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We are talking about tests, right? You should have a machine for testing
only so it is ok to remove all containers quickly. That does simplify
your work and life.&lt;/p&gt;
&lt;h3 id=&#34;enable-ipv4-ip-forwarding&#34;&gt;Enable IPv4 IP Forwarding&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ sudo vi /usr/lib/sysctl.d/00-system.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Add the following line:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;net.ipv4.ip_forward=1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Save and exit the file. Restart network:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ sudo systemctl restart network
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Docker and Docker-compose</title>
      <link>https://oharastream.github.io/en/docs/master/docker/</link>
      <pubDate>Tue, 16 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/master/docker/</guid>
      <description>&lt;h2 id=&#34;why-we-need-docker-compose&#34;&gt;Why we need docker-compose&lt;/h2&gt;
&lt;p&gt;Ohara is good at connecting to various systems to collect, transform, aggregate
(and other operations you can imagine) data. In order to test Ohara, we need a
way to run a bunch of systems simultaneously. We can build a heavy infra to iron
out this problem. Or we can leverage docker-compose to host various systems &amp;ldquo;locally&amp;rdquo;
(yes, you need a powerful machine to use Ohara&amp;rsquo;s docker-compose file).&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Centos 7.6+ (supported by official community. However, other
GNU/Linux should work well also)&lt;/li&gt;
&lt;li&gt;Docker 18.09+&lt;/li&gt;
&lt;li&gt;Docker-compose 1.23.2+&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;how-to-install&#34;&gt;How to install&lt;/h2&gt;
&lt;h3 id=&#34;install-docker&#34;&gt;Install docker&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;This section is a clone of &lt;a href=&#34;https://docs.docker.com/install/linux/docker-ce/centos/&#34;&gt;https://docs.docker.com/install/linux/docker-ce/centos/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Uninstall old versions&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ sudo yum remove docker \
                  docker-client \
                  docker-client-latest \
                  docker-common \
                  docker-latest \
                  docker-latest-logrotate \
                  docker-logrotate \
                  docker-engine
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Install required packages&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ sudo yum install -y yum-utils \
    device-mapper-persistent-data \
    lvm2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Install using the repository&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ sudo yum-config-manager \
    --add-repo \
    https://download.docker.com/linux/centos/docker-ce.repo
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Install docker-ce&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ sudo yum install docker-ce
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;install-docker-compose&#34;&gt;Install Docker-compose&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ wget https://github.com/docker/compose/releases/download/1.23.2/docker-compose-Linux-x86_64 -O docker-compose
$ sudo chmod +x ./docker-compose
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    see &lt;a href=&#34;https://github.com/docker/compose/releases&#34;&gt;https://github.com/docker/compose/releases&lt;/a&gt; for more details
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;how-to-&#34;&gt;How to &amp;hellip;&lt;/h2&gt;
&lt;h3 id=&#34;start-services-by-docker-compose-file&#34;&gt;Start services by docker-compose file&lt;/h3&gt;
&lt;p&gt;Before start services, you must set postgresql connection info for
environment variable, example:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export POSTGRES_DB=postgres
export POSTGRES_USER=username
export POSTGRES_PASSWORD=password
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start services command&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ./docker-compose -f {docker-compose file} up
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;stop-services&#34;&gt;Stop services&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ctrl+c
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We are talking about tests, right? We don&amp;rsquo;t care about how to shut down services gracefully&lt;/p&gt;
&lt;h3 id=&#34;clean-up-all-containers&#34;&gt;Clean up all containers&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ docker rm -f $(docker ps -q -a)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We are talking about tests, right? You should have a machine for testing
only so it is ok to remove all containers quickly. That does simplify
your work and life.&lt;/p&gt;
&lt;h3 id=&#34;enable-ipv4-ip-forwarding&#34;&gt;Enable IPv4 IP Forwarding&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ sudo vi /usr/lib/sysctl.d/00-system.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Add the following line:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;net.ipv4.ip_forward=1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Save and exit the file. Restart network:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ sudo systemctl restart network
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Integration Test</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/integration_test/</link>
      <pubDate>Tue, 16 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/integration_test/</guid>
      <description>&lt;p&gt;&lt;strong&gt;How to deploy ohara integration test to QA environment?&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;node-裡需要安裝的工具&#34;&gt;Node 裡需要安裝的工具&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;安裝 JDK 11, 需要設定以下的 link&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ sudo yum install -y java-11-openjdk-devel
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在 CentOS 的 Node 需要安裝 jq&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ sudo yum install -y epel-release
$ sudo yum install -y jq
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ssh server&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ sudo yum install -y openssh-server
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Docker: Please follow 
&lt;a href=&#34;https://docs.docker.com/install/linux/docker-ce/centos/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;docker official tutorial&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;防火牆設定允許 docker container 的 port, 並且重新 reload 防火牆的服務&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# sudo firewall-cmd --permanent --zone=trusted --add-interface={docker network}
# sudo firewall-cmd --reload
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;jenkins-需要做的設定&#34;&gt;Jenkins 需要做的設定&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;確認 jenkins 是否加入了登入的帳號密碼設定&lt;/p&gt;
&lt;p&gt;Credentials -&amp;gt; global -&amp;gt; Add Credentials -&amp;gt; 輸入 Username, Password, Description. ID 不用輸入 -&amp;gt; OK&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;把 Node 加入到 Jenkins 裡&lt;/p&gt;
&lt;p&gt;管理 Jenkins -&amp;gt; 管理節點 -&amp;gt; 新增節點 -&amp;gt; 輸入節點名稱的 hostname -&amp;gt; 選複製既有節點 -&amp;gt; 複製來源選一台現有的 slave 來輸入, 例如：ohara-it01 -&amp;gt; OK&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;把 Node 加入到 ssh remote hosts&lt;/p&gt;
&lt;p&gt;管理 Jenkins -&amp;gt; 設定系統 -&amp;gt; SSH remote hosts -&amp;gt; 往下拉會看到新增按鈕 -&amp;gt; 之後輸入 Hostname, port, 選 Credentials -&amp;gt; 新增&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;設定 PreTest 和 PreCommit Job&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;修改標籤表示式, 避免 IT 的 node 跑到 UT 上面&lt;/li&gt;
&lt;li&gt;增加 node 在 shell script 裡
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;NODE01_HOSTNAME=&amp;quot;ohara-it02&amp;quot;
NODE01_IP=$(getent hosts $NODE01_HOSTNAME | cut -d&amp;quot; &amp;quot; -f 1)
NODE01_INFO=&amp;quot;$NODE_USER_NAME:$NODE_PASSWORD@$NODE01_HOSTNAME:22&amp;quot;
EXTRA_PROPERTIES=&amp;quot;-Pohara.it.docker=$NODE00_INFO,$NODE01_INFO&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;建立 Execute shell script on remote host using ssh, 用來在 IT 的 Node 拉 docker image
新增建置步驟 -&amp;gt; Execute shell script on remote host using ssh -&amp;gt; 輸入拉 docker image 的 command&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Integration Test</title>
      <link>https://oharastream.github.io/en/docs/master/integration_test/</link>
      <pubDate>Tue, 16 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/master/integration_test/</guid>
      <description>&lt;p&gt;&lt;strong&gt;How to deploy ohara integration test to QA environment?&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;node-裡需要安裝的工具&#34;&gt;Node 裡需要安裝的工具&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;安裝 JDK 11, 需要設定以下的 link&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ sudo yum install -y java-11-openjdk-devel
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在 CentOS 的 Node 需要安裝 jq&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ sudo yum install -y epel-release
$ sudo yum install -y jq
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ssh server&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ sudo yum install -y openssh-server
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Docker: Please follow 
&lt;a href=&#34;https://docs.docker.com/install/linux/docker-ce/centos/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;docker official tutorial&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;防火牆設定允許 docker container 的 port, 並且重新 reload 防火牆的服務&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;# sudo firewall-cmd --permanent --zone=trusted --add-interface={docker network}
# sudo firewall-cmd --reload
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;jenkins-需要做的設定&#34;&gt;Jenkins 需要做的設定&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;確認 jenkins 是否加入了登入的帳號密碼設定&lt;/p&gt;
&lt;p&gt;Credentials -&amp;gt; global -&amp;gt; Add Credentials -&amp;gt; 輸入 Username, Password, Description. ID 不用輸入 -&amp;gt; OK&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;把 Node 加入到 Jenkins 裡&lt;/p&gt;
&lt;p&gt;管理 Jenkins -&amp;gt; 管理節點 -&amp;gt; 新增節點 -&amp;gt; 輸入節點名稱的 hostname -&amp;gt; 選複製既有節點 -&amp;gt; 複製來源選一台現有的 slave 來輸入, 例如：ohara-it01 -&amp;gt; OK&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;把 Node 加入到 ssh remote hosts&lt;/p&gt;
&lt;p&gt;管理 Jenkins -&amp;gt; 設定系統 -&amp;gt; SSH remote hosts -&amp;gt; 往下拉會看到新增按鈕 -&amp;gt; 之後輸入 Hostname, port, 選 Credentials -&amp;gt; 新增&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;設定 PreTest 和 PreCommit Job&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;修改標籤表示式, 避免 IT 的 node 跑到 UT 上面&lt;/li&gt;
&lt;li&gt;增加 node 在 shell script 裡
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;NODE01_HOSTNAME=&amp;quot;ohara-it02&amp;quot;
NODE01_IP=$(getent hosts $NODE01_HOSTNAME | cut -d&amp;quot; &amp;quot; -f 1)
NODE01_INFO=&amp;quot;$NODE_USER_NAME:$NODE_PASSWORD@$NODE01_HOSTNAME:22&amp;quot;
EXTRA_PROPERTIES=&amp;quot;-Pohara.it.docker=$NODE00_INFO,$NODE01_INFO&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;建立 Execute shell script on remote host using ssh, 用來在 IT 的 Node 拉 docker image
新增建置步驟 -&amp;gt; Execute shell script on remote host using ssh -&amp;gt; 輸入拉 docker image 的 command&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Ohara Manager Development Guideline</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/manager_dev_guide/</link>
      <pubDate>Tue, 16 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/manager_dev_guide/</guid>
      <description>&lt;p&gt;This module contains Ohara manager (an HTTP server powered by

&lt;a href=&#34;https://nodejs.org/en/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Node.js&lt;/a&gt;) and Ohara manager client (A web-based
user interface built with 
&lt;a href=&#34;https://reactjs.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;React.js&lt;/a&gt; ). In the
following docs, we will refer &lt;strong&gt;Server&lt;/strong&gt; as Ohara manager and &lt;strong&gt;Client&lt;/strong&gt;
as Ohara manager client.&lt;/p&gt;
&lt;h2 id=&#34;initial-machine-setup&#34;&gt;Initial machine setup&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Install 
&lt;a href=&#34;https://nodejs.org/en/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Node.js&lt;/a&gt; 10.16.3 or
node.js &amp;gt;=10.16.3 and &amp;lt; 13.0.0&lt;/li&gt;
&lt;li&gt;Install 
&lt;a href=&#34;https://yarnpkg.com/en/docs/install#mac-stable&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yarn&lt;/a&gt;
1.13.0 or greater&lt;/li&gt;
&lt;li&gt;Make sure you&amp;rsquo;re in the ohara-manager root and use this command to
setup the app: &lt;code&gt;yarn setup&lt;/code&gt;. This will install all the dependencies
for both the &lt;strong&gt;Server&lt;/strong&gt; and &lt;strong&gt;Client&lt;/strong&gt; as well as creating a
production build for the client.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Optional&lt;/strong&gt;: If you&amp;rsquo;re using Visual Studio Code as your editor,
have a look at our 
&lt;a href=&#34;#editors&#34;&gt;Editors&lt;/a&gt; section.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;mac&#34;&gt;Mac&lt;/h3&gt;
&lt;p&gt;Make sure you have &lt;code&gt;watchman&lt;/code&gt; installed on your machine. You can do this
with homebrew:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ brew install watchman
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;linux&#34;&gt;Linux&lt;/h3&gt;
&lt;p&gt;Install these dependencies for cypress:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yum install -y xorg-x11-server-Xvfb gtk2-2.24* libXtst* libXScrnSaver* GConf2* alsa-lib*
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;development&#34;&gt;Development&lt;/h2&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    If this is your first time running this project, you need to complete
the &lt;a href=&#34;#initial-machine-setup&#34;&gt;Initial machine setup&lt;/a&gt; section above 👆
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;quick-start-guide&#34;&gt;Quick start guide&lt;/h3&gt;
&lt;p&gt;Make sure you&amp;rsquo;re at the Ohara manager root, then start it with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn start --configurator ${http://host:port/v0}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that the configurator option is &lt;strong&gt;required&lt;/strong&gt;, and you should have
configurator running before starting Ohara manager. You can see the

&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/user_guide/&#34;&gt;user guide&lt;/a&gt; on how to spin
up a Configurator&lt;/p&gt;
&lt;p&gt;Open another terminal tab, and start the &lt;strong&gt;Client&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn start:client
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, go to http://localhost:3000 and start your development, happy
hacking 😎&lt;/p&gt;
&lt;h3 id=&#34;full-development-guide&#34;&gt;Full development guide&lt;/h3&gt;
&lt;p&gt;In development, you need to start both the &lt;strong&gt;Ohara manager&lt;/strong&gt; and &lt;strong&gt;Ohara
manager client&lt;/strong&gt; servers before you can start your development. Follow
the instructions below:&lt;/p&gt;
&lt;h4 id=&#34;server&#34;&gt;Server&lt;/h4&gt;
&lt;p&gt;Make sure you&amp;rsquo;re at the ohara-manager root:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn start --configurator ${http://host:port/v0}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Note that the &lt;code&gt;--configurator&lt;/code&gt; argument is required, you should pass
in Ohara configurator API URL.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;You can also override the default port &lt;code&gt;5050&lt;/code&gt; by passing in &lt;code&gt;--port&lt;/code&gt;
like the following:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn start --configurator ${http://host:port/v0} --port ${1234}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After starting the server, visit &lt;code&gt;http://localhost:${PORT}&lt;/code&gt; in your browser.&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Passing the CLI option &lt;code&gt;-c&lt;/code&gt; has the same effect as &lt;code&gt;--configurator&lt;/code&gt;
and &lt;code&gt;-p&lt;/code&gt; for &lt;code&gt;--port&lt;/code&gt; as well
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Double check the &lt;code&gt;--configurator&lt;/code&gt; spelling and API URL, the URL should
contain the API version number: &lt;code&gt;/v0&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&#34;client&#34;&gt;Client&lt;/h4&gt;
&lt;p&gt;Start the &lt;strong&gt;Client&lt;/strong&gt; development server with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn start:client
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After starting the dev server, visit &lt;code&gt;http://localhost:3000&lt;/code&gt; in your
browser and start you development.&lt;/p&gt;
&lt;p&gt;You can override the default port &lt;code&gt;3000&lt;/code&gt; by passing in an environment
variable:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ PORT=7777 yarn start:client
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The dev server will then start at &lt;code&gt;http://localhost:7777&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&#34;testing&#34;&gt;Testing&lt;/h3&gt;
&lt;h4 id=&#34;unit-test&#34;&gt;Unit test&lt;/h4&gt;
&lt;p&gt;You can run &lt;strong&gt;Client&lt;/strong&gt; unit test with a single npm script:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn test:unit:ci
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Please note that this is a one-off run command, often when you&amp;rsquo;re in
the development, you would run test and stay in Jest&amp;rsquo;s watch mode
which reloads the test once you save your changes:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn test:unit:watch
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn test:unit:ci
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This command will generate test coverage reports, which can be found in
&lt;code&gt;ohara-manager/client/coverage/ut/&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    We will automate check the threshold of code coverage by
&lt;strong&gt;Statements &amp;gt; 40%&lt;/strong&gt; if you issued the &lt;code&gt;test:unit:ci&lt;/code&gt; command.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;api-test&#34;&gt;API test&lt;/h4&gt;
&lt;p&gt;We&amp;rsquo;re using Cypress to test our RESTful API, this ensures our backend
API is always compatible with Ohara manager and won&amp;rsquo;t break our UI
(ideally). You can run the test in different modes:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;GUI mode&lt;/strong&gt;: this will open Cypress test runner, you can then run
your test manually through the UI.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn test:api:open
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Electron mode(headless)&lt;/strong&gt;: since we&amp;rsquo;re running our API test on CI
under this mode. You might often want to run your tests in this mode
locally as well.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn test:api:ci --configurator ${http://host:port/v0 --port 0}
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;Generated test coverage reports could be found in &lt;code&gt;ohara-manager/client/coverage/api&lt;/code&gt;
if you executed test with &lt;strong&gt;Electron mode&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;--port 0&lt;/code&gt; means randomly choose a port for this test run.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    We will automate check the threshold of code coverage by
&lt;strong&gt;Statements &amp;gt; 80%&lt;/strong&gt; if you issued the &lt;code&gt;test:api:ci&lt;/code&gt; command.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;it-test&#34;&gt;IT test&lt;/h4&gt;
&lt;p&gt;To test our UI flows, we use Cypress to test our UI flow with &lt;strong&gt;fake&lt;/strong&gt; configurator. These
tests focus on the behaviors of UI flow (by different operations from UI), so they should
cover most of our UI logic.  You can run the test in different modes:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;GUI mode&lt;/strong&gt;: this will open Cypress test runner, you can then run
your test manually through the UI.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn test:it:open
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Electron mode(headless)&lt;/strong&gt;: since we&amp;rsquo;re running our API test on CI
under this mode. You might often want to run your tests in this mode
locally as well.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn test:it:ci --configurator ${http://host:port/v0 --port 0}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This command will generate test coverage reports, which can be found in
&lt;code&gt;ohara-manager/client/coverage/it/&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    We will automate check the threshold of code coverage by
&lt;strong&gt;Statements &amp;gt; 75%&lt;/strong&gt; if you issued the &lt;code&gt;test:it:ci&lt;/code&gt; command.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;end-to-end-test&#34;&gt;End-to-End test&lt;/h4&gt;
&lt;p&gt;Just like API test, our End-to-End test also runs in two different
modes:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;GUI mode&lt;/strong&gt;: this will open Cypress test runner, you can then run
your test manually through the UI.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn test:e2e:open
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Electron mode(headless)&lt;/strong&gt;: since we&amp;rsquo;re running our E2E test on CI
under this mode. You might often want to run your tests in this mode
locally as well.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn test:e2e:ci --configurator ${http://host:port/v0}
&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Before running in this mode we advise that you run &lt;code&gt;yarn setup&lt;/code&gt; prior
to the tests as the dev server is not running, so you might have stale
build asserts in your build directory&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You also need to create a &lt;strong&gt;cypress.env.json&lt;/strong&gt; under the
&lt;code&gt;/ohara-manager/client/&lt;/code&gt;, these are the config that Cypress will
be using when running tests:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;nodeHost&amp;quot;: &amp;quot;ohara-dev-01&amp;quot;,
  &amp;quot;nodePort&amp;quot;: 22,
  &amp;quot;nodeUser&amp;quot;: &amp;quot;nodeUserName&amp;quot;,
  &amp;quot;nodePass&amp;quot;: &amp;quot;nodePassword&amp;quot;,
  &amp;quot;servicePrefix&amp;quot;: &amp;quot;prPrefix&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Unlike API test, the test should run in production environment&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;code-coverage&#34;&gt;Code Coverage&lt;/h3&gt;
&lt;p&gt;As the above test phases are tend to cover different range of our source code, after you executed
the following commands:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;yarn test:unit:ci&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;yarn test:api:ci&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;yarn test:it:ci&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;we will generate the corresponded coverage reports in relative path as each test section described, and
you could combine them to see the overall picture:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn report:combined
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The combined coverage report could be found at &lt;code&gt;/ohara-manager/client/coverage/index.html&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-info&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;You could also check the combined report by yourself:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn test:coverage:check
&lt;/code&gt;&lt;/pre&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;linting&#34;&gt;Linting&lt;/h3&gt;
&lt;p&gt;We use 
&lt;a href=&#34;https://github.com/eslint/eslint&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ESLint&lt;/a&gt; to lint all the
JavaScript:&lt;/p&gt;
&lt;p&gt;Server:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn lint:server
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It&amp;rsquo;s usually helpful to run linting while developing and that&amp;rsquo;s
included in &lt;code&gt;yarn start&lt;/code&gt; command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn start --configurator ${http://host:port/v0}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will start the server with &lt;code&gt;nodemon&lt;/code&gt; and run the linting script
whenever nodemon reloads.&lt;/p&gt;
&lt;p&gt;Client:&lt;/p&gt;
&lt;p&gt;Since our client is bootstrapped with create-react-app, so the
linting part is already taken care. When starting the &lt;strong&gt;Client&lt;/strong&gt; dev
server with &lt;code&gt;yarn start:client&lt;/code&gt;, the linting will be starting
automatically.&lt;/p&gt;
&lt;p&gt;Note that due to create-react-app doesn&amp;rsquo;t support custom eslint
rules. You need to use your text editor plugin to display the custom
linting rule warnings or errors. For more info about this, please
take a look at the create-react-app

&lt;a href=&#34;https://facebook.github.io/create-react-app/docs/setting-up-your-editor#displaying-lint-output-in-the-editor&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;docs&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;format&#34;&gt;Format&lt;/h3&gt;
&lt;p&gt;We use 
&lt;a href=&#34;https://github.com/prettier/prettier&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Prettier&lt;/a&gt; to format our
code. You can format all &lt;code&gt;.js&lt;/code&gt; files with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn format
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;You can ignore files or folders when running &lt;code&gt;yarn format&lt;/code&gt; by
editing the &lt;code&gt;.prettierignore&lt;/code&gt; in the Ohara-manager root.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;build&#34;&gt;Build&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Note that this step is only required for the Client NOT THE SERVER&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You can get production-ready static files by using the following
command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn build
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    These static files will be built and put into the
&lt;strong&gt;/ohara-manager/client/build&lt;/strong&gt; directory.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;ohara-manager-image&#34;&gt;Ohara manager image&lt;/h3&gt;
&lt;p&gt;Run the following command to get the production ready build of both
the &lt;strong&gt;Server&lt;/strong&gt; and &lt;strong&gt;Client&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn setup
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After the build, copy/use these files and directories to the
destination directory (Note this step is automatically done by
Ohara-${module} module):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;start.js&lt;/li&gt;
&lt;li&gt;config.js&lt;/li&gt;
&lt;li&gt;client &amp;ndash; only build directory is needed
&lt;ul&gt;
&lt;li&gt;build&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;constants&lt;/li&gt;
&lt;li&gt;node_modules&lt;/li&gt;
&lt;li&gt;routes&lt;/li&gt;
&lt;li&gt;utils&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Note that if you add new files or dirs to the &lt;strong&gt;Server&lt;/strong&gt; or &lt;strong&gt;Client&lt;/strong&gt;
and these files and dirs are required for production build, please
list that file in the above list as well as editing the gradle file
under &lt;code&gt;ohara/ohara-manager/build.gradle&lt;/code&gt;. &lt;strong&gt;Skipping this step will
cause production build failed!&lt;/strong&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;From the Ohara manager project root&lt;/strong&gt;, use the following command to
start the manager:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn start:prod --configurator ${http://host:port/v0}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;ci-server-integration&#34;&gt;CI server integration&lt;/h3&gt;
&lt;p&gt;In order to run tests on Jenkins, Ohara manager provides a few npm scripts that are used in Gradle, these scripts generate test reports in &lt;em&gt;/ohara-manager/test-reports&lt;/em&gt; which can be consumed by Jenkins to determine if a test passes or not, you will sometimes need to run these commands locally if you edit related npm scripts in Ohara manager or want to reproduce fail build on CI:&lt;/p&gt;
&lt;p&gt;Unit test:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ ./gradlew test
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Run &lt;strong&gt;Client&lt;/strong&gt;&amp;rsquo;s unit tests. The test reports can be found in &lt;code&gt;ohara-manager/test-reports/&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;API test:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ ./gradlew api -Pohara.manager.api.configurator=${http://host:port/v0}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;End-to-End test:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ ./gradlew e2e -Pohara.manager.e2e.port=5050 -Pohara.manager.e2e.configurator=${http://host:port/v0}-Pohara.manager.e2e.nodeHost=${slaveNodeName} -Pohara.manager.e2e.nodePort=${slaveNodePort} -Pohara.manager.e2e.nodeUser=${slaveNodeUsername} -Pohara.manager.e2e.nodePass=${slaveNodePassword} -Pohara.it.container.prefix=${pullRequestNumber}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&amp;rsquo;s take a close look at these options:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-Pohara.manager.e2e.port=5050&lt;/code&gt;: start Ohara manager at this port in the test run&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-Pohara.manager.e2e.configurator=${http://host:port/v0}&lt;/code&gt;: Configurator URL, Ohara manager will hit this API endpoint when running test&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-Pohara.manager.e2e.nodeHost=${slaveNodeName}&lt;/code&gt;: K8s&amp;rsquo; slave node, the services started in the test will be deploy on this node&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-Pohara.manager.e2e.nodePort=${slaveNodePort}&lt;/code&gt;: port of the given node&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-Pohara.manager.e2e.nodeUser=${slaveNodeUsername}&lt;/code&gt;: username of the given node&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-Pohara.manager.e2e.nodePass=${slaveNodePassword}&lt;/code&gt;: password of the given node&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-Pohara.it.container.prefix=${pullRequestNumber}&lt;/code&gt;: pull request number of this test run, this prefix is used by Jenkins to do the cleanup after the test is done&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are more gradle tasks that are not listed in the above, you can
view them in &lt;code&gt;/ohara-manager/build.gradle&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&#34;clean&#34;&gt;Clean&lt;/h3&gt;
&lt;p&gt;Clean up all running processes, removing &lt;code&gt;test-reports/&lt;/code&gt; in the
&lt;strong&gt;Server&lt;/strong&gt; and &lt;code&gt;/build&lt;/code&gt; directory in the &lt;strong&gt;Client&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn clean
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Clean all running processes started with node.js&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn clean:process
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is useful when you want to kill all node.js processes locally&lt;/p&gt;
&lt;h3 id=&#34;prepush&#34;&gt;Prepush&lt;/h3&gt;
&lt;p&gt;We also provide a npm script to run Client&amp;rsquo;s unit test, linting, and
format all the JavaScript files with. &lt;strong&gt;Ideally, you&amp;rsquo;d run this
before pushing your code to the remote repo:&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn prepush
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;editors&#34;&gt;Editors&lt;/h2&gt;
&lt;p&gt;We highly recommended that you use 
&lt;a href=&#34;https://code.visualstudio.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Visual Studio
Code&lt;/a&gt; (vscode for short) to edit and
author Ohara manager code.&lt;/p&gt;
&lt;p&gt;Recommended vscode settings&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;editor.tabSize&amp;quot;: 2,
  &amp;quot;editor.formatOnSave&amp;quot;: true,
  &amp;quot;editor.formatOnSaveTimeout&amp;quot;: 2000,
  &amp;quot;editor.tabCompletion&amp;quot;: true,
  &amp;quot;emmet.triggerExpansionOnTab&amp;quot;: true,
  &amp;quot;emmet.includeLanguages&amp;quot;: {
    &amp;quot;javascript&amp;quot;: &amp;quot;javascriptreact&amp;quot;,
    &amp;quot;markdown&amp;quot;: &amp;quot;html&amp;quot;
  },
  &amp;quot;search.exclude&amp;quot;: {
    &amp;quot;**/node_modules&amp;quot;: true,
    &amp;quot;**/bower_components&amp;quot;: true,
    &amp;quot;**/coverage&amp;quot;: true
  },
  &amp;quot;javascript.updateImportsOnFileMove.enabled&amp;quot;: &amp;quot;always&amp;quot;,
  &amp;quot;eslint.workingDirectories&amp;quot;: [
     &amp;quot;./client&amp;quot;
   ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Recommend extensions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=dbaeumer.vscode-eslint&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ESLint&lt;/a&gt; &amp;mdash;
install this so vscode can display linting errors right in the editor&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=jpoissonnier.vscode-styled-components&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;vscode-styled-components&lt;/a&gt; &amp;mdash;
syntax highlighting support for 
&lt;a href=&#34;https://github.com/styled-components/styled-components&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;styled component&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=esbenp.prettier-vscode&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Prettier - Code formatter&lt;/a&gt; &amp;mdash;
code formatter, it consumes the config in &lt;code&gt;.prettierrc&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=mikestead.dotenv&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DotENV&lt;/a&gt; &amp;mdash;
&lt;code&gt;.env&lt;/code&gt; file syntax highlighting support&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=naumovs.color-highlight&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Color Highlight&lt;/a&gt; &amp;mdash;
Highlight web colors in VSCode&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;switch-different-version-of-nodejs&#34;&gt;Switch different version of Node.js&lt;/h2&gt;
&lt;p&gt;Oftentimes you would need to switch between different Node.js versions
for debugging. There&amp;rsquo;s a handy npm package that can reduce the pain of
managing different version of Node.js on your machine:&lt;/p&gt;
&lt;p&gt;First, let&amp;rsquo;s install this package &lt;code&gt;n&lt;/code&gt;, note that we&amp;rsquo;re installing it globally so it&amp;rsquo;s can be used throughout your projects:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ npm install -g n # or yarn global add n
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Second, let&amp;rsquo;s use &lt;code&gt;n&lt;/code&gt; to install a specific version of Node.js:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ n 8.16.0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Switch between installed NodeJS versions:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ n # Yep, just type n in your terminal...,
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more info, you can read the 
&lt;a href=&#34;https://github.com/tj/n&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;docs&lt;/a&gt; here.&lt;/p&gt;
&lt;h2 id=&#34;having-issues&#34;&gt;Having issues?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Got an error while starting up the server: Error: Cannot find
module ${module-name}&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If you&amp;rsquo;re running into this, it&amp;rsquo;s probably that this module is not
correctly installed on your machine. You can fix this by simply
run:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn # If this doesn&#39;t work, try `yarn add ${module-name}`
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After the installation is completed, start the server again.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Got an error while starting up the server or client on a Linux
machine: ENOSPC&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You can run this command to increase the limit on the number of
files Linux will watch. Read more

&lt;a href=&#34;https://github.com/guard/listen/wiki/Increasing-the-amount-of-inotify-watchers#the-technical-details&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ echo fs.inotify.max_user_watches=524288 | sudo tee -a /etc/sysctl.conf &amp;amp;&amp;amp; sudo sysctl -p.
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Node.js processes cannot be stopped even after using kill -9&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;re using &lt;code&gt;forever&lt;/code&gt; to start our node.js servers on CI, and
&lt;code&gt;nodemon&lt;/code&gt; while in development, so you need to use the following
commands to kill them. &lt;code&gt;kill -9&lt;/code&gt; or &lt;code&gt;fuser&lt;/code&gt; might not work as you
expected.&lt;/p&gt;
&lt;p&gt;use &lt;code&gt;yarn clean:processes&lt;/code&gt; command or &lt;code&gt;pkill node&lt;/code&gt; to kill all the
node.js processes&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;While running test in jest&amp;rsquo;s watch modal, an error is thrown&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Error watching file for changes: EMFILE
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Try installing &lt;code&gt;watchman&lt;/code&gt; for your mac with the 
&lt;a href=&#34;#mac&#34;&gt;instruction&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For more info: &lt;a href=&#34;https://github.com/facebook/jest/issues/1767&#34;&gt;https://github.com/facebook/jest/issues/1767&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ohara manager is not able to connect to Configurator&lt;/strong&gt; And I&amp;rsquo;m seeing something like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--configurator: we&#39;re not able to connect to `{http://host:port/v0}`
Please make sure your Configurator is running at `${http://host:port/v0}`
[nodemon] app crashed - waiting for file changes before starting...
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This could happen due to several reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Configurator hasn&amp;rsquo;t fully started yet&lt;/strong&gt;: after you start the
configurator container. The container needs some time to fully
initialize the service. This usually takes about a minute or
so. And as we&amp;rsquo;re doing the API check by hitting the real API
in Ohara manager. This results to the error in the above.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;You&amp;rsquo;re not using the correct IP in Manager container&lt;/strong&gt;: if
you start a configurator container in your local as well as a
manager. You should specify an IP instead of something like
localhost in: &lt;code&gt;--configurator http://localhost:12345/v0&lt;/code&gt; This
won&amp;rsquo;t work as the manager is started in the container so it
won&amp;rsquo;t be able to connect to the configurator without a real IP&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;As we mentioned in the previous sections. Please double
check your configurator URL spelling. This is usually the
cause of the above-mentioned error.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Ohara Manager Development Guideline</title>
      <link>https://oharastream.github.io/en/docs/master/manager_dev_guide/</link>
      <pubDate>Tue, 16 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/master/manager_dev_guide/</guid>
      <description>&lt;p&gt;This module contains Ohara manager (an HTTP server powered by

&lt;a href=&#34;https://nodejs.org/en/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Node.js&lt;/a&gt;) and Ohara manager client (A web-based
user interface built with 
&lt;a href=&#34;https://reactjs.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;React.js&lt;/a&gt; ). In the
following docs, we will refer &lt;strong&gt;Server&lt;/strong&gt; as Ohara manager and &lt;strong&gt;Client&lt;/strong&gt;
as Ohara manager client.&lt;/p&gt;
&lt;h2 id=&#34;initial-machine-setup&#34;&gt;Initial machine setup&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Install 
&lt;a href=&#34;https://nodejs.org/en/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Node.js&lt;/a&gt; 10.16.3 or
node.js &amp;gt;=10.16.3 and &amp;lt; 13.0.0&lt;/li&gt;
&lt;li&gt;Install 
&lt;a href=&#34;https://yarnpkg.com/en/docs/install#mac-stable&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yarn&lt;/a&gt;
1.13.0 or greater&lt;/li&gt;
&lt;li&gt;Make sure you&amp;rsquo;re in the ohara-manager root and use this command to
setup the app: &lt;code&gt;yarn setup&lt;/code&gt;. This will install all the dependencies
for both the &lt;strong&gt;Server&lt;/strong&gt; and &lt;strong&gt;Client&lt;/strong&gt; as well as creating a
production build for the client.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Optional&lt;/strong&gt;: If you&amp;rsquo;re using Visual Studio Code as your editor,
have a look at our 
&lt;a href=&#34;#editors&#34;&gt;Editors&lt;/a&gt; section.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;mac&#34;&gt;Mac&lt;/h3&gt;
&lt;p&gt;Make sure you have &lt;code&gt;watchman&lt;/code&gt; installed on your machine. You can do this
with homebrew:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ brew install watchman
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;linux&#34;&gt;Linux&lt;/h3&gt;
&lt;p&gt;Install these dependencies for cypress:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yum install -y xorg-x11-server-Xvfb gtk2-2.24* libXtst* libXScrnSaver* GConf2* alsa-lib*
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;development&#34;&gt;Development&lt;/h2&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    If this is your first time running this project, you need to complete
the &lt;a href=&#34;#initial-machine-setup&#34;&gt;Initial machine setup&lt;/a&gt; section above 👆
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;quick-start-guide&#34;&gt;Quick start guide&lt;/h3&gt;
&lt;p&gt;Make sure you&amp;rsquo;re at the Ohara manager root, then start it with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn start --configurator ${http://host:port/v0}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that the configurator option is &lt;strong&gt;required&lt;/strong&gt;, and you should have
configurator running before starting Ohara manager. You can see the

&lt;a href=&#34;https://oharastream.github.io/en/docs/master/user_guide/&#34;&gt;user guide&lt;/a&gt; on how to spin
up a Configurator&lt;/p&gt;
&lt;p&gt;Open another terminal tab, and start the &lt;strong&gt;Client&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn start:client
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, go to http://localhost:3000 and start your development, happy
hacking 😎&lt;/p&gt;
&lt;h3 id=&#34;full-development-guide&#34;&gt;Full development guide&lt;/h3&gt;
&lt;p&gt;In development, you need to start both the &lt;strong&gt;Ohara manager&lt;/strong&gt; and &lt;strong&gt;Ohara
manager client&lt;/strong&gt; servers before you can start your development. Follow
the instructions below:&lt;/p&gt;
&lt;h4 id=&#34;server&#34;&gt;Server&lt;/h4&gt;
&lt;p&gt;Make sure you&amp;rsquo;re at the ohara-manager root:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn start --configurator ${http://host:port/v0}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Note that the &lt;code&gt;--configurator&lt;/code&gt; argument is required, you should pass
in Ohara configurator API URL.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;You can also override the default port &lt;code&gt;5050&lt;/code&gt; by passing in &lt;code&gt;--port&lt;/code&gt;
like the following:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn start --configurator ${http://host:port/v0} --port ${1234}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After starting the server, visit &lt;code&gt;http://localhost:${PORT}&lt;/code&gt; in your browser.&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Passing the CLI option &lt;code&gt;-c&lt;/code&gt; has the same effect as &lt;code&gt;--configurator&lt;/code&gt;
and &lt;code&gt;-p&lt;/code&gt; for &lt;code&gt;--port&lt;/code&gt; as well
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Double check the &lt;code&gt;--configurator&lt;/code&gt; spelling and API URL, the URL should
contain the API version number: &lt;code&gt;/v0&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&#34;client&#34;&gt;Client&lt;/h4&gt;
&lt;p&gt;Start the &lt;strong&gt;Client&lt;/strong&gt; development server with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn start:client
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After starting the dev server, visit &lt;code&gt;http://localhost:3000&lt;/code&gt; in your
browser and start you development.&lt;/p&gt;
&lt;p&gt;You can override the default port &lt;code&gt;3000&lt;/code&gt; by passing in an environment
variable:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ PORT=7777 yarn start:client
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The dev server will then start at &lt;code&gt;http://localhost:7777&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&#34;testing&#34;&gt;Testing&lt;/h3&gt;
&lt;h4 id=&#34;unit-test&#34;&gt;Unit test&lt;/h4&gt;
&lt;p&gt;You can run &lt;strong&gt;Client&lt;/strong&gt; unit test with a single npm script:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn test:unit:ci
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Please note that this is a one-off run command, often when you&amp;rsquo;re in
the development, you would run the test and stay in Jest&amp;rsquo;s watch mode
which reloads the test once you save your changes:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn test:unit:watch
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn test:unit:ci
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This command will generate test coverage reports, which can be found in
&lt;code&gt;ohara-manager/client/coverage/ut/&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    We will automatically check the code coverage threshold by
&lt;strong&gt;Statements &amp;gt; 40%&lt;/strong&gt; if you issue the &lt;code&gt;test:unit:ci&lt;/code&gt; command.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;api-test&#34;&gt;API test&lt;/h4&gt;
&lt;p&gt;We&amp;rsquo;re using Cypress to test our RESTful API, this ensures our backend
API is always compatible with Ohara manager and won&amp;rsquo;t break our UI
(ideally). You can run the test in different modes:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;GUI mode&lt;/strong&gt;: this will open Cypress test runner, you can then run
your test manually through the UI.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn test:api:open
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Electron mode(headless)&lt;/strong&gt;: since we&amp;rsquo;re running our API test on CI
under this mode. You might often want to run your tests in this mode
locally as well.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn test:api:ci --configurator ${http://host:port/v0} --port 0
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;Generated test coverage reports could be found in &lt;code&gt;ohara-manager/client/coverage/api&lt;/code&gt;
if you executed test with &lt;strong&gt;Electron mode&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;--port 0&lt;/code&gt; means using a random port.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    We will automate check the threshold of code coverage by
&lt;strong&gt;Statements &amp;gt; 80%&lt;/strong&gt; if you issued the &lt;code&gt;test:api:ci&lt;/code&gt; command.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;it-test&#34;&gt;IT test&lt;/h4&gt;
&lt;p&gt;To test our UI flows, we run these test via Cypress with a &lt;strong&gt;fake&lt;/strong&gt; configurator. These
tests focus on the behaviors of UI flow (by different operations from UI), so they should
cover most of our UI logic. You can run the test in different modes:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;GUI mode&lt;/strong&gt;: this will open Cypress test runner, you can then run
your test manually through the UI.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn test:it:open
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Electron mode(headless)&lt;/strong&gt;: since we&amp;rsquo;re running our API test on CI
under this mode. You might often want to run your tests in this mode
locally as well.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn test:it:ci --configurator ${http://host:port/v0} --port 0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This command will generate test coverage reports, which can be found in
&lt;code&gt;ohara-manager/client/coverage/it/&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    We will automate check the code coverage threshold by
&lt;strong&gt;Statements &amp;gt; 75%&lt;/strong&gt; if you issue the &lt;code&gt;test:it:ci&lt;/code&gt; command.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;end-to-end-test&#34;&gt;End-to-End test&lt;/h4&gt;
&lt;p&gt;Just like API test, our End-to-End test also runs in two different
modes:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;GUI mode&lt;/strong&gt;: this will open Cypress test runner, you can then run
your test manually through the UI.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn test:e2e:open
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Electron mode(headless)&lt;/strong&gt;: since we&amp;rsquo;re running our E2E test on CI
under this mode. You might often want to run your tests in this mode
locally as well.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn test:e2e:ci --configurator ${http://host:port/v0}
&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Before running in this mode we advise that you run &lt;code&gt;yarn setup&lt;/code&gt; prior
to the tests as the dev server is not running, so you might have stale
build asserts in your build directory&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You also need to create a &lt;strong&gt;cypress.env.json&lt;/strong&gt; under the
&lt;code&gt;/ohara-manager/client/&lt;/code&gt;, these are the config that Cypress will
be using when running tests:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;nodeHost&amp;quot;: &amp;quot;ohara-dev-01&amp;quot;,
  &amp;quot;nodePort&amp;quot;: 22,
  &amp;quot;nodeUser&amp;quot;: &amp;quot;nodeUserName&amp;quot;,
  &amp;quot;nodePass&amp;quot;: &amp;quot;nodePassword&amp;quot;,
  &amp;quot;servicePrefix&amp;quot;: &amp;quot;prPrefix&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Unlike API test, the test should run in production environment&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;code-coverage&#34;&gt;Code Coverage&lt;/h3&gt;
&lt;p&gt;As the above test phases are tend to cover different range of our source code, after you executed
the following commands:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;yarn test:unit:ci&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;yarn test:api:ci&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;yarn test:it:ci&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;we will generate the corresponded coverage reports in relative path as each test section described, and
you could combine them to see the overall picture:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn report:combined
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The combined coverage report could be found at &lt;code&gt;/ohara-manager/client/coverage/index.html&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-info&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;You could also check the combined report by yourself:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn test:coverage:check
&lt;/code&gt;&lt;/pre&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;linting&#34;&gt;Linting&lt;/h3&gt;
&lt;p&gt;We use 
&lt;a href=&#34;https://github.com/eslint/eslint&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ESLint&lt;/a&gt; to lint all the
JavaScript:&lt;/p&gt;
&lt;p&gt;Server:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn lint:server
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It&amp;rsquo;s usually helpful to run linting while developing and that&amp;rsquo;s
included in &lt;code&gt;yarn start&lt;/code&gt; command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn start --configurator ${http://host:port/v0}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will start the server with &lt;code&gt;nodemon&lt;/code&gt; and run the linting script
whenever nodemon reloads.&lt;/p&gt;
&lt;p&gt;Client:&lt;/p&gt;
&lt;p&gt;Since our client is bootstrapped with create-react-app, so the
linting part is already taken care. When starting the &lt;strong&gt;Client&lt;/strong&gt; dev
server with &lt;code&gt;yarn start:client&lt;/code&gt;, the linting will be starting
automatically.&lt;/p&gt;
&lt;p&gt;Note that due to create-react-app doesn&amp;rsquo;t support custom eslint
rules. You need to use your text editor plugin to display the custom
linting rule warnings or errors. For more info about this, please
take a look at the create-react-app

&lt;a href=&#34;https://facebook.github.io/create-react-app/docs/setting-up-your-editor#displaying-lint-output-in-the-editor&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;docs&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;format&#34;&gt;Format&lt;/h3&gt;
&lt;p&gt;We use 
&lt;a href=&#34;https://github.com/prettier/prettier&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Prettier&lt;/a&gt; to format our
code. You can format all &lt;code&gt;.js&lt;/code&gt; files with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn format
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;You can ignore files or folders when running &lt;code&gt;yarn format&lt;/code&gt; by
editing the &lt;code&gt;.prettierignore&lt;/code&gt; in the Ohara-manager root.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;type-checking&#34;&gt;Type checking&lt;/h3&gt;
&lt;p&gt;We&amp;rsquo;re in the progress of moving from plain JavaScript to TypeScript. Although not all source are moved to TS, you can still type checking files:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn typecheck
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;license&#34;&gt;License&lt;/h3&gt;
&lt;p&gt;We&amp;rsquo;re enforcing all of our source code files to have a license header, so when creating a new file like &lt;code&gt;.js&lt;/code&gt; or &lt;code&gt;.tsx&lt;/code&gt; etc. You will need to include the license header or it would fail on our CI. We provide two npm scripts that your can take advantage of and so you won&amp;rsquo;t need to add the license header manually&lt;/p&gt;
&lt;p&gt;Checking if all files include the license header&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn license:test
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Add license header for files that miss it&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ license:apply
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;build&#34;&gt;Build&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Note that this step is only required for the Client NOT THE SERVER&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You can get production-ready static files by using the following
command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn build
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    These static files will be built and put into the
&lt;strong&gt;/ohara-manager/client/build&lt;/strong&gt; directory.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;ohara-manager-image&#34;&gt;Ohara manager image&lt;/h3&gt;
&lt;p&gt;Run the following command to get the production ready build of both
the &lt;strong&gt;Server&lt;/strong&gt; and &lt;strong&gt;Client&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn setup
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After the build, copy/use these files and directories to the
destination directory (Note this step is automatically done by
Ohara-${module} module):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;start.js&lt;/li&gt;
&lt;li&gt;config.js&lt;/li&gt;
&lt;li&gt;client &amp;ndash; only build directory is needed
&lt;ul&gt;
&lt;li&gt;build&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;constants&lt;/li&gt;
&lt;li&gt;node_modules&lt;/li&gt;
&lt;li&gt;routes&lt;/li&gt;
&lt;li&gt;utils&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Note that if you add new files or dirs to the &lt;strong&gt;Server&lt;/strong&gt; or &lt;strong&gt;Client&lt;/strong&gt;
and these files and dirs are required for production build, please
list that file in the above list as well as editing the gradle file
under &lt;code&gt;ohara/ohara-manager/build.gradle&lt;/code&gt;. &lt;strong&gt;Skipping this step will
cause production build failed!&lt;/strong&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;From the Ohara manager project root&lt;/strong&gt;, use the following command to
start the manager:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn start:prod --configurator ${http://host:port/v0}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;ci-server-integration&#34;&gt;CI server integration&lt;/h3&gt;
&lt;p&gt;In order to run tests on Jenkins, Ohara manager provides a few npm scripts that are used in Gradle, these scripts generate test reports in &lt;em&gt;/ohara-manager/test-reports&lt;/em&gt; which can be consumed by Jenkins to determine if a test passes or not, you will sometimes need to run these commands locally if you edit related npm scripts in Ohara manager or want to reproduce fail build on CI:&lt;/p&gt;
&lt;p&gt;Unit test:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ ./gradlew test
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Run &lt;strong&gt;Client&lt;/strong&gt;&amp;rsquo;s unit tests. The test reports can be found in &lt;code&gt;ohara-manager/test-reports/&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;API test:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ ./gradlew api -Pohara.manager.api.configurator=${http://host:port/v0}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;End-to-End test:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ ./gradlew e2e -Pohara.manager.e2e.port=5050 -Pohara.manager.e2e.configurator=${http://host:port/v0}-Pohara.manager.e2e.nodeHost=${slaveNodeName} -Pohara.manager.e2e.nodePort=${slaveNodePort} -Pohara.manager.e2e.nodeUser=${slaveNodeUsername} -Pohara.manager.e2e.nodePass=${slaveNodePassword} -Pohara.it.container.prefix=${pullRequestNumber}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&amp;rsquo;s take a close look at these options:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-Pohara.manager.e2e.port=5050&lt;/code&gt;: start Ohara manager at this port in the test run&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-Pohara.manager.e2e.configurator=${http://host:port/v0}&lt;/code&gt;: Configurator URL, Ohara manager will hit this API endpoint when running test&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-Pohara.manager.e2e.nodeHost=${slaveNodeName}&lt;/code&gt;: K8s&amp;rsquo; slave node, the services started in the test will be deploy on this node&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-Pohara.manager.e2e.nodePort=${slaveNodePort}&lt;/code&gt;: port of the given node&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-Pohara.manager.e2e.nodeUser=${slaveNodeUsername}&lt;/code&gt;: username of the given node&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-Pohara.manager.e2e.nodePass=${slaveNodePassword}&lt;/code&gt;: password of the given node&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-Pohara.it.container.prefix=${pullRequestNumber}&lt;/code&gt;: pull request number of this test run, this prefix is used by Jenkins to do the cleanup after the test is done&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are more gradle tasks that are not listed in the above, you can
view them in &lt;code&gt;/ohara-manager/build.gradle&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&#34;clean&#34;&gt;Clean&lt;/h3&gt;
&lt;p&gt;Clean all running processes started with node.js&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn clean:processes
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is useful when you want to kill all node.js processes locally&lt;/p&gt;
&lt;p&gt;Clean test test reports, coverage reports and build artifacts&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn clean:files
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Remove both &lt;code&gt;node_modules&lt;/code&gt; from Server and Client, this is useful when you want to do a clean install&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn clean:deps
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;prepush&#34;&gt;Prepush&lt;/h3&gt;
&lt;p&gt;We also provide a npm script to run Client&amp;rsquo;s unit test, linting, and
format all the JavaScript files with. &lt;strong&gt;Ideally, you&amp;rsquo;d run this
before pushing your code to the remote repo:&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn prepush
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;editors&#34;&gt;Editors&lt;/h2&gt;
&lt;p&gt;We highly recommended that you use 
&lt;a href=&#34;https://code.visualstudio.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Visual Studio
Code&lt;/a&gt; (vscode for short) to edit and
author Ohara manager code.&lt;/p&gt;
&lt;p&gt;Recommended vscode settings&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;editor.tabSize&amp;quot;: 2,
  &amp;quot;editor.formatOnSave&amp;quot;: true,
  &amp;quot;editor.formatOnSaveTimeout&amp;quot;: 2000,
  &amp;quot;editor.tabCompletion&amp;quot;: true,
  &amp;quot;emmet.triggerExpansionOnTab&amp;quot;: true,
  &amp;quot;emmet.includeLanguages&amp;quot;: {
    &amp;quot;javascript&amp;quot;: &amp;quot;javascriptreact&amp;quot;,
    &amp;quot;markdown&amp;quot;: &amp;quot;html&amp;quot;
  },
  &amp;quot;search.exclude&amp;quot;: {
    &amp;quot;**/node_modules&amp;quot;: true,
    &amp;quot;**/bower_components&amp;quot;: true,
    &amp;quot;**/coverage&amp;quot;: true
  },
  &amp;quot;javascript.updateImportsOnFileMove.enabled&amp;quot;: &amp;quot;always&amp;quot;,
  &amp;quot;eslint.workingDirectories&amp;quot;: [&amp;quot;./client&amp;quot;]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Recommend extensions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=dbaeumer.vscode-eslint&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ESLint&lt;/a&gt; &amp;mdash;
install this so vscode can display linting errors right in the editor&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=jpoissonnier.vscode-styled-components&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;vscode-styled-components&lt;/a&gt; &amp;mdash;
syntax highlighting support for 
&lt;a href=&#34;https://github.com/styled-components/styled-components&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;styled component&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=esbenp.prettier-vscode&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Prettier - Code formatter&lt;/a&gt; &amp;mdash;
code formatter, it consumes the config in &lt;code&gt;.prettierrc&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=mikestead.dotenv&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DotENV&lt;/a&gt; &amp;mdash;
&lt;code&gt;.env&lt;/code&gt; file syntax highlighting support&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=naumovs.color-highlight&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Color Highlight&lt;/a&gt; &amp;mdash;
Highlight web colors in VSCode&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;switch-different-version-of-nodejs&#34;&gt;Switch different version of Node.js&lt;/h2&gt;
&lt;p&gt;Oftentimes you would need to switch between different Node.js versions
for debugging. There&amp;rsquo;s a handy npm package that can reduce the pain of
managing different version of Node.js on your machine:&lt;/p&gt;
&lt;p&gt;First, let&amp;rsquo;s install this package &lt;code&gt;n&lt;/code&gt;, note that we&amp;rsquo;re installing it globally so it&amp;rsquo;s can be used throughout your projects:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ npm install -g n # or yarn global add n
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Second, let&amp;rsquo;s use &lt;code&gt;n&lt;/code&gt; to install a specific version of Node.js:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ n 8.16.0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Switch between installed NodeJS versions:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ n # Yep, just type n in your terminal...,
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more info, you can read the 
&lt;a href=&#34;https://github.com/tj/n&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;docs&lt;/a&gt; here.&lt;/p&gt;
&lt;h2 id=&#34;having-issues&#34;&gt;Having issues?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Got an error while starting up the server: Error: Cannot find
module ${module-name}&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If you&amp;rsquo;re running into this, it&amp;rsquo;s probably that this module is not
correctly installed on your machine. You can fix this by simply
run:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ yarn # If this doesn&#39;t work, try `yarn add ${module-name}`
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After the installation is completed, start the server again.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Got an error while starting up the server or client on a Linux
machine: ENOSPC&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You can run this command to increase the limit on the number of
files Linux will watch. Read more

&lt;a href=&#34;https://github.com/guard/listen/wiki/Increasing-the-amount-of-inotify-watchers#the-technical-details&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ echo fs.inotify.max_user_watches=524288 | sudo tee -a /etc/sysctl.conf &amp;amp;&amp;amp; sudo sysctl -p.
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Node.js processes cannot be stopped even after using kill -9&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;re using &lt;code&gt;forever&lt;/code&gt; to start our node.js servers on CI, and
&lt;code&gt;nodemon&lt;/code&gt; while in development, so you need to use the following
commands to kill them. &lt;code&gt;kill -9&lt;/code&gt; or &lt;code&gt;fuser&lt;/code&gt; might not work as you
expected.&lt;/p&gt;
&lt;p&gt;use &lt;code&gt;yarn clean:processes&lt;/code&gt; command or &lt;code&gt;pkill node&lt;/code&gt; to kill all the
node.js processes&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;While running test in jest&amp;rsquo;s watch modal, an error is thrown&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Error watching file for changes: EMFILE
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Try installing &lt;code&gt;watchman&lt;/code&gt; for your mac with the 
&lt;a href=&#34;#mac&#34;&gt;instruction&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For more info: &lt;a href=&#34;https://github.com/facebook/jest/issues/1767&#34;&gt;https://github.com/facebook/jest/issues/1767&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ohara manager is not able to connect to Configurator&lt;/strong&gt; And I&amp;rsquo;m seeing something like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--configurator: we&#39;re not able to connect to `{http://host:port/v0}`
Please make sure your Configurator is running at `${http://host:port/v0}`
[nodemon] app crashed - waiting for file changes before starting...
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This could happen due to several reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Configurator hasn&amp;rsquo;t fully started yet&lt;/strong&gt;: after you start the
configurator container. The container needs some time to fully
initialize the service. This usually takes about a minute or
so. And as we&amp;rsquo;re doing the API check by hitting the real API
in Ohara manager. This results to the error in the above.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;You&amp;rsquo;re not using the correct IP in Manager container&lt;/strong&gt;: if
you start a configurator container in your local as well as a
manager. You should specify an IP instead of something like
localhost in: &lt;code&gt;--configurator http://localhost:12345/v0&lt;/code&gt; This
won&amp;rsquo;t work as the manager is started in the container so it
won&amp;rsquo;t be able to connect to the configurator without a real IP&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;As we mentioned in the previous sections. Please double
check your configurator URL spelling. This is usually the
cause of the above-mentioned errors.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Shabondi</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/shabondi/</link>
      <pubDate>Tue, 16 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/shabondi/</guid>
      <description>&lt;p&gt;Shabondi service play the role of a &lt;em&gt;http proxy service&lt;/em&gt; in the Pipeline
of Ohara. If you want to integrate Ohara pipeline with your application,
Shabondi is a good choice. Just send the simple http request to
&lt;strong&gt;Shabondi source&lt;/strong&gt; service, you can hand over your data to Pipeline for
processing. On the other hand, you can send the http request to
&lt;strong&gt;Shabondi sink&lt;/strong&gt; service to fetch the output data of the Pipeline.&lt;/p&gt;
&lt;p&gt;Following is a simple diagram of Pipeline to demonstrate about both the source and sink of Shabondi:&lt;/p&gt;















&lt;figure id=&#34;figure-shabondi-pipeline&#34;&gt;



  &lt;img src=&#34;../img/shabondi-pipeline.png&#34; alt=&#34;&#34;  &gt;



  
  
  &lt;figcaption&gt;
    Shabondi Pipeline
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;data-format&#34;&gt;Data format&lt;/h2&gt;
&lt;p&gt;Both Shabondi source and sink use 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/custom_connector/#datamodel&#34;&gt;Row&lt;/a&gt; in JSON format
for data input and output. Row is a table structure data defined in Ohara code base.
A row is comprised of multiple cells. Each cell has its &lt;strong&gt;name&lt;/strong&gt; and &lt;strong&gt;value&lt;/strong&gt;.
Every row of your input data will be stored in the &lt;strong&gt;Topic&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;A table:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;row #&lt;/th&gt;
&lt;th&gt;name&lt;/th&gt;
&lt;th&gt;age&lt;/th&gt;
&lt;th&gt;email&lt;/th&gt;
&lt;th&gt;career&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;(row 1)&lt;/td&gt;
&lt;td&gt;jason&lt;/td&gt;
&lt;td&gt;42&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;mailto:jason@example.com&#34;&gt;jason@example.com&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Surgeon&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;(row n)&lt;/td&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Example of row using Java:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import oharastream.ohara.common.data.Row;
import oharastream.ohara.common.data.Cell;
class ExampleOfRow {
    public static void main(String[] args) {
        Row row = Row.of(
                Cell.of(&amp;quot;name&amp;quot;, &amp;quot;jason&amp;quot;),
                Cell.of(&amp;quot;age&amp;quot;, &amp;quot;42&amp;quot;),
                Cell.of(&amp;quot;email&amp;quot;, &amp;quot;jason@example.com&amp;quot;),
                Cell.of(&amp;quot;career&amp;quot;, &amp;quot;Surgeon&amp;quot;)
                );
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Example of row in JSON format&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;jason&amp;quot;,
  &amp;quot;age&amp;quot;: 42,
  &amp;quot;email&amp;quot;: &amp;quot;jason@example.com&amp;quot;,
  &amp;quot;career&amp;quot;: &amp;quot;Surgeon&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;deployment&#34;&gt;Deployment&lt;/h2&gt;
&lt;p&gt;There are two ways to deploy Shabondi service&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ohara Manager: (TBD)&lt;/li&gt;
&lt;li&gt;Use Configurator 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/rest-api/shabondis/&#34;&gt;REST API&lt;/a&gt; to create
and start Shabondi service.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After a Shabondi service is properly configured, deploy and successfully started.
It&amp;rsquo;s ready to receive or send requests via HTTP.&lt;/p&gt;
&lt;h2 id=&#34;service-rest-api&#34;&gt;Service REST API&lt;/h2&gt;
&lt;p&gt;Shabondi source service receives single row message through HTTP
requests and then writes to the connected &lt;strong&gt;Topic&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;source-api&#34;&gt;Source API&lt;/h3&gt;
&lt;h4 id=&#34;send-row&#34;&gt;Send Row&lt;/h4&gt;
&lt;p&gt;Send a JSON data of 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/custom_connector/#datamodel&#34;&gt;Row&lt;/a&gt; to Shabondi source service.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Request&lt;br&gt;
POST /&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Request body&lt;br&gt;
The row data in JSON format&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example 1 (Succeed)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;POST http://node00:58456 HTTP/1.1
Content-Type: application/json

{
  &amp;quot;name&amp;quot;: &amp;quot;jason&amp;quot;,
  &amp;quot;age&amp;quot;: 42,
  &amp;quot;email&amp;quot;: &amp;quot;jason@example.com&amp;quot;,
  &amp;quot;career&amp;quot;: &amp;quot;Surgeon&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;HTTP/1.1 200 OK
Server: akka-http/10.1.11
Date: Tue, 19 May 2020 02:41:20 GMT
Content-Type: text/plain; charset=UTF-8
Content-Length: 2

OK
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example 2 (Failure)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{.http}&#34;&gt;GET http://node00:58456 HTTP/1.1
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;HTTP/1.1 405 Method Not Allowed
Server: akka-http/10.1.11
Date: Tue, 19 May 2020 02:45:56 GMT
Content-Type: text/plain; charset=UTF-8
Content-Length: 90
    
Unsupported method, please reference: https://oharastream.github.io/docs/master/shabondi/
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;sink-api&#34;&gt;Sink API&lt;/h3&gt;
&lt;p&gt;The Shabondi Sink service accepts the http request, and then reads the
rows from the connected &lt;strong&gt;Topic&lt;/strong&gt; and response it in JSON format.&lt;/p&gt;
&lt;h4 id=&#34;fetch-rows&#34;&gt;Fetch Rows&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Request&lt;br&gt;
GET /groups/$groupName&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Response&lt;br&gt;
The array of row in JSON format&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example 1 (Succeed)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;GET http://node00:58458/groups/g1 HTTP/1.1
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;HTTP/1.1 200 OK
Server: akka-http/10.1.11
Date: Wed, 20 May 2020 06:18:44 GMT
Content-Type: application/json
Content-Length: 115
    
[
  {
    &amp;quot;name&amp;quot;: &amp;quot;jason&amp;quot;,
    &amp;quot;age&amp;quot;: 42,
    &amp;quot;email&amp;quot;: &amp;quot;jason@example.com&amp;quot;,
    &amp;quot;career&amp;quot;: &amp;quot;Surgeon&amp;quot;
  },
  {
    &amp;quot;name&amp;quot;: &amp;quot;robert&amp;quot;,
    &amp;quot;age&amp;quot;: 36,
    &amp;quot;email&amp;quot;: &amp;quot;robert99@gmail.com&amp;quot;,
    &amp;quot;career&amp;quot;: &amp;quot;Teacher&amp;quot;
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example 2 - Failure response(Illegal group name)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;GET http://node00:58458/groups/g1-h HTTP/1.1
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;HTTP/1.1 406 Not Acceptable
Server: akka-http/10.1.11
Date: Wed, 20 May 2020 07:34:10 GMT
Content-Type: text/plain; charset=UTF-8
Content-Length: 50
    
Illegal group name, only accept alpha and numeric.
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Shabondi</title>
      <link>https://oharastream.github.io/en/docs/master/shabondi/</link>
      <pubDate>Tue, 16 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/master/shabondi/</guid>
      <description>&lt;p&gt;Shabondi service play the role of a &lt;em&gt;http proxy service&lt;/em&gt; in the Pipeline
of Ohara. If you want to integrate Ohara pipeline with your application,
Shabondi is a good choice. Just send the simple http request to
&lt;strong&gt;Shabondi source&lt;/strong&gt; service, you can hand over your data to Pipeline for
processing. On the other hand, you can send the http request to
&lt;strong&gt;Shabondi sink&lt;/strong&gt; service to fetch the output data of the Pipeline.&lt;/p&gt;
&lt;p&gt;Following is a simple diagram of Pipeline to demonstrate about both the source and sink of Shabondi:&lt;/p&gt;















&lt;figure id=&#34;figure-shabondi-pipeline&#34;&gt;



  &lt;img src=&#34;../img/shabondi-pipeline.png&#34; alt=&#34;&#34;  &gt;



  
  
  &lt;figcaption&gt;
    Shabondi Pipeline
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;data-format&#34;&gt;Data format&lt;/h2&gt;
&lt;p&gt;Both Shabondi source and sink use 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/custom_connector/#datamodel&#34;&gt;Row&lt;/a&gt; in JSON format
for data input and output. Row is a table structure data defined in Ohara code base.
A row is comprised of multiple cells. Each cell has its &lt;strong&gt;name&lt;/strong&gt; and &lt;strong&gt;value&lt;/strong&gt;.
Every row of your input data will be stored in the &lt;strong&gt;Topic&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;A table:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;row #&lt;/th&gt;
&lt;th&gt;name&lt;/th&gt;
&lt;th&gt;age&lt;/th&gt;
&lt;th&gt;email&lt;/th&gt;
&lt;th&gt;career&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;(row 1)&lt;/td&gt;
&lt;td&gt;jason&lt;/td&gt;
&lt;td&gt;42&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;mailto:jason@example.com&#34;&gt;jason@example.com&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Surgeon&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;(row n)&lt;/td&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Example of row using Java:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import oharastream.ohara.common.data.Row;
import oharastream.ohara.common.data.Cell;
class ExampleOfRow {
    public static void main(String[] args) {
        Row row = Row.of(
                Cell.of(&amp;quot;name&amp;quot;, &amp;quot;jason&amp;quot;),
                Cell.of(&amp;quot;age&amp;quot;, &amp;quot;42&amp;quot;),
                Cell.of(&amp;quot;email&amp;quot;, &amp;quot;jason@example.com&amp;quot;),
                Cell.of(&amp;quot;career&amp;quot;, &amp;quot;Surgeon&amp;quot;)
                );
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Example of row in JSON format&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;jason&amp;quot;,
  &amp;quot;age&amp;quot;: 42,
  &amp;quot;email&amp;quot;: &amp;quot;jason@example.com&amp;quot;,
  &amp;quot;career&amp;quot;: &amp;quot;Surgeon&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;deployment&#34;&gt;Deployment&lt;/h2&gt;
&lt;p&gt;There are two ways to deploy Shabondi service&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ohara Manager: (TBD)&lt;/li&gt;
&lt;li&gt;Use Configurator 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/rest-api/shabondis/&#34;&gt;REST API&lt;/a&gt; to create
and start Shabondi service.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After a Shabondi service is properly configured, deploy and successfully started.
It&amp;rsquo;s ready to receive or send requests via HTTP.&lt;/p&gt;
&lt;h2 id=&#34;service-rest-api&#34;&gt;Service REST API&lt;/h2&gt;
&lt;p&gt;Shabondi source service receives single row message through HTTP
requests and then writes to the connected &lt;strong&gt;Topic&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;source-api&#34;&gt;Source API&lt;/h3&gt;
&lt;h4 id=&#34;send-row&#34;&gt;Send Row&lt;/h4&gt;
&lt;p&gt;Send a JSON data of 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/custom_connector/#datamodel&#34;&gt;Row&lt;/a&gt; to Shabondi source service.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Request&lt;br&gt;
POST /&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Request body&lt;br&gt;
The row data in JSON format&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example 1 (Succeed)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;POST http://node00:58456 HTTP/1.1
Content-Type: application/json

{
  &amp;quot;name&amp;quot;: &amp;quot;jason&amp;quot;,
  &amp;quot;age&amp;quot;: 42,
  &amp;quot;email&amp;quot;: &amp;quot;jason@example.com&amp;quot;,
  &amp;quot;career&amp;quot;: &amp;quot;Surgeon&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;HTTP/1.1 200 OK
Server: akka-http/10.1.11
Date: Tue, 19 May 2020 02:41:20 GMT
Content-Type: text/plain; charset=UTF-8
Content-Length: 2

OK
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example 2 (Failure)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{.http}&#34;&gt;GET http://node00:58456 HTTP/1.1
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;HTTP/1.1 405 Method Not Allowed
Server: akka-http/10.1.11
Date: Tue, 19 May 2020 02:45:56 GMT
Content-Type: text/plain; charset=UTF-8
Content-Length: 90
    
Unsupported method, please reference: https://oharastream.github.io/docs/master/shabondi/
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;sink-api&#34;&gt;Sink API&lt;/h3&gt;
&lt;p&gt;The Shabondi Sink service accepts the http request, and then reads the
rows from the connected &lt;strong&gt;Topic&lt;/strong&gt; and response it in JSON format.&lt;/p&gt;
&lt;h4 id=&#34;fetch-rows&#34;&gt;Fetch Rows&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Request&lt;br&gt;
GET /groups/$groupName&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Response&lt;br&gt;
The array of row in JSON format&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example 1 (Succeed)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;GET http://node00:58458/groups/g1 HTTP/1.1
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;HTTP/1.1 200 OK
Server: akka-http/10.1.11
Date: Wed, 20 May 2020 06:18:44 GMT
Content-Type: application/json
Content-Length: 115
    
[
  {
    &amp;quot;name&amp;quot;: &amp;quot;jason&amp;quot;,
    &amp;quot;age&amp;quot;: 42,
    &amp;quot;email&amp;quot;: &amp;quot;jason@example.com&amp;quot;,
    &amp;quot;career&amp;quot;: &amp;quot;Surgeon&amp;quot;
  },
  {
    &amp;quot;name&amp;quot;: &amp;quot;robert&amp;quot;,
    &amp;quot;age&amp;quot;: 36,
    &amp;quot;email&amp;quot;: &amp;quot;robert99@gmail.com&amp;quot;,
    &amp;quot;career&amp;quot;: &amp;quot;Teacher&amp;quot;
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example 2 - Failure response(Illegal group name)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;GET http://node00:58458/groups/g1-h HTTP/1.1
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;HTTP/1.1 406 Not Acceptable
Server: akka-http/10.1.11
Date: Wed, 20 May 2020 07:34:10 GMT
Content-Type: text/plain; charset=UTF-8
Content-Length: 50
    
Illegal group name, only accept alpha and numeric.
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Contributing</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/contributing/</link>
      <pubDate>Mon, 15 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/contributing/</guid>
      <description>&lt;p&gt;All we love is only pull request so we have some rules used to make your
PR looks good for reviewers.&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Note that you should file a new issue to discuss the PR detail with us
before submitting a PR.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;quick-start&#34;&gt;Quick start&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Fork and clone the 
&lt;a href=&#34;https://github.com/oharastream/ohara&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;oharastream/ohara&lt;/a&gt; repo&lt;/li&gt;
&lt;li&gt;Install dependencies. See our 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/build/build-ohara/&#34;&gt;how_to_build_Ohara&lt;/a&gt; for
development machine setup&lt;/li&gt;
&lt;li&gt;Create a branch with your PR with:&lt;br&gt;
&lt;code&gt;git checkout -b ${your-branch-name}&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Push your PR to remote:&lt;br&gt;
&lt;code&gt;git push origin ${your-branch-name}&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Create the PR with GitHub web UI and wait for reviews from our committers&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;testing-commands-in-the-pull-request&#34;&gt;Testing commands in the pull request&lt;/h2&gt;
&lt;p&gt;These commands will come in handy when you want to test your PR on our QA(CI server). To start a QA run,
you can simply leave a comment with one of the following commands in the PR:&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Note that the comment should contain the exact command as listed below,
comments like &lt;strong&gt;Please retry my PR&lt;/strong&gt; or &lt;strong&gt;Bot, retry -fae&lt;/strong&gt; won&amp;rsquo;t work:
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;retry&lt;/code&gt;&lt;br&gt;
trigger a full QA run&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;retry -fae&lt;/code&gt;&lt;br&gt;
trigger a full QA run even if there&amp;rsquo;s fail test during the run&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;retry ${moduleName}&lt;/code&gt;&lt;br&gt;
trigger a QA run for a specific module. If a module is named &lt;strong&gt;ohara-awesome&lt;/strong&gt;, you can enter
&lt;code&gt;retry awesome&lt;/code&gt; to run the QA against this specific module. Note that the module prefix
&lt;strong&gt;ohara-&lt;/strong&gt; is not needed. Following are some examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;retry manager&lt;/code&gt;: run &lt;strong&gt;ohara-manager&lt;/strong&gt;&amp;rsquo;s unit test.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;retry configurator&lt;/code&gt;: run &lt;strong&gt;ohara-configurator&lt;/strong&gt;&amp;rsquo;s unit test.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ohara manager has a couple of different tests and can be run separately by using the
above-mentioned &lt;code&gt;retry&lt;/code&gt; command.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;retry manager-api&lt;/code&gt;: run manager&amp;rsquo;s API tests&lt;/li&gt;
&lt;li&gt;&lt;code&gt;retry manager-ut&lt;/code&gt;: run manager&amp;rsquo;s unit tests&lt;/li&gt;
&lt;li&gt;&lt;code&gt;retry manager-e2e&lt;/code&gt;: run manager&amp;rsquo;s end-to-end tests&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;run&lt;/code&gt;: start both Configurator and Manager on jenkins server. If the specified PR makes
some changes to UI, you can run this command to see the changes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The QA build status can be seen at the bottom of your PR.&lt;/p&gt;
&lt;h2 id=&#34;important-things-about-pull-request&#34;&gt;Important things about pull request&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;A pull request must&amp;hellip;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Pass all tests&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Your PR should not make ohara unstable, if it does. It should be reverted ASAP.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You can either run these tests on your local
(see our 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/build/build-ohara/&#34;&gt;how_to_build_Ohara&lt;/a&gt; for more
info on how to run tests) or by opening the PR on our repo. These tests will be running
on your CI server.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pass code style check. You can automatically fix these issues with a
single command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ./gradlew spotlessApply
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Address all reviewers&amp;rsquo; comments&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;A pull request should&amp;hellip;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Be as small in scope as possible. Large PR is often hard to review.&lt;/li&gt;
&lt;li&gt;Add new tests&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;A pull request should not&amp;hellip;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bring in new libraries (or updating libraries to new version) without prior discussion.
Do not update the dependencies unless you have a good reason.&lt;/li&gt;
&lt;li&gt;Bring in the new module without prior discussion&lt;/li&gt;
&lt;li&gt;Bring in new APIs for Configurator without prior discussion&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Contributing</title>
      <link>https://oharastream.github.io/en/docs/master/contributing/</link>
      <pubDate>Mon, 15 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/master/contributing/</guid>
      <description>&lt;p&gt;All we love is only pull request so we have some rules used to make your
PR looks good for reviewers.&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Note that you should file a new issue to discuss the PR detail with us
before submitting a PR.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;quick-start&#34;&gt;Quick start&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Fork and clone the 
&lt;a href=&#34;https://github.com/oharastream/ohara&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;oharastream/ohara&lt;/a&gt; repo&lt;/li&gt;
&lt;li&gt;Install dependencies. See our 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/build/build-ohara/&#34;&gt;how_to_build_Ohara&lt;/a&gt; for
development machine setup&lt;/li&gt;
&lt;li&gt;Create a branch with your PR with:&lt;br&gt;
&lt;code&gt;git checkout -b ${your-branch-name}&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Push your PR to remote:&lt;br&gt;
&lt;code&gt;git push origin ${your-branch-name}&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Create the PR with GitHub web UI and wait for reviews from our committers&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;testing-commands-in-the-pull-request&#34;&gt;Testing commands in the pull request&lt;/h2&gt;
&lt;p&gt;These commands will come in handy when you want to test your PR on our QA(CI server). To start a QA run,
you can simply leave a comment with one of the following commands in the PR:&lt;/p&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Note that the comment should contain the exact command as listed below,
comments like &lt;strong&gt;Please retry my PR&lt;/strong&gt; or &lt;strong&gt;Bot, retry -fae&lt;/strong&gt; won&amp;rsquo;t work:
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;retry&lt;/code&gt;&lt;br&gt;
trigger a full QA run&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;retry -fae&lt;/code&gt;&lt;br&gt;
trigger a full QA run even if there&amp;rsquo;s fail test during the run&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;retry ${moduleName}&lt;/code&gt;&lt;br&gt;
trigger a QA run for a specific module. If a module is named &lt;strong&gt;ohara-awesome&lt;/strong&gt;, you can enter
&lt;code&gt;retry awesome&lt;/code&gt; to run the QA against this specific module. Note that the module prefix
&lt;strong&gt;ohara-&lt;/strong&gt; is not needed. Following are some examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;retry manager&lt;/code&gt;: run &lt;strong&gt;ohara-manager&lt;/strong&gt;&amp;rsquo;s unit test.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;retry configurator&lt;/code&gt;: run &lt;strong&gt;ohara-configurator&lt;/strong&gt;&amp;rsquo;s unit test.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ohara manager has a couple of different tests and can be run separately by using the
above-mentioned &lt;code&gt;retry&lt;/code&gt; command.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;retry manager-api&lt;/code&gt;: run manager&amp;rsquo;s API tests&lt;/li&gt;
&lt;li&gt;&lt;code&gt;retry manager-ut&lt;/code&gt;: run manager&amp;rsquo;s unit tests&lt;/li&gt;
&lt;li&gt;&lt;code&gt;retry manager-e2e&lt;/code&gt;: run manager&amp;rsquo;s end-to-end tests&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;run&lt;/code&gt;: start both Configurator and Manager on jenkins server. If the specified PR makes
some changes to UI, you can run this command to see the changes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The QA build status can be seen at the bottom of your PR.&lt;/p&gt;
&lt;h2 id=&#34;important-things-about-pull-request&#34;&gt;Important things about pull request&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;A pull request must&amp;hellip;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Pass all tests&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Your PR should not make ohara unstable, if it does. It should be reverted ASAP.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You can either run these tests on your local
(see our 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/build/build-ohara/&#34;&gt;how_to_build_Ohara&lt;/a&gt; for more
info on how to run tests) or by opening the PR on our repo. These tests will be running
on your CI server.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pass code style check. You can automatically fix these issues with a
single command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ./gradlew spotlessApply
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Address all reviewers&amp;rsquo; comments&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;A pull request should&amp;hellip;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Be as small in scope as possible. Large PR is often hard to review.&lt;/li&gt;
&lt;li&gt;Add new tests&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;A pull request should not&amp;hellip;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bring in new libraries (or updating libraries to new version) without prior discussion.
Do not update the dependencies unless you have a good reason.&lt;/li&gt;
&lt;li&gt;Bring in the new module without prior discussion&lt;/li&gt;
&lt;li&gt;Bring in new APIs for Configurator without prior discussion&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>FTP to Topic to Stream to HDFS</title>
      <link>https://oharastream.github.io/en/testcases/pipeline-ftp-topic-stream-hdfs/</link>
      <pubDate>Mon, 15 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/testcases/pipeline-ftp-topic-stream-hdfs/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#create-a-new-workspace-with-three-nodes&#34;&gt;Create a new workspace with three nodes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#create-two-topic-and-upload-a-stream-app-jar-into-the-workspace&#34;&gt;Create two topic and upload a stream app jar into the workspace&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#create-a-new-pipeline--add-some-connectors--topics-and-a-stream-app&#34;&gt;Create a new pipeline, add some connectors, topics and a stream app&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#ftp-source---topic---stream---topic---hdfs-sink&#34;&gt;FTP source -&amp;gt; Topic -&amp;gt; Stream -&amp;gt; Topic -&amp;gt; HDFS sink&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#prepare-the-required-folders-and-test-data-on-the-ftp-server&#34;&gt;Prepare the required folders and test data on the FTP server&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#start-all-connectors-and-stream-app&#34;&gt;Start all connectors and stream app&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#verify-which-test-data-was-successfully-dumped-to-hdfs&#34;&gt;Verify which test data was successfully dumped to HDFS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;create-a-new-workspace-with-three-nodes&#34;&gt;Create a new workspace with three nodes&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Add three nodes:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;On the Nodes page, click the &lt;kbd&gt;NEW NODE&lt;/kbd&gt; button.&lt;/li&gt;
&lt;li&gt;Enter &lt;code&gt;&amp;lt;ohara_node_host&amp;gt;&lt;/code&gt; in the &lt;strong&gt;Node&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Enter &lt;code&gt;&amp;lt;ohara_node_port&amp;gt;&lt;/code&gt; in the &lt;strong&gt;Port&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Enter &lt;code&gt;&amp;lt;node_user&amp;gt;&lt;/code&gt; in the &lt;strong&gt;User&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Enter &lt;code&gt;&amp;lt;node_password&amp;gt;&lt;/code&gt; in the &lt;strong&gt;Password&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Click &lt;kbd&gt;TEST CONNECTION&lt;/kbd&gt; to test your connection.&lt;/li&gt;
&lt;li&gt;If the test passes, click &lt;kbd&gt;ADD&lt;/kbd&gt;.&lt;/li&gt;
&lt;li&gt;Repeat the above steps to add &lt;strong&gt;three nodes&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Create a new workspace:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;On the Workspaces page, click the &lt;kbd&gt;NEW WORKSPACE&lt;/kbd&gt; button.&lt;/li&gt;
&lt;li&gt;Enter “wk00” in the &lt;strong&gt;Name&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Select all available nodes from the Node List.&lt;/li&gt;
&lt;li&gt;Click &lt;kbd&gt;ADD&lt;/kbd&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;create-two-topics-and-upload-a-stream-app-jar-in-the-workspace&#34;&gt;Create two topics and upload a stream app jar in the workspace&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Add two topics:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;On the &lt;strong&gt;Workspaces&lt;/strong&gt; &amp;gt; &lt;strong&gt;wk00&lt;/strong&gt; &amp;gt; &lt;strong&gt;TOPICS&lt;/strong&gt; tab, click the &lt;kbd&gt;NEW TOPIC&lt;/kbd&gt; button.&lt;/li&gt;
&lt;li&gt;Enter “t1” in the &lt;strong&gt;Topic name&lt;/strong&gt; field and enter default value in other fields, click &lt;kbd&gt;ADD&lt;/kbd&gt;.&lt;/li&gt;
&lt;li&gt;Enter “t2” in the &lt;strong&gt;Topic name&lt;/strong&gt; field and enter default value in other fields, click &lt;kbd&gt;ADD&lt;/kbd&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Add a stream jar:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;On the &lt;strong&gt;Workspaces&lt;/strong&gt; &amp;gt; &lt;strong&gt;wk00&lt;/strong&gt; &amp;gt; &lt;strong&gt;STREAM JARS&lt;/strong&gt; tab, click the &lt;kbd&gt;NEW JAR&lt;/kbd&gt; button.&lt;/li&gt;
&lt;li&gt;Browse to the location of your jar file &lt;code&gt;ohara-it-stream.jar&lt;/code&gt;, click the file, and click &lt;kbd&gt;Open&lt;/kbd&gt;.
&lt;blockquote&gt;
&lt;p&gt;if You don&amp;rsquo;t know how to build a stream app jar, see this 
&lt;a href=&#34;#how-to-get-ohara-it-streamjar&#34;&gt;link&lt;/a&gt; for how&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;create-a-new-pipeline-add-some-connectors-topics-and-a-stream-app&#34;&gt;Create a new pipeline, add some connectors, topics and a stream app&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;On the &lt;strong&gt;Pipelines&lt;/strong&gt; list page, click the &lt;kbd&gt;NEW PIPELINE&lt;/kbd&gt; button.&lt;/li&gt;
&lt;li&gt;Enter “firstpipeline” in the &lt;strong&gt;Pipeline name&lt;/strong&gt; field and select “wk00” from the Workspace name dropdown. Then, click &lt;kbd&gt;ADD&lt;/kbd&gt;.&lt;/li&gt;
&lt;li&gt;Click the &lt;strong&gt;Add a source connector&lt;/strong&gt; icon and select &lt;strong&gt;oharastream.ohara.connector.ftp.FTPSource&lt;/strong&gt; from the list, then click &lt;kbd&gt;ADD&lt;/kbd&gt;.&lt;/li&gt;
&lt;li&gt;Enter “ftpsource” in the &lt;strong&gt;myconnector&lt;/strong&gt; field and click &lt;kbd&gt;ADD&lt;/kbd&gt;.&lt;/li&gt;
&lt;li&gt;Click the &lt;strong&gt;Add a topic&lt;/strong&gt; icon and select &lt;strong&gt;t1&lt;/strong&gt; from the dropdown and click &lt;kbd&gt;ADD&lt;/kbd&gt;.&lt;/li&gt;
&lt;li&gt;Click the &lt;strong&gt;Add a stream app&lt;/strong&gt; icon and select &lt;strong&gt;ohara-it-stream.jar&lt;/strong&gt; from the dropdown, then click &lt;kbd&gt;ADD&lt;/kbd&gt;.&lt;/li&gt;
&lt;li&gt;Enter “dumb” in the &lt;strong&gt;mystream&lt;/strong&gt; field and click &lt;kbd&gt;ADD&lt;/kbd&gt;.&lt;/li&gt;
&lt;li&gt;Click the &lt;strong&gt;Add a topic&lt;/strong&gt; icon and select &lt;strong&gt;t2&lt;/strong&gt; from the dropdown, then click &lt;kbd&gt;ADD&lt;/kbd&gt;.&lt;/li&gt;
&lt;li&gt;Click the &lt;strong&gt;Add a sink connector&lt;/strong&gt; icon and select &lt;strong&gt;oharastream.ohara.connector.hdfs.sink.HDFSSink&lt;/strong&gt; from the list, then click &lt;kbd&gt;ADD&lt;/kbd&gt;.&lt;/li&gt;
&lt;li&gt;Enter “hdfssink” in the &lt;strong&gt;myconnector&lt;/strong&gt; field and click &lt;kbd&gt;ADD&lt;/kbd&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;ftp-source---topic---stream---topic---hdfs-sink&#34;&gt;FTP source -&amp;gt; Topic -&amp;gt; Stream -&amp;gt; Topic -&amp;gt; HDFS sink&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Set up ftpsource connector:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;On the &lt;strong&gt;firstpipeline&lt;/strong&gt; page, click the &lt;strong&gt;ftpsource&lt;/strong&gt; graph in the pipeline graph.&lt;/li&gt;
&lt;li&gt;Select the &lt;strong&gt;COMMON&lt;/strong&gt; tab and fill out the following config:
&lt;ol&gt;
&lt;li&gt;Enter “/demo/input” in the &lt;strong&gt;Input Folder&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Enter “/demo/completed” in the &lt;strong&gt;Completed Folder&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Enter “/demo/error” in the &lt;strong&gt;Error Folder&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Enter &lt;code&gt;&amp;lt;ftp_server_ip&amp;gt;&lt;/code&gt; in the &lt;strong&gt;Hostname of Ftp Server&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Enter &lt;code&gt;&amp;lt;ftp_server_port&amp;gt;&lt;/code&gt; in the &lt;strong&gt;Port of Ftp Server&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Enter &lt;code&gt;ftp_username&lt;/code&gt; in the &lt;strong&gt;User of Ftp Server&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Enter &lt;code&gt;ftp_password&lt;/code&gt; in the &lt;strong&gt;Password of Ftp Server&lt;/strong&gt; field.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Select the &lt;strong&gt;CORE&lt;/strong&gt; tab and choose &lt;strong&gt;t1&lt;/strong&gt; from the &lt;strong&gt;Topics&lt;/strong&gt; dropdown.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Set up &lt;strong&gt;dumb&lt;/strong&gt; stream app:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Click the &lt;strong&gt;dumb&lt;/strong&gt; graph in the pipeline graph.&lt;/li&gt;
&lt;li&gt;Enter “ohara1” to &lt;strong&gt;filter value&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Click the &lt;strong&gt;CORE&lt;/strong&gt; tab.&lt;/li&gt;
&lt;li&gt;Select &lt;strong&gt;t1&lt;/strong&gt; from the &lt;strong&gt;From topic of data consuming from&lt;/strong&gt; dropdown.&lt;/li&gt;
&lt;li&gt;Select &lt;strong&gt;t2&lt;/strong&gt; from the &lt;strong&gt;To topic of data produce to&lt;/strong&gt; dropdown.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Set up hdfssink connector:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Click the &lt;strong&gt;hdfssink&lt;/strong&gt; graph in the pipeline graph.&lt;/li&gt;
&lt;li&gt;Select the &lt;strong&gt;COMMON&lt;/strong&gt; tab and fill out the following config:
&lt;ol&gt;
&lt;li&gt;Enter “/data“ in the Output Folder field&lt;/li&gt;
&lt;li&gt;Change &lt;strong&gt;Flush Size&lt;/strong&gt; value from “1000” to “5”&lt;/li&gt;
&lt;li&gt;Check the &lt;strong&gt;File Need Header&lt;/strong&gt; checkbox&lt;/li&gt;
&lt;li&gt;Enter “hdfs://&lt;code&gt;&amp;lt;hdfs_host&amp;gt;&lt;/code&gt;:&lt;code&gt;&amp;lt;hdfs_port&amp;gt;&lt;/code&gt;” in the &lt;strong&gt;HDSF URL&lt;/strong&gt; field&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Select the &lt;strong&gt;CORE&lt;/strong&gt; tab and choose &lt;strong&gt;t2&lt;/strong&gt; from the &lt;strong&gt;Topics&lt;/strong&gt; dropdown.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;prepare-the-required-folders-and-test-data-on-the-ftp-server&#34;&gt;Prepare the required folders and test data on the FTP server&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Open a terminal, login to FTP server (or use a FTP client of your choice)&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;$ ftp `ftp_server_ip`
Name: `ftp_username`
Password: `ftp_password`
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Create the following folders on your FTP server&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;ftp&amp;gt; mkdir demo
ftp&amp;gt; cd demo
ftp&amp;gt; mkdir input
ftp&amp;gt; mkdir completed
ftp&amp;gt; mkdir error
ftp&amp;gt; bye
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Copy the test file &lt;code&gt;demo.csv&lt;/code&gt; to &lt;strong&gt;demo/input&lt;/strong&gt; folder. See this 
&lt;a href=&#34;#how-to-create-democsv&#34;&gt;link&lt;/a&gt; to create demo CSV files&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;start-all-connectors-and-stream-app&#34;&gt;Start all connectors and stream app&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;On the &lt;strong&gt;firstpipeline&lt;/strong&gt; page.&lt;/li&gt;
&lt;li&gt;Click the &lt;strong&gt;Start pipeline&lt;/strong&gt; icon.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;verify-which-test-data-was-successfully-dumped-to-hdfs&#34;&gt;Verify which test data was successfully dumped to HDFS&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Open a terminal and ssh to HDFS server.&lt;/li&gt;
&lt;li&gt;List all CSV files in &lt;strong&gt;/data/wk00-t2/partition0&lt;/strong&gt; folder:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ hdfs dfs -ls /data/wk00-t2/partition0

# You should see something similar like this in your terminal:
/data/wk00-t2/partition0/part-000000000-000000005.csv
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;View the content of &lt;strong&gt;part-000000000-000000005.csv&lt;/strong&gt;:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ hdfs dfs -cat /data/wk00-t2/partition0/part-000000000-000000005.csv

# The result should be like the following:
ID,NAME,CREATE_AT
1,ohara1,2019-03-01 00:00:01
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;how-to-create-democsv&#34;&gt;How to create demo.csv?&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Create the txt copy the date save to demo.csv&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;ID,NAME,CREATE_AT
1,ohara1,2019-03-01 00:00:01
2,ohara2,2019-03-01 00:00:02
3,ohara3,2019-03-01 00:00:03
4,ohara4,2019-03-01 00:00:04
5,ohara5,2019-03-01 00:00:05
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;how-to-get-ohara-it-streamjar&#34;&gt;How to get ohara-it-stream.jar?&lt;/h2&gt;
&lt;p&gt;Open a new terminal from your machine and go to Ohara&amp;rsquo;s source folder.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd ohara/
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then &lt;code&gt;cd&lt;/code&gt; to Stream DumbStream source folder.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd ohara-it/src/main/scala/oharastream/ohara/it/stream/
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Use Vi to edit &lt;strong&gt;DumbStream.scala&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;vi DumbStream.scala
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Enter &amp;ldquo;I&amp;rdquo; key from your keyboard to activate the &amp;ldquo;INSERT&amp;rdquo; mode&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;-- INSERT --
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Overwrite DumbStream class from&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class DumbStream extends Stream {

  override def start(ostream: OStream[Row], configs: StreamDefinitions): Unit = {

    // do nothing but only start stream and write exactly data to output topic
    ostream.start()
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/*
 * Copyright 2019 is-land
 *
 * Licensed under the Apache License, Version 2.0 (the &amp;quot;License&amp;quot;);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &amp;quot;AS IS&amp;quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package oharastream.ohara.it.stream
import oharastream.ohara.common.data.Row
import oharastream.ohara.common.setting.SettingDef
import oharastream.ohara.stream.config.StreamSetting
import oharastream.ohara.stream.{OStream, Stream}

class DumbStream extends Stream {

  override def config(): StreamDefinitions = StreamDefinitions
    .`with`(
      SettingDef
        .builder()
        .key(&amp;quot;filterValue&amp;quot;)
        .displayName(&amp;quot;filter value&amp;quot;)
        .documentation(&amp;quot;filter the row that contains this value&amp;quot;)
        .build())

  override def start(ostream: OStream[Row], configs: StreamDefinitions): Unit = {

    ostream
      // we filter row which the cell values contain the pre-defined &amp;quot;filterValue&amp;quot;. Note:
      // 1) configs.string(&amp;quot;filterValue&amp;quot;) will try to get the value from env and it should NOT be null
      // 2) we ignore case for the value (i.e., &amp;quot;aa&amp;quot; = &amp;quot;AA&amp;quot;)
      .filter(
      r =&amp;gt;
        r.cells()
          .stream()
          .anyMatch(c =&amp;gt; {
            c.value().toString.equalsIgnoreCase(configs.string(&amp;quot;filterValue&amp;quot;))
          }))
      .start()
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &amp;ldquo;Esc&amp;rdquo; key to leave the insert mode and enter &lt;code&gt;:wq&lt;/code&gt; to save and exit from this file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;:wq
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Build stream jar&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# Make sure you&#39;re at the project root `/ohara`, then build the jar with:
./gradlew clean :ohara-it:jar -PskipManager
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Go to stream jar folder and list the jars that you have&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd ohara-it/build/libs/ &amp;amp;&amp;amp; ls

# You should see something like this in your terminal:
ohara-it-sink.jar ohara-it-source.jar ohara-it-stream.jar
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>How to build Ohara</title>
      <link>https://oharastream.github.io/en/docs/0.11.x/build/build-ohara/</link>
      <pubDate>Mon, 15 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/0.11.x/build/build-ohara/</guid>
      <description>&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;OpenJDK 11&lt;/li&gt;
&lt;li&gt;Scala 2.13.2&lt;/li&gt;
&lt;li&gt;Gradle 6.5&lt;/li&gt;
&lt;li&gt;Node.js 8.12.0&lt;/li&gt;
&lt;li&gt;Yarn 1.13.0 or greater&lt;/li&gt;
&lt;li&gt;Docker 19.03.8 (Docker multi-stage, which is supported by Docker 17.05 or higher, is required in building ohara images. see 
&lt;a href=&#34;https://docs.docker.com/develop/develop-images/multistage-build/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Use multi-stage builds&lt;/a&gt; for more details)&lt;/li&gt;
&lt;li&gt;Kubernetes 1.18.1 (Official QA uses the Kubernetes version is 1.18.1)&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;gradle-commands&#34;&gt;Gradle Commands&lt;/h2&gt;
&lt;p&gt;Ohara build is based on 
&lt;a href=&#34;https://gradle.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;gradle&lt;/a&gt;. Ohara has defined many gradle tasks to simplify the development of Ohara.&lt;/p&gt;
&lt;h3 id=&#34;build-binary&#34;&gt;Build Binary&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ./gradlew clean build -x test
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    the tar file is located at ohara-${module}/build/distributions
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;run-all-uts&#34;&gt;Run All UTs&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ./gradlew clean test
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Ohara IT tests requires specific envs, and all IT tests will be skipped if you don&amp;rsquo;t pass the related setting to IT. Ohara recommends you testing your code on &lt;a href=&#34;https://builds.is-land.com.tw/job/PreCommit-OHARA/&#34;&gt;official QA&lt;/a&gt; which offers the powerful machine and IT envs.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    add flag &amp;ldquo;-PskipManager&amp;rdquo; to skip the tests of Ohara Manager. Ohara Manager is a module in charge of Ohara UI. Feel free to skip it if you are totally a backend developer. By the way, the prerequisites of testing Ohara Manager is shown in &lt;code&gt;here &amp;lt;managerdev&amp;gt;&lt;/code&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    add flag &amp;ldquo;-PmaxParallelForks=6&amp;rdquo; to increase the number of test process to start in parallel. The default value is number of cores / 2, and noted that too many tests running in parallel may easily
produce tests timeout.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;code-style-auto-apply&#34;&gt;Code Style Auto-Apply&lt;/h3&gt;
&lt;p&gt;Use this task to make sure your added code will have the same format and conventions with the rest of codebase.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{.console}&#34;&gt;$ ./gradlew spotlessApply
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    we have this style check in early QA build.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;license-auto-apply&#34;&gt;License Auto-Apply&lt;/h3&gt;
&lt;p&gt;If you have added any new files in a PR. This task will automatically insert an Apache 2.0 license header in each one of these newly created files&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ./gradlew licenseApply
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Note that a file without the license header will fail at early QA build
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;publish-artifacts&#34;&gt;Publish Artifacts&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ./gradlew clean bintrayUpload -PskipManager -PbintrayUser=$user -PbintrayKey=$key
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;ul&gt;
&lt;li&gt;bintrayUser: the account that has write permission to the
repository&lt;/li&gt;
&lt;li&gt;bintrayKey: the account API Key&lt;/li&gt;
&lt;li&gt;public: whether to auto published after uploading. default is
false&lt;/li&gt;
&lt;li&gt;override: whether to override version artifacts already
published. default is false&lt;/li&gt;
&lt;/ul&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: Only release manager has permission to upload artifacts&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;publish-artifacts-1&#34;&gt;Publish Artifacts&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ./gradlew clean build publishToMavenLocal -PskipManager -x test
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;
&lt;p&gt;see 
&lt;a href=&#34;https://oharastream.github.io/en/docs/0.11.x/user_guide/&#34;&gt;User Guide&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to build Ohara</title>
      <link>https://oharastream.github.io/en/docs/master/build/build-ohara/</link>
      <pubDate>Mon, 15 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/master/build/build-ohara/</guid>
      <description>&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;OpenJDK 11&lt;/li&gt;
&lt;li&gt;Scala 2.13.2&lt;/li&gt;
&lt;li&gt;Gradle 6.5&lt;/li&gt;
&lt;li&gt;Node.js 8.12.0&lt;/li&gt;
&lt;li&gt;Yarn 1.13.0 or greater&lt;/li&gt;
&lt;li&gt;Docker 19.03.8 (Docker multi-stage, which is supported by Docker 17.05 or higher, is required in building ohara images. see 
&lt;a href=&#34;https://docs.docker.com/develop/develop-images/multistage-build/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Use multi-stage builds&lt;/a&gt; for more details)&lt;/li&gt;
&lt;li&gt;Kubernetes 1.18.1 (Official QA uses the Kubernetes version is 1.18.1)&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;gradle-commands&#34;&gt;Gradle Commands&lt;/h2&gt;
&lt;p&gt;Ohara build is based on 
&lt;a href=&#34;https://gradle.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;gradle&lt;/a&gt;. Ohara has defined many gradle tasks to simplify the development of Ohara.&lt;/p&gt;
&lt;h3 id=&#34;build-binary&#34;&gt;Build Binary&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ./gradlew clean build -x test
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    the tar file is located at ohara-${module}/build/distributions
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;run-all-uts&#34;&gt;Run All UTs&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ./gradlew clean test
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Ohara IT tests requires specific envs, and all IT tests will be skipped if you don&amp;rsquo;t pass the related setting to IT. Ohara recommends you testing your code on &lt;a href=&#34;https://builds.is-land.com.tw/job/PreCommit-OHARA/&#34;&gt;official QA&lt;/a&gt; which offers the powerful machine and IT envs.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    add flag &amp;ldquo;-PskipManager&amp;rdquo; to skip the tests of Ohara Manager. Ohara Manager is a module in charge of Ohara UI. Feel free to skip it if you are totally a backend developer. By the way, the prerequisites of testing Ohara Manager is shown in &lt;code&gt;here &amp;lt;managerdev&amp;gt;&lt;/code&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    add flag &amp;ldquo;-PmaxParallelForks=6&amp;rdquo; to increase the number of test process to start in parallel. The default value is number of cores / 2, and noted that too many tests running in parallel may easily
produce tests timeout.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;code-style-auto-apply&#34;&gt;Code Style Auto-Apply&lt;/h3&gt;
&lt;p&gt;Use this task to make sure your added code will have the same format and conventions with the rest of codebase.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{.console}&#34;&gt;$ ./gradlew spotlessApply
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    we have this style check in early QA build.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;license-auto-apply&#34;&gt;License Auto-Apply&lt;/h3&gt;
&lt;p&gt;If you have added any new files in a PR. This task will automatically insert an Apache 2.0 license header in each one of these newly created files&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ./gradlew licenseApply
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    Note that a file without the license header will fail at early QA build
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;publish-artifacts&#34;&gt;Publish Artifacts&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ./gradlew clean bintrayUpload -PskipManager -PbintrayUser=$user -PbintrayKey=$key
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;ul&gt;
&lt;li&gt;bintrayUser: the account that has write permission to the
repository&lt;/li&gt;
&lt;li&gt;bintrayKey: the account API Key&lt;/li&gt;
&lt;li&gt;public: whether to auto published after uploading. default is
false&lt;/li&gt;
&lt;li&gt;override: whether to override version artifacts already
published. default is false&lt;/li&gt;
&lt;/ul&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: Only release manager has permission to upload artifacts&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;publish-artifacts-1&#34;&gt;Publish Artifacts&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;$ ./gradlew clean build publishToMavenLocal -PskipManager -x test
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;
&lt;p&gt;see 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/user_guide/&#34;&gt;User Guide&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>JDBC to Topic to FTP</title>
      <link>https://oharastream.github.io/en/testcases/pipeline-jdbc-topic-ftp/</link>
      <pubDate>Mon, 15 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/testcases/pipeline-jdbc-topic-ftp/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#create-a-new-workspace-with-three-nodes&#34;&gt;Create a new workspace with three nodes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#create-a-new-topic-in-the-workspace&#34;&gt;Create new topic into the workspace&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#create-a-new-pipeline-add-a-jdbc-source-connector-topics-and-a-ftp-sink-connector&#34;&gt;Create a new pipeline, add a jdbc source connector, topics and a ftp sink connector&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#%e9%80%a3%e6%8e%a5-jdbc-source---topic---ftp-sink&#34;&gt;連接 JDBC source -&amp;gt; Topic -&amp;gt; FTP sink&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#prepare-the-required-table-and-data-on-the-postgresql-server&#34;&gt;Prepare the required table and data on the PostgreSQL server&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#prepare-the-required-output-folder-on-the-ftp-server&#34;&gt;Prepare the required output folder on the FTP server&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#start-all-connectors-on-the-secondpipeline-page&#34;&gt;Start all connectors on the secondpipeline page&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#verify-which-test-data-was-successfully-dumped-to-ftp-server&#34;&gt;Verify which test data was successfully dumped to FTP server&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;create-a-new-workspace-with-three-nodes&#34;&gt;Create a new workspace with three nodes&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Add three nodes:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;On the Nodes page, click the &lt;kbd&gt;NEW NODE&lt;/kbd&gt; button.&lt;/li&gt;
&lt;li&gt;Enter &lt;code&gt;&amp;lt;ohara_node_host&amp;gt;&lt;/code&gt; in the &lt;strong&gt;Node&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Enter &lt;code&gt;&amp;lt;ohara_node_port&amp;gt;&lt;/code&gt; in the &lt;strong&gt;Port&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Enter &lt;code&gt;&amp;lt;node_user&amp;gt;&lt;/code&gt; in the &lt;strong&gt;User&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Enter &lt;code&gt;&amp;lt;node_password&amp;gt;&lt;/code&gt; in the &lt;strong&gt;Password&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Click &lt;kbd&gt;TEST CONNECTION&lt;/kbd&gt; to test your connection.&lt;/li&gt;
&lt;li&gt;If the test passes, click &lt;kbd&gt;ADD&lt;/kbd&gt;.&lt;/li&gt;
&lt;li&gt;Repeat the above steps to add &lt;strong&gt;three nodes&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Create a new workspace:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;On the Workspaces page, click the &lt;kbd&gt;NEW WORKSPACE&lt;/kbd&gt; button.&lt;/li&gt;
&lt;li&gt;Enter “wk01” in the &lt;strong&gt;Name&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Select all available nodes from the Node List.&lt;/li&gt;
&lt;li&gt;Add plugins:
&lt;ol&gt;
&lt;li&gt;Click the &lt;kbd&gt;NEW PLUGIN&lt;/kbd&gt; button.&lt;/li&gt;
&lt;li&gt;Select &lt;code&gt;postgresql-9.1-901-1.jdbc4.jar&lt;/code&gt; form your disk (download the jar 
&lt;a href=&#34;https://repo1.maven.org/maven2/postgresql/postgresql/9.1-901-1.jdbc4/postgresql-9.1-901-1.jdbc4.jar&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;), the jar should be displayed in the &lt;strong&gt;Plugin List&lt;/strong&gt;, make sure you check the jar you just uploaded.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Click &lt;kbd&gt;ADD&lt;/kbd&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;create-a-new-topic-in-the-workspace&#34;&gt;Create a new topic in the workspace&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Add a new topic:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;On the &lt;strong&gt;Workspaces&lt;/strong&gt; &amp;gt; &lt;strong&gt;wk01&lt;/strong&gt; &amp;gt; &lt;strong&gt;TOPICS&lt;/strong&gt; tab, click the &lt;kbd&gt;NEW TOPIC&lt;/kbd&gt; button.&lt;/li&gt;
&lt;li&gt;Enter “t3” in the &lt;strong&gt;Topic name&lt;/strong&gt; field and enter default value in other fields, click &lt;kbd&gt;ADD&lt;/kbd&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;create-a-new-pipeline-add-a-jdbc-source-connector-topics-and-a-ftp-sink-connector&#34;&gt;Create a new pipeline, add a jdbc source connector, topics and a ftp sink connector&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;On the &lt;strong&gt;Pipelines&lt;/strong&gt; list page, click the &lt;kbd&gt;NEW PIPLINE&lt;/kbd&gt; button.&lt;/li&gt;
&lt;li&gt;Enter “secondpipeline” in the &lt;strong&gt;Pipeline name&lt;/strong&gt; field and select “wk01” from the Workspace name dropdown. Then, click &lt;kbd&gt;ADD&lt;/kbd&gt;.&lt;/li&gt;
&lt;li&gt;Click the &lt;strong&gt;Add a source connector&lt;/strong&gt; icon and select &lt;strong&gt;oharastream.ohara.connector.jdbc.source.JDBCSourceConnector&lt;/strong&gt; from the list, then click &lt;kbd&gt;ADD&lt;/kbd&gt;.&lt;/li&gt;
&lt;li&gt;Enter “jdbcsource” in the &lt;strong&gt;myconnector&lt;/strong&gt; field and click &lt;kbd&gt;ADD&lt;/kbd&gt;.&lt;/li&gt;
&lt;li&gt;Click the &lt;strong&gt;Add a topic&lt;/strong&gt; icon and select &lt;strong&gt;t3&lt;/strong&gt; from the dropdown and click &lt;kbd&gt;ADD&lt;/kbd&gt;.&lt;/li&gt;
&lt;li&gt;Click the &lt;strong&gt;Add a sink connector&lt;/strong&gt; icon and select &lt;strong&gt;oharastream.ohara.connector.ftp.FtpSink&lt;/strong&gt; from the list, then click &lt;kbd&gt;ADD&lt;/kbd&gt;.&lt;/li&gt;
&lt;li&gt;Enter “ftpsink” in the &lt;strong&gt;myconnector&lt;/strong&gt; field and click &lt;kbd&gt;ADD&lt;/kbd&gt; button.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;連接-jdbc-source---topic---ftp-sink&#34;&gt;連接 JDBC source -&amp;gt; Topic -&amp;gt; FTP sink&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Set up jdbcsource connector:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;On the &lt;strong&gt;secondpipeline&lt;/strong&gt; page, click the &lt;strong&gt;jdbcsource&lt;/strong&gt; graph in the pipeline graph.&lt;/li&gt;
&lt;li&gt;Select the &lt;strong&gt;COMMON&lt;/strong&gt; tab, fill out the form with the following config:
&lt;ol&gt;
&lt;li&gt;Enter “&amp;lt;jdbc_url&amp;gt;” (jdbc url for PostgreSQL server) in the &lt;strong&gt;jdbc url&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Enter “&amp;lt;database_username&amp;gt;“ in the &lt;strong&gt;user name&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Enter “&amp;lt;database_password&amp;gt;“ in the &lt;strong&gt;password&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Enter “&amp;lt;database_table&amp;gt;” in the &lt;strong&gt;table name&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Enter “&amp;lt;table_timestamp&amp;gt;” in the &lt;strong&gt;timestamp column name&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Change flush size from 1000 to 10 in the &lt;strong&gt;JDBC flush Size&lt;/strong&gt; field.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Select the &lt;strong&gt;CORE&lt;/strong&gt; tab, select the &lt;strong&gt;t3&lt;/strong&gt; from the &lt;strong&gt;Topics&lt;/strong&gt; dropdown.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Set up ftpsink connector:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Click the &lt;strong&gt;ftpsink&lt;/strong&gt; object in pipeline graph.&lt;/li&gt;
&lt;li&gt;Select the &lt;strong&gt;COMMON&lt;/strong&gt; tab, enter the following in the fields.
&lt;ol&gt;
&lt;li&gt;Enter “/demo/output” in the &lt;strong&gt;Output Folder&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Click the &lt;strong&gt;write header&lt;/strong&gt; checkbox, make it checked.&lt;/li&gt;
&lt;li&gt;Enter &lt;code&gt;&amp;lt;ftp_server_ip&amp;gt;&lt;/code&gt; in the &lt;strong&gt;Hostname of FTP Server&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Enter &lt;code&gt;&amp;lt;ftp_server_port&amp;gt;&lt;/code&gt; in the &lt;strong&gt;Port of FTP Server&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Enter &lt;code&gt;ftp_username&lt;/code&gt; in the &lt;strong&gt;User of FTP Server&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Enter &lt;code&gt;ftp_password&lt;/code&gt; in the &lt;strong&gt;Password of FTP Server&lt;/strong&gt; field.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Select the &lt;strong&gt;CORE&lt;/strong&gt; tab and select &lt;strong&gt;t3&lt;/strong&gt; from the &lt;strong&gt;Topics&lt;/strong&gt; dropdown.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;prepare-the-required-output-folder-on-the-ftp-server&#34;&gt;Prepare the required output folder on the FTP server&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Open a terminal, login to FTP server (or use a FTP client of your choice)&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;$ ftp `ftp_server_ip`
Name: `ftp_username`
Password: `ftp_password`
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Create the following folders.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;ftp&amp;gt; mkdir demo
ftp&amp;gt; cd demo
ftp&amp;gt; mkdir output
ftp&amp;gt; bye
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;prepare-the-required-table-and-data-on-the-postgresql-server&#34;&gt;Prepare the required table and data on the PostgreSQL server&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Check database has table and data:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Open a terminal and log into the PostgreSQL server.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;$ psql -h &amp;lt;PostgreSQL_server_ip&amp;gt; -W &amp;lt;database_name&amp;gt; -U &amp;lt;user_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;check table is exist&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;postgres=# \dt
          List of relations
 Schema |    Name     | Type  | Owner
--------+-------------+-------+-------
 public | person_data | table | ohara
 public | test_data   | table | ohara
(2 rows)
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;check table info&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;postgres=# \d person_data
                        Table &amp;quot;public.person_data&amp;quot;
  Column   |            Type             | Collation | Nullable | Default
-----------+-----------------------------+-----------+----------+---------
 index     | integer                     |           | not null |
 name      | character varying           |           |          |
 age       | integer                     |           |          |
 id        | character varying           |           |          |
 timestamp | timestamp without time zone |           |          | now()

&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;check table has data&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;postgres=# select * from person_data;
 index |  name   | age |     id     |      timestamp
-------+---------+-----+------------+---------------------
     1 | Sam     |  33 | H123378803 | 2019-03-08 18:52:00
     2 | Jay     |  25 | A159330943 | 2019-03-08 18:53:00
     3 | Leon    |  31 | J156498160 | 2019-03-08 19:52:00
     4 | Stanley |  40 | D113134484 | 2019-03-08 20:00:00
     5 | Jordan  |  21 | U141236791 | 2019-03-08 20:10:20
     6 | Kayden  |  20 | E290773637 | 2019-03-09 18:52:59
     7 | Dillon  |  28 | M225842758 | 2019-03-09 20:52:59
     8 | Ross    |  33 | F229128254 | 2019-03-09 20:15:59
     9 | Gunnar  |  50 | Q107872026 | 2019-03-09 21:00:59
    10 | Tyson   |  26 | N197744193 | 2019-03-09 21:05:59
..........
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;
&lt;a href=&#34;#how-to-create-table-and-insert-data&#34;&gt;How to create table and insert data?&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;start-all-connectors-on-the-secondpipeline-page&#34;&gt;Start all connectors on the secondpipeline page&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;On the &lt;strong&gt;secondpipeline&lt;/strong&gt; page.&lt;/li&gt;
&lt;li&gt;Click the &lt;strong&gt;Start pipeline&lt;/strong&gt; icon.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;verify-which-test-data-was-successfully-dumped-to-ftp-server&#34;&gt;Verify which test data was successfully dumped to FTP server&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Open a terminal, login to FTP server.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;$ ftp `ftp_server_ip`
Name: `ftp_username`
Password: `ftp_password`
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;list all result CSV files in &lt;strong&gt;/demo/output/wk01-t3/partition0&lt;/strong&gt; folder.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;$ ftp ls /demo/output/wk01-t3/partition0
/demo/output/wk01-t3/partition0/wk01-t3-0-000000000.csv
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;get the CSV file from ftp server to local.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;$ ftp cd /demo/output/wk01-t3/wk01
$ ftp get wk01-t3-0-000000000.csv ./wk01-t3-0-000000000.csv
$ ftp bye
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;View the content of &lt;strong&gt;wk01-t3-0-000000000.csv&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;$ cat wk01-t3-0-000000000.csv
index,name,age,id,timestamp
1,Sam,33,H123378803,2019-03-08 18:52:00.0
2,Jay,25,A159330943,2019-03-08 18:53:00.0
3,Leon,31,J156498160,2019-03-08 19:52:00.0
4,Stanley,40,D113134484,2019-03-08 20:00:00.0
5,Jordan,21,U141236791,2019-03-08 20:10:20.0
6,Kayden,20,E290773637,2019-03-09 18:52:59.0
8,Ross,33,F229128254,2019-03-09 20:15:59.0
7,Dillon,28,M225842758,2019-03-09 20:52:59.0
9,Gunnar,50,Q107872026,2019-03-09 21:00:59.0
10,Tyson,26,N197744193,2019-03-09 21:05:59.0

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;how-to-create-table-and-insert-data&#34;&gt;How to create table and insert data?&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Create table &lt;strong&gt;person_data&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;postgres=# create table person_data (
postgres=#   index INTEGER NOT NULL,
postgres=#   name character varying,
postgres=#   age INTEGER,
postgres=#   id character varying,
postgres=#   timestamp timestamp without time zone DEFAULT NOW()
postgres=# );
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;insert data into table &lt;strong&gt;person_data&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;postgres=# insert into person_data (index,name,age,id)values(1,&#39;Sam&#39;,33,&#39;H123378803&#39;),
	(2,&#39;Jay&#39;,25,&#39;A159330943&#39;),
	(3,&#39;Leon&#39;,31,&#39;J156498160&#39;),
	(4,&#39;Stanley&#39;,40,&#39;D113134484&#39;),
	(5,&#39;Jordan&#39;,21,&#39;U141236791&#39;),
	(6,&#39;Kayden&#39;,20,&#39;E290773637&#39;),
	(7,&#39;Dillon&#39;,28,&#39;M225842758&#39;),
	(8,&#39;Ross&#39;,33,&#39;F229128254&#39;),
	(9,&#39;Gunnar&#39;,50,&#39;Q107872026&#39;),
	(10,&#39;Tyson&#39;,26,&#39;N197744193&#39;);
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>JDBC to Topic to Stream to HDFS</title>
      <link>https://oharastream.github.io/en/testcases/pipeline-jdbc-topic-stream-topic-hdfs/</link>
      <pubDate>Mon, 15 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/testcases/pipeline-jdbc-topic-stream-topic-hdfs/</guid>
      <description>&lt;h2 id=&#34;k8s-mode&#34;&gt;K8S Mode&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#create-new-workspace-with-three-nodes&#34;&gt;Create new workspace with three nodes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#create-two-topics-in-the-workspace&#34;&gt;Create two topics into the workspace&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#create-new-pipeline&#34;&gt;Create new pipeline&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#add-jdbc-source-connector-topics-and-hdfs-sink-connector&#34;&gt;Add jdbc source connector, topics and a hdfs sink connector&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#link-jdbc-source---stream---hdfs-sink&#34;&gt;Link JDBC source -&amp;gt; Stream -&amp;gt; HDFS sink&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#prepare-the-required-table-and-data-on-the-postgresql-server&#34;&gt;Prepare the required table and data on the PostgreSQL server&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#start-all-components-on-the-pipeline-page&#34;&gt;Start all components on the pipeline page&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#verify-which-test-data-was-successfully-dumped-to-hdfs&#34;&gt;Verify which test data was successfully dumped to HDFS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;docker-mode&#34;&gt;Docker Mode&lt;/h2&gt;
&lt;p&gt;Will accomplish this section in 
&lt;a href=&#34;https://github.com/oharastream/ohara/issues/3696&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;another issue&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;create-new-workspace-with-three-nodes&#34;&gt;Create new workspace with three nodes&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Click &lt;em&gt;QUICK START&lt;/em&gt; button.&lt;/li&gt;
&lt;li&gt;In the &lt;strong&gt;About this workspace&lt;/strong&gt; step, enter &amp;ldquo;wk01&amp;rdquo; in the text field.&lt;/li&gt;
&lt;li&gt;Click &lt;em&gt;NEXT&lt;/em&gt; button.&lt;/li&gt;
&lt;li&gt;In the &lt;strong&gt;Select nodes&lt;/strong&gt; step, click &lt;em&gt;Select nodes&lt;/em&gt; button.&lt;/li&gt;
&lt;li&gt;Select three of available nodes from the Nodes list.&lt;/li&gt;
&lt;li&gt;Click &lt;em&gt;SAVE&lt;/em&gt; button.&lt;/li&gt;
&lt;li&gt;In the &lt;strong&gt;Upload or select worker plugins(Optional)&lt;/strong&gt; step, Click &lt;em&gt;NEXT&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;In the &lt;strong&gt;Create this workspace&lt;/strong&gt; step, make sure
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Workspace Name&lt;/strong&gt; is &amp;ldquo;wk01&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Node Names&lt;/strong&gt; has three nodes which are decided by us.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Plugins&lt;/strong&gt; is empty.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Click &lt;em&gt;FINISH&lt;/em&gt; button.&lt;/li&gt;
&lt;li&gt;Wait the creation finished, the url will be redirected to &lt;code&gt;http://{url}/wk01&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;create-two-topics-in-the-workspace&#34;&gt;Create two topics in the workspace&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Click th down arrow of workspace &amp;ldquo;wk01&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;Select &lt;em&gt;Topics&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Click &lt;em&gt;ADD TOPIC&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Enter &amp;ldquo;topic1&amp;rdquo;, &amp;ldquo;1&amp;rdquo;, &amp;ldquo;1&amp;rdquo; in order of form fields.&lt;/li&gt;
&lt;li&gt;Click &lt;em&gt;ADD TOPIC&lt;/em&gt; again.&lt;/li&gt;
&lt;li&gt;Enter &amp;ldquo;topic2&amp;rdquo;, &amp;ldquo;1&amp;rdquo;, &amp;ldquo;1&amp;rdquo; in order of form fields.&lt;/li&gt;
&lt;li&gt;Click the left arrow to go back the homepage.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;create-new-pipeline&#34;&gt;Create new pipeline&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Click the plus symbol besides the &lt;em&gt;Pipelines&lt;/em&gt; to add a pipeline.&lt;/li&gt;
&lt;li&gt;Enter &amp;ldquo;pipeline1&amp;rdquo; in the text field.&lt;/li&gt;
&lt;li&gt;Click &lt;em&gt;ADD&lt;/em&gt; button.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;add-jdbc-source-connector-topics-and-hdfs-sink-connector&#34;&gt;Add jdbc source connector, topics and hdfs sink connector&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Click &lt;em&gt;Source&lt;/em&gt; in the &lt;em&gt;Toolbox&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Drag and drop the &lt;strong&gt;JDBCSourceCOnnector&lt;/strong&gt; in the paper.&lt;/li&gt;
&lt;li&gt;Enter &amp;ldquo;jdbc&amp;rdquo; in the text field.&lt;/li&gt;
&lt;li&gt;Click &lt;em&gt;ADD&lt;/em&gt; button.&lt;/li&gt;
&lt;li&gt;Click &lt;em&gt;Topic&lt;/em&gt; in the &lt;em&gt;Toolbox&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Drag and drop the &lt;strong&gt;topic1&lt;/strong&gt; and &lt;strong&gt;topic2&lt;/strong&gt; in the paper.&lt;/li&gt;
&lt;li&gt;Click &lt;em&gt;Sink&lt;/em&gt; in the &lt;em&gt;Toolbox&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Drag and drop the &lt;strong&gt;HDFSSink&lt;/strong&gt; in the paper.&lt;/li&gt;
&lt;li&gt;Enter &amp;ldquo;hdfs&amp;rdquo; in the text field.&lt;/li&gt;
&lt;li&gt;Click &lt;em&gt;ADD&lt;/em&gt; button.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;add-stream-jar&#34;&gt;Add stream jar&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Click &lt;em&gt;Stream&lt;/em&gt; in the &lt;em&gt;Toolbox&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;Click &lt;strong&gt;Add streams&lt;/strong&gt; plus symbol in the &lt;em&gt;Toolbox&lt;/em&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Browse to the location of your jar file &lt;code&gt;ohara-it-stream.jar&lt;/code&gt;, click the file, and click Open.
&lt;blockquote&gt;
&lt;p&gt;if You don&amp;rsquo;t know how to build a stream app jar, see this 
&lt;a href=&#34;#how-to-get-ohara-it-streamjar&#34;&gt;link&lt;/a&gt; for how&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;Press F5 to fetch stream class in the &lt;em&gt;Toolbox&lt;/em&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;link-jdbc-source---stream---hdfs-sink&#34;&gt;Link JDBC source -&amp;gt; Stream -&amp;gt; HDFS sink&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Set up jdbc source connector:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;On the &lt;strong&gt;pipeline1&lt;/strong&gt; page, click the &lt;strong&gt;jdbc&lt;/strong&gt; component in the pipeline graph.&lt;/li&gt;
&lt;li&gt;Select the &lt;strong&gt;COMMON&lt;/strong&gt; tab, fill out the form with the following config:
&lt;ol&gt;
&lt;li&gt;Enter &amp;ldquo;&amp;lt;jdbc_url&amp;gt;&amp;rdquo; (jdbc url for PostgreSQL server) in the &lt;strong&gt;jdbc url&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Enter &amp;ldquo;&amp;lt;database_username&amp;gt;&amp;rdquo; in the &lt;strong&gt;user name&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Enter &amp;ldquo;&amp;lt;database_password&amp;gt;&amp;rdquo; in the &lt;strong&gt;password&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Enter &amp;ldquo;&amp;lt;database_table&amp;gt;&amp;rdquo; in the &lt;strong&gt;table name&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Enter &amp;ldquo;&amp;lt;table_timestamp&amp;gt;&amp;rdquo; in the &lt;strong&gt;timestamp column name&lt;/strong&gt; field.&lt;/li&gt;
&lt;li&gt;Change flush size from 1000 to 10 in the &lt;strong&gt;JDBC flush Size&lt;/strong&gt; field.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Select the &lt;strong&gt;CORE&lt;/strong&gt; tab, select the &lt;strong&gt;t3&lt;/strong&gt; from the &lt;strong&gt;Topics&lt;/strong&gt; dropdown.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Set up hdfs sink connector:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;On the &lt;strong&gt;pipeline1&lt;/strong&gt; page, click the &lt;strong&gt;hdfs&lt;/strong&gt; component in the pipeline graph.&lt;/li&gt;
&lt;li&gt;Select the &lt;strong&gt;COMMON&lt;/strong&gt; tab and fill out the following config:
&lt;ol&gt;
&lt;li&gt;Enter &amp;ldquo;/data&amp;rdquo; in the Output Folder field&lt;/li&gt;
&lt;li&gt;Change &lt;strong&gt;Flush Size&lt;/strong&gt; value from &amp;ldquo;1000&amp;rdquo; to &amp;ldquo;5&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Check the &lt;strong&gt;File Need Header&lt;/strong&gt; checkbox&lt;/li&gt;
&lt;li&gt;Enter &amp;ldquo;hdfs://&lt;code&gt;&amp;lt;hdfs_host&amp;gt;&lt;/code&gt;:&lt;code&gt;&amp;lt;hdfs_port&amp;gt;&lt;/code&gt;&amp;rdquo; in the &lt;strong&gt;HDSF URL&lt;/strong&gt; field&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Select the &lt;strong&gt;CORE&lt;/strong&gt; tab and choose &lt;strong&gt;t2&lt;/strong&gt; from the &lt;strong&gt;Topics&lt;/strong&gt; dropdown.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;prepare-the-required-table-and-data-on-the-postgresql-server&#34;&gt;Prepare the required table and data on the PostgreSQL server&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Check database has table and data:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Open a terminal and log into the PostgreSQL server.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;$ psql -h &amp;lt;PostgreSQL_server_ip&amp;gt; -W &amp;lt;database_name&amp;gt; -U &amp;lt;user_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;check table is exist&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;postgres=# \dt
          List of relations
 Schema |    Name     | Type  | Owner
--------+-------------+-------+-------
 public | person_data | table | ohara
 public | test_data   | table | ohara
(2 rows)
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;check table info&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;postgres=# \d person_data
                        Table &amp;quot;public.person_data&amp;quot;
  Column   |            Type             | Collation | Nullable | Default
-----------+-----------------------------+-----------+----------+---------
 index     | integer                     |           | not null |
 name      | character varying           |           |          |
 age       | integer                     |           |          |
 id        | character varying           |           |          |
 timestamp | timestamp without time zone |           |          | now()

&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;check table has data&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;postgres=# select * from person_data;
 index |  name   | age |     id     |      timestamp
-------+---------+-----+------------+---------------------
     1 | Sam     |  33 | H123378803 | 2019-03-08 18:52:00
     2 | Jay     |  25 | A159330943 | 2019-03-08 18:53:00
     3 | Leon    |  31 | J156498160 | 2019-03-08 19:52:00
     4 | Stanley |  40 | D113134484 | 2019-03-08 20:00:00
     5 | Jordan  |  21 | U141236791 | 2019-03-08 20:10:20
     6 | Kayden  |  20 | E290773637 | 2019-03-09 18:52:59
     7 | Dillon  |  28 | M225842758 | 2019-03-09 20:52:59
     8 | Ross    |  33 | F229128254 | 2019-03-09 20:15:59
     9 | Gunnar  |  50 | Q107872026 | 2019-03-09 21:00:59
    10 | Tyson   |  26 | N197744193 | 2019-03-09 21:05:59
..........
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;
&lt;a href=&#34;#how-to-create-table-and-insert-data&#34;&gt;How to create table and insert data?&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;start-all-components-on-the-pipeline-page&#34;&gt;Start all components on the pipeline page&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;On the &lt;strong&gt;pipeline1&lt;/strong&gt; page.&lt;/li&gt;
&lt;li&gt;Click the &lt;em&gt;PIPELINE&lt;/em&gt; Actions on the top tab.&lt;/li&gt;
&lt;li&gt;Click &lt;em&gt;Start all components&lt;/em&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;verify-which-test-data-was-successfully-dumped-to-hdfs&#34;&gt;Verify which test data was successfully dumped to HDFS&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Open a terminal and ssh to HDFS server.&lt;/li&gt;
&lt;li&gt;List all CSV files in &lt;strong&gt;/data/wk00-t2/partition0&lt;/strong&gt; folder:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ hdfs dfs -ls /data/wk00-t2/partition0

# You should see something similar like this in your terminal:
/data/wk00-t2/partition0/part-000000000-000000005.csv
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;View the content of &lt;strong&gt;part-000000000-000000005.csv&lt;/strong&gt;:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ hdfs dfs -cat /data/wk00-t2/partition0/part-000000000-000000005.csv

# The result should be like the following:
ID,NAME,CREATE_AT
1,ohara1,2019-03-01 00:00:01
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;how-to-create-table-and-insert-data&#34;&gt;How to create table and insert data?&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Create table &lt;strong&gt;person_data&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;postgres=# create table person_data (
postgres=#   index INTEGER NOT NULL,
postgres=#   name character varying,
postgres=#   age INTEGER,
postgres=#   id character varying,
postgres=#   timestamp timestamp without time zone DEFAULT NOW()
postgres=# );
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;insert data into table &lt;strong&gt;person_data&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;postgres=# insert into person_data (index,name,age,id)values(1,&#39;Sam&#39;,33,&#39;H123378803&#39;),
	(2,&#39;Jay&#39;,25,&#39;A159330943&#39;),
	(3,&#39;Leon&#39;,31,&#39;J156498160&#39;),
	(4,&#39;Stanley&#39;,40,&#39;D113134484&#39;),
	(5,&#39;Jordan&#39;,21,&#39;U141236791&#39;),
	(6,&#39;Kayden&#39;,20,&#39;E290773637&#39;),
	(7,&#39;Dillon&#39;,28,&#39;M225842758&#39;),
	(8,&#39;Ross&#39;,33,&#39;F229128254&#39;),
	(9,&#39;Gunnar&#39;,50,&#39;Q107872026&#39;),
	(10,&#39;Tyson&#39;,26,&#39;N197744193&#39;);
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;how-to-get-ohara-it-streamjar&#34;&gt;How to get ohara-it-stream.jar?&lt;/h4&gt;
&lt;p&gt;Open a new terminal from your machine and go to Ohara&amp;rsquo;s source folder.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd ohara/
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then &lt;code&gt;cd&lt;/code&gt; to Stream DumbStream source folder.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd ohara-it/src/main/scala/oharastream/ohara/it/stream/
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Use Vi to edit &lt;strong&gt;DumbStream.scala&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;vi DumbStream.scala
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Enter &amp;ldquo;I&amp;rdquo; key from your keyboard to activate the &amp;ldquo;INSERT&amp;rdquo; mode&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;-- INSERT --
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Overwrite DumbStream class from&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class DumbStream extends Stream {
  override def start(ostream: OStream[Row], configs: StreamSetting): Unit = {
    // do nothing but only start stream and write exactly data to output topic
    ostream.start()
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import oharastream.ohara.common.data.Row
import oharastream.ohara.common.setting.SettingDef
import oharastream.ohara.stream.config.StreamSetting
import oharastream.ohara.stream.{OStream, Stream}

class DumbStream extends Stream {

  override def config(): StreamDefinitions = StreamDefinitions
    .`with`(
      SettingDef
        .builder()
        .key(&amp;quot;filterValue&amp;quot;)
        .displayName(&amp;quot;filter value&amp;quot;)
        .documentation(&amp;quot;filter the row that contains this value&amp;quot;)
        .build())

  override def start(ostream: OStream[Row], configs: StreamDefinitions): Unit = {

    ostream
      // we filter row which the cell values contain the pre-defined &amp;quot;filterValue&amp;quot;. Note:
      // 1) configs.string(&amp;quot;filterValue&amp;quot;) will try to get the value from env and it should NOT be null
      // 2) we ignore case for the value (i.e., &amp;quot;aa&amp;quot; = &amp;quot;AA&amp;quot;)
      .filter(
      r =&amp;gt;
        r.cells()
          .stream()
          .anyMatch(c =&amp;gt; {
            c.value().toString.equalsIgnoreCase(configs.string(&amp;quot;filterValue&amp;quot;))
          }))
      .start()
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &amp;ldquo;Esc&amp;rdquo; key to leave the insert mode and enter &lt;code&gt;:wq&lt;/code&gt; to save and exit from this file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;:wq
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Build stream jar&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# Make sure you&#39;re at the project root `/ohara`, then build the jar with:
./gradlew clean :ohara-it:jar -PskipManager
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Go to stream jar folder and list the jars that you have&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd ohara-it/build/libs/ &amp;amp;&amp;amp; ls

# You should see something like this in your terminal:
ohara-it-sink.jar ohara-it-source.jar ohara-it-stream.jar
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Ohara installation</title>
      <link>https://oharastream.github.io/en/testcases/ohara-installation/</link>
      <pubDate>Mon, 15 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/testcases/ohara-installation/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#use-the-hardware-specification&#34;&gt;Use the hardware specification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#use-version-information&#34;&gt;Use version information&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#install-the-kubernetes&#34;&gt;Install the Kubernetes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#running-the-ohara-configuration-service&#34;&gt;Running the Ohara Configuration service&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#running-the-ohara-manager-service&#34;&gt;Running the Ohara Manager service&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;use-the-hardware-specification&#34;&gt;Use the hardware specification&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Preparation 5 nodes&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;K8S Master: &lt;strong&gt;1 個 Node&lt;/strong&gt;, &lt;strong&gt;CPU 4 Core&lt;/strong&gt;, &lt;strong&gt;Memory 4 GB&lt;/strong&gt;, &lt;strong&gt;Disk 100 GB&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;K8S Slave: &lt;strong&gt;3 個 Node&lt;/strong&gt;, &lt;strong&gt;CPU 4 Core&lt;/strong&gt;, &lt;strong&gt;Memory 4 GB&lt;/strong&gt;, &lt;strong&gt;Disk 100 GB&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ohara Configurator 和 Ohara Manager 在同一台 Node, &lt;strong&gt;CPU 4 Core&lt;/strong&gt;, &lt;strong&gt;Memory 4 GB&lt;/strong&gt;, &lt;strong&gt;Disk 100 GB&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;HostName and IP Information&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;k8s-m-test 10.100.0.140&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s-s-test-0 10.100.0.169&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s-s-test-1 10.100.0.167&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s-s-test-2 10.100.0.114&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ohara-configurator 10.2.0.32&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ohara-manager 10.2.0.32&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;environment&#34;&gt;Environment&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Operating System: &lt;strong&gt;CentOS 7.6.1810&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Docker: &lt;strong&gt;19.03.8&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Kubernetes: &lt;strong&gt;1.18.1&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ohara: &lt;strong&gt;${ohara version name}&lt;/strong&gt; 這裡以 0.7.0-SNAPSHOT 當做 example&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;install-kubernetes&#34;&gt;Install Kubernetes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Please refer to the 
&lt;a href=&#34;https://oharastream.github.io/en/docs/master/user_guide/#k8s&#34;&gt;document&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;需要在每台 Kubernetes 的 Slave Node Pull zookeeper, broker, connector-worker 和 stream 的 docker image，指令如下：&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ docker pull oharastream/zookeeper:${ohara version name}
$ docker pull oharastream/broker:${ohara version name}
$ docker pull oharastream/connect-worker:${ohara version name}
$ docker pull oharastream/stream:${ohara version name}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Example&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ docker pull oharastream/zookeeper:0.7.0-SNAPSHOT
$ docker pull oharastream/broker:0.7.0-SNAPSHOT
$ docker pull oharastream/connect-worker:0.7.0-SNAPSHOT
$ docker pull oharastream/stream:0.7.0-SNAPSHOT
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;running-ohara-configuration-service&#34;&gt;Running Ohara Configuration service&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;使用 ssh 登入到要啟動 Ohara Configuration Service 的 node 裡&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pull Ohara Configurator docker image&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ docker pull oharastream/configurator:${ohara version name}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ docker pull oharastream/configurator:0.7.0-SNAPSHOT
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;執行 Ohara Configurator service Docker container&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ docker run --rm \
           -p 5000:5000 \
           --add-host ${K8S_WORKER01_HOSTNAME}:${K8S_WORKER01_IP} \
           --add-host ${K8S_WORKER02_HOSTNAME}:${K8S_WORKER02_IP} \
           oharastream/configurator:0.7.0-SNAPSHOT \
           --port 5000 \
           --hostname ${Start Configurator Host Name} \
           --k8s http://${Your_K8S_Master_Host_IP}:8080/api/v1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ docker run -d --rm \
           -p 5000:5000 \
           --add-host k8s-m-test:10.100.0.140 \
           --add-host k8s-s-test-0:10.100.0.169 \
           --add-host k8s-s-test-1:10.100.0.167 \
           --add-host k8s-s-test-2:10.100.0.114 \
           oharastream/configurator:0.7.0-SNAPSHOT \
           --port 5000 \
           --hostname 10.2.0.32 \
           --k8s http://10.100.0.140:8080/api/v1
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;使用 docker 指令確認 Ohara Configurator 的 container 是否有啟動&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ docker ps -a

CONTAINER ID        IMAGE                                     COMMAND                  CREATED             STATUS              PORTS                    NAMES
d6127177b18f        oharastream/configurator:0.7.0-SNAPSHOT   &amp;quot;/tini -- configurat…&amp;quot;   About an hour ago   Up About an hour    0.0.0.0:5000-&amp;gt;5000/tcp   adoring_bartik
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;使用以下指令確認 Ohara Configurator 的 Restful API 是否能顯示版本資訊&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ curl -X GET http://${Your Configurator Node name}:5000/v0/info
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ curl -X GET http://10.2.0.32:5000/v0/info

{&amp;quot;versionInfo&amp;quot;:{&amp;quot;branch&amp;quot;:&amp;quot;master&amp;quot;,&amp;quot;revision&amp;quot;:&amp;quot;1b38aaff103c7fa84440c2bbdfc7699eafb0716f&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;0.7.0-SNAPSHOT&amp;quot;,&amp;quot;date&amp;quot;:&amp;quot;2019-08-17 17:09:26&amp;quot;,&amp;quot;user&amp;quot;:&amp;quot;root&amp;quot;},&amp;quot;mode&amp;quot;:&amp;quot;K8S&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;以上步驟不能正常執行，請使用 docker logs 指令查看 log，並且回報到 ohara GitHub 的 
&lt;a href=&#34;https://github.com/oharastream/ohara/issues&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ohara issues page&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ docker logs ${CONFIGURATOR CONTAINER ID}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;running-the-ohara-manager-service&#34;&gt;Running the Ohara Manager service&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;使用 ssh 登入到要啟動 Ohara Manager Service 的 node 裡&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pull Ohara Manager docker image&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ docker pull oharastream/manager:${ohara version name}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Example&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ docker pull oharastream/manager:0.7.0-SNAPSHOT
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;執行 Ohara Manager service Docker container&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ docker run -d --rm \
                       -p ${ohara-manager-port}:5050 \
                       oharastream/manager:${ohara version name} \
                      --port ${ohara-manager-port} \
                      --configurator http://${ohara-configurator-host}:${ohara-configurator-port}/v0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Example&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ docker run -d --rm \
                           -p 5050:5050 \
                          oharastream/manager:0.7.0-SNAPSHOT \
                          --port 5050 \
                         --configurator http://10.2.0.32:5000/v0
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;使用 docker ps 指令查看 ohara manager service 的 container 是否有正常執行&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ docker ps -a

# Output
CONTAINER ID        IMAGE                                COMMAND                  CREATED             STATUS              PORTS                    NAMES
1f1b2cfac5d8        oharastream/manager:0.7.0-SNAPSHOT   &amp;quot;/tini -- manager.sh…&amp;quot;   4 seconds ago       Up 3 seconds        0.0.0.0:5050-&amp;gt;5050/tcp   sleepy_nightingale
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;使用 docker logs 指令查看 ohara manager service container 的 log&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ docker logs ${CONTAINER ID}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Example&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ docker logs -f 1f1b2cfac5d8

# Manager&#39;s log
[HPM] Proxy created: /  -&amp;gt;  http://10.2.0.32:5000/v0
[HPM] Proxy rewrite rule created: &amp;quot;/api&amp;quot; ~&amp;gt; &amp;quot;&amp;quot;
Ohara manager is running at port: 5050
Successfully connected to the configurator: http://10.2.0.32:5000/v0
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;開啟 ohara manager 的 web 畫面，在 browser 的 URL 輸入以下網址：&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;http://10.2.0.32:5050
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;就可以看到 Ohara manager 的畫面&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Write content example</title>
      <link>https://oharastream.github.io/en/docs/master/write-content/</link>
      <pubDate>Mon, 15 Jun 2020 00:00:00 +0100</pubDate>
      <guid>https://oharastream.github.io/en/docs/master/write-content/</guid>
      <description>&lt;h2 id=&#34;shortcode&#34;&gt;Shortcode&lt;/h2&gt;
&lt;h3 id=&#34;hugo--academic&#34;&gt;Hugo &amp;amp; Academic&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34;&gt;https://sourcethemes.com/academic/docs/writing-markdown-latex/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gohugo.io/content-management/shortcodes/&#34;&gt;https://gohugo.io/content-management/shortcodes/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;custom-by-ohara&#34;&gt;Custom by Ohara&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Branch: master&lt;/li&gt;
&lt;li&gt;Version: 0.11.0-SNAPSHOT&lt;/li&gt;
&lt;li&gt;Ohara file link: 
&lt;a href=&#34;https://github.com/oharastream/ohara/blob/master/docker/backend.dockerfile&#34;&gt;backend docker file&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Ohara issue link: 
&lt;a href=&#34;https://github.com/oharastream/ohara/issues/5266

&#34;&gt;#5266&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Ohara file content:
&lt;div class=&#34;highlight&#34;&gt;&lt;div style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;
&lt;table style=&#34;border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;&#34;&gt;&lt;tr&gt;&lt;td style=&#34;vertical-align:top;padding:0;margin:0;border:0;&#34;&gt;
&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;  1
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;  2
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;  3
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;  4
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;  5
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;  6
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;  7
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;  8
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;  9
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 10
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 11
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 12
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 13
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 14
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 15
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 16
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 17
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 18
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 19
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 20
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 21
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 22
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 23
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 24
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 25
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 26
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 27
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 28
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 29
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 30
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 31
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 32
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 33
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 34
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 35
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 36
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 37
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 38
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 39
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 40
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 41
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 42
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 43
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 44
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 45
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 46
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 47
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 48
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 49
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 50
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 51
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 52
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 53
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 54
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 55
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 56
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 57
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 58
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 59
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 60
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 61
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 62
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 63
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 64
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 65
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 66
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 67
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 68
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 69
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 70
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 71
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 72
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 73
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 74
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 75
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 76
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 77
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 78
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 79
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 80
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 81
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 82
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 83
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 84
&lt;/span&gt;&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 85
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 86
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 87
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 88
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 89
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 90
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 91
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 92
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 93
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 94
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 95
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 96
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 97
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 98
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt; 99
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;100
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;101
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;102
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;103
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;104
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;105
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;106
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;107
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;108
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;109
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;110
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;111
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;112
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;113
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;114
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;115
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;116
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;117
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;118
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;119
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;120
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;121
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;122
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;123
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;124
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;125
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;126
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;127
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;128
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;129
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;130
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;131
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;132
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;133
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;134
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;135
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;136
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;137
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;138
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;139
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;140
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;141
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;142
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;143
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;144
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;145
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;146
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;147
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;148
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;149
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;150
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;151
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;152
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;153
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;154
&lt;/span&gt;&lt;span style=&#34;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f&#34;&gt;155
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td style=&#34;vertical-align:top;padding:0;margin:0;border:0;;width:100%&#34;&gt;
&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;/*
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt; * Copyright 2019 is-land
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt; *
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt; * Licensed under the Apache License, Version 2.0 (the &amp;#34;License&amp;#34;);
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt; * you may not use this file except in compliance with the License.
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt; * You may obtain a copy of the License at
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt; *
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt; *     http://www.apache.org/licenses/LICENSE-2.0
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt; *
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt; * Unless required by applicable law or agreed to in writing, software
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt; * distributed under the License is distributed on an &amp;#34;AS IS&amp;#34; BASIS,
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt; * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt; * See the License for the specific language governing permissions and
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt; * limitations under the License.
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt; */&lt;/span&gt;

&lt;span style=&#34;color:#f92672&#34;&gt;package&lt;/span&gt; oharastream.ohara.common.data&lt;span style=&#34;color:#f92672&#34;&gt;;&lt;/span&gt;

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; java.util.Iterator&lt;span style=&#34;color:#f92672&#34;&gt;;&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; java.util.List&lt;span style=&#34;color:#f92672&#34;&gt;;&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; java.util.NoSuchElementException&lt;span style=&#34;color:#f92672&#34;&gt;;&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; java.util.Objects&lt;span style=&#34;color:#f92672&#34;&gt;;&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; java.util.function.IntBinaryOperator&lt;span style=&#34;color:#f92672&#34;&gt;;&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; java.util.stream.Collectors&lt;span style=&#34;color:#f92672&#34;&gt;;&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;/**
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt; * a collection from {@link Cell}. Also, {@link Row} can carry variable tags which can be used to
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt; * add more &amp;#34;description&amp;#34; to the {@link Row}. NOTED. the default implementation from {@link Row} has
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt; * implemented the
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt; */&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;interface&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Row&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;extends&lt;/span&gt; Iterable&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;Cell&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;?&amp;gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;/** a empty row. It means no tag and cell exist in this row. */&lt;/span&gt;
  Row EMPTY &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Row&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;of&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;();&lt;/span&gt;

  &lt;span style=&#34;color:#75715e&#34;&gt;/** @return a collection from name from cells */&lt;/span&gt;
  List&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;String&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;names&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;();&lt;/span&gt;

  &lt;span style=&#34;color:#75715e&#34;&gt;/**
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;   * seek the cell by specified index
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;   *
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;   * @param index cell&amp;#39;s index
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;   * @return a cell or throw NoSuchElementException
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;   */&lt;/span&gt;
  Cell&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;?&amp;gt;&lt;/span&gt; cell&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; index&lt;span style=&#34;color:#f92672&#34;&gt;);&lt;/span&gt;

  &lt;span style=&#34;color:#75715e&#34;&gt;/**
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;   * seek the cell by specified name
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;   *
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;   * @param name cell&amp;#39;s name
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;   * @return a cell or throw NoSuchElementException
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;   */&lt;/span&gt;
  Cell&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;?&amp;gt;&lt;/span&gt; cell&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;String name&lt;span style=&#34;color:#f92672&#34;&gt;);&lt;/span&gt;

  &lt;span style=&#34;color:#75715e&#34;&gt;/** @return a immutable collection from cells */&lt;/span&gt;
  List&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;Cell&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;?&amp;gt;&amp;gt;&lt;/span&gt; cells&lt;span style=&#34;color:#f92672&#34;&gt;();&lt;/span&gt;

  &lt;span style=&#34;color:#75715e&#34;&gt;/**
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;   * the default order from cells from this method is same to {@link #cells()}
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;   *
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;   * @return an iterator over the {@link Cell} in this row in proper sequence
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;   */&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;@Override&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;default&lt;/span&gt; Iterator&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;Cell&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;?&amp;gt;&amp;gt;&lt;/span&gt; iterator&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
    List&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;Cell&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;?&amp;gt;&amp;gt;&lt;/span&gt; cells &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cells&lt;span style=&#34;color:#f92672&#34;&gt;();&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;cells &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; cells &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; List&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;of&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;();&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; cells&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;iterator&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;();&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;

  &lt;span style=&#34;color:#75715e&#34;&gt;/** @return a immutable collection from tags */&lt;/span&gt;
  List&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;String&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;tags&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;();&lt;/span&gt;

  &lt;span style=&#34;color:#75715e&#34;&gt;/** @return the number from elements in this row */&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;default&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;size&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; cells&lt;span style=&#34;color:#f92672&#34;&gt;().&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;size&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;();&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;

  &lt;span style=&#34;color:#75715e&#34;&gt;/**
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;   * Compare all cells one-by-one. Noted: the order from cells doesn&amp;#39;t impact the comparison.
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;   *
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;   * @param that another row
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;   * @param includeTags true if the tags should be considered in the comparison
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;   * @return true if both rows have same cells and tags (if includeTags is true)
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;   */&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;default&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;boolean&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;equals&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Row that&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;boolean&lt;/span&gt; includeTags&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
&lt;span style=&#34;display:block;width:100%;background-color:#3c3d38&#34;&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;cells&lt;span style=&#34;color:#f92672&#34;&gt;().&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;size&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; that&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;cells&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;().&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;size&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;())&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;false&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;includeTags &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;!&lt;/span&gt;tags&lt;span style=&#34;color:#f92672&#34;&gt;().&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;stream&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;().&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;allMatch&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;tag &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; that&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;tags&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;().&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;stream&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;().&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;anyMatch&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;tag&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;equals&lt;span style=&#34;color:#f92672&#34;&gt;)))&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;false&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;;&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; cells&lt;span style=&#34;color:#f92672&#34;&gt;().&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;stream&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;().&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;allMatch&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;cell &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; that&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;cells&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;().&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;stream&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;().&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;anyMatch&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;cell&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;equals&lt;span style=&#34;color:#f92672&#34;&gt;));&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;

  &lt;span style=&#34;color:#66d9ef&#34;&gt;static&lt;/span&gt; Row &lt;span style=&#34;color:#a6e22e&#34;&gt;of&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Cell&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;?&amp;gt;...&lt;/span&gt; cells&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; of&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;List&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;of&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(),&lt;/span&gt; cells&lt;span style=&#34;color:#f92672&#34;&gt;);&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;

  &lt;span style=&#34;color:#66d9ef&#34;&gt;static&lt;/span&gt; Row &lt;span style=&#34;color:#a6e22e&#34;&gt;of&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;List&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;String&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; tags&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt; Cell&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;?&amp;gt;...&lt;/span&gt; cells&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
    var tagsCopy &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; List&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;copyOf&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;tags&lt;span style=&#34;color:#f92672&#34;&gt;);&lt;/span&gt;
    var cellsCopy &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; List&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;of&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;cells&lt;span style=&#34;color:#f92672&#34;&gt;);&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;// check duplicate names
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; numberOfNames &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
        cellsCopy&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;stream&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;().&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;map&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Cell&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;name&lt;span style=&#34;color:#f92672&#34;&gt;).&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;collect&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Collectors&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;toUnmodifiableSet&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;()).&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;size&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;();&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;numberOfNames &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; cellsCopy&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;size&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;())&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;throw&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;new&lt;/span&gt; IllegalArgumentException&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Row can&amp;#39;t accept duplicate cell name&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;);&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;new&lt;/span&gt; Row&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;

      &lt;span style=&#34;color:#a6e22e&#34;&gt;@Override&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; List&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;String&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;names&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; cellsCopy&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;stream&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;().&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;map&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Cell&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;name&lt;span style=&#34;color:#f92672&#34;&gt;).&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;collect&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Collectors&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;toUnmodifiableList&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;());&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;

      &lt;span style=&#34;color:#a6e22e&#34;&gt;@Override&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; Cell&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;?&amp;gt;&lt;/span&gt; cell&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; index&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
        Cell&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;?&amp;gt;&lt;/span&gt; cell &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cellsCopy&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;get&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;index&lt;span style=&#34;color:#f92672&#34;&gt;);&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;cell &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;throw&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;new&lt;/span&gt; NoSuchElementException&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;no cell exists with index:&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; index&lt;span style=&#34;color:#f92672&#34;&gt;);&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; cell&lt;span style=&#34;color:#f92672&#34;&gt;;&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;

      &lt;span style=&#34;color:#a6e22e&#34;&gt;@Override&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; Cell&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;?&amp;gt;&lt;/span&gt; cell&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;String name&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; cellsCopy&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;stream&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;filter&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;c &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; c&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;().&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;equals&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;name&lt;span style=&#34;color:#f92672&#34;&gt;))&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;findFirst&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;orElseThrow&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(()&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;new&lt;/span&gt; NoSuchElementException&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;no cell exists with name:&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; name&lt;span style=&#34;color:#f92672&#34;&gt;));&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;

      &lt;span style=&#34;color:#a6e22e&#34;&gt;@Override&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; List&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;Cell&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;?&amp;gt;&amp;gt;&lt;/span&gt; cells&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; cellsCopy&lt;span style=&#34;color:#f92672&#34;&gt;;&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;

      &lt;span style=&#34;color:#a6e22e&#34;&gt;@Override&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; List&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;String&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;tags&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; tagsCopy&lt;span style=&#34;color:#f92672&#34;&gt;;&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;

      &lt;span style=&#34;color:#a6e22e&#34;&gt;@Override&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;hashCode&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
        IntBinaryOperator accumulate &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;hash&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt; current&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; hash &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; 31 &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; current&lt;span style=&#34;color:#f92672&#34;&gt;;&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; 31 &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; cells&lt;span style=&#34;color:#f92672&#34;&gt;().&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;stream&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;().&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;mapToInt&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Objects&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;hashCode&lt;span style=&#34;color:#f92672&#34;&gt;).&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;reduce&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;1&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt; accumulate&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tags&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;stream&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;().&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;mapToInt&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Objects&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;hashCode&lt;span style=&#34;color:#f92672&#34;&gt;).&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;reduce&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;1&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt; accumulate&lt;span style=&#34;color:#f92672&#34;&gt;);&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;

      &lt;span style=&#34;color:#a6e22e&#34;&gt;@Override&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;boolean&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;equals&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Object obj&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;obj &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;this&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;;&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;obj &lt;span style=&#34;color:#66d9ef&#34;&gt;instanceof&lt;/span&gt; Row&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; equals&lt;span style=&#34;color:#f92672&#34;&gt;((&lt;/span&gt;Row&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; obj&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;);&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;false&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;;&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;

      &lt;span style=&#34;color:#a6e22e&#34;&gt;@Override&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; String &lt;span style=&#34;color:#a6e22e&#34;&gt;toString&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;cells:&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; cells&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;, tags:&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tags&lt;span style=&#34;color:#f92672&#34;&gt;;&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;};&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Volume</title>
      <link>https://oharastream.github.io/en/docs/master/rest-api/volumes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://oharastream.github.io/en/docs/master/rest-api/volumes/</guid>
      <description>&lt;p&gt;Ohara volume feature is persisting data by zookeeper container and broker container.&lt;/p&gt;
&lt;p&gt;Note: Confirm your user name is ohara and UUID is 1000 in the running cluster environment.&lt;/p&gt;
&lt;p&gt;The properties which can be set by user are shown below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;name (&lt;strong&gt;String&lt;/strong&gt;) &amp;mdash; The legal character is lowercase alphanumerics characters and number.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;group (&lt;strong&gt;String&lt;/strong&gt;) &amp;mdash; The legal character is lowercase alphanumerics characters and number.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;path (&lt;strong&gt;String&lt;/strong&gt;) &amp;mdash; The data folder path in the node.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;nodeNames (&lt;strong&gt;Set[String]&lt;/strong&gt;) &amp;mdash; The nodes to create ohara volume for zookeeper and broker containers.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;tags (&lt;strong&gt;Object&lt;/strong&gt;) &amp;mdash; User-defined parameters.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;create-properties&#34;&gt;create a volume properties&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;POST /v0/volumes&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example Request&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;volume&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ],
  &amp;quot;path&amp;quot;: &amp;quot;/tmp/workspace&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1606457846012,
  &amp;quot;name&amp;quot;: &amp;quot;volume1&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;
  ],
  &amp;quot;path&amp;quot;: &amp;quot;/tmp/workspace&amp;quot;,
  &amp;quot;tags&amp;quot;: {}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;The /tmp/workspace data folder own MUST set ohara user name and UID is 1000&lt;/p&gt;
&lt;h2 id=&#34;start-a-ohara-volume&#34;&gt;start a ohara volume&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/volumes/$name/start?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Resposne
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-hint&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;You should use 
&lt;a href=&#34;#get&#34;&gt;Get volume info&lt;/a&gt; to show volume up-to-date status.&lt;/p&gt;
&lt;h2 id=&#34;get&#34;&gt;get a volume info&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;GET /v0/volumes/$name?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Get volume info by name and group. This API could fetch all volume info.
We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you don&amp;rsquo;t
specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1606457846012,
  &amp;quot;name&amp;quot;: &amp;quot;volume1&amp;quot;,
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;k8s-master&amp;quot;
  ],
  &amp;quot;path&amp;quot;: &amp;quot;/tmp/workspace1/bk12345&amp;quot;,
  &amp;quot;state&amp;quot;: &amp;quot;RUNNING&amp;quot;,
  &amp;quot;tags&amp;quot;: {}
 }
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;add-a-volume-to-a-running-volumes&#34;&gt;add a volume to a running volumes&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/volumes/$name/$nodeName?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Add a new volume for other node. We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Resposne
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;update-volume-properties-setting&#34;&gt;update volume properties setting&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/volumes/$name?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;If the required volume (group, name) doesn&amp;rsquo;t exists, we will try to use this request as POST.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Request
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;nodeNames&amp;quot;: [
    &amp;quot;node00&amp;quot;, &amp;quot;node01&amp;quot;
  ],
  &amp;quot;path&amp;quot;: &amp;quot;/tmp/workspace2&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;group&amp;quot;: &amp;quot;default&amp;quot;,
  &amp;quot;lastModified&amp;quot;: 1606465299352, 
  &amp;quot;name&amp;quot;: $name,
  &amp;quot;nodeNames&amp;quot;: [&amp;quot;node00&amp;quot;, &amp;quot;node01&amp;quot;],
  &amp;quot;path&amp;quot;: &amp;quot;/tmp/workspace2&amp;quot;,
  &amp;quot;tags&amp;quot;: {}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;stop-a-volume-info&#34;&gt;stop a volume info&lt;/h2&gt;
&lt;p&gt;Stop a running volume and remove the volume data folder (dangerous). It is disallowed to stop a volume cluster used by a running zookeeper or broker container.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;PUT /v0/volumes/$name/stop?group=$group[&amp;amp;force=true]&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We will use the default value as the query parameter &amp;ldquo;?group=&amp;rdquo; if you don&amp;rsquo;t specify it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Query Parameters&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;force (&lt;strong&gt;boolean&lt;/strong&gt;) - true if you don&amp;rsquo;t want to wait the graceful
shutdown (it can save your time but may damage your data).&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Example Response&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;delete-a-volume-properties&#34;&gt;delete a volume properties&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;DELETE /v0/volumes/$name?group=$group&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;After the stop volume, you could delete volume setting.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example Response
&lt;pre&gt;&lt;code&gt;202 Accepted
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
  &lt;/div&gt;
&lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
